{
  "statistics": {
    "detectionDate": "2025-07-15T13:05:04.093Z",
    "formats": {
      "javascript": {
        "sources": {
          "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/utils.js": {
            "lines": 182,
            "tokens": 1146,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/index.js": {
            "lines": 60,
            "tokens": 275,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/Postgresql.js": {
            "lines": 52,
            "tokens": 386,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 41,
            "duplicatedTokens": 288,
            "percentage": 78.85,
            "percentageTokens": 74.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/MySQL.js": {
            "lines": 59,
            "tokens": 493,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 192,
            "percentage": 44.07,
            "percentageTokens": 38.95,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/MSSQL.js": {
            "lines": 88,
            "tokens": 686,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 96,
            "percentage": 17.05,
            "percentageTokens": 13.99,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/helpers/untooled.js": {
            "lines": 156,
            "tokens": 1344,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/helpers/classes.js": {
            "lines": 16,
            "tokens": 154,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/query.js": {
            "lines": 101,
            "tokens": 686,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 39,
            "duplicatedTokens": 224,
            "percentage": 38.61,
            "percentageTokens": 32.65,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/list-table.js": {
            "lines": 85,
            "tokens": 630,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 165,
            "percentage": 32.94,
            "percentageTokens": 26.19,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/list-database.js": {
            "lines": 49,
            "tokens": 362,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/index.js": {
            "lines": 21,
            "tokens": 142,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/sql-agent/get-table-schema.js": {
            "lines": 98,
            "tokens": 679,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 59,
            "percentage": 11.22,
            "percentageTokens": 8.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/example/websocket/websock-multi-turn-chat.js": {
            "lines": 91,
            "tokens": 661,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 56,
            "duplicatedTokens": 397,
            "percentage": 61.54,
            "percentageTokens": 60.06,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/example/websocket/websock-branding-collab.js": {
            "lines": 100,
            "tokens": 642,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 56,
            "duplicatedTokens": 397,
            "percentage": 56,
            "percentageTokens": 61.84,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/utils/summarize.js": {
            "lines": 63,
            "tokens": 381,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/utils/dedupe.js": {
            "lines": 87,
            "tokens": 564,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/xai.js": {
            "lines": 116,
            "tokens": 783,
            "sources": 1,
            "clones": 37,
            "duplicatedLines": 1538,
            "duplicatedTokens": 9495,
            "percentage": 1325.86,
            "percentageTokens": 1212.64,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/togetherai.js": {
            "lines": 117,
            "tokens": 783,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 92,
            "duplicatedTokens": 586,
            "percentage": 78.63,
            "percentageTokens": 74.84,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/textgenwebui.js": {
            "lines": 116,
            "tokens": 776,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 87,
            "duplicatedTokens": 552,
            "percentage": 75,
            "percentageTokens": 71.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/ppio.js": {
            "lines": 115,
            "tokens": 783,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 128,
            "duplicatedTokens": 860,
            "percentage": 111.3,
            "percentageTokens": 109.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/perplexity.js": {
            "lines": 116,
            "tokens": 788,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 219,
            "duplicatedTokens": 1427,
            "percentage": 188.79,
            "percentageTokens": 181.09,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/openrouter.js": {
            "lines": 121,
            "tokens": 807,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 92,
            "duplicatedTokens": 583,
            "percentage": 76.03,
            "percentageTokens": 72.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/openai.js": {
            "lines": 159,
            "tokens": 987,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 62,
            "duplicatedTokens": 386,
            "percentage": 38.99,
            "percentageTokens": 39.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/ollama.js": {
            "lines": 117,
            "tokens": 752,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 77,
            "duplicatedTokens": 429,
            "percentage": 65.81,
            "percentageTokens": 57.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/nvidiaNim.js": {
            "lines": 117,
            "tokens": 779,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 136,
            "duplicatedTokens": 843,
            "percentage": 116.24,
            "percentageTokens": 108.22,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/novita.js": {
            "lines": 115,
            "tokens": 777,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 87,
            "duplicatedTokens": 562,
            "percentage": 75.65,
            "percentageTokens": 72.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/mistral.js": {
            "lines": 120,
            "tokens": 783,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 99,
            "duplicatedTokens": 641,
            "percentage": 82.5,
            "percentageTokens": 81.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/localai.js": {
            "lines": 118,
            "tokens": 792,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 81,
            "duplicatedTokens": 545,
            "percentage": 68.64,
            "percentageTokens": 68.81,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/lmstudio.js": {
            "lines": 125,
            "tokens": 815,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 123,
            "duplicatedTokens": 816,
            "percentage": 98.4,
            "percentageTokens": 100.12,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/litellm.js": {
            "lines": 110,
            "tokens": 797,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 81,
            "duplicatedTokens": 553,
            "percentage": 73.64,
            "percentageTokens": 69.39,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/koboldcpp.js": {
            "lines": 117,
            "tokens": 793,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 99,
            "duplicatedTokens": 622,
            "percentage": 84.62,
            "percentageTokens": 78.44,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/index.js": {
            "lines": 53,
            "tokens": 411,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/groq.js": {
            "lines": 118,
            "tokens": 783,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 98,
            "duplicatedTokens": 614,
            "percentage": 83.05,
            "percentageTokens": 78.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/genericOpenAi.js": {
            "lines": 124,
            "tokens": 851,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 106,
            "duplicatedTokens": 675,
            "percentage": 85.48,
            "percentageTokens": 79.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/gemini.js": {
            "lines": 154,
            "tokens": 1041,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 79,
            "duplicatedTokens": 480,
            "percentage": 51.3,
            "percentageTokens": 46.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/fireworksai.js": {
            "lines": 118,
            "tokens": 784,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 97,
            "duplicatedTokens": 614,
            "percentage": 82.2,
            "percentageTokens": 78.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/dellProAiStudio.js": {
            "lines": 122,
            "tokens": 795,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 92,
            "duplicatedTokens": 561,
            "percentage": 75.41,
            "percentageTokens": 70.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/deepseek.js": {
            "lines": 118,
            "tokens": 845,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 93,
            "duplicatedTokens": 589,
            "percentage": 78.81,
            "percentageTokens": 69.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/bedrock.js": {
            "lines": 172,
            "tokens": 1098,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 111,
            "duplicatedTokens": 568,
            "percentage": 64.53,
            "percentageTokens": 51.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/azure.js": {
            "lines": 108,
            "tokens": 669,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 62,
            "duplicatedTokens": 386,
            "percentage": 57.41,
            "percentageTokens": 57.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/apipie.js": {
            "lines": 116,
            "tokens": 783,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 97,
            "duplicatedTokens": 614,
            "percentage": 83.62,
            "percentageTokens": 78.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/anthropic.js": {
            "lines": 211,
            "tokens": 1454,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/providers/ai-provider.js": {
            "lines": 278,
            "tokens": 1831,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/websocket.js": {
            "lines": 156,
            "tokens": 1030,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 202,
            "percentage": 17.95,
            "percentageTokens": 19.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/web-scraping.js": {
            "lines": 113,
            "tokens": 774,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 34,
            "duplicatedTokens": 237,
            "percentage": 30.09,
            "percentageTokens": 30.62,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/web-browsing.js": {
            "lines": 660,
            "tokens": 5480,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 157,
            "duplicatedTokens": 1109,
            "percentage": 23.79,
            "percentageTokens": 20.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/summarize.js": {
            "lines": 180,
            "tokens": 1343,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 23,
            "duplicatedTokens": 151,
            "percentage": 12.78,
            "percentageTokens": 11.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/save-file-browser.js": {
            "lines": 96,
            "tokens": 650,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/rechart.js": {
            "lines": 109,
            "tokens": 723,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/memory.js": {
            "lines": 166,
            "tokens": 1302,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 127,
            "percentage": 12.05,
            "percentageTokens": 9.75,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/index.js": {
            "lines": 32,
            "tokens": 294,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/http-socket.js": {
            "lines": 82,
            "tokens": 584,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 202,
            "percentage": 34.15,
            "percentageTokens": 34.59,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/file-history.js": {
            "lines": 37,
            "tokens": 285,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/cli.js": {
            "lines": 135,
            "tokens": 967,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/plugins/chat-history.js": {
            "lines": 84,
            "tokens": 699,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/example/blog-post-coding.js": {
            "lines": 55,
            "tokens": 304,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/example/beginner-chat.js": {
            "lines": 56,
            "tokens": 418,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/perplexity/scripts/parse.mjs": {
            "lines": 49,
            "tokens": 310,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/fireworksAi/scripts/parse.mjs": {
            "lines": 46,
            "tokens": 311,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/zilliz/index.js": {
            "lines": 400,
            "tokens": 3931,
            "sources": 1,
            "clones": 32,
            "duplicatedLines": 748,
            "duplicatedTokens": 6760,
            "percentage": 187,
            "percentageTokens": 171.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/weaviate/index.js": {
            "lines": 483,
            "tokens": 4701,
            "sources": 1,
            "clones": 25,
            "duplicatedLines": 502,
            "duplicatedTokens": 4571,
            "percentage": 103.93,
            "percentageTokens": 97.23,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/qdrant/index.js": {
            "lines": 406,
            "tokens": 3877,
            "sources": 1,
            "clones": 13,
            "duplicatedLines": 251,
            "duplicatedTokens": 2356,
            "percentage": 61.82,
            "percentageTokens": 60.77,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/pinecone/index.js": {
            "lines": 293,
            "tokens": 2991,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 131,
            "duplicatedTokens": 1066,
            "percentage": 44.71,
            "percentageTokens": 35.64,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/pgvector/index.js": {
            "lines": 784,
            "tokens": 6206,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 144,
            "duplicatedTokens": 817,
            "percentage": 18.37,
            "percentageTokens": 13.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/milvus/index.js": {
            "lines": 408,
            "tokens": 3998,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 328,
            "duplicatedTokens": 3237,
            "percentage": 80.39,
            "percentageTokens": 80.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/lance/index.js": {
            "lines": 478,
            "tokens": 4068,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 171,
            "duplicatedTokens": 1563,
            "percentage": 35.77,
            "percentageTokens": 38.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/chroma/index.js": {
            "lines": 434,
            "tokens": 4239,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 156,
            "duplicatedTokens": 1405,
            "percentage": 35.94,
            "percentageTokens": 33.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorDbProviders/astra/index.js": {
            "lines": 448,
            "tokens": 4186,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 159,
            "duplicatedTokens": 1531,
            "percentage": 35.49,
            "percentageTokens": 36.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/chat/responses.js": {
            "lines": 265,
            "tokens": 1741,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 128,
            "percentage": 8.3,
            "percentageTokens": 7.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/chat/index.js": {
            "lines": 448,
            "tokens": 3019,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 142,
            "duplicatedTokens": 1084,
            "percentage": 31.7,
            "percentageTokens": 35.91,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/chat/convertTo.js": {
            "lines": 209,
            "tokens": 1659,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/chat/LLMPerformanceMonitor.js": {
            "lines": 101,
            "tokens": 534,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/admin/index.js": {
            "lines": 56,
            "tokens": 638,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/commands/reset.js": {
            "lines": 32,
            "tokens": 184,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/index.js": {
            "lines": 849,
            "tokens": 5083,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/aibitat/error.js": {
            "lines": 18,
            "tokens": 75,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agentFlows/executors/web-scraping.js": {
            "lines": 110,
            "tokens": 873,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agentFlows/executors/llm-instruction.js": {
            "lines": 43,
            "tokens": 322,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agentFlows/executors/api-call.js": {
            "lines": 60,
            "tokens": 587,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/TextToSpeech/openAiGeneric/index.js": {
            "lines": 50,
            "tokens": 347,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 17,
            "duplicatedTokens": 126,
            "percentage": 34,
            "percentageTokens": 36.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/TextToSpeech/openAi/index.js": {
            "lines": 29,
            "tokens": 238,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 17,
            "duplicatedTokens": 126,
            "percentage": 58.62,
            "percentageTokens": 52.94,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/TextToSpeech/elevenLabs/index.js": {
            "lines": 54,
            "tokens": 474,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/MCP/hypervisor/index.js": {
            "lines": 443,
            "tokens": 2942,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 23,
            "duplicatedTokens": 175,
            "percentage": 5.19,
            "percentageTokens": 5.95,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingRerankers/native/index.js": {
            "lines": 241,
            "tokens": 1684,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/voyageAi/index.js": {
            "lines": 71,
            "tokens": 489,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/openAi/index.js": {
            "lines": 97,
            "tokens": 887,
            "sources": 1,
            "clones": 16,
            "duplicatedLines": 355,
            "duplicatedTokens": 3200,
            "percentage": 365.98,
            "percentageTokens": 360.77,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/ollama/index.js": {
            "lines": 104,
            "tokens": 745,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 38,
            "duplicatedTokens": 196,
            "percentage": 36.54,
            "percentageTokens": 26.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/native/index.js": {
            "lines": 186,
            "tokens": 1584,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 73,
            "percentage": 5.38,
            "percentageTokens": 4.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/mistral/index.js": {
            "lines": 43,
            "tokens": 389,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 95,
            "percentage": 23.26,
            "percentageTokens": 24.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/localAi/index.js": {
            "lines": 89,
            "tokens": 853,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 67,
            "duplicatedTokens": 626,
            "percentage": 75.28,
            "percentageTokens": 73.39,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/lmstudio/index.js": {
            "lines": 116,
            "tokens": 1039,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 122,
            "percentage": 12.93,
            "percentageTokens": 11.74,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/liteLLM/index.js": {
            "lines": 93,
            "tokens": 870,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 65,
            "duplicatedTokens": 617,
            "percentage": 69.89,
            "percentageTokens": 70.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/genericOpenAi/index.js": {
            "lines": 117,
            "tokens": 1019,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 65,
            "duplicatedTokens": 610,
            "percentage": 55.56,
            "percentageTokens": 59.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/gemini/index.js": {
            "lines": 118,
            "tokens": 968,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 69,
            "duplicatedTokens": 620,
            "percentage": 58.47,
            "percentageTokens": 64.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/cohere/index.js": {
            "lines": 86,
            "tokens": 813,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 17,
            "duplicatedTokens": 179,
            "percentage": 19.77,
            "percentageTokens": 22.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EmbeddingEngines/azureOpenAi/index.js": {
            "lines": 109,
            "tokens": 972,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 63,
            "duplicatedTokens": 601,
            "percentage": 57.8,
            "percentageTokens": 61.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/xai/index.js": {
            "lines": 194,
            "tokens": 1518,
            "sources": 1,
            "clones": 80,
            "duplicatedLines": 1843,
            "duplicatedTokens": 13806,
            "percentage": 950,
            "percentageTokens": 909.49,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/togetherAi/index.js": {
            "lines": 257,
            "tokens": 2294,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 218,
            "duplicatedTokens": 1737,
            "percentage": 84.82,
            "percentageTokens": 75.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/textGenWebUI/index.js": {
            "lines": 190,
            "tokens": 1499,
            "sources": 1,
            "clones": 12,
            "duplicatedLines": 371,
            "duplicatedTokens": 2739,
            "percentage": 195.26,
            "percentageTokens": 182.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/ppio/index.js": {
            "lines": 266,
            "tokens": 2312,
            "sources": 1,
            "clones": 15,
            "duplicatedLines": 255,
            "duplicatedTokens": 1852,
            "percentage": 95.86,
            "percentageTokens": 80.1,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/perplexity/models.js": {
            "lines": 24,
            "tokens": 146,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/perplexity/index.js": {
            "lines": 297,
            "tokens": 2444,
            "sources": 1,
            "clones": 18,
            "duplicatedLines": 332,
            "duplicatedTokens": 2637,
            "percentage": 111.78,
            "percentageTokens": 107.9,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/openRouter/index.js": {
            "lines": 545,
            "tokens": 4138,
            "sources": 1,
            "clones": 34,
            "duplicatedLines": 735,
            "duplicatedTokens": 5485,
            "percentage": 134.86,
            "percentageTokens": 132.55,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/openAi/index.js": {
            "lines": 221,
            "tokens": 1742,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 163,
            "duplicatedTokens": 1231,
            "percentage": 73.76,
            "percentageTokens": 70.67,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/ollama/index.js": {
            "lines": 308,
            "tokens": 2360,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 159,
            "duplicatedTokens": 1156,
            "percentage": 51.62,
            "percentageTokens": 48.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/nvidiaNim/index.js": {
            "lines": 246,
            "tokens": 1886,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 260,
            "duplicatedTokens": 1722,
            "percentage": 105.69,
            "percentageTokens": 91.3,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/novita/index.js": {
            "lines": 419,
            "tokens": 3302,
            "sources": 1,
            "clones": 17,
            "duplicatedLines": 403,
            "duplicatedTokens": 2974,
            "percentage": 96.18,
            "percentageTokens": 90.07,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/modelMap/legacy.js": {
            "lines": 112,
            "tokens": 754,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/modelMap/index.js": {
            "lines": 206,
            "tokens": 1527,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/mistral/index.js": {
            "lines": 185,
            "tokens": 1449,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 223,
            "duplicatedTokens": 1509,
            "percentage": 120.54,
            "percentageTokens": 104.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/localAi/index.js": {
            "lines": 191,
            "tokens": 1493,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 275,
            "duplicatedTokens": 2219,
            "percentage": 143.98,
            "percentageTokens": 148.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/lmStudio/index.js": {
            "lines": 217,
            "tokens": 1586,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 158,
            "duplicatedTokens": 1158,
            "percentage": 72.81,
            "percentageTokens": 73.01,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/liteLLM/index.js": {
            "lines": 198,
            "tokens": 1601,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 277,
            "duplicatedTokens": 2130,
            "percentage": 139.9,
            "percentageTokens": 133.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/koboldCPP/index.js": {
            "lines": 257,
            "tokens": 2064,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 265,
            "duplicatedTokens": 1898,
            "percentage": 103.11,
            "percentageTokens": 91.96,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/huggingface/index.js": {
            "lines": 158,
            "tokens": 1308,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 89,
            "duplicatedTokens": 722,
            "percentage": 56.33,
            "percentageTokens": 55.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/groq/index.js": {
            "lines": 251,
            "tokens": 1743,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 137,
            "duplicatedTokens": 897,
            "percentage": 54.58,
            "percentageTokens": 51.46,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/genericOpenAi/index.js": {
            "lines": 364,
            "tokens": 2709,
            "sources": 1,
            "clones": 16,
            "duplicatedLines": 449,
            "duplicatedTokens": 3030,
            "percentage": 123.35,
            "percentageTokens": 111.85,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/gemini/syncStaticLists.mjs": {
            "lines": 48,
            "tokens": 381,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/gemini/index.js": {
            "lines": 448,
            "tokens": 3665,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 193,
            "duplicatedTokens": 1609,
            "percentage": 43.08,
            "percentageTokens": 43.9,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/gemini/defaultModels.js": {
            "lines": 74,
            "tokens": 366,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/fireworksAi/models.js": {
            "lines": 124,
            "tokens": 782,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/fireworksAi/index.js": {
            "lines": 157,
            "tokens": 1322,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 122,
            "duplicatedTokens": 1033,
            "percentage": 77.71,
            "percentageTokens": 78.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/dellProAiStudio/index.js": {
            "lines": 210,
            "tokens": 1617,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 143,
            "duplicatedTokens": 1086,
            "percentage": 68.1,
            "percentageTokens": 67.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/deepseek/index.js": {
            "lines": 311,
            "tokens": 2511,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 295,
            "duplicatedTokens": 2197,
            "percentage": 94.86,
            "percentageTokens": 87.5,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/cohere/index.js": {
            "lines": 256,
            "tokens": 2092,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 75,
            "duplicatedTokens": 648,
            "percentage": 29.3,
            "percentageTokens": 30.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/bedrock/utils.js": {
            "lines": 67,
            "tokens": 410,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/bedrock/index.js": {
            "lines": 751,
            "tokens": 4973,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 65,
            "duplicatedTokens": 374,
            "percentage": 8.66,
            "percentageTokens": 7.52,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/azureOpenAi/index.js": {
            "lines": 205,
            "tokens": 1638,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 127,
            "duplicatedTokens": 954,
            "percentage": 61.95,
            "percentageTokens": 58.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/apipie/index.js": {
            "lines": 379,
            "tokens": 3114,
            "sources": 1,
            "clones": 14,
            "duplicatedLines": 325,
            "duplicatedTokens": 2450,
            "percentage": 85.75,
            "percentageTokens": 78.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/AiProviders/anthropic/index.js": {
            "lines": 278,
            "tokens": 2165,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 108,
            "duplicatedTokens": 708,
            "percentage": 38.85,
            "percentageTokens": 32.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/workspaceThread/index.js": {
            "lines": 636,
            "tokens": 2954,
            "sources": 1,
            "clones": 14,
            "duplicatedLines": 254,
            "duplicatedTokens": 2057,
            "percentage": 39.94,
            "percentageTokens": 69.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/userManagement/index.js": {
            "lines": 124,
            "tokens": 581,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/system/index.js": {
            "lines": 276,
            "tokens": 1040,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/openai/index.js": {
            "lines": 343,
            "tokens": 2038,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 129,
            "percentage": 3.5,
            "percentageTokens": 6.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/openai/compatibility-test-script.cjs": {
            "lines": 79,
            "tokens": 612,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/embed/index.js": {
            "lines": 409,
            "tokens": 1388,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 158,
            "percentage": 4.89,
            "percentageTokens": 11.38,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/auth/index.js": {
            "lines": 33,
            "tokens": 106,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/admin/index.js": {
            "lines": 775,
            "tokens": 2974,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 109,
            "duplicatedTokens": 837,
            "percentage": 14.06,
            "percentageTokens": 28.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/vectorStore/resetAllVectorStores.js": {
            "lines": 59,
            "tokens": 382,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/telemetry/index.js": {
            "lines": 41,
            "tokens": 230,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 24,
            "duplicatedTokens": 108,
            "percentage": 58.54,
            "percentageTokens": 46.96,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/prisma/index.js": {
            "lines": 13,
            "tokens": 77,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/validatedRequest.js": {
            "lines": 111,
            "tokens": 834,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 176,
            "percentage": 19.82,
            "percentageTokens": 21.1,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/validWorkspace.js": {
            "lines": 52,
            "tokens": 468,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 220,
            "percentage": 42.31,
            "percentageTokens": 47.01,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/validBrowserExtensionApiKey.js": {
            "lines": 36,
            "tokens": 313,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/validApiKey.js": {
            "lines": 29,
            "tokens": 243,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/simpleSSOEnabled.js": {
            "lines": 39,
            "tokens": 200,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/multiUserProtected.js": {
            "lines": 94,
            "tokens": 621,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 24,
            "duplicatedTokens": 170,
            "percentage": 25.53,
            "percentageTokens": 27.38,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/isSupportedRepoProviders.js": {
            "lines": 12,
            "tokens": 114,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/featureFlagEnabled.js": {
            "lines": 24,
            "tokens": 197,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/embedMiddleware.js": {
            "lines": 178,
            "tokens": 1412,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 114,
            "percentage": 11.24,
            "percentageTokens": 8.07,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/communityHubDownloadsEnabled.js": {
            "lines": 77,
            "tokens": 403,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/middleware/chatHistoryViewable.js": {
            "lines": 18,
            "tokens": 73,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/logger/index.js": {
            "lines": 66,
            "tokens": 528,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/http/index.js": {
            "lines": 112,
            "tokens": 976,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/tiktoken.js": {
            "lines": 107,
            "tokens": 617,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/portAvailabilityChecker.js": {
            "lines": 46,
            "tokens": 370,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/index.js": {
            "lines": 455,
            "tokens": 3422,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/customModels.js": {
            "lines": 680,
            "tokens": 6353,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 70,
            "duplicatedTokens": 594,
            "percentage": 10.29,
            "percentageTokens": 9.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/helpers/camelcase.js": {
            "lines": 143,
            "tokens": 1214,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/files/purgeDocument.js": {
            "lines": 91,
            "tokens": 737,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/files/pfp.js": {
            "lines": 63,
            "tokens": 629,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 290,
            "percentage": 41.27,
            "percentageTokens": 46.1,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/files/multer.js": {
            "lines": 182,
            "tokens": 1440,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 162,
            "duplicatedTokens": 1144,
            "percentage": 89.01,
            "percentageTokens": 79.44,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/files/logo.js": {
            "lines": 114,
            "tokens": 966,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/files/index.js": {
            "lines": 473,
            "tokens": 3786,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/database/index.js": {
            "lines": 116,
            "tokens": 885,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 24,
            "duplicatedTokens": 108,
            "percentage": 20.69,
            "percentageTokens": 12.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/comKey/index.js": {
            "lines": 86,
            "tokens": 598,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/collectorApi/index.js": {
            "lines": 237,
            "tokens": 1786,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 136,
            "duplicatedTokens": 1128,
            "percentage": 57.38,
            "percentageTokens": 63.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/stream.js": {
            "lines": 297,
            "tokens": 2054,
            "sources": 1,
            "clones": 23,
            "duplicatedLines": 478,
            "duplicatedTokens": 3292,
            "percentage": 160.94,
            "percentageTokens": 160.27,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/openaiCompatible.js": {
            "lines": 502,
            "tokens": 3576,
            "sources": 1,
            "clones": 17,
            "duplicatedLines": 358,
            "duplicatedTokens": 2538,
            "percentage": 71.31,
            "percentageTokens": 70.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/index.js": {
            "lines": 118,
            "tokens": 822,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 128,
            "percentage": 18.64,
            "percentageTokens": 15.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/embed.js": {
            "lines": 226,
            "tokens": 1736,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 66,
            "duplicatedTokens": 467,
            "percentage": 29.2,
            "percentageTokens": 26.9,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/apiChatHandler.js": {
            "lines": 714,
            "tokens": 4691,
            "sources": 1,
            "clones": 24,
            "duplicatedLines": 520,
            "duplicatedTokens": 3561,
            "percentage": 72.83,
            "percentageTokens": 75.91,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/chats/agents.js": {
            "lines": 73,
            "tokens": 468,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/boot/index.js": {
            "lines": 160,
            "tokens": 1186,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/boot/MetaGenerator.js": {
            "lines": 233,
            "tokens": 1354,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/index.js": {
            "lines": 571,
            "tokens": 4272,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 233,
            "duplicatedTokens": 1558,
            "percentage": 40.81,
            "percentageTokens": 36.47,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/imported.js": {
            "lines": 308,
            "tokens": 2379,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 208,
            "percentage": 6.49,
            "percentageTokens": 8.74,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/ephemeral.js": {
            "lines": 496,
            "tokens": 3266,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 233,
            "duplicatedTokens": 1558,
            "percentage": 46.98,
            "percentageTokens": 47.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agents/defaults.js": {
            "lines": 94,
            "tokens": 643,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agentFlows/index.js": {
            "lines": 262,
            "tokens": 2033,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agentFlows/flowTypes.js": {
            "lines": 85,
            "tokens": 538,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/agentFlows/executor.js": {
            "lines": 235,
            "tokens": 1995,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/TextToSpeech/index.js": {
            "lines": 18,
            "tokens": 167,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/TextSplitter/index.js": {
            "lines": 187,
            "tokens": 1275,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/PasswordRecovery/index.js": {
            "lines": 103,
            "tokens": 1074,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/MCP/index.js": {
            "lines": 203,
            "tokens": 1578,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/EncryptionManager/index.js": {
            "lines": 111,
            "tokens": 941,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/DocumentManager/index.js": {
            "lines": 74,
            "tokens": 628,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/utils/BackgroundWorkers/index.js": {
            "lines": 82,
            "tokens": 665,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/jobs/helpers/index.js": {
            "lines": 31,
            "tokens": 318,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/extensions/index.js": {
            "lines": 175,
            "tokens": 1422,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 106,
            "duplicatedTokens": 760,
            "percentage": 60.57,
            "percentageTokens": 53.45,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/experimental/liveSync.js": {
            "lines": 114,
            "tokens": 948,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/experimental/index.js": {
            "lines": 12,
            "tokens": 77,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/experimental/imported-agent-plugins.js": {
            "lines": 65,
            "tokens": 558,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/embed/index.js": {
            "lines": 110,
            "tokens": 883,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 86,
            "percentage": 10.91,
            "percentageTokens": 9.74,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/api/index.js": {
            "lines": 29,
            "tokens": 275,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/swagger/utils.js": {
            "lines": 51,
            "tokens": 401,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/swagger/init.js": {
            "lines": 79,
            "tokens": 683,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/swagger/index.js": {
            "lines": 27,
            "tokens": 238,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/prisma/seed.js": {
            "lines": 31,
            "tokens": 252,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/workspacesSuggestedMessages.js": {
            "lines": 83,
            "tokens": 678,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 34,
            "duplicatedTokens": 264,
            "percentage": 40.96,
            "percentageTokens": 38.94,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/workspaceUsers.js": {
            "lines": 103,
            "tokens": 837,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 40,
            "duplicatedTokens": 324,
            "percentage": 38.83,
            "percentageTokens": 38.71,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/workspaceThread.js": {
            "lines": 144,
            "tokens": 1312,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 123,
            "duplicatedTokens": 1013,
            "percentage": 85.42,
            "percentageTokens": 77.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/workspaceChats.js": {
            "lines": 319,
            "tokens": 2710,
            "sources": 1,
            "clones": 20,
            "duplicatedLines": 259,
            "duplicatedTokens": 1827,
            "percentage": 81.19,
            "percentageTokens": 67.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/workspaceAgentInvocation.js": {
            "lines": 97,
            "tokens": 869,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 67,
            "duplicatedTokens": 542,
            "percentage": 69.07,
            "percentageTokens": 62.37,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/workspace.js": {
            "lines": 559,
            "tokens": 4327,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 60,
            "duplicatedTokens": 457,
            "percentage": 10.73,
            "percentageTokens": 10.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/welcomeMessages.js": {
            "lines": 65,
            "tokens": 539,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 23,
            "duplicatedTokens": 182,
            "percentage": 35.38,
            "percentageTokens": 33.77,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/vectors.js": {
            "lines": 79,
            "tokens": 693,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/user.js": {
            "lines": 328,
            "tokens": 2966,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 38,
            "duplicatedTokens": 199,
            "percentage": 11.59,
            "percentageTokens": 6.71,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/temporaryAuthToken.js": {
            "lines": 104,
            "tokens": 775,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/telemetry.js": {
            "lines": 146,
            "tokens": 1087,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/systemSettings.js": {
            "lines": 664,
            "tokens": 5396,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/systemPromptVariables.js": {
            "lines": 286,
            "tokens": 2315,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/slashCommandsPresets.js": {
            "lines": 117,
            "tokens": 1054,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/promptHistory.js": {
            "lines": 107,
            "tokens": 860,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 176,
            "percentage": 24.3,
            "percentageTokens": 20.47,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/passwordRecovery.js": {
            "lines": 115,
            "tokens": 1133,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/invite.js": {
            "lines": 144,
            "tokens": 1418,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 21,
            "duplicatedTokens": 189,
            "percentage": 14.58,
            "percentageTokens": 13.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/eventLogs.js": {
            "lines": 129,
            "tokens": 1229,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 98,
            "duplicatedTokens": 709,
            "percentage": 75.97,
            "percentageTokens": 57.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/embedConfig.js": {
            "lines": 239,
            "tokens": 1899,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 68,
            "duplicatedTokens": 545,
            "percentage": 28.45,
            "percentageTokens": 28.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/embedChats.js": {
            "lines": 199,
            "tokens": 1572,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 88,
            "duplicatedTokens": 757,
            "percentage": 44.22,
            "percentageTokens": 48.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/documents.js": {
            "lines": 307,
            "tokens": 2840,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 23,
            "duplicatedTokens": 191,
            "percentage": 7.49,
            "percentageTokens": 6.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/documentSyncRun.js": {
            "lines": 88,
            "tokens": 806,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 39,
            "duplicatedTokens": 259,
            "percentage": 44.32,
            "percentageTokens": 32.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/documentSyncQueue.js": {
            "lines": 255,
            "tokens": 1961,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 90,
            "duplicatedTokens": 648,
            "percentage": 35.29,
            "percentageTokens": 33.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/communityHub.js": {
            "lines": 177,
            "tokens": 1410,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/cacheData.js": {
            "lines": 69,
            "tokens": 665,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 23,
            "duplicatedTokens": 170,
            "percentage": 33.33,
            "percentageTokens": 25.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/browserExtensionApiKey.js": {
            "lines": 168,
            "tokens": 1185,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/models/apiKeys.js": {
            "lines": 96,
            "tokens": 846,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/jobs/sync-watched-documents.js": {
            "lines": 153,
            "tokens": 1524,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/workspaceThreads.js": {
            "lines": 253,
            "tokens": 2220,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 106,
            "duplicatedTokens": 762,
            "percentage": 41.9,
            "percentageTokens": 34.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/utils.js": {
            "lines": 155,
            "tokens": 1075,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/mcpServers.js": {
            "lines": 100,
            "tokens": 840,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 118,
            "percentage": 20,
            "percentageTokens": 14.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/invite.js": {
            "lines": 76,
            "tokens": 715,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/embedManagement.js": {
            "lines": 131,
            "tokens": 1313,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 31,
            "duplicatedTokens": 251,
            "percentage": 23.66,
            "percentageTokens": 19.12,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/document.js": {
            "lines": 111,
            "tokens": 1097,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/communityHub.js": {
            "lines": 186,
            "tokens": 1662,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 64,
            "duplicatedTokens": 510,
            "percentage": 34.41,
            "percentageTokens": 30.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/chat.js": {
            "lines": 213,
            "tokens": 1750,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 162,
            "duplicatedTokens": 1228,
            "percentage": 76.06,
            "percentageTokens": 70.17,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/browserExtension.js": {
            "lines": 224,
            "tokens": 2117,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 140,
            "percentage": 8.93,
            "percentageTokens": 6.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/agentWebsocket.js": {
            "lines": 61,
            "tokens": 516,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/agentFlows.js": {
            "lines": 200,
            "tokens": 1470,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/endpoints/admin.js": {
            "lines": 555,
            "tokens": 5122,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 100,
            "duplicatedTokens": 750,
            "percentage": 18.02,
            "percentageTokens": 14.64,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "server/index.js": {
            "lines": 171,
            "tokens": 1545,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/index.js": {
            "lines": 15,
            "tokens": 99,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/Unknown.jsx": {
            "lines": 0,
            "tokens": 3,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SystemPrompt.jsx": {
            "lines": 50,
            "tokens": 388,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SlashCommand.jsx": {
            "lines": 40,
            "tokens": 315,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentSkill.jsx": {
            "lines": 127,
            "tokens": 1095,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentFlow.jsx": {
            "lines": 31,
            "tokens": 296,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/DocumentSyncQueueRow/index.jsx": {
            "lines": 14,
            "tokens": 178,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/piperTTS.jsx": {
            "lines": 26,
            "tokens": 191,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/native.jsx": {
            "lines": 12,
            "tokens": 93,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/index.jsx": {
            "lines": 10,
            "tokens": 76,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/asyncTts.jsx": {
            "lines": 27,
            "tokens": 191,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/RenderMetrics/index.jsx": {
            "lines": 28,
            "tokens": 167,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/EditMessage/index.jsx": {
            "lines": 78,
            "tokens": 583,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/DeleteMessage/index.jsx": {
            "lines": 4,
            "tokens": 27,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/ActionMenu/index.jsx": {
            "lines": 23,
            "tokens": 171,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatPromptSettings/ChatPromptHistory/PromptHistoryItem/index.jsx": {
            "lines": 41,
            "tokens": 287,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/ChecklistItem/icons/SlashCommand.jsx": {
            "lines": 5,
            "tokens": 33,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/FooterCustomization/NewIconForm/index.jsx": {
            "lines": 54,
            "tokens": 384,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/systemPrompt.jsx": {
            "lines": 19,
            "tokens": 190,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/slashCommand.jsx": {
            "lines": 26,
            "tokens": 233,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/index.jsx": {
            "lines": 8,
            "tokens": 85,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/generic.jsx": {
            "lines": 31,
            "tokens": 239,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/agentSkill.jsx": {
            "lines": 26,
            "tokens": 275,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/agentFlow.jsx": {
            "lines": 22,
            "tokens": 239,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/index.jsx": {
            "lines": 3,
            "tokens": 21,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/Introduction/index.jsx": {
            "lines": 26,
            "tokens": 179,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/Completed/index.jsx": {
            "lines": 0,
            "tokens": 9,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx": {
            "lines": 62,
            "tokens": 443,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/CodeSnippetModal/index.jsx": {
            "lines": 102,
            "tokens": 468,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx": {
            "lines": 75,
            "tokens": 604,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/index.jsx": {
            "lines": 32,
            "tokens": 217,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/EditPresetModal.jsx": {
            "lines": 87,
            "tokens": 540,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/AddPresetModal.jsx": {
            "lines": 84,
            "tokens": 535,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx": {
            "lines": 60,
            "tokens": 450,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/LLMSelector/index.jsx": {
            "lines": 15,
            "tokens": 134,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx": {
            "lines": 75,
            "tokens": 556,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/index.jsx": {
            "lines": 111,
            "tokens": 715,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/WorkspaceDirectory/WorkspaceFileRow/index.jsx": {
            "lines": 206,
            "tokens": 1493,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/UploadFile/FileUploadProgress/index.jsx": {
            "lines": 51,
            "tokens": 316,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx": {
            "lines": 32,
            "tokens": 241,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx": {
            "lines": 1,
            "tokens": 19,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/FolderRow/index.jsx": {
            "lines": 50,
            "tokens": 329,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/FileRow/index.jsx": {
            "lines": 20,
            "tokens": 133,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/ContextMenu/index.jsx": {
            "lines": 6,
            "tokens": 41,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx": {
            "lines": 38,
            "tokens": 258,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx": {
            "lines": 66,
            "tokens": 447,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Obsidian/index.jsx": {
            "lines": 65,
            "tokens": 486,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx": {
            "lines": 282,
            "tokens": 2043,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 247,
            "duplicatedTokens": 1760,
            "percentage": 87.59,
            "percentageTokens": 86.15,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx": {
            "lines": 243,
            "tokens": 1745,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 247,
            "duplicatedTokens": 1760,
            "percentage": 101.65,
            "percentageTokens": 100.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx": {
            "lines": 114,
            "tokens": 812,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Confluence/index.jsx": {
            "lines": 197,
            "tokens": 1345,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx": {
            "lines": 115,
            "tokens": 891,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 30,
            "duplicatedTokens": 214,
            "percentage": 26.09,
            "percentageTokens": 24.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx": {
            "lines": 71,
            "tokens": 538,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 39,
            "duplicatedTokens": 276,
            "percentage": 54.93,
            "percentageTokens": 51.3,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatPromptSettings/ChatPromptHistory/index.jsx": {
            "lines": 62,
            "tokens": 410,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx": {
            "lines": 117,
            "tokens": 903,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 30,
            "duplicatedTokens": 214,
            "percentage": 25.64,
            "percentageTokens": 23.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/ChecklistItem/index.jsx": {
            "lines": 33,
            "tokens": 156,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/ThemePreference/index.jsx": {
            "lines": 5,
            "tokens": 70,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/SupportEmail/index.jsx": {
            "lines": 22,
            "tokens": 158,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/SpellCheck/index.jsx": {
            "lines": 2,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/ShowScrollbar/index.jsx": {
            "lines": 2,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/MessageDirection/index.jsx": {
            "lines": 42,
            "tokens": 314,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/LanguagePreference/index.jsx": {
            "lines": 5,
            "tokens": 62,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomSiteSettings/index.jsx": {
            "lines": 47,
            "tokens": 361,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomMessages/index.jsx": {
            "lines": 58,
            "tokens": 442,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomLogo/index.jsx": {
            "lines": 51,
            "tokens": 308,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomAppName/index.jsx": {
            "lines": 22,
            "tokens": 158,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/AutoSubmit/index.jsx": {
            "lines": 2,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/AutoSpeak/index.jsx": {
            "lines": 2,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/index.jsx": {
            "lines": 79,
            "tokens": 584,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/index.jsx": {
            "lines": 52,
            "tokens": 386,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Authentication/UserItems/index.jsx": {
            "lines": 61,
            "tokens": 642,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx": {
            "lines": 301,
            "tokens": 2282,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/index.jsx": {
            "lines": 84,
            "tokens": 620,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/ChatRow/index.jsx": {
            "lines": 72,
            "tokens": 509,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx": {
            "lines": 99,
            "tokens": 683,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx": {
            "lines": 71,
            "tokens": 467,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/toggle.jsx": {
            "lines": 37,
            "tokens": 349,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx": {
            "lines": 288,
            "tokens": 2095,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderItem/index.jsx": {
            "lines": 14,
            "tokens": 96,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/Imported/SkillList/index.jsx": {
            "lines": 22,
            "tokens": 198,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx": {
            "lines": 128,
            "tokens": 1023,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/WebsiteNode/index.jsx": {
            "lines": 38,
            "tokens": 302,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/WebScrapingNode/index.jsx": {
            "lines": 79,
            "tokens": 553,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/StartNode/index.jsx": {
            "lines": 29,
            "tokens": 260,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/LLMInstructionNode/index.jsx": {
            "lines": 8,
            "tokens": 51,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/FlowInfoNode/index.jsx": {
            "lines": 37,
            "tokens": 289,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/FileNode/index.jsx": {
            "lines": 41,
            "tokens": 330,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/CodeNode/index.jsx": {
            "lines": 26,
            "tokens": 210,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/ApiCallNode/index.jsx": {
            "lines": 209,
            "tokens": 1589,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/TextSizeMenu/index.jsx": {
            "lines": 115,
            "tokens": 785,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/StopGenerationButton/index.jsx": {
            "lines": 35,
            "tokens": 193,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SpeechToText/index.jsx": {
            "lines": 17,
            "tokens": 110,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/reset.jsx": {
            "lines": 3,
            "tokens": 25,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/index.jsx": {
            "lines": 49,
            "tokens": 396,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/endAgentSession.jsx": {
            "lines": 3,
            "tokens": 25,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/utils.js": {
            "lines": 61,
            "tokens": 414,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/index.jsx": {
            "lines": 46,
            "tokens": 268,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/action.jsx": {
            "lines": 30,
            "tokens": 201,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/Attachments/index.jsx": {
            "lines": 171,
            "tokens": 1121,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/AttachItem/index.jsx": {
            "lines": 18,
            "tokens": 114,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/AgentMenu/index.jsx": {
            "lines": 102,
            "tokens": 757,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/ThoughtContainer/index.jsx": {
            "lines": 61,
            "tokens": 412,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/StatusResponse/index.jsx": {
            "lines": 52,
            "tokens": 358,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/PromptReply/index.jsx": {
            "lines": 109,
            "tokens": 813,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/index.jsx": {
            "lines": 184,
            "tokens": 1255,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Citation/index.jsx": {
            "lines": 265,
            "tokens": 1991,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx": {
            "lines": 393,
            "tokens": 2773,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 176,
            "duplicatedTokens": 1158,
            "percentage": 44.78,
            "percentageTokens": 41.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/chart-utils.js": {
            "lines": 98,
            "tokens": 602,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/CustomTooltip.jsx": {
            "lines": 34,
            "tokens": 264,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/CustomCell.jsx": {
            "lines": 26,
            "tokens": 230,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/ActiveWorkspaces/ThreadContainer/ThreadItem/index.jsx": {
            "lines": 223,
            "tokens": 1511,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/WorkspaceDirectory/index.jsx": {
            "lines": 336,
            "tokens": 2542,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/UploadFile/index.jsx": {
            "lines": 29,
            "tokens": 194,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/utils.js": {
            "lines": 62,
            "tokens": 450,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/index.jsx": {
            "lines": 137,
            "tokens": 906,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/MoveToFolderIcon.jsx": {
            "lines": 5,
            "tokens": 33,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/ConnectorOption/index.jsx": {
            "lines": 5,
            "tokens": 49,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/VectorSearchMode/index.jsx": {
            "lines": 6,
            "tokens": 45,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/ResetDatabase/index.jsx": {
            "lines": 1,
            "tokens": 9,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/MaxContextSnippets/index.jsx": {
            "lines": 9,
            "tokens": 83,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/DocumentSimilarityThreshold/index.jsx": {
            "lines": 8,
            "tokens": 108,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/Members/AddMemberModal/index.jsx": {
            "lines": 73,
            "tokens": 509,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/WorkspacePfp/index.jsx": {
            "lines": 23,
            "tokens": 150,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/WorkspaceName/index.jsx": {
            "lines": 7,
            "tokens": 56,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/SuggestedChatMessages/index.jsx": {
            "lines": 68,
            "tokens": 480,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/DeleteWorkspace/index.jsx": {
            "lines": 1,
            "tokens": 9,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx": {
            "lines": 132,
            "tokens": 972,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 69,
            "duplicatedTokens": 485,
            "percentage": 52.27,
            "percentageTokens": 49.9,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatTemperatureSettings/index.jsx": {
            "lines": 8,
            "tokens": 78,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatQueryRefusalResponse/index.jsx": {
            "lines": 7,
            "tokens": 56,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatPromptSettings/index.jsx": {
            "lines": 119,
            "tokens": 886,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatModeSelection/index.jsx": {
            "lines": 18,
            "tokens": 114,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatHistorySettings/index.jsx": {
            "lines": 9,
            "tokens": 83,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx": {
            "lines": 103,
            "tokens": 811,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 39,
            "duplicatedTokens": 276,
            "percentage": 37.86,
            "percentageTokens": 34.03,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx": {
            "lines": 97,
            "tokens": 720,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 69,
            "duplicatedTokens": 485,
            "percentage": 71.13,
            "percentageTokens": 67.36,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/UserSetup/index.jsx": {
            "lines": 269,
            "tokens": 1986,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/Survey/index.jsx": {
            "lines": 150,
            "tokens": 913,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx": {
            "lines": 312,
            "tokens": 2602,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 1111,
            "duplicatedTokens": 9203,
            "percentage": 356.09,
            "percentageTokens": 353.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/Home/index.jsx": {
            "lines": 5,
            "tokens": 41,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/DataHandling/index.jsx": {
            "lines": 41,
            "tokens": 318,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/CreateWorkspace/index.jsx": {
            "lines": 26,
            "tokens": 174,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Updates/index.jsx": {
            "lines": 43,
            "tokens": 314,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Resources/index.jsx": {
            "lines": 20,
            "tokens": 153,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/QuickLinks/index.jsx": {
            "lines": 31,
            "tokens": 189,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/ExploreFeatures/index.jsx": {
            "lines": 81,
            "tokens": 416,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/index.jsx": {
            "lines": 67,
            "tokens": 492,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/constants.js": {
            "lines": 168,
            "tokens": 1107,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 42,
            "duplicatedTokens": 320,
            "percentage": 25,
            "percentageTokens": 28.91,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/Interface/index.jsx": {
            "lines": 0,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/Chat/index.jsx": {
            "lines": 0,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/Branding/index.jsx": {
            "lines": 0,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/index.jsx": {
            "lines": 0,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/index.jsx": {
            "lines": 81,
            "tokens": 631,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Authentication/useUserItems.js": {
            "lines": 40,
            "tokens": 358,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Authentication/index.jsx": {
            "lines": 86,
            "tokens": 731,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx": {
            "lines": 40,
            "tokens": 315,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/index.jsx": {
            "lines": 58,
            "tokens": 475,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx": {
            "lines": 101,
            "tokens": 752,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx": {
            "lines": 57,
            "tokens": 479,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/BrowserExtensionApiKeyRow/index.jsx": {
            "lines": 41,
            "tokens": 308,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx": {
            "lines": 69,
            "tokens": 490,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ApiKeys/ApiKeyRow/index.jsx": {
            "lines": 7,
            "tokens": 45,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Workspaces/WorkspaceRow/index.jsx": {
            "lines": 27,
            "tokens": 218,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Workspaces/NewWorkspaceModal/index.jsx": {
            "lines": 35,
            "tokens": 287,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/UserRow/index.jsx": {
            "lines": 39,
            "tokens": 269,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/NewUserModal/index.jsx": {
            "lines": 102,
            "tokens": 716,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/index.jsx": {
            "lines": 44,
            "tokens": 321,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx": {
            "lines": 68,
            "tokens": 443,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Logging/LogRow/index.jsx": {
            "lines": 82,
            "tokens": 640,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx": {
            "lines": 132,
            "tokens": 951,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Invitations/InviteRow/index.jsx": {
            "lines": 24,
            "tokens": 207,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/WebSearchSelection/index.jsx": {
            "lines": 213,
            "tokens": 1621,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/SQLConnectorSelection/index.jsx": {
            "lines": 95,
            "tokens": 686,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/SQLConnectorSelection/NewConnectionModal.jsx": {
            "lines": 194,
            "tokens": 1331,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/SQLConnectorSelection/DBConnection.jsx": {
            "lines": 14,
            "tokens": 126,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/MCPServers/index.jsx": {
            "lines": 94,
            "tokens": 660,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/MCPServers/ServerPanel.jsx": {
            "lines": 150,
            "tokens": 1308,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/GenericSkillPanel/index.jsx": {
            "lines": 15,
            "tokens": 118,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/DefaultSkillPanel/index.jsx": {
            "lines": 15,
            "tokens": 117,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/AgentFlows/index.jsx": {
            "lines": 20,
            "tokens": 154,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/AgentFlows/FlowPanel.jsx": {
            "lines": 72,
            "tokens": 640,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/HeaderMenu/index.jsx": {
            "lines": 86,
            "tokens": 601,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/BlockList/index.jsx": {
            "lines": 158,
            "tokens": 1178,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/AddBlockMenu/index.jsx": {
            "lines": 23,
            "tokens": 189,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/index.jsx": {
            "lines": 86,
            "tokens": 529,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/DnDWrapper/index.jsx": {
            "lines": 32,
            "tokens": 286,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatTooltips/index.jsx": {
            "lines": 48,
            "tokens": 243,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/index.jsx": {
            "lines": 181,
            "tokens": 1348,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/ActiveWorkspaces/ThreadContainer/index.jsx": {
            "lines": 94,
            "tokens": 686,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/index.jsx": {
            "lines": 30,
            "tokens": 187,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/index.jsx": {
            "lines": 23,
            "tokens": 182,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/chat/plugins/markdown-katex.js": {
            "lines": 277,
            "tokens": 2434,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/index.jsx": {
            "lines": 24,
            "tokens": 184,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/Members/index.jsx": {
            "lines": 45,
            "tokens": 349,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/index.jsx": {
            "lines": 19,
            "tokens": 147,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/index.jsx": {
            "lines": 36,
            "tokens": 198,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/index.jsx": {
            "lines": 65,
            "tokens": 431,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/index.jsx": {
            "lines": 75,
            "tokens": 433,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/index.jsx": {
            "lines": 0,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Invite/NewUserModal/index.jsx": {
            "lines": 33,
            "tokens": 181,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx": {
            "lines": 199,
            "tokens": 1408,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 496,
            "duplicatedTokens": 4270,
            "percentage": 249.25,
            "percentageTokens": 303.27,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx": {
            "lines": 202,
            "tokens": 1663,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 210,
            "duplicatedTokens": 1735,
            "percentage": 103.96,
            "percentageTokens": 104.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Security/index.jsx": {
            "lines": 309,
            "tokens": 2383,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx": {
            "lines": 145,
            "tokens": 1191,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx": {
            "lines": 438,
            "tokens": 3448,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 540,
            "duplicatedTokens": 4404,
            "percentage": 123.29,
            "percentageTokens": 127.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/EmbeddingTextSplitterPreference/index.jsx": {
            "lines": 96,
            "tokens": 752,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx": {
            "lines": 329,
            "tokens": 2668,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 271,
            "duplicatedTokens": 2278,
            "percentage": 82.37,
            "percentageTokens": 85.38,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/utils.js": {
            "lines": 43,
            "tokens": 198,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Chats/index.jsx": {
            "lines": 155,
            "tokens": 1128,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/index.jsx": {
            "lines": 129,
            "tokens": 868,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx": {
            "lines": 100,
            "tokens": 733,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx": {
            "lines": 191,
            "tokens": 1653,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 134,
            "duplicatedTokens": 973,
            "percentage": 70.16,
            "percentageTokens": 58.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx": {
            "lines": 165,
            "tokens": 1445,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 198,
            "duplicatedTokens": 1677,
            "percentage": 120,
            "percentageTokens": 116.06,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/AudioPreference/index.jsx": {
            "lines": 13,
            "tokens": 109,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ApiKeys/index.jsx": {
            "lines": 84,
            "tokens": 630,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Workspaces/index.jsx": {
            "lines": 91,
            "tokens": 726,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/index.jsx": {
            "lines": 114,
            "tokens": 870,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/index.jsx": {
            "lines": 75,
            "tokens": 578,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Logging/index.jsx": {
            "lines": 95,
            "tokens": 653,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Invitations/index.jsx": {
            "lines": 74,
            "tokens": 620,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/index.jsx": {
            "lines": 229,
            "tokens": 1782,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/features.js": {
            "lines": 9,
            "tokens": 53,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/skills.js": {
            "lines": 76,
            "tokens": 465,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/index.jsx": {
            "lines": 457,
            "tokens": 2982,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 176,
            "duplicatedTokens": 1116,
            "percentage": 38.51,
            "percentageTokens": 37.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/index.jsx": {
            "lines": 99,
            "tokens": 709,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/lib/CTAButton/index.jsx": {
            "lines": 2,
            "tokens": 27,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/LoadingChat/index.jsx": {
            "lines": 43,
            "tokens": 258,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/index.jsx": {
            "lines": 20,
            "tokens": 131,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/ZillizCloudOptions/index.jsx": {
            "lines": 18,
            "tokens": 125,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/WeaviateDBOptions/index.jsx": {
            "lines": 18,
            "tokens": 113,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx": {
            "lines": 16,
            "tokens": 104,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 32,
            "duplicatedTokens": 208,
            "percentage": 200,
            "percentageTokens": 200,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/QDrantDBOptions/index.jsx": {
            "lines": 18,
            "tokens": 113,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/PineconeDBOptions/index.jsx": {
            "lines": 18,
            "tokens": 132,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/PGVectorOptions/index.jsx": {
            "lines": 81,
            "tokens": 636,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/MilvusDBOptions/index.jsx": {
            "lines": 32,
            "tokens": 213,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/ChromaDBOptions/index.jsx": {
            "lines": 29,
            "tokens": 190,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/AstraDBOptions/index.jsx": {
            "lines": 21,
            "tokens": 136,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserMenu/UserButton/index.jsx": {
            "lines": 61,
            "tokens": 412,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserMenu/AccountModal/index.jsx": {
            "lines": 314,
            "tokens": 2098,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TranscriptionSelection/OpenAiOptions/index.jsx": {
            "lines": 16,
            "tokens": 142,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TranscriptionSelection/NativeTranscriptionOptions/index.jsx": {
            "lines": 65,
            "tokens": 471,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/PiperTTSOptions/index.jsx": {
            "lines": 200,
            "tokens": 1709,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/OpenAiOptions/index.jsx": {
            "lines": 18,
            "tokens": 157,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/OpenAiGenericOptions/index.jsx": {
            "lines": 43,
            "tokens": 338,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx": {
            "lines": 78,
            "tokens": 656,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/SidebarToggle/index.jsx": {
            "lines": 22,
            "tokens": 132,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/ActiveWorkspaces/index.jsx": {
            "lines": 166,
            "tokens": 1016,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/SettingsSidebar/MenuOption/index.jsx": {
            "lines": 32,
            "tokens": 139,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/Password/index.jsx": {
            "lines": 25,
            "tokens": 134,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/Password/SingleUserAuth.jsx": {
            "lines": 51,
            "tokens": 387,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/Password/MultiUserAuth.jsx": {
            "lines": 318,
            "tokens": 2542,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/index.jsx": {
            "lines": 96,
            "tokens": 676,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/DisplayRecoveryCodeModal/index.jsx": {
            "lines": 45,
            "tokens": 403,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx": {
            "lines": 81,
            "tokens": 652,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 161,
            "duplicatedTokens": 1358,
            "percentage": 198.77,
            "percentageTokens": 208.28,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/TogetherAiOptions/index.jsx": {
            "lines": 85,
            "tokens": 781,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 80,
            "duplicatedTokens": 717,
            "percentage": 94.12,
            "percentageTokens": 91.81,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/TextGenWebUIOptions/index.jsx": {
            "lines": 33,
            "tokens": 241,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/PerplexityOptions/index.jsx": {
            "lines": 63,
            "tokens": 494,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx": {
            "lines": 73,
            "tokens": 615,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx": {
            "lines": 114,
            "tokens": 929,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 117,
            "duplicatedTokens": 969,
            "percentage": 102.63,
            "percentageTokens": 104.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx": {
            "lines": 78,
            "tokens": 656,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx": {
            "lines": 268,
            "tokens": 2108,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 495,
            "duplicatedTokens": 3688,
            "percentage": 184.7,
            "percentageTokens": 174.95,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/NvidiaNimOptions/remote.jsx": {
            "lines": 85,
            "tokens": 589,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/NvidiaNimOptions/index.jsx": {
            "lines": 2,
            "tokens": 22,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx": {
            "lines": 117,
            "tokens": 981,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 117,
            "duplicatedTokens": 969,
            "percentage": 100,
            "percentageTokens": 98.78,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/MistralOptions/index.jsx": {
            "lines": 75,
            "tokens": 597,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx": {
            "lines": 178,
            "tokens": 1354,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 234,
            "duplicatedTokens": 1774,
            "percentage": 131.46,
            "percentageTokens": 131.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx": {
            "lines": 115,
            "tokens": 893,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 117,
            "duplicatedTokens": 905,
            "percentage": 101.74,
            "percentageTokens": 101.34,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx": {
            "lines": 169,
            "tokens": 1289,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 297,
            "duplicatedTokens": 2219,
            "percentage": 175.74,
            "percentageTokens": 172.15,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LLMProviderOption/index.jsx": {
            "lines": 18,
            "tokens": 157,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LLMItem/index.jsx": {
            "lines": 16,
            "tokens": 104,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 16,
            "duplicatedTokens": 104,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx": {
            "lines": 172,
            "tokens": 1279,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 156,
            "duplicatedTokens": 1158,
            "percentage": 90.7,
            "percentageTokens": 90.54,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/HuggingFaceOptions/index.jsx": {
            "lines": 35,
            "tokens": 240,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx": {
            "lines": 81,
            "tokens": 652,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 81,
            "duplicatedTokens": 641,
            "percentage": 100,
            "percentageTokens": 98.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/GenericOpenAiOptions/index.jsx": {
            "lines": 64,
            "tokens": 440,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/GeminiLLMOptions/index.jsx": {
            "lines": 108,
            "tokens": 738,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/FireworksAiOptions/index.jsx": {
            "lines": 73,
            "tokens": 606,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 74,
            "duplicatedTokens": 600,
            "percentage": 101.37,
            "percentageTokens": 99.01,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx": {
            "lines": 71,
            "tokens": 552,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/DPAISOptions/index.jsx": {
            "lines": 139,
            "tokens": 1000,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 125,
            "duplicatedTokens": 888,
            "percentage": 89.93,
            "percentageTokens": 88.8,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/CohereAiOptions/index.jsx": {
            "lines": 25,
            "tokens": 175,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AzureAiOptions/index.jsx": {
            "lines": 71,
            "tokens": 606,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AwsBedrockLLMOptions/regions.js": {
            "lines": 204,
            "tokens": 1380,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AwsBedrockLLMOptions/index.jsx": {
            "lines": 171,
            "tokens": 1249,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/ApiPieOptions/index.jsx": {
            "lines": 74,
            "tokens": 611,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 74,
            "duplicatedTokens": 600,
            "percentage": 100,
            "percentageTokens": 98.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AnthropicAiOptions/index.jsx": {
            "lines": 109,
            "tokens": 732,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ErrorBoundary/__tests__/ErrorBoundary.test.jsx": {
            "lines": 0,
            "tokens": 3,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx": {
            "lines": 31,
            "tokens": 201,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/OpenAiOptions/index.jsx": {
            "lines": 25,
            "tokens": 171,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx": {
            "lines": 151,
            "tokens": 1141,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 290,
            "duplicatedTokens": 2200,
            "percentage": 192.05,
            "percentageTokens": 192.81,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/MistralAiOptions/index.jsx": {
            "lines": 19,
            "tokens": 156,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx": {
            "lines": 158,
            "tokens": 1204,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 142,
            "duplicatedTokens": 1076,
            "percentage": 89.87,
            "percentageTokens": 89.37,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx": {
            "lines": 144,
            "tokens": 1048,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 117,
            "duplicatedTokens": 905,
            "percentage": 81.25,
            "percentageTokens": 86.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx": {
            "lines": 153,
            "tokens": 1159,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 153,
            "duplicatedTokens": 1159,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/GenericOpenAiOptions/index.jsx": {
            "lines": 93,
            "tokens": 690,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/GeminiOptions/index.jsx": {
            "lines": 21,
            "tokens": 162,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/EmbedderItem/index.jsx": {
            "lines": 16,
            "tokens": 104,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 16,
            "duplicatedTokens": 104,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/CohereOptions/index.jsx": {
            "lines": 29,
            "tokens": 187,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/AzureAiOptions/index.jsx": {
            "lines": 35,
            "tokens": 228,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/DataConnectorOption/media/index.js": {
            "lines": 19,
            "tokens": 131,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/piperTTS/worker.js": {
            "lines": 94,
            "tokens": 572,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/piperTTS/index.js": {
            "lines": 138,
            "tokens": 1183,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 32,
            "duplicatedTokens": 182,
            "percentage": 23.19,
            "percentageTokens": 15.38,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/chat/markdown.js": {
            "lines": 78,
            "tokens": 554,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/chat/index.js": {
            "lines": 200,
            "tokens": 1362,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/chat/agent.js": {
            "lines": 123,
            "tokens": 1015,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 48,
            "duplicatedTokens": 344,
            "percentage": 39.02,
            "percentageTokens": 33.89,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/index.jsx": {
            "lines": 97,
            "tokens": 820,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceChat/index.jsx": {
            "lines": 35,
            "tokens": 292,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/index.jsx": {
            "lines": 2,
            "tokens": 15,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/index.jsx": {
            "lines": 0,
            "tokens": 3,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Login/index.jsx": {
            "lines": 2,
            "tokens": 23,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Invite/index.jsx": {
            "lines": 0,
            "tokens": 3,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/experimental/liveSync.js": {
            "lines": 59,
            "tokens": 534,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 109,
            "percentage": 33.9,
            "percentageTokens": 20.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/experimental/agentPlugins.js": {
            "lines": 57,
            "tokens": 498,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 55,
            "percentage": 17.54,
            "percentageTokens": 11.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/zh_TW/common.js": {
            "lines": 928,
            "tokens": 5611,
            "sources": 1,
            "clones": 55,
            "duplicatedLines": 1574,
            "duplicatedTokens": 9807,
            "percentage": 169.61,
            "percentageTokens": 174.78,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/zh/common.js": {
            "lines": 927,
            "tokens": 5610,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 86,
            "duplicatedTokens": 546,
            "percentage": 9.28,
            "percentageTokens": 9.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/vn/common.js": {
            "lines": 925,
            "tokens": 5608,
            "sources": 1,
            "clones": 26,
            "duplicatedLines": 4362,
            "duplicatedTokens": 28108,
            "percentage": 471.57,
            "percentageTokens": 501.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/tr/common.js": {
            "lines": 926,
            "tokens": 5609,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 504,
            "duplicatedTokens": 3238,
            "percentage": 54.43,
            "percentageTokens": 57.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/ru/common.js": {
            "lines": 971,
            "tokens": 5654,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 283,
            "duplicatedTokens": 1759,
            "percentage": 29.15,
            "percentageTokens": 31.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/pt_BR/common.js": {
            "lines": 968,
            "tokens": 5651,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 64,
            "duplicatedTokens": 371,
            "percentage": 6.61,
            "percentageTokens": 6.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/nl/common.js": {
            "lines": 926,
            "tokens": 5609,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 505,
            "duplicatedTokens": 3245,
            "percentage": 54.54,
            "percentageTokens": 57.85,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/lv/common.js": {
            "lines": 987,
            "tokens": 5670,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 85,
            "duplicatedTokens": 546,
            "percentage": 8.61,
            "percentageTokens": 9.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/ko/common.js": {
            "lines": 916,
            "tokens": 5599,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 504,
            "duplicatedTokens": 3238,
            "percentage": 55.02,
            "percentageTokens": 57.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/ja/common.js": {
            "lines": 965,
            "tokens": 5648,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 229,
            "duplicatedTokens": 1396,
            "percentage": 23.73,
            "percentageTokens": 24.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/it/common.js": {
            "lines": 929,
            "tokens": 5612,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 504,
            "duplicatedTokens": 3238,
            "percentage": 54.25,
            "percentageTokens": 57.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/he/common.js": {
            "lines": 916,
            "tokens": 5599,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 504,
            "duplicatedTokens": 3238,
            "percentage": 55.02,
            "percentageTokens": 57.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/fr/common.js": {
            "lines": 931,
            "tokens": 5614,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 504,
            "duplicatedTokens": 3238,
            "percentage": 54.14,
            "percentageTokens": 57.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/fa/common.js": {
            "lines": 923,
            "tokens": 5606,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 504,
            "duplicatedTokens": 3238,
            "percentage": 54.6,
            "percentageTokens": 57.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/es/common.js": {
            "lines": 935,
            "tokens": 5618,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 430,
            "duplicatedTokens": 2775,
            "percentage": 45.99,
            "percentageTokens": 49.39,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/de/common.js": {
            "lines": 975,
            "tokens": 5658,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 260,
            "duplicatedTokens": 1624,
            "percentage": 26.67,
            "percentageTokens": 28.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/da/common.js": {
            "lines": 970,
            "tokens": 5653,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 283,
            "duplicatedTokens": 1759,
            "percentage": 29.18,
            "percentageTokens": 31.12,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/ar/common.js": {
            "lines": 931,
            "tokens": 5614,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 453,
            "duplicatedTokens": 2910,
            "percentage": 48.66,
            "percentageTokens": 51.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/contexts/TTSProvider.jsx": {
            "lines": 4,
            "tokens": 11,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/index.jsx": {
            "lines": 39,
            "tokens": 292,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserIcon/index.jsx": {
            "lines": 24,
            "tokens": 130,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/index.jsx": {
            "lines": 171,
            "tokens": 1228,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/SettingsSidebar/index.jsx": {
            "lines": 346,
            "tokens": 2263,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/PrivateRoute/index.jsx": {
            "lines": 59,
            "tokens": 476,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/NewWorkspace.jsx": {
            "lines": 38,
            "tokens": 278,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/KeyboardShortcutsHelp/index.jsx": {
            "lines": 11,
            "tokens": 93,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Footer/index.jsx": {
            "lines": 87,
            "tokens": 522,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ErrorBoundary/index.jsx": {
            "lines": 184,
            "tokens": 1135,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EditingChatBubble/index.jsx": {
            "lines": 46,
            "tokens": 327,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/DefaultChat/index.jsx": {
            "lines": 200,
            "tokens": 1633,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/DataConnectorOption/index.jsx": {
            "lines": 10,
            "tokens": 103,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ContextualSaveBar/index.jsx": {
            "lines": 12,
            "tokens": 86,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ChatBubble/index.jsx": {
            "lines": 13,
            "tokens": 92,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ChangeWarning/index.jsx": {
            "lines": 34,
            "tokens": 247,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/types.js": {
            "lines": 19,
            "tokens": 165,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/toast.js": {
            "lines": 39,
            "tokens": 295,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/session.js": {
            "lines": 15,
            "tokens": 130,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/request.js": {
            "lines": 26,
            "tokens": 211,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/paths.js": {
            "lines": 205,
            "tokens": 1539,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/numbers.js": {
            "lines": 60,
            "tokens": 704,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/keyboardShortcuts.js": {
            "lines": 146,
            "tokens": 1203,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 138,
            "percentage": 13.7,
            "percentageTokens": 11.47,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/directories.js": {
            "lines": 33,
            "tokens": 396,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/utils/constants.js": {
            "lines": 59,
            "tokens": 341,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/workspaceThread.js": {
            "lines": 214,
            "tokens": 1822,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 43,
            "duplicatedTokens": 336,
            "percentage": 20.09,
            "percentageTokens": 18.44,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/workspace.js": {
            "lines": 514,
            "tokens": 4759,
            "sources": 1,
            "clones": 12,
            "duplicatedLines": 139,
            "duplicatedTokens": 1164,
            "percentage": 27.04,
            "percentageTokens": 24.46,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/systemPromptVariable.js": {
            "lines": 106,
            "tokens": 788,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/system.js": {
            "lines": 752,
            "tokens": 7805,
            "sources": 1,
            "clones": 33,
            "duplicatedLines": 373,
            "duplicatedTokens": 3288,
            "percentage": 49.6,
            "percentageTokens": 42.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/promptHistory.js": {
            "lines": 84,
            "tokens": 569,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/mcpServers.js": {
            "lines": 76,
            "tokens": 530,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 32,
            "duplicatedTokens": 276,
            "percentage": 42.11,
            "percentageTokens": 52.08,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/invite.js": {
            "lines": 27,
            "tokens": 278,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/embed.js": {
            "lines": 80,
            "tokens": 843,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 45,
            "duplicatedTokens": 411,
            "percentage": 56.25,
            "percentageTokens": 48.75,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/document.js": {
            "lines": 38,
            "tokens": 397,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 13,
            "duplicatedTokens": 112,
            "percentage": 34.21,
            "percentageTokens": 28.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/dataConnector.js": {
            "lines": 212,
            "tokens": 2171,
            "sources": 1,
            "clones": 14,
            "duplicatedLines": 208,
            "duplicatedTokens": 2160,
            "percentage": 98.11,
            "percentageTokens": 99.49,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/communityHub.js": {
            "lines": 158,
            "tokens": 1157,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 84,
            "percentage": 6.33,
            "percentageTokens": 7.26,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/browserExtensionApiKey.js": {
            "lines": 42,
            "tokens": 410,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 187,
            "percentage": 52.38,
            "percentageTokens": 45.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/appearance.js": {
            "lines": 69,
            "tokens": 347,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/agentFlows.js": {
            "lines": 149,
            "tokens": 1007,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 62,
            "duplicatedTokens": 298,
            "percentage": 41.61,
            "percentageTokens": 29.59,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/models/admin.js": {
            "lines": 251,
            "tokens": 2428,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 81,
            "duplicatedTokens": 734,
            "percentage": 32.27,
            "percentageTokens": 30.23,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/verifyTranslations.mjs": {
            "lines": 100,
            "tokens": 858,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 73,
            "duplicatedTokens": 597,
            "percentage": 73,
            "percentageTokens": 69.58,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/resources.js": {
            "lines": 96,
            "tokens": 548,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/locales/normalizeEn.mjs": {
            "lines": 157,
            "tokens": 1214,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 73,
            "duplicatedTokens": 597,
            "percentage": 46.5,
            "percentageTokens": 49.18,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useUser.js": {
            "lines": 18,
            "tokens": 86,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useTheme.js": {
            "lines": 56,
            "tokens": 457,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useTextSize.js": {
            "lines": 38,
            "tokens": 300,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useProviderEndpointAutoDiscovery.js": {
            "lines": 122,
            "tokens": 964,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/usePrefersDarkMode.js": {
            "lines": 9,
            "tokens": 67,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useModal.js": {
            "lines": 10,
            "tokens": 97,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useLoginMode.js": {
            "lines": 18,
            "tokens": 195,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useLanguageOptions.js": {
            "lines": 20,
            "tokens": 191,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useGetProvidersModels.js": {
            "lines": 84,
            "tokens": 616,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useCopyText.js": {
            "lines": 15,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/hooks/useChatMessageAlignment.js": {
            "lines": 30,
            "tokens": 209,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Preloader.jsx": {
            "lines": 0,
            "tokens": 11,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/test-setup.js": {
            "lines": 48,
            "tokens": 346,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/i18n.js": {
            "lines": 21,
            "tokens": 139,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/ThemeContext.jsx": {
            "lines": 0,
            "tokens": 3,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/PfpContext.jsx": {
            "lines": 0,
            "tokens": 7,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/LogoContext.jsx": {
            "lines": 0,
            "tokens": 11,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/AuthContext.jsx": {
            "lines": 0,
            "tokens": 7,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/App.jsx": {
            "lines": 209,
            "tokens": 1087,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 90076,
          "tokens": 657676,
          "sources": 630,
          "clones": 621,
          "duplicatedLines": 20302,
          "duplicatedTokens": 146742,
          "percentage": 22.54,
          "percentageTokens": 22.31,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      },
      "jsx": {
        "sources": {
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/Unknown.jsx": {
            "lines": 39,
            "tokens": 382,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SystemPrompt.jsx": {
            "lines": 106,
            "tokens": 849,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 48,
            "duplicatedTokens": 310,
            "percentage": 45.28,
            "percentageTokens": 36.51,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SlashCommand.jsx": {
            "lines": 81,
            "tokens": 638,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 25,
            "duplicatedTokens": 166,
            "percentage": 30.86,
            "percentageTokens": 26.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentSkill.jsx": {
            "lines": 190,
            "tokens": 1580,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 98,
            "percentage": 7.89,
            "percentageTokens": 6.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentFlow.jsx": {
            "lines": 80,
            "tokens": 767,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 190,
            "percentage": 35,
            "percentageTokens": 24.77,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/DocumentSyncQueueRow/index.jsx": {
            "lines": 44,
            "tokens": 397,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/piperTTS.jsx": {
            "lines": 85,
            "tokens": 685,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 77,
            "duplicatedTokens": 609,
            "percentage": 90.59,
            "percentageTokens": 88.91,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/native.jsx": {
            "lines": 55,
            "tokens": 434,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 49,
            "duplicatedTokens": 320,
            "percentage": 89.09,
            "percentageTokens": 73.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/index.jsx": {
            "lines": 26,
            "tokens": 223,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/asyncTts.jsx": {
            "lines": 92,
            "tokens": 762,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 63,
            "duplicatedTokens": 426,
            "percentage": 68.48,
            "percentageTokens": 55.91,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/RenderMetrics/index.jsx": {
            "lines": 118,
            "tokens": 717,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/EditMessage/index.jsx": {
            "lines": 129,
            "tokens": 1018,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/DeleteMessage/index.jsx": {
            "lines": 58,
            "tokens": 483,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/ActionMenu/index.jsx": {
            "lines": 72,
            "tokens": 618,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 120,
            "percentage": 20.83,
            "percentageTokens": 19.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatPromptSettings/ChatPromptHistory/PromptHistoryItem/index.jsx": {
            "lines": 122,
            "tokens": 942,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/ChecklistItem/icons/SlashCommand.jsx": {
            "lines": 28,
            "tokens": 150,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/FooterCustomization/NewIconForm/index.jsx": {
            "lines": 117,
            "tokens": 942,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/systemPrompt.jsx": {
            "lines": 38,
            "tokens": 306,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 65,
            "duplicatedTokens": 479,
            "percentage": 171.05,
            "percentageTokens": 156.54,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/slashCommand.jsx": {
            "lines": 45,
            "tokens": 349,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 35,
            "duplicatedTokens": 267,
            "percentage": 77.78,
            "percentageTokens": 76.5,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/index.jsx": {
            "lines": 20,
            "tokens": 182,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/generic.jsx": {
            "lines": 45,
            "tokens": 338,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/agentSkill.jsx": {
            "lines": 45,
            "tokens": 391,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 30,
            "duplicatedTokens": 212,
            "percentage": 66.67,
            "percentageTokens": 54.22,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/agentFlow.jsx": {
            "lines": 39,
            "tokens": 354,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/index.jsx": {
            "lines": 86,
            "tokens": 766,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/Introduction/index.jsx": {
            "lines": 76,
            "tokens": 766,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/Completed/index.jsx": {
            "lines": 46,
            "tokens": 406,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx": {
            "lines": 122,
            "tokens": 897,
            "sources": 1,
            "clones": 19,
            "duplicatedLines": 293,
            "duplicatedTokens": 1919,
            "percentage": 240.16,
            "percentageTokens": 213.94,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/CodeSnippetModal/index.jsx": {
            "lines": 126,
            "tokens": 666,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 82,
            "percentage": 9.52,
            "percentageTokens": 12.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx": {
            "lines": 94,
            "tokens": 742,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 89,
            "duplicatedTokens": 518,
            "percentage": 94.68,
            "percentageTokens": 69.81,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/icons/SlashCommandIcon.jsx": {
            "lines": 28,
            "tokens": 147,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/index.jsx": {
            "lines": 155,
            "tokens": 1143,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/EditPresetModal.jsx": {
            "lines": 155,
            "tokens": 1053,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 27,
            "duplicatedTokens": 138,
            "percentage": 17.42,
            "percentageTokens": 13.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/AddPresetModal.jsx": {
            "lines": 131,
            "tokens": 935,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 68,
            "duplicatedTokens": 420,
            "percentage": 51.91,
            "percentageTokens": 44.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx": {
            "lines": 109,
            "tokens": 824,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 72,
            "duplicatedTokens": 540,
            "percentage": 66.06,
            "percentageTokens": 65.53,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/LLMSelector/index.jsx": {
            "lines": 42,
            "tokens": 299,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx": {
            "lines": 120,
            "tokens": 840,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 183,
            "duplicatedTokens": 1267,
            "percentage": 152.5,
            "percentageTokens": 150.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/index.jsx": {
            "lines": 153,
            "tokens": 1043,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/WorkspaceDirectory/WorkspaceFileRow/index.jsx": {
            "lines": 270,
            "tokens": 1925,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/UploadFile/FileUploadProgress/index.jsx": {
            "lines": 151,
            "tokens": 1160,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 36,
            "duplicatedTokens": 240,
            "percentage": 23.84,
            "percentageTokens": 20.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx": {
            "lines": 91,
            "tokens": 679,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 67,
            "duplicatedTokens": 416,
            "percentage": 73.63,
            "percentageTokens": 61.27,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx": {
            "lines": 24,
            "tokens": 177,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/FolderRow/index.jsx": {
            "lines": 81,
            "tokens": 521,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/FileRow/index.jsx": {
            "lines": 53,
            "tokens": 363,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/ContextMenu/index.jsx": {
            "lines": 79,
            "tokens": 577,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx": {
            "lines": 102,
            "tokens": 778,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 162,
            "duplicatedTokens": 1232,
            "percentage": 158.82,
            "percentageTokens": 158.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx": {
            "lines": 135,
            "tokens": 1002,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 85,
            "duplicatedTokens": 707,
            "percentage": 62.96,
            "percentageTokens": 70.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Obsidian/index.jsx": {
            "lines": 175,
            "tokens": 1382,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 138,
            "percentage": 8.57,
            "percentageTokens": 9.99,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx": {
            "lines": 359,
            "tokens": 2756,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 204,
            "duplicatedTokens": 1524,
            "percentage": 56.82,
            "percentageTokens": 55.3,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx": {
            "lines": 319,
            "tokens": 2435,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 206,
            "duplicatedTokens": 1555,
            "percentage": 64.58,
            "percentageTokens": 63.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx": {
            "lines": 190,
            "tokens": 1366,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 92,
            "duplicatedTokens": 701,
            "percentage": 48.42,
            "percentageTokens": 51.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Confluence/index.jsx": {
            "lines": 271,
            "tokens": 1965,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 46,
            "duplicatedTokens": 353,
            "percentage": 16.97,
            "percentageTokens": 17.96,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx": {
            "lines": 186,
            "tokens": 1379,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 226,
            "duplicatedTokens": 1724,
            "percentage": 121.51,
            "percentageTokens": 125.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx": {
            "lines": 112,
            "tokens": 810,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 87,
            "duplicatedTokens": 641,
            "percentage": 77.68,
            "percentageTokens": 79.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatPromptSettings/ChatPromptHistory/index.jsx": {
            "lines": 116,
            "tokens": 862,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx": {
            "lines": 188,
            "tokens": 1400,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 164,
            "duplicatedTokens": 1234,
            "percentage": 87.23,
            "percentageTokens": 88.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/ChecklistItem/index.jsx": {
            "lines": 81,
            "tokens": 583,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/ThemePreference/index.jsx": {
            "lines": 31,
            "tokens": 266,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/SupportEmail/index.jsx": {
            "lines": 98,
            "tokens": 795,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 36,
            "duplicatedTokens": 227,
            "percentage": 36.73,
            "percentageTokens": 28.55,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/SpellCheck/index.jsx": {
            "lines": 50,
            "tokens": 401,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 39,
            "duplicatedTokens": 213,
            "percentage": 78,
            "percentageTokens": 53.12,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/ShowScrollbar/index.jsx": {
            "lines": 56,
            "tokens": 457,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 13,
            "duplicatedTokens": 71,
            "percentage": 23.21,
            "percentageTokens": 15.54,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/MessageDirection/index.jsx": {
            "lines": 69,
            "tokens": 521,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/LanguagePreference/index.jsx": {
            "lines": 39,
            "tokens": 286,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/FooterCustomization/index.jsx": {
            "lines": 81,
            "tokens": 785,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomSiteSettings/index.jsx": {
            "lines": 118,
            "tokens": 861,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomMessages/index.jsx": {
            "lines": 139,
            "tokens": 1107,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomLogo/index.jsx": {
            "lines": 149,
            "tokens": 1144,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/CustomAppName/index.jsx": {
            "lines": 103,
            "tokens": 845,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 21,
            "duplicatedTokens": 110,
            "percentage": 20.39,
            "percentageTokens": 13.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/AutoSubmit/index.jsx": {
            "lines": 56,
            "tokens": 462,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 13,
            "duplicatedTokens": 71,
            "percentage": 23.21,
            "percentageTokens": 15.37,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/components/AutoSpeak/index.jsx": {
            "lines": 59,
            "tokens": 467,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 13,
            "duplicatedTokens": 71,
            "percentage": 22.03,
            "percentageTokens": 15.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/index.jsx": {
            "lines": 135,
            "tokens": 1117,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 42,
            "duplicatedTokens": 236,
            "percentage": 31.11,
            "percentageTokens": 21.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/index.jsx": {
            "lines": 77,
            "tokens": 575,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Authentication/UserItems/index.jsx": {
            "lines": 103,
            "tokens": 1020,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx": {
            "lines": 357,
            "tokens": 2831,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 116,
            "duplicatedTokens": 750,
            "percentage": 32.49,
            "percentageTokens": 26.49,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/index.jsx": {
            "lines": 160,
            "tokens": 1260,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 54,
            "percentage": 6.25,
            "percentageTokens": 4.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/ChatRow/index.jsx": {
            "lines": 180,
            "tokens": 1302,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 61,
            "duplicatedTokens": 420,
            "percentage": 33.89,
            "percentageTokens": 32.26,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx": {
            "lines": 172,
            "tokens": 1331,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 122,
            "duplicatedTokens": 798,
            "percentage": 70.93,
            "percentageTokens": 59.95,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx": {
            "lines": 133,
            "tokens": 967,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 110,
            "duplicatedTokens": 699,
            "percentage": 82.71,
            "percentageTokens": 72.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/toggle.jsx": {
            "lines": 89,
            "tokens": 728,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx": {
            "lines": 329,
            "tokens": 2367,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 80,
            "duplicatedTokens": 544,
            "percentage": 24.32,
            "percentageTokens": 22.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderItem/index.jsx": {
            "lines": 27,
            "tokens": 227,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 18,
            "duplicatedTokens": 100,
            "percentage": 66.67,
            "percentageTokens": 44.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/Imported/SkillList/index.jsx": {
            "lines": 60,
            "tokens": 435,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 130,
            "percentage": 43.33,
            "percentageTokens": 29.89,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx": {
            "lines": 251,
            "tokens": 2005,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 100,
            "duplicatedTokens": 789,
            "percentage": 39.84,
            "percentageTokens": 39.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/WebsiteNode/index.jsx": {
            "lines": 68,
            "tokens": 482,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 32,
            "duplicatedTokens": 183,
            "percentage": 47.06,
            "percentageTokens": 37.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/WebScrapingNode/index.jsx": {
            "lines": 117,
            "tokens": 793,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 88,
            "percentage": 12.82,
            "percentageTokens": 11.1,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/StartNode/index.jsx": {
            "lines": 72,
            "tokens": 620,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/LLMInstructionNode/index.jsx": {
            "lines": 41,
            "tokens": 236,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 88,
            "percentage": 36.59,
            "percentageTokens": 37.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/FlowInfoNode/index.jsx": {
            "lines": 65,
            "tokens": 508,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/FinishNode/index.jsx": {
            "lines": 10,
            "tokens": 84,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/FileNode/index.jsx": {
            "lines": 72,
            "tokens": 506,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 14,
            "duplicatedTokens": 82,
            "percentage": 19.44,
            "percentageTokens": 16.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/CodeNode/index.jsx": {
            "lines": 56,
            "tokens": 382,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 18,
            "duplicatedTokens": 101,
            "percentage": 32.14,
            "percentageTokens": 26.44,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/nodes/ApiCallNode/index.jsx": {
            "lines": 293,
            "tokens": 2311,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/TextSizeMenu/index.jsx": {
            "lines": 140,
            "tokens": 982,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 109,
            "percentage": 7.86,
            "percentageTokens": 11.1,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/StopGenerationButton/index.jsx": {
            "lines": 53,
            "tokens": 299,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SpeechToText/index.jsx": {
            "lines": 129,
            "tokens": 874,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 78,
            "percentage": 7.75,
            "percentageTokens": 8.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/reset.jsx": {
            "lines": 27,
            "tokens": 209,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/index.jsx": {
            "lines": 75,
            "tokens": 604,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/endAgentSession.jsx": {
            "lines": 23,
            "tokens": 175,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/index.jsx": {
            "lines": 151,
            "tokens": 1213,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/action.jsx": {
            "lines": 131,
            "tokens": 947,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/Attachments/index.jsx": {
            "lines": 234,
            "tokens": 1578,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 62,
            "duplicatedTokens": 350,
            "percentage": 26.5,
            "percentageTokens": 22.18,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/AttachItem/index.jsx": {
            "lines": 43,
            "tokens": 280,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/AgentMenu/index.jsx": {
            "lines": 137,
            "tokens": 1048,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 109,
            "percentage": 8.03,
            "percentageTokens": 10.4,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/ThoughtContainer/index.jsx": {
            "lines": 161,
            "tokens": 1218,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/StatusResponse/index.jsx": {
            "lines": 104,
            "tokens": 736,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/PromptReply/index.jsx": {
            "lines": 144,
            "tokens": 1042,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 65,
            "percentage": 8.33,
            "percentageTokens": 6.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/index.jsx": {
            "lines": 247,
            "tokens": 1759,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 65,
            "percentage": 4.86,
            "percentageTokens": 3.7,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Citation/index.jsx": {
            "lines": 331,
            "tokens": 2588,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 13,
            "duplicatedTokens": 85,
            "percentage": 3.93,
            "percentageTokens": 3.28,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx": {
            "lines": 487,
            "tokens": 3527,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 178,
            "duplicatedTokens": 1242,
            "percentage": 36.55,
            "percentageTokens": 35.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/CustomTooltip.jsx": {
            "lines": 89,
            "tokens": 804,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/CustomCell.jsx": {
            "lines": 50,
            "tokens": 355,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/ActiveWorkspaces/ThreadContainer/ThreadItem/index.jsx": {
            "lines": 268,
            "tokens": 1832,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/WorkspaceDirectory/index.jsx": {
            "lines": 470,
            "tokens": 3653,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 152,
            "percentage": 5.53,
            "percentageTokens": 4.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/UploadFile/index.jsx": {
            "lines": 160,
            "tokens": 1283,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/index.jsx": {
            "lines": 377,
            "tokens": 2898,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/MoveToFolderIcon.jsx": {
            "lines": 44,
            "tokens": 230,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/ConnectorOption/index.jsx": {
            "lines": 25,
            "tokens": 178,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/VectorSearchMode/index.jsx": {
            "lines": 51,
            "tokens": 359,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/VectorDBIdentifier/index.jsx": {
            "lines": 12,
            "tokens": 122,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/VectorCount/index.jsx": {
            "lines": 38,
            "tokens": 339,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/ResetDatabase/index.jsx": {
            "lines": 48,
            "tokens": 337,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/MaxContextSnippets/index.jsx": {
            "lines": 33,
            "tokens": 264,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/DocumentSimilarityThreshold/index.jsx": {
            "lines": 32,
            "tokens": 279,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/Members/WorkspaceMemberRow/index.jsx": {
            "lines": 15,
            "tokens": 136,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/Members/AddMemberModal/index.jsx": {
            "lines": 163,
            "tokens": 1262,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/WorkspacePfp/index.jsx": {
            "lines": 97,
            "tokens": 782,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/WorkspaceName/index.jsx": {
            "lines": 29,
            "tokens": 217,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/SuggestedChatMessages/index.jsx": {
            "lines": 195,
            "tokens": 1617,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/DeleteWorkspace/index.jsx": {
            "lines": 51,
            "tokens": 438,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx": {
            "lines": 223,
            "tokens": 1743,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 117,
            "duplicatedTokens": 889,
            "percentage": 52.47,
            "percentageTokens": 51,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatTemperatureSettings/index.jsx": {
            "lines": 48,
            "tokens": 365,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatQueryRefusalResponse/index.jsx": {
            "lines": 32,
            "tokens": 261,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatPromptSettings/index.jsx": {
            "lines": 202,
            "tokens": 1571,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatModeSelection/index.jsx": {
            "lines": 60,
            "tokens": 515,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/ChatHistorySettings/index.jsx": {
            "lines": 32,
            "tokens": 267,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx": {
            "lines": 170,
            "tokens": 1199,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 54,
            "duplicatedTokens": 397,
            "percentage": 31.76,
            "percentageTokens": 33.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx": {
            "lines": 213,
            "tokens": 1530,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 102,
            "duplicatedTokens": 776,
            "percentage": 47.89,
            "percentageTokens": 50.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/UserSetup/index.jsx": {
            "lines": 341,
            "tokens": 2684,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/Survey/index.jsx": {
            "lines": 272,
            "tokens": 1939,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 100,
            "duplicatedTokens": 574,
            "percentage": 36.76,
            "percentageTokens": 29.6,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx": {
            "lines": 390,
            "tokens": 3261,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 39,
            "duplicatedTokens": 319,
            "percentage": 10,
            "percentageTokens": 9.78,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/Home/index.jsx": {
            "lines": 62,
            "tokens": 464,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/DataHandling/index.jsx": {
            "lines": 548,
            "tokens": 3539,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 24,
            "duplicatedTokens": 197,
            "percentage": 4.38,
            "percentageTokens": 5.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/CreateWorkspace/index.jsx": {
            "lines": 95,
            "tokens": 796,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Updates/index.jsx": {
            "lines": 209,
            "tokens": 1604,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Resources/index.jsx": {
            "lines": 48,
            "tokens": 370,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/QuickLinks/index.jsx": {
            "lines": 96,
            "tokens": 763,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/ExploreFeatures/index.jsx": {
            "lines": 153,
            "tokens": 1016,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/Checklist/index.jsx": {
            "lines": 216,
            "tokens": 1716,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/Interface/index.jsx": {
            "lines": 38,
            "tokens": 292,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 39,
            "duplicatedTokens": 337,
            "percentage": 102.63,
            "percentageTokens": 115.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/Chat/index.jsx": {
            "lines": 36,
            "tokens": 273,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 14,
            "duplicatedTokens": 122,
            "percentage": 38.89,
            "percentageTokens": 44.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Settings/Branding/index.jsx": {
            "lines": 42,
            "tokens": 318,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 14,
            "duplicatedTokens": 122,
            "percentage": 33.33,
            "percentageTokens": 38.36,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Trending/index.jsx": {
            "lines": 29,
            "tokens": 218,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 93,
            "percentage": 37.93,
            "percentageTokens": 42.66,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/index.jsx": {
            "lines": 106,
            "tokens": 814,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/CommunityHub/Authentication/index.jsx": {
            "lines": 206,
            "tokens": 1628,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx": {
            "lines": 112,
            "tokens": 848,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 71,
            "duplicatedTokens": 483,
            "percentage": 63.39,
            "percentageTokens": 56.96,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/index.jsx": {
            "lines": 97,
            "tokens": 814,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 46,
            "duplicatedTokens": 273,
            "percentage": 47.42,
            "percentageTokens": 33.54,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx": {
            "lines": 232,
            "tokens": 1923,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 83,
            "duplicatedTokens": 531,
            "percentage": 35.78,
            "percentageTokens": 27.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx": {
            "lines": 129,
            "tokens": 1046,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 93,
            "duplicatedTokens": 611,
            "percentage": 72.09,
            "percentageTokens": 58.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/BrowserExtensionApiKeyRow/index.jsx": {
            "lines": 109,
            "tokens": 793,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx": {
            "lines": 139,
            "tokens": 1079,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 106,
            "duplicatedTokens": 663,
            "percentage": 76.26,
            "percentageTokens": 61.45,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ApiKeys/ApiKeyRow/index.jsx": {
            "lines": 68,
            "tokens": 564,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 27,
            "duplicatedTokens": 155,
            "percentage": 39.71,
            "percentageTokens": 27.48,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Workspaces/WorkspaceRow/index.jsx": {
            "lines": 58,
            "tokens": 439,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 120,
            "percentage": 37.93,
            "percentageTokens": 27.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Workspaces/NewWorkspaceModal/index.jsx": {
            "lines": 81,
            "tokens": 662,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 41,
            "duplicatedTokens": 280,
            "percentage": 50.62,
            "percentageTokens": 42.3,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/UserRow/index.jsx": {
            "lines": 103,
            "tokens": 871,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 54,
            "percentage": 9.71,
            "percentageTokens": 6.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/NewUserModal/index.jsx": {
            "lines": 160,
            "tokens": 1221,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 109,
            "duplicatedTokens": 690,
            "percentage": 68.13,
            "percentageTokens": 56.51,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/index.jsx": {
            "lines": 115,
            "tokens": 821,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx": {
            "lines": 129,
            "tokens": 920,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 90,
            "duplicatedTokens": 551,
            "percentage": 69.77,
            "percentageTokens": 59.89,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Logging/LogRow/index.jsx": {
            "lines": 117,
            "tokens": 926,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx": {
            "lines": 217,
            "tokens": 1708,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 83,
            "duplicatedTokens": 494,
            "percentage": 38.25,
            "percentageTokens": 28.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Invitations/InviteRow/index.jsx": {
            "lines": 79,
            "tokens": 646,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 17,
            "duplicatedTokens": 104,
            "percentage": 21.52,
            "percentageTokens": 16.1,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/WebSearchSelection/index.jsx": {
            "lines": 278,
            "tokens": 2062,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 29,
            "duplicatedTokens": 234,
            "percentage": 10.43,
            "percentageTokens": 11.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/SQLConnectorSelection/index.jsx": {
            "lines": 129,
            "tokens": 989,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 91,
            "percentage": 9.3,
            "percentageTokens": 9.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/SQLConnectorSelection/NewConnectionModal.jsx": {
            "lines": 274,
            "tokens": 2030,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 25,
            "duplicatedTokens": 165,
            "percentage": 9.12,
            "percentageTokens": 8.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/SQLConnectorSelection/DBConnection.jsx": {
            "lines": 48,
            "tokens": 350,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/MCPServers/index.jsx": {
            "lines": 154,
            "tokens": 1115,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 130,
            "percentage": 16.88,
            "percentageTokens": 11.66,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/MCPServers/ServerPanel.jsx": {
            "lines": 241,
            "tokens": 2048,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 218,
            "percentage": 11.62,
            "percentageTokens": 10.64,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/GenericSkillPanel/index.jsx": {
            "lines": 52,
            "tokens": 342,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/DefaultSkillPanel/index.jsx": {
            "lines": 56,
            "tokens": 418,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 14,
            "duplicatedTokens": 121,
            "percentage": 25,
            "percentageTokens": 28.95,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/Badges/default.jsx": {
            "lines": 17,
            "tokens": 98,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/AgentFlows/index.jsx": {
            "lines": 57,
            "tokens": 388,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 13,
            "duplicatedTokens": 66,
            "percentage": 22.81,
            "percentageTokens": 17.01,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/AgentFlows/FlowPanel.jsx": {
            "lines": 124,
            "tokens": 1082,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 45,
            "duplicatedTokens": 360,
            "percentage": 36.29,
            "percentageTokens": 33.27,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/HeaderMenu/index.jsx": {
            "lines": 141,
            "tokens": 1047,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 72,
            "percentage": 7.8,
            "percentageTokens": 6.88,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/BlockList/index.jsx": {
            "lines": 355,
            "tokens": 2420,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/AddBlockMenu/index.jsx": {
            "lines": 85,
            "tokens": 646,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/index.jsx": {
            "lines": 372,
            "tokens": 2689,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 78,
            "percentage": 2.69,
            "percentageTokens": 2.9,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/DnDWrapper/index.jsx": {
            "lines": 289,
            "tokens": 2144,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 48,
            "duplicatedTokens": 338,
            "percentage": 16.61,
            "percentageTokens": 15.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatTooltips/index.jsx": {
            "lines": 100,
            "tokens": 408,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/index.jsx": {
            "lines": 356,
            "tokens": 2822,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/ActiveWorkspaces/ThreadContainer/index.jsx": {
            "lines": 233,
            "tokens": 1958,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/Documents/index.jsx": {
            "lines": 230,
            "tokens": 1876,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/DataConnectors/index.jsx": {
            "lines": 113,
            "tokens": 928,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/VectorDatabase/index.jsx": {
            "lines": 69,
            "tokens": 634,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 46,
            "duplicatedTokens": 403,
            "percentage": 66.67,
            "percentageTokens": 63.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/Members/index.jsx": {
            "lines": 91,
            "tokens": 760,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 17,
            "duplicatedTokens": 82,
            "percentage": 18.68,
            "percentageTokens": 10.79,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/GeneralAppearance/index.jsx": {
            "lines": 72,
            "tokens": 689,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 59,
            "duplicatedTokens": 581,
            "percentage": 81.94,
            "percentageTokens": 84.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/ChatSettings/index.jsx": {
            "lines": 92,
            "tokens": 754,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 33,
            "duplicatedTokens": 314,
            "percentage": 35.87,
            "percentageTokens": 41.64,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/AgentConfig/index.jsx": {
            "lines": 149,
            "tokens": 1237,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 21,
            "duplicatedTokens": 203,
            "percentage": 14.09,
            "percentageTokens": 16.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/Steps/index.jsx": {
            "lines": 142,
            "tokens": 937,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/Home/index.jsx": {
            "lines": 26,
            "tokens": 187,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Login/SSO/simple.jsx": {
            "lines": 53,
            "tokens": 533,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Invite/NewUserModal/index.jsx": {
            "lines": 97,
            "tokens": 804,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx": {
            "lines": 329,
            "tokens": 2635,
            "sources": 1,
            "clones": 20,
            "duplicatedLines": 367,
            "duplicatedTokens": 2572,
            "percentage": 111.55,
            "percentageTokens": 97.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx": {
            "lines": 237,
            "tokens": 1948,
            "sources": 1,
            "clones": 12,
            "duplicatedLines": 232,
            "duplicatedTokens": 1779,
            "percentage": 97.89,
            "percentageTokens": 91.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Security/index.jsx": {
            "lines": 343,
            "tokens": 2631,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 96,
            "duplicatedTokens": 676,
            "percentage": 27.99,
            "percentageTokens": 25.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx": {
            "lines": 220,
            "tokens": 1857,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 80,
            "duplicatedTokens": 625,
            "percentage": 36.36,
            "percentageTokens": 33.66,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx": {
            "lines": 526,
            "tokens": 4198,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 144,
            "duplicatedTokens": 1053,
            "percentage": 27.38,
            "percentageTokens": 25.08,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/EmbeddingTextSplitterPreference/index.jsx": {
            "lines": 177,
            "tokens": 1387,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 40,
            "duplicatedTokens": 272,
            "percentage": 22.6,
            "percentageTokens": 19.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx": {
            "lines": 380,
            "tokens": 3104,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 148,
            "duplicatedTokens": 1041,
            "percentage": 38.95,
            "percentageTokens": 33.54,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/Chats/index.jsx": {
            "lines": 285,
            "tokens": 2271,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 45,
            "duplicatedTokens": 302,
            "percentage": 15.79,
            "percentageTokens": 13.3,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/index.jsx": {
            "lines": 156,
            "tokens": 1087,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 33,
            "duplicatedTokens": 216,
            "percentage": 21.15,
            "percentageTokens": 19.87,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx": {
            "lines": 151,
            "tokens": 1231,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 101,
            "duplicatedTokens": 756,
            "percentage": 66.89,
            "percentageTokens": 61.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx": {
            "lines": 226,
            "tokens": 1935,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 139,
            "duplicatedTokens": 1056,
            "percentage": 61.5,
            "percentageTokens": 54.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx": {
            "lines": 191,
            "tokens": 1654,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 141,
            "duplicatedTokens": 1102,
            "percentage": 73.82,
            "percentageTokens": 66.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/AudioPreference/index.jsx": {
            "lines": 45,
            "tokens": 367,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 20,
            "duplicatedTokens": 140,
            "percentage": 44.44,
            "percentageTokens": 38.15,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/GeneralSettings/ApiKeys/index.jsx": {
            "lines": 134,
            "tokens": 1107,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 31,
            "duplicatedTokens": 236,
            "percentage": 23.13,
            "percentageTokens": 21.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Workspaces/index.jsx": {
            "lines": 118,
            "tokens": 940,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 72,
            "duplicatedTokens": 514,
            "percentage": 61.02,
            "percentageTokens": 54.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Users/index.jsx": {
            "lines": 199,
            "tokens": 1569,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 205,
            "percentage": 14.07,
            "percentageTokens": 13.07,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/SystemPromptVariables/index.jsx": {
            "lines": 120,
            "tokens": 979,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 14,
            "duplicatedTokens": 103,
            "percentage": 11.67,
            "percentageTokens": 10.52,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Logging/index.jsx": {
            "lines": 162,
            "tokens": 1243,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 43,
            "duplicatedTokens": 289,
            "percentage": 26.54,
            "percentageTokens": 23.25,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Invitations/index.jsx": {
            "lines": 112,
            "tokens": 948,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 32,
            "duplicatedTokens": 231,
            "percentage": 28.57,
            "percentageTokens": 24.37,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/ExperimentalFeatures/index.jsx": {
            "lines": 286,
            "tokens": 2238,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 41,
            "duplicatedTokens": 206,
            "percentage": 14.34,
            "percentageTokens": 9.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/Agents/index.jsx": {
            "lines": 698,
            "tokens": 5265,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 54,
            "duplicatedTokens": 421,
            "percentage": 7.74,
            "percentageTokens": 8,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Admin/AgentBuilder/index.jsx": {
            "lines": 368,
            "tokens": 3105,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/lib/CTAButton/index.jsx": {
            "lines": 16,
            "tokens": 107,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/LoadingChat/index.jsx": {
            "lines": 60,
            "tokens": 364,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 30,
            "duplicatedTokens": 166,
            "percentage": 50,
            "percentageTokens": 45.6,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/ChatContainer/index.jsx": {
            "lines": 302,
            "tokens": 2268,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/ZillizCloudOptions/index.jsx": {
            "lines": 38,
            "tokens": 254,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 40,
            "duplicatedTokens": 328,
            "percentage": 105.26,
            "percentageTokens": 129.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/WeaviateDBOptions/index.jsx": {
            "lines": 38,
            "tokens": 242,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 164,
            "percentage": 73.68,
            "percentageTokens": 67.77,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx": {
            "lines": 37,
            "tokens": 228,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 92,
            "duplicatedTokens": 542,
            "percentage": 248.65,
            "percentageTokens": 237.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/QDrantDBOptions/index.jsx": {
            "lines": 38,
            "tokens": 244,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 14,
            "duplicatedTokens": 82,
            "percentage": 36.84,
            "percentageTokens": 33.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/PineconeDBOptions/index.jsx": {
            "lines": 38,
            "tokens": 265,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/PGVectorOptions/index.jsx": {
            "lines": 103,
            "tokens": 793,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/MilvusDBOptions/index.jsx": {
            "lines": 52,
            "tokens": 344,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/LanceDBOptions/index.jsx": {
            "lines": 11,
            "tokens": 91,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/ChromaDBOptions/index.jsx": {
            "lines": 51,
            "tokens": 331,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/VectorDBSelection/AstraDBOptions/index.jsx": {
            "lines": 41,
            "tokens": 267,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserMenu/UserButton/index.jsx": {
            "lines": 131,
            "tokens": 1036,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserMenu/AccountModal/index.jsx": {
            "lines": 391,
            "tokens": 2883,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 47,
            "duplicatedTokens": 323,
            "percentage": 12.02,
            "percentageTokens": 11.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TranscriptionSelection/OpenAiOptions/index.jsx": {
            "lines": 41,
            "tokens": 326,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 18,
            "duplicatedTokens": 143,
            "percentage": 43.9,
            "percentageTokens": 43.87,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TranscriptionSelection/NativeTranscriptionOptions/index.jsx": {
            "lines": 88,
            "tokens": 675,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 236,
            "percentage": 29.55,
            "percentageTokens": 34.96,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/PiperTTSOptions/index.jsx": {
            "lines": 220,
            "tokens": 1904,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 39,
            "duplicatedTokens": 339,
            "percentage": 17.73,
            "percentageTokens": 17.8,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/OpenAiOptions/index.jsx": {
            "lines": 49,
            "tokens": 375,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 64,
            "percentage": 20.41,
            "percentageTokens": 17.07,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/OpenAiGenericOptions/index.jsx": {
            "lines": 69,
            "tokens": 551,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx": {
            "lines": 109,
            "tokens": 869,
            "sources": 1,
            "clones": 26,
            "duplicatedLines": 458,
            "duplicatedTokens": 3023,
            "percentage": 420.18,
            "percentageTokens": 347.87,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/TextToSpeech/BrowserNative/index.jsx": {
            "lines": 9,
            "tokens": 72,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/SpeechToText/BrowserNative/index.jsx": {
            "lines": 9,
            "tokens": 72,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/SidebarToggle/index.jsx": {
            "lines": 105,
            "tokens": 751,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/ActiveWorkspaces/index.jsx": {
            "lines": 213,
            "tokens": 1459,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/SettingsSidebar/MenuOption/index.jsx": {
            "lines": 187,
            "tokens": 1445,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/Password/index.jsx": {
            "lines": 152,
            "tokens": 1060,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/Password/SingleUserAuth.jsx": {
            "lines": 128,
            "tokens": 1116,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 94,
            "duplicatedTokens": 723,
            "percentage": 73.44,
            "percentageTokens": 64.78,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/Password/MultiUserAuth.jsx": {
            "lines": 357,
            "tokens": 2886,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 94,
            "duplicatedTokens": 723,
            "percentage": 26.33,
            "percentageTokens": 25.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/ManageWorkspace/index.jsx": {
            "lines": 174,
            "tokens": 1385,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 71,
            "percentage": 6.32,
            "percentageTokens": 5.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/DisplayRecoveryCodeModal/index.jsx": {
            "lines": 91,
            "tokens": 754,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx": {
            "lines": 114,
            "tokens": 906,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 77,
            "duplicatedTokens": 553,
            "percentage": 67.54,
            "percentageTokens": 61.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/TogetherAiOptions/index.jsx": {
            "lines": 114,
            "tokens": 994,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 41,
            "duplicatedTokens": 267,
            "percentage": 35.96,
            "percentageTokens": 26.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/TextGenWebUIOptions/index.jsx": {
            "lines": 51,
            "tokens": 354,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/PerplexityOptions/index.jsx": {
            "lines": 90,
            "tokens": 665,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 33,
            "duplicatedTokens": 205,
            "percentage": 36.67,
            "percentageTokens": 30.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx": {
            "lines": 100,
            "tokens": 794,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 99,
            "duplicatedTokens": 762,
            "percentage": 99,
            "percentageTokens": 95.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx": {
            "lines": 142,
            "tokens": 1124,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 77,
            "duplicatedTokens": 540,
            "percentage": 54.23,
            "percentageTokens": 48.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx": {
            "lines": 107,
            "tokens": 865,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 94,
            "duplicatedTokens": 682,
            "percentage": 87.85,
            "percentageTokens": 78.84,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx": {
            "lines": 317,
            "tokens": 2475,
            "sources": 1,
            "clones": 18,
            "duplicatedLines": 323,
            "duplicatedTokens": 2382,
            "percentage": 101.89,
            "percentageTokens": 96.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/NvidiaNimOptions/remote.jsx": {
            "lines": 130,
            "tokens": 874,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 52,
            "duplicatedTokens": 307,
            "percentage": 40,
            "percentageTokens": 35.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/NvidiaNimOptions/index.jsx": {
            "lines": 11,
            "tokens": 97,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx": {
            "lines": 145,
            "tokens": 1176,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 95,
            "duplicatedTokens": 702,
            "percentage": 65.52,
            "percentageTokens": 59.69,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/MistralOptions/index.jsx": {
            "lines": 105,
            "tokens": 811,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 44,
            "duplicatedTokens": 243,
            "percentage": 41.9,
            "percentageTokens": 29.96,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx": {
            "lines": 219,
            "tokens": 1679,
            "sources": 1,
            "clones": 15,
            "duplicatedLines": 279,
            "duplicatedTokens": 2002,
            "percentage": 127.4,
            "percentageTokens": 119.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx": {
            "lines": 148,
            "tokens": 1158,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 162,
            "duplicatedTokens": 1231,
            "percentage": 109.46,
            "percentageTokens": 106.3,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx": {
            "lines": 219,
            "tokens": 1675,
            "sources": 1,
            "clones": 17,
            "duplicatedLines": 295,
            "duplicatedTokens": 2331,
            "percentage": 134.7,
            "percentageTokens": 139.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LLMProviderOption/index.jsx": {
            "lines": 37,
            "tokens": 249,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 100,
            "percentage": 29.73,
            "percentageTokens": 40.16,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/LLMItem/index.jsx": {
            "lines": 37,
            "tokens": 228,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 37,
            "duplicatedTokens": 221,
            "percentage": 100,
            "percentageTokens": 96.93,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx": {
            "lines": 224,
            "tokens": 1675,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 84,
            "duplicatedTokens": 658,
            "percentage": 37.5,
            "percentageTokens": 39.28,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/HuggingFaceOptions/index.jsx": {
            "lines": 56,
            "tokens": 377,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx": {
            "lines": 114,
            "tokens": 906,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 63,
            "duplicatedTokens": 466,
            "percentage": 55.26,
            "percentageTokens": 51.43,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/GenericOpenAiOptions/index.jsx": {
            "lines": 85,
            "tokens": 575,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/GeminiLLMOptions/index.jsx": {
            "lines": 138,
            "tokens": 962,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 31,
            "duplicatedTokens": 196,
            "percentage": 22.46,
            "percentageTokens": 20.37,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/FireworksAiOptions/index.jsx": {
            "lines": 99,
            "tokens": 776,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 65,
            "duplicatedTokens": 469,
            "percentage": 65.66,
            "percentageTokens": 60.44,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx": {
            "lines": 100,
            "tokens": 755,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 71,
            "duplicatedTokens": 443,
            "percentage": 71,
            "percentageTokens": 58.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/DPAISOptions/index.jsx": {
            "lines": 181,
            "tokens": 1271,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 115,
            "duplicatedTokens": 807,
            "percentage": 63.54,
            "percentageTokens": 63.49,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/CohereAiOptions/index.jsx": {
            "lines": 49,
            "tokens": 329,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 106,
            "percentage": 30.61,
            "percentageTokens": 32.22,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AzureAiOptions/index.jsx": {
            "lines": 102,
            "tokens": 822,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 32,
            "duplicatedTokens": 196,
            "percentage": 31.37,
            "percentageTokens": 23.84,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AwsBedrockLLMOptions/index.jsx": {
            "lines": 196,
            "tokens": 1446,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/ApiPieOptions/index.jsx": {
            "lines": 101,
            "tokens": 790,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 60,
            "duplicatedTokens": 444,
            "percentage": 59.41,
            "percentageTokens": 56.2,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/LLMSelection/AnthropicAiOptions/index.jsx": {
            "lines": 139,
            "tokens": 948,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 48,
            "duplicatedTokens": 295,
            "percentage": 34.53,
            "percentageTokens": 31.12,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ErrorBoundary/__tests__/ErrorBoundary.test.jsx": {
            "lines": 154,
            "tokens": 1163,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx": {
            "lines": 56,
            "tokens": 358,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 93,
            "duplicatedTokens": 594,
            "percentage": 166.07,
            "percentageTokens": 165.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/OpenAiOptions/index.jsx": {
            "lines": 51,
            "tokens": 329,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 55,
            "duplicatedTokens": 327,
            "percentage": 107.84,
            "percentageTokens": 99.39,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx": {
            "lines": 199,
            "tokens": 1490,
            "sources": 1,
            "clones": 13,
            "duplicatedLines": 279,
            "duplicatedTokens": 2014,
            "percentage": 140.2,
            "percentageTokens": 135.17,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/NativeEmbeddingOptions/index.jsx": {
            "lines": 12,
            "tokens": 92,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/MistralAiOptions/index.jsx": {
            "lines": 44,
            "tokens": 313,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 42,
            "duplicatedTokens": 292,
            "percentage": 95.45,
            "percentageTokens": 93.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx": {
            "lines": 197,
            "tokens": 1491,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 179,
            "duplicatedTokens": 1273,
            "percentage": 90.86,
            "percentageTokens": 85.38,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx": {
            "lines": 186,
            "tokens": 1413,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 156,
            "duplicatedTokens": 1152,
            "percentage": 83.87,
            "percentageTokens": 81.53,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx": {
            "lines": 200,
            "tokens": 1510,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 196,
            "duplicatedTokens": 1440,
            "percentage": 98,
            "percentageTokens": 95.36,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/GenericOpenAiOptions/index.jsx": {
            "lines": 118,
            "tokens": 875,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 48,
            "duplicatedTokens": 371,
            "percentage": 40.68,
            "percentageTokens": 42.4,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/GeminiOptions/index.jsx": {
            "lines": 62,
            "tokens": 397,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 27,
            "duplicatedTokens": 199,
            "percentage": 43.55,
            "percentageTokens": 50.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/EmbedderItem/index.jsx": {
            "lines": 37,
            "tokens": 228,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 37,
            "duplicatedTokens": 221,
            "percentage": 100,
            "percentageTokens": 96.93,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/CohereOptions/index.jsx": {
            "lines": 55,
            "tokens": 345,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 62,
            "duplicatedTokens": 406,
            "percentage": 112.73,
            "percentageTokens": 117.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EmbeddingSelection/AzureAiOptions/index.jsx": {
            "lines": 55,
            "tokens": 359,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 46,
            "duplicatedTokens": 278,
            "percentage": 83.64,
            "percentageTokens": 77.44,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceSettings/index.jsx": {
            "lines": 144,
            "tokens": 1217,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 24,
            "duplicatedTokens": 229,
            "percentage": 16.67,
            "percentageTokens": 18.82,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/WorkspaceChat/index.jsx": {
            "lines": 54,
            "tokens": 502,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 24,
            "duplicatedTokens": 229,
            "percentage": 44.44,
            "percentageTokens": 45.62,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/OnboardingFlow/index.jsx": {
            "lines": 21,
            "tokens": 173,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Main/index.jsx": {
            "lines": 24,
            "tokens": 281,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Login/index.jsx": {
            "lines": 15,
            "tokens": 185,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/Invite/index.jsx": {
            "lines": 56,
            "tokens": 435,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/contexts/TTSProvider.jsx": {
            "lines": 136,
            "tokens": 683,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/__tests__/Preloader.test.jsx": {
            "lines": 54,
            "tokens": 524,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/WorkspaceChat/index.jsx": {
            "lines": 122,
            "tokens": 1016,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserMenu/index.jsx": {
            "lines": 10,
            "tokens": 64,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/UserIcon/index.jsx": {
            "lines": 42,
            "tokens": 270,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Sidebar/index.jsx": {
            "lines": 206,
            "tokens": 1547,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 55,
            "duplicatedTokens": 336,
            "percentage": 26.7,
            "percentageTokens": 21.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/SettingsSidebar/index.jsx": {
            "lines": 453,
            "tokens": 3129,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 199,
            "percentage": 6.18,
            "percentageTokens": 6.36,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/SettingsButton/index.jsx": {
            "lines": 49,
            "tokens": 344,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/PrivateRoute/index.jsx": {
            "lines": 154,
            "tokens": 1187,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 40,
            "duplicatedTokens": 336,
            "percentage": 25.97,
            "percentageTokens": 28.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Modals/NewWorkspace.jsx": {
            "lines": 98,
            "tokens": 822,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 99,
            "percentage": 15.31,
            "percentageTokens": 12.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ModalWrapper/index.jsx": {
            "lines": 35,
            "tokens": 143,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/KeyboardShortcutsHelp/index.jsx": {
            "lines": 60,
            "tokens": 483,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Footer/index.jsx": {
            "lines": 146,
            "tokens": 952,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 154,
            "percentage": 17.81,
            "percentageTokens": 16.18,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ErrorBoundary/index.jsx": {
            "lines": 269,
            "tokens": 1661,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/EditingChatBubble/index.jsx": {
            "lines": 76,
            "tokens": 539,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/DefaultChat/index.jsx": {
            "lines": 257,
            "tokens": 2147,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/DataConnectorOption/index.jsx": {
            "lines": 25,
            "tokens": 219,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 100,
            "percentage": 44,
            "percentageTokens": 45.66,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ContextualSaveBar/index.jsx": {
            "lines": 32,
            "tokens": 204,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ChatBubble/index.jsx": {
            "lines": 31,
            "tokens": 214,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/ChangeWarning/index.jsx": {
            "lines": 61,
            "tokens": 429,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/CanViewChatHistory/index.jsx": {
            "lines": 50,
            "tokens": 362,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/pages/404.jsx": {
            "lines": 24,
            "tokens": 156,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/components/Preloader.jsx": {
            "lines": 18,
            "tokens": 113,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/main.jsx": {
            "lines": 15,
            "tokens": 131,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/ThemeContext.jsx": {
            "lines": 16,
            "tokens": 122,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/PfpContext.jsx": {
            "lines": 30,
            "tokens": 262,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/LogoContext.jsx": {
            "lines": 57,
            "tokens": 496,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/AuthContext.jsx": {
            "lines": 32,
            "tokens": 335,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "frontend/src/App.jsx": {
            "lines": 326,
            "tokens": 2101,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 42291,
          "tokens": 322607,
          "sources": 331,
          "clones": 354,
          "duplicatedLines": 6115,
          "duplicatedTokens": 43248,
          "percentage": 14.46,
          "percentageTokens": 13.41,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      }
    },
    "total": {
      "lines": 132367,
      "tokens": 980283,
      "sources": 961,
      "clones": 975,
      "duplicatedLines": 26417,
      "duplicatedTokens": 189990,
      "percentage": 19.96,
      "percentageTokens": 19.38,
      "newDuplicatedLines": 0,
      "newClones": 0
    }
  },
  "duplicates": [
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ");\n    this.#connected = true;\n    return this._client;\n  }\n\n  /**\n   *\n   * @param {string} queryString the SQL query to be run\n   * @returns {import(\".\").QueryResult}\n   */\n  async runQuery(queryString = \"\") {\n    const result = { rows: [], count: 0, error: null };\n    try {\n      if (!this.#connected) await this.connect();\n      const [",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/MySQL.js",
        "start": 24,
        "end": 38,
        "startLoc": {
          "line": 24,
          "column": 2,
          "position": 210
        },
        "endLoc": {
          "line": 38,
          "column": 2,
          "position": 309
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/Postgresql.js",
        "start": 17,
        "end": 31,
        "startLoc": {
          "line": 17,
          "column": 2,
          "position": 116
        },
        "endLoc": {
          "line": 31,
          "column": 6,
          "position": 215
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ";\n    } catch (err) {\n      console.log(this.constructor.name, err);\n      result.error = err.message;\n    } finally {\n      await this._client.end();\n      this.#connected = false;\n    }\n    return result;\n  }\n\n  getTablesSql() {\n    return `SELECT table_name FROM information_schema.tables WHERE table_schema = '",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/MySQL.js",
        "start": 40,
        "end": 52,
        "startLoc": {
          "line": 40,
          "column": 7,
          "position": 348
        },
        "endLoc": {
          "line": 52,
          "column": 73,
          "position": 441
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/Postgresql.js",
        "start": 33,
        "end": 45,
        "startLoc": {
          "line": 33,
          "column": 9,
          "position": 253
        },
        "endLoc": {
          "line": 45,
          "column": 65,
          "position": 346
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n    this.#connected = true;\n    return this._client;\n  }\n\n  /**\n   *\n   * @param {string} queryString the SQL query to be run\n   * @returns {import(\".\").QueryResult}\n   */\n  async runQuery(queryString = \"\") {\n    const result = { rows: [], count: 0, error: null };\n    try {\n      if (!this.#connected) await this.connect();\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/MSSQL.js",
        "start": 52,
        "end": 67,
        "startLoc": {
          "line": 52,
          "column": 17,
          "position": 394
        },
        "endLoc": {
          "line": 67,
          "column": 1,
          "position": 490
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/SQLConnectors/Postgresql.js",
        "start": 17,
        "end": 31,
        "startLoc": {
          "line": 17,
          "column": 2,
          "position": 116
        },
        "endLoc": {
          "line": 31,
          "column": 7,
          "position": 212
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "}),\n            },\n          ],\n          parameters: {\n            $schema: \"http://json-schema.org/draft-07/schema#\",\n            type: \"object\",\n            properties: {\n              database_id: {\n                type: \"string\",\n                description:\n                  \"The database identifier for which we will list all tables for. This is a required parameter\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/list-table.js",
        "start": 29,
        "end": 39,
        "startLoc": {
          "line": 29,
          "column": 2,
          "position": 202
        },
        "endLoc": {
          "line": 39,
          "column": 94,
          "position": 258
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/query.js",
        "start": 40,
        "end": 50,
        "startLoc": {
          "line": 40,
          "column": 15,
          "position": 234
        },
        "endLoc": {
          "line": 50,
          "column": 121,
          "position": 290
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ",\n                  result.error\n                );\n                this.super.introspect(`Error: ${result.error}`);\n                return `There was an error running the query: ${result.error}`;\n              }\n\n              return JSON.stringify(result);\n            } catch (e) {\n              console.error(e);\n              return e.message;\n            }\n          },\n        });\n      },\n    };\n  },\n};\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/list-table.js",
        "start": 68,
        "end": 86,
        "startLoc": {
          "line": 68,
          "column": 38,
          "position": 521
        },
        "endLoc": {
          "line": 86,
          "column": 1,
          "position": 630
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/query.js",
        "start": 84,
        "end": 102,
        "startLoc": {
          "line": 84,
          "column": 32,
          "position": 577
        },
        "endLoc": {
          "line": 102,
          "column": 1,
          "position": 686
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n              }),\n            },\n          ],\n          parameters: {\n            $schema: \"http://json-schema.org/draft-07/schema#\",\n            type: \"object\",\n            properties: {\n              database_id: {\n                type: \"string\",\n                description:\n                  \"The database identifier for which we will connect to to query the table schema. This is a required field.\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/get-table-schema.js",
        "start": 30,
        "end": 41,
        "startLoc": {
          "line": 30,
          "column": 8,
          "position": 186
        },
        "endLoc": {
          "line": 41,
          "column": 108,
          "position": 245
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/sql-agent/query.js",
        "start": 39,
        "end": 50,
        "startLoc": {
          "line": 39,
          "column": 66,
          "position": 231
        },
        "endLoc": {
          "line": 50,
          "column": 121,
          "position": 290
        }
      }
    },
    {
      "format": "javascript",
      "lines": 41,
      "fragment": "\n// Scraping is enabled, but search requires AGENT_GSE_* keys.\n\nconst express = require(\"express\");\nconst chalk = require(\"chalk\");\nconst AIbitat = require(\"../../index.js\");\nconst {\n  websocket,\n  webBrowsing,\n  webScraping,\n} = require(\"../../plugins/index.js\");\nconst path = require(\"path\");\nconst port = 3000;\nconst app = express();\nrequire(\"@mintplex-labs/express-ws\").default(app); // load WebSockets in non-SSL mode.\nrequire(\"dotenv\").config({ path: `../../../../../.env.development` });\n\n// Debugging echo function if this is working for you.\n// app.ws('/echo', function (ws, req) {\n//   ws.on('message', function (msg) {\n//     ws.send(msg);\n//   });\n// });\n\n// Set up WSS sockets for listening.\napp.ws(\"/ws\", function (ws, _response) {\n  try {\n    ws.on(\"message\", function (msg) {\n      if (ws?.handleFeedback) ws.handleFeedback(msg);\n    });\n\n    ws.on(\"close\", function () {\n      console.log(\"Socket killed\");\n      return;\n    });\n\n    console.log(\"Socket online and waiting...\");\n    runAIbitat(ws).catch((error) => {\n      ws.send(\n        JSON.stringify({\n          from: \"AI\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/example/websocket/websock-branding-collab.js",
        "start": 2,
        "end": 42,
        "startLoc": {
          "line": 2,
          "column": 56,
          "position": 3
        },
        "endLoc": {
          "line": 42,
          "column": 5,
          "position": 287
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/example/websocket/websock-multi-turn-chat.js",
        "start": 2,
        "end": 42,
        "startLoc": {
          "line": 2,
          "column": 56,
          "position": 3
        },
        "endLoc": {
          "line": 42,
          "column": 6,
          "position": 287
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ",\n          content: error.message,\n        })\n      );\n    });\n  } catch (error) {}\n});\n\napp.all(\"*\", function (_, response) {\n  response.sendFile(path.join(__dirname, \"index.html\"));\n});\n\napp.listen(port, () => {\n  console.log(`Testing HTTP/WSS server listening at http://localhost:${port}`);\n});\n\nasync",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/example/websocket/websock-branding-collab.js",
        "start": 43,
        "end": 59,
        "startLoc": {
          "line": 43,
          "column": 8,
          "position": 295
        },
        "endLoc": {
          "line": 59,
          "column": 6,
          "position": 408
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/example/websocket/websock-multi-turn-chat.js",
        "start": 43,
        "end": 59,
        "startLoc": {
          "line": 43,
          "column": 6,
          "position": 299
        },
        "endLoc": {
          "line": 59,
          "column": 6,
          "position": 412
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"LMStudio chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/togetherai.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 20,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 29,
          "position": 305
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 16,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 71,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since LMStudio has no cost basis.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/togetherai.js",
        "start": 41,
        "end": 111,
        "startLoc": {
          "line": 41,
          "column": 36,
          "position": 332
        },
        "endLoc": {
          "line": 111,
          "column": 6,
          "position": 753
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 110,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 753
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"Oobabooga chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/textgenwebui.js",
        "start": 21,
        "end": 38,
        "startLoc": {
          "line": 21,
          "column": 47,
          "position": 167
        },
        "endLoc": {
          "line": 38,
          "column": 30,
          "position": 298
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 22,
        "end": 39,
        "startLoc": {
          "line": 22,
          "column": 2,
          "position": 174
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 71,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since KoboldCPP has no cost basis.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/textgenwebui.js",
        "start": 40,
        "end": 110,
        "startLoc": {
          "line": 40,
          "column": 37,
          "position": 325
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 746
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 110,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 753
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ",\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!Object",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/ppio.js",
        "start": 22,
        "end": 42,
        "startLoc": {
          "line": 22,
          "column": 2,
          "position": 171
        },
        "endLoc": {
          "line": 42,
          "column": 7,
          "position": 314
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 18,
        "end": 38,
        "startLoc": {
          "line": 18,
          "column": 2,
          "position": 147
        },
        "endLoc": {
          "line": 38,
          "column": 7,
          "position": 290
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = null",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/ppio.js",
        "start": 45,
        "end": 60,
        "startLoc": {
          "line": 45,
          "column": 32,
          "position": 363
        },
        "endLoc": {
          "line": 60,
          "column": 5,
          "position": 427
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 56,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 56,
          "column": 2,
          "position": 396
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"Perplexity chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/perplexity.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 5,
          "position": 145
        },
        "endLoc": {
          "line": 39,
          "column": 31,
          "position": 310
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 16,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 76,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = PerplexityProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/perplexity.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 38,
          "position": 337
        },
        "endLoc": {
          "line": 116,
          "column": 19,
          "position": 786
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      },\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"OpenRouter chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/openrouter.js",
        "start": 21,
        "end": 43,
        "startLoc": {
          "line": 21,
          "column": 14,
          "position": 167
        },
        "endLoc": {
          "line": 43,
          "column": 31,
          "position": 329
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/ppio.js",
        "start": 21,
        "end": 39,
        "startLoc": {
          "line": 21,
          "column": 14,
          "position": 167
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 71,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since OpenRouter has no cost basis.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/openrouter.js",
        "start": 45,
        "end": 115,
        "startLoc": {
          "line": 45,
          "column": 38,
          "position": 356
        },
        "endLoc": {
          "line": 115,
          "column": 6,
          "position": 777
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 110,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 753
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ";\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/ollama.js",
        "start": 25,
        "end": 35,
        "startLoc": {
          "line": 25,
          "column": 2,
          "position": 196
        },
        "endLoc": {
          "line": 35,
          "column": 6,
          "position": 264
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 21,
        "end": 31,
        "startLoc": {
          "line": 21,
          "column": 7,
          "position": 163
        },
        "endLoc": {
          "line": 31,
          "column": 7,
          "position": 231
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": ";\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/ollama.js",
        "start": 42,
        "end": 81,
        "startLoc": {
          "line": 42,
          "column": 5,
          "position": 329
        },
        "endLoc": {
          "line": 81,
          "column": 5,
          "position": 584
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 46,
        "end": 85,
        "startLoc": {
          "line": 46,
          "column": 2,
          "position": 375
        },
        "endLoc": {
          "line": 85,
          "column": 5,
          "position": 630
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ".message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since LMStudio has no cost basis.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = OllamaProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/ollama.js",
        "start": 89,
        "end": 117,
        "startLoc": {
          "line": 89,
          "column": 9,
          "position": 644
        },
        "endLoc": {
          "line": 117,
          "column": 15,
          "position": 750
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 89,
        "end": 117,
        "startLoc": {
          "line": 89,
          "column": 2,
          "position": 675
        },
        "endLoc": {
          "line": 117,
          "column": 19,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ",\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"NVIDIA NIM chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/nvidiaNim.js",
        "start": 19,
        "end": 40,
        "startLoc": {
          "line": 19,
          "column": 2,
          "position": 143
        },
        "endLoc": {
          "line": 40,
          "column": 31,
          "position": 301
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 18,
        "end": 39,
        "startLoc": {
          "line": 18,
          "column": 2,
          "position": 147
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 76,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = NvidiaNimProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/nvidiaNim.js",
        "start": 42,
        "end": 117,
        "startLoc": {
          "line": 42,
          "column": 38,
          "position": 328
        },
        "endLoc": {
          "line": 117,
          "column": 18,
          "position": 777
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ": \"anythingllm\",\n      },\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"Novita chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/novita.js",
        "start": 21,
        "end": 43,
        "startLoc": {
          "line": 21,
          "column": 18,
          "position": 164
        },
        "endLoc": {
          "line": 43,
          "column": 27,
          "position": 329
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/ppio.js",
        "start": 21,
        "end": 39,
        "startLoc": {
          "line": 21,
          "column": 15,
          "position": 164
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    let",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/novita.js",
        "start": 45,
        "end": 61,
        "startLoc": {
          "line": 45,
          "column": 34,
          "position": 356
        },
        "endLoc": {
          "line": 61,
          "column": 4,
          "position": 427
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 57,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 57,
          "column": 4,
          "position": 403
        }
      }
    },
    {
      "format": "javascript",
      "lines": 50,
      "fragment": ") {\n    let completion;\n    if (functions.length > 0) {\n      const { toolCall, text } = await this.functionCall(\n        messages,\n        functions,\n        this.#handleFunctionCallChat.bind(this)\n      );\n\n      if (toolCall !== null) {\n        this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n        this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n        return {\n          result: null,\n          functionCall: {\n            name: toolCall.name,\n            arguments: toolCall.arguments,\n          },\n          cost: 0,\n        };\n      }\n      completion = { content: text };\n    }\n\n    if (!completion?.content) {\n      this.providerLog(\"Will assume chat completion without tool call inputs.\");\n      const response = await this.client.chat.completions.create({\n        model: this.model,\n        messages: this.cleanMsgs(messages),\n      });\n      completion = response.choices[0].message;\n    }\n\n    // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n    // from calling the exact same function over and over in a loop within a single chat exchange\n    // _but_ we should enable it to call previously used tools in a new chat interaction.\n    this.deduplicator.reset(\"runs\");\n    return {\n      result: completion.content,\n      cost: 0,\n    };\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since Novita AI has no cost basis.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/novita.js",
        "start": 60,
        "end": 109,
        "startLoc": {
          "line": 60,
          "column": 2,
          "position": 422
        },
        "endLoc": {
          "line": 109,
          "column": 6,
          "position": 748
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/ppio.js",
        "start": 60,
        "end": 109,
        "startLoc": {
          "line": 60,
          "column": 5,
          "position": 428
        },
        "endLoc": {
          "line": 109,
          "column": 6,
          "position": 754
        }
      }
    },
    {
      "format": "javascript",
      "lines": 100,
      "fragment": ",\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"LMStudio chat: No results!\");\n        if (result.choices.length === 0)\n          throw new Error(\"LMStudio chat: No results length!\");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = MistralProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/mistral.js",
        "start": 21,
        "end": 120,
        "startLoc": {
          "line": 21,
          "column": 16,
          "position": 140
        },
        "endLoc": {
          "line": 120,
          "column": 16,
          "position": 781
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 17,
        "end": 116,
        "startLoc": {
          "line": 17,
          "column": 16,
          "position": 140
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": " ?? null,\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"LocalAI chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/localai.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 17,
          "position": 144
        },
        "endLoc": {
          "line": 39,
          "column": 28,
          "position": 314
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/perplexity.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 19,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/localai.js",
        "start": 43,
        "end": 62,
        "startLoc": {
          "line": 43,
          "column": 1,
          "position": 345
        },
        "endLoc": {
          "line": 62,
          "column": 1,
          "position": 424
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 59,
        "startLoc": {
          "line": 41,
          "column": 2,
          "position": 334
        },
        "endLoc": {
          "line": 59,
          "column": 7,
          "position": 413
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/localai.js",
        "start": 61,
        "end": 82,
        "startLoc": {
          "line": 61,
          "column": 1,
          "position": 424
        },
        "endLoc": {
          "line": 82,
          "column": 1,
          "position": 584
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 58,
        "end": 78,
        "startLoc": {
          "line": 58,
          "column": 2,
          "position": 412
        },
        "endLoc": {
          "line": 78,
          "column": 9,
          "position": 572
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return { ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/localai.js",
        "start": 81,
        "end": 100,
        "startLoc": {
          "line": 81,
          "column": 1,
          "position": 584
        },
        "endLoc": {
          "line": 100,
          "column": 2,
          "position": 720
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 77,
        "end": 97,
        "startLoc": {
          "line": 77,
          "column": 2,
          "position": 571
        },
        "endLoc": {
          "line": 97,
          "column": 1,
          "position": 707
        }
      }
    },
    {
      "format": "javascript",
      "lines": 101,
      "fragment": " null,\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"LMStudio chat: No results!\");\n        if (result.choices.length === 0)\n          throw new Error(\"LMStudio chat: No results length!\");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since LMStudio has no cost basis.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = LMStudioProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/lmstudio.js",
        "start": 25,
        "end": 125,
        "startLoc": {
          "line": 25,
          "column": 2,
          "position": 170
        },
        "endLoc": {
          "line": 125,
          "column": 17,
          "position": 813
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/perplexity.js",
        "start": 17,
        "end": 117,
        "startLoc": {
          "line": 17,
          "column": 2,
          "position": 143
        },
        "endLoc": {
          "line": 117,
          "column": 19,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ";\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"LiteLLM chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/litellm.js",
        "start": 22,
        "end": 39,
        "startLoc": {
          "line": 22,
          "column": 20,
          "position": 190
        },
        "endLoc": {
          "line": 39,
          "column": 28,
          "position": 322
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 22,
        "end": 39,
        "startLoc": {
          "line": 22,
          "column": 6,
          "position": 173
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 65,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  getCost",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/litellm.js",
        "start": 41,
        "end": 105,
        "startLoc": {
          "line": 41,
          "column": 35,
          "position": 349
        },
        "endLoc": {
          "line": 105,
          "column": 8,
          "position": 770
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 110,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 753
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "),\n      apiKey: null,\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"KoboldCPP chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/koboldcpp.js",
        "start": 16,
        "end": 39,
        "startLoc": {
          "line": 16,
          "column": 3,
          "position": 142
        },
        "endLoc": {
          "line": 39,
          "column": 30,
          "position": 315
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/lmstudio.js",
        "start": 24,
        "end": 39,
        "startLoc": {
          "line": 24,
          "column": 19,
          "position": 164
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 77,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since KoboldCPP has no cost basis.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = KoboldCPPProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/koboldcpp.js",
        "start": 41,
        "end": 117,
        "startLoc": {
          "line": 41,
          "column": 37,
          "position": 342
        },
        "endLoc": {
          "line": 117,
          "column": 18,
          "position": 791
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 21,
          "position": 774
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"GroqAI chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/groq.js",
        "start": 18,
        "end": 40,
        "startLoc": {
          "line": 18,
          "column": 13,
          "position": 140
        },
        "endLoc": {
          "line": 40,
          "column": 27,
          "position": 305
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 16,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 77,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since LMStudio has no cost basis.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = GroqProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/groq.js",
        "start": 42,
        "end": 118,
        "startLoc": {
          "line": 42,
          "column": 34,
          "position": 332
        },
        "endLoc": {
          "line": 118,
          "column": 13,
          "position": 781
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 117,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 117,
          "column": 19,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ";\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/genericOpenAi.js",
        "start": 30,
        "end": 43,
        "startLoc": {
          "line": 30,
          "column": 5,
          "position": 242
        },
        "endLoc": {
          "line": 43,
          "column": 9,
          "position": 328
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 23,
        "end": 36,
        "startLoc": {
          "line": 23,
          "column": 5,
          "position": 183
        },
        "endLoc": {
          "line": 36,
          "column": 7,
          "position": 269
        }
      }
    },
    {
      "format": "javascript",
      "lines": 76,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = GenericOpenAiProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/genericOpenAi.js",
        "start": 49,
        "end": 124,
        "startLoc": {
          "line": 49,
          "column": 42,
          "position": 400
        },
        "endLoc": {
          "line": 124,
          "column": 22,
          "position": 849
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ",\n      maxRetries: 0,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  /**\n   * Format the messages to the format required by the Gemini API since some models do not support system prompts.\n   * @see {NO_SYSTEM_PROMPT_MODELS}\n   * @param {import(\"openai\").OpenAI.ChatCompletionMessage[]} messages\n   * @returns {import(\"openai\").OpenAI.ChatCompletionMessage[]}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/gemini.js",
        "start": 22,
        "end": 40,
        "startLoc": {
          "line": 22,
          "column": 15,
          "position": 174
        },
        "endLoc": {
          "line": 40,
          "column": 6,
          "position": 245
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/nvidiaNim.js",
        "start": 18,
        "end": 30,
        "startLoc": {
          "line": 18,
          "column": 5,
          "position": 136
        },
        "endLoc": {
          "line": 30,
          "column": 6,
          "position": 211
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/gemini.js",
        "start": 74,
        "end": 95,
        "startLoc": {
          "line": 74,
          "column": 34,
          "position": 538
        },
        "endLoc": {
          "line": 95,
          "column": 5,
          "position": 657
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 64,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 64,
          "column": 9,
          "position": 462
        }
      }
    },
    {
      "format": "javascript",
      "lines": 27,
      "fragment": ",\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/gemini.js",
        "start": 95,
        "end": 121,
        "startLoc": {
          "line": 95,
          "column": 2,
          "position": 668
        },
        "endLoc": {
          "line": 121,
          "column": 5,
          "position": 872
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 61,
        "end": 87,
        "startLoc": {
          "line": 61,
          "column": 9,
          "position": 451
        },
        "endLoc": {
          "line": 87,
          "column": 9,
          "position": 655
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw new",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/gemini.js",
        "start": 121,
        "end": 135,
        "startLoc": {
          "line": 121,
          "column": 2,
          "position": 878
        },
        "endLoc": {
          "line": 135,
          "column": 4,
          "position": 964
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 87,
        "end": 101,
        "startLoc": {
          "line": 87,
          "column": 9,
          "position": 656
        },
        "endLoc": {
          "line": 101,
          "column": 6,
          "position": 742
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      maxRetries: 0,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"FireworksAI chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/fireworksai.js",
        "start": 19,
        "end": 41,
        "startLoc": {
          "line": 19,
          "column": 25,
          "position": 141
        },
        "endLoc": {
          "line": 41,
          "column": 32,
          "position": 306
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/nvidiaNim.js",
        "start": 18,
        "end": 39,
        "startLoc": {
          "line": 18,
          "column": 5,
          "position": 136
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 76,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = FireworksAIProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/fireworksai.js",
        "start": 43,
        "end": 118,
        "startLoc": {
          "line": 43,
          "column": 39,
          "position": 333
        },
        "endLoc": {
          "line": 118,
          "column": 20,
          "position": 782
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ",\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        messages",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/dellProAiStudio.js",
        "start": 24,
        "end": 40,
        "startLoc": {
          "line": 24,
          "column": 5,
          "position": 166
        },
        "endLoc": {
          "line": 40,
          "column": 9,
          "position": 278
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 18,
        "end": 34,
        "startLoc": {
          "line": 18,
          "column": 2,
          "position": 147
        },
        "endLoc": {
          "line": 34,
          "column": 12,
          "position": 259
        }
      }
    },
    {
      "format": "javascript",
      "lines": 77,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since LMStudio has no cost basis.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = DellProAiStudioProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/dellProAiStudio.js",
        "start": 46,
        "end": 122,
        "startLoc": {
          "line": 46,
          "column": 43,
          "position": 344
        },
        "endLoc": {
          "line": 122,
          "column": 24,
          "position": 793
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 117,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 117,
          "column": 19,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ", 1024)\n      : 1024;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n        max_tokens: this.maxTokens,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"DeepSeek chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/deepseek.js",
        "start": 23,
        "end": 41,
        "startLoc": {
          "line": 23,
          "column": 20,
          "position": 227
        },
        "endLoc": {
          "line": 41,
          "column": 29,
          "position": 367
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/genericOpenAi.js",
        "start": 29,
        "end": 47,
        "startLoc": {
          "line": 29,
          "column": 27,
          "position": 233
        },
        "endLoc": {
          "line": 47,
          "column": 35,
          "position": 373
        }
      }
    },
    {
      "format": "javascript",
      "lines": 76,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = DeepSeekProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/deepseek.js",
        "start": 43,
        "end": 118,
        "startLoc": {
          "line": 43,
          "column": 36,
          "position": 394
        },
        "endLoc": {
          "line": 118,
          "column": 17,
          "position": 843
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": ";\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.invoke",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/bedrock.js",
        "start": 102,
        "end": 141,
        "startLoc": {
          "line": 102,
          "column": 8,
          "position": 710
        },
        "endLoc": {
          "line": 141,
          "column": 7,
          "position": 965
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 46,
        "end": 85,
        "startLoc": {
          "line": 46,
          "column": 2,
          "position": 375
        },
        "endLoc": {
          "line": 85,
          "column": 5,
          "position": 630
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ";\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   * Stubbed since KoboldCPP has no cost basis.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = AWSBedrockProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/bedrock.js",
        "start": 144,
        "end": 172,
        "startLoc": {
          "line": 144,
          "column": 9,
          "position": 992
        },
        "endLoc": {
          "line": 172,
          "column": 19,
          "position": 1096
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 89,
        "end": 116,
        "startLoc": {
          "line": 89,
          "column": 8,
          "position": 677
        },
        "endLoc": {
          "line": 116,
          "column": 21,
          "position": 774
        }
      }
    },
    {
      "format": "javascript",
      "lines": 63,
      "fragment": "\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the OpenAI API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      const response = await this.client.chat.completions.create({\n        model: this.model,\n        // stream: true,\n        messages,\n        ...(Array.isArray(functions) && functions?.length > 0\n          ? { functions }\n          : {}),\n      });\n\n      // Right now, we only support one completion,\n      // so we just take the first one in the list\n      const completion = response.choices[0].message;\n      const cost = this.getCost(response.usage);\n      // treat function calls\n      if (completion.function_call) {\n        let functionArgs = {};\n        try {\n          functionArgs = JSON.parse(completion.function_call.arguments);\n        } catch (error) {\n          // call the complete function again in case it gets a json error\n          return this.complete(\n            [\n              ...messages,\n              {\n                role: \"function\",\n                name: completion.function_call.name,\n                function_call: completion.function_call,\n                content: error?.message,\n              },\n            ],\n            functions\n          );\n        }\n\n        // console.log(completion, { functionArgs })\n        return {\n          result: null,\n          functionCall: {\n            name: completion.function_call.name,\n            arguments: functionArgs,\n          },\n          cost,\n        };\n      }\n\n      return {\n        result: completion.content,\n        cost,\n      };\n    } catch (error) {\n      // If invalid Auth error we need to abort because no amount of waiting\n      // will make auth better.\n      if (error instanceof AzureOpenAI",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/azure.js",
        "start": 20,
        "end": 82,
        "startLoc": {
          "line": 20,
          "column": 2,
          "position": 168
        },
        "endLoc": {
          "line": 82,
          "column": 12,
          "position": 554
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/openai.js",
        "start": 57,
        "end": 119,
        "startLoc": {
          "line": 57,
          "column": 1,
          "position": 340
        },
        "endLoc": {
          "line": 119,
          "column": 7,
          "position": 726
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      maxRetries: 3,\n    });\n\n    this._client = client;\n    this.model = model;\n    this.verbose = true;\n  }\n\n  get client() {\n    return this._client;\n  }\n\n  async #handleFunctionCallChat({ messages = [] }) {\n    return await this.client.chat.completions\n      .create({\n        model: this.model,\n        temperature: 0,\n        messages,\n      })\n      .then((result) => {\n        if (!result.hasOwnProperty(\"choices\"))\n          throw new Error(\"ApiPie chat: No results!\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/apipie.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 19,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 27,
          "position": 305
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 17,
        "end": 39,
        "startLoc": {
          "line": 17,
          "column": 16,
          "position": 140
        },
        "endLoc": {
          "line": 39,
          "column": 24,
          "position": 305
        }
      }
    },
    {
      "format": "javascript",
      "lines": 76,
      "fragment": ");\n        return result.choices[0].message.content;\n      })\n      .catch((_) => {\n        return null;\n      });\n  }\n\n  /**\n   * Create a completion based on the received messages.\n   *\n   * @param messages A list of messages to send to the API.\n   * @param functions\n   * @returns The completion.\n   */\n  async complete(messages, functions = []) {\n    try {\n      let completion;\n      if (functions.length > 0) {\n        const { toolCall, text } = await this.functionCall(\n          messages,\n          functions,\n          this.#handleFunctionCallChat.bind(this)\n        );\n\n        if (toolCall !== null) {\n          this.providerLog(`Valid tool call found - running ${toolCall.name}.`);\n          this.deduplicator.trackRun(toolCall.name, toolCall.arguments);\n          return {\n            result: null,\n            functionCall: {\n              name: toolCall.name,\n              arguments: toolCall.arguments,\n            },\n            cost: 0,\n          };\n        }\n        completion = { content: text };\n      }\n\n      if (!completion?.content) {\n        this.providerLog(\n          \"Will assume chat completion without tool call inputs.\"\n        );\n        const response = await this.client.chat.completions.create({\n          model: this.model,\n          messages: this.cleanMsgs(messages),\n        });\n        completion = response.choices[0].message;\n      }\n\n      // The UnTooled class inherited Deduplicator is mostly useful to prevent the agent\n      // from calling the exact same function over and over in a loop within a single chat exchange\n      // _but_ we should enable it to call previously used tools in a new chat interaction.\n      this.deduplicator.reset(\"runs\");\n      return {\n        result: completion.content,\n        cost: 0,\n      };\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  /**\n   * Get the cost of the completion.\n   *\n   * @param _usage The completion to get the cost for.\n   * @returns The cost of the completion.\n   */\n  getCost(_usage) {\n    return 0;\n  }\n}\n\nmodule.exports = ApiPieProvider",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/providers/apipie.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 34,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 15,
          "position": 781
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/xai.js",
        "start": 41,
        "end": 116,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 332
        },
        "endLoc": {
          "line": 116,
          "column": 12,
          "position": 781
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n  startupConfig: {\n    params: {},\n  },\n  plugin: function () {\n    return {\n      name: this.name,\n      setup(aibitat) {\n        aibitat.function({\n          super: aibitat,\n          name: this.name,\n          countTokens",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 6,
        "end": 17,
        "startLoc": {
          "line": 6,
          "column": 15,
          "position": 59
        },
        "endLoc": {
          "line": 17,
          "column": 12,
          "position": 136
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-scraping.js",
        "start": 6,
        "end": 17,
        "startLoc": {
          "line": 6,
          "column": 15,
          "position": 58
        },
        "endLoc": {
          "line": 17,
          "column": 11,
          "position": 135
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "});\n\n            if (data.length === 0)\n              return `No information was found online for the search query.`;\n\n            const result = JSON.stringify(data);\n            this.super.introspect(\n              `${this.caller}: I found ${data.length} results - reviewing the results now. (~${this.countTokens(result)} tokens)`\n            );\n            return result;\n          },\n\n          /**\n           * Use Serper.dev\n           * Free to set up, easy to use, 2,500 calls for free one-time\n           * https://serper.dev\n           */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 232,
        "end": 248,
        "startLoc": {
          "line": 232,
          "column": 13,
          "position": 1832
        },
        "endLoc": {
          "line": 248,
          "column": 14,
          "position": 1920
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 158,
        "end": 174,
        "startLoc": {
          "line": 158,
          "column": 15,
          "position": 1186
        },
        "endLoc": {
          "line": 174,
          "column": 14,
          "position": 1274
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": "?.forEach((searchResult) => {\n              const { title, link, snippet } = searchResult;\n              data.push({\n                title,\n                link,\n                snippet,\n              });\n            });\n\n            if (data.length === 0)\n              return `No information was found online for the search query.`;\n\n            const result = JSON.stringify(data);\n            this.super.introspect(\n              `${this.caller}: I found ${data.length} results - reviewing the results now. (~${this.countTokens(result)} tokens)`\n            );\n            return result;\n          },\n          ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 293,
        "end": 311,
        "startLoc": {
          "line": 293,
          "column": 8,
          "position": 2346
        },
        "endLoc": {
          "line": 311,
          "column": 11,
          "position": 2489
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 225,
        "end": 170,
        "startLoc": {
          "line": 225,
          "column": 16,
          "position": 1775
        },
        "endLoc": {
          "line": 170,
          "column": 1,
          "position": 1272
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n              });\n            });\n\n            if (data.length === 0)\n              return `No information was found online for the search query.`;\n\n            const result = JSON.stringify(data);\n            this.super.introspect(\n              `${this.caller}: I found ${data.length} results - reviewing the results now. (~${this.countTokens(result)} tokens)`\n            );\n            return result;\n          },\n          _searXNGEngine",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 436,
        "end": 449,
        "startLoc": {
          "line": 436,
          "column": 12,
          "position": 3559
        },
        "endLoc": {
          "line": 449,
          "column": 15,
          "position": 3654
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 230,
        "end": 311,
        "startLoc": {
          "line": 230,
          "column": 8,
          "position": 1824
        },
        "endLoc": {
          "line": 311,
          "column": 15,
          "position": 2490
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n              });\n            });\n\n            if (data.length === 0)\n              return `No information was found online for the search query.`;\n\n            const result = JSON.stringify(data);\n            this.super.introspect(\n              `${this.caller}: I found ${data.length} results - reviewing the results now. (~${this.countTokens(result)} tokens)`\n            );\n            return result;\n          },\n          _tavilySearch",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 508,
        "end": 521,
        "startLoc": {
          "line": 508,
          "column": 14,
          "position": 4198
        },
        "endLoc": {
          "line": 521,
          "column": 14,
          "position": 4293
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 230,
        "end": 311,
        "startLoc": {
          "line": 230,
          "column": 8,
          "position": 1824
        },
        "endLoc": {
          "line": 311,
          "column": 15,
          "position": 2490
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n              });\n            });\n\n            if (data.length === 0)\n              return `No information was found online for the search query.`;\n\n            const result = JSON.stringify(data);\n            this.super.introspect(\n              `${this.caller}: I found ${data.length} results - reviewing the results now. (~${this.countTokens(result)} tokens)`\n            );\n            return result;\n          },\n          _duckDuckGoEngine",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 571,
        "end": 584,
        "startLoc": {
          "line": 571,
          "column": 8,
          "position": 4755
        },
        "endLoc": {
          "line": 584,
          "column": 18,
          "position": 4850
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-browsing.js",
        "start": 230,
        "end": 311,
        "startLoc": {
          "line": 230,
          "column": 8,
          "position": 1824
        },
        "endLoc": {
          "line": 311,
          "column": 15,
          "position": 2490
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n  startupConfig: {\n    params: {},\n  },\n  plugin: function () {\n    return {\n      name: this.name,\n      setup(aibitat) {\n        aibitat.function({\n          super: aibitat,\n          name: this.name,\n          controller: new AbortController(),\n          description:\n            \"Can get the list of files available to search with descriptions and can select a single file to open and summarize.\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/summarize.js",
        "start": 7,
        "end": 20,
        "startLoc": {
          "line": 7,
          "column": 22,
          "position": 74
        },
        "endLoc": {
          "line": 20,
          "column": 118,
          "position": 166
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-scraping.js",
        "start": 6,
        "end": 19,
        "startLoc": {
          "line": 6,
          "column": 15,
          "position": 58
        },
        "endLoc": {
          "line": 19,
          "column": 75,
          "position": 150
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n  startupConfig: {\n    params: {},\n  },\n  plugin: function () {\n    return {\n      name: this.name,\n      setup(aibitat) {\n        aibitat.function({\n          super: aibitat,\n          tracker",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/memory.js",
        "start": 6,
        "end": 16,
        "startLoc": {
          "line": 6,
          "column": 13,
          "position": 65
        },
        "endLoc": {
          "line": 16,
          "column": 8,
          "position": 133
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/web-scraping.js",
        "start": 6,
        "end": 16,
        "startLoc": {
          "line": 6,
          "column": 15,
          "position": 58
        },
        "endLoc": {
          "line": 16,
          "column": 5,
          "position": 126
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n              }),\n            },\n          ],\n          parameters: {\n            $schema: \"http://json-schema.org/draft-07/schema#\",\n            type: \"object\",\n            properties: {\n              action: {\n                type: \"string\",\n                enum: [\"search\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/memory.js",
        "start": 46,
        "end": 56,
        "startLoc": {
          "line": 46,
          "column": 45,
          "position": 327
        },
        "endLoc": {
          "line": 56,
          "column": 9,
          "position": 386
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/summarize.js",
        "start": 37,
        "end": 47,
        "startLoc": {
          "line": 37,
          "column": 12,
          "position": 289
        },
        "endLoc": {
          "line": 47,
          "column": 7,
          "position": 348
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ": {\n        required: true,\n      },\n      muteUserReply: {\n        required: false,\n        default: true,\n      },\n      introspection: {\n        required: false,\n        default: true,\n      },\n    },\n  },\n  plugin: function ({\n    handler",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/http-socket.js",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 8,
          "position": 60
        },
        "endLoc": {
          "line": 27,
          "column": 8,
          "position": 141
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/websocket.js",
        "start": 29,
        "end": 43,
        "startLoc": {
          "line": 29,
          "column": 7,
          "position": 129
        },
        "endLoc": {
          "line": 43,
          "column": 7,
          "position": 210
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "\n    muteUserReply = true, // Do not post messages to \"USER\" back to frontend.\n    introspection = false, // when enabled will attach socket to Aibitat object with .introspect method which reports status updates to frontend.\n  }) {\n    return {\n      name: this.name,\n      setup(aibitat) {\n        aibitat.onError(async (error) => {\n          let errorMessage =\n            error?.message || \"An error occurred while running the agent.\";\n          console.error(chalk.red(`   error: ${errorMessage}`), error);\n          aibitat.introspect(\n            `Error encountered while running: ${errorMessage}`\n          );\n          handler",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/aibitat/plugins/http-socket.js",
        "start": 27,
        "end": 41,
        "startLoc": {
          "line": 27,
          "column": 2,
          "position": 143
        },
        "endLoc": {
          "line": 41,
          "column": 8,
          "position": 264
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/plugins/websocket.js",
        "start": 43,
        "end": 57,
        "startLoc": {
          "line": 43,
          "column": 26,
          "position": 214
        },
        "endLoc": {
          "line": 57,
          "column": 7,
          "position": 335
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "\n  },\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const result = {\n      contextTexts: [],\n      sourceDocuments: [],\n      scores: [],\n    };\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 75,
        "end": 91,
        "startLoc": {
          "line": 75,
          "column": 2,
          "position": 843
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 939
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 324,
        "end": 339,
        "startLoc": {
          "line": 324,
          "column": 2,
          "position": 3175
        },
        "endLoc": {
          "line": 339,
          "column": 5,
          "position": 3271
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 177,
        "end": 187,
        "startLoc": {
          "line": 177,
          "column": 2,
          "position": 1914
        },
        "endLoc": {
          "line": 187,
          "column": 6,
          "position": 1985
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 136,
        "end": 146,
        "startLoc": {
          "line": 136,
          "column": 2,
          "position": 1335
        },
        "endLoc": {
          "line": 146,
          "column": 4,
          "position": 1406
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 252,
        "end": 273,
        "startLoc": {
          "line": 252,
          "column": 18,
          "position": 2529
        },
        "endLoc": {
          "line": 273,
          "column": 7,
          "position": 2712
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 186,
        "end": 208,
        "startLoc": {
          "line": 186,
          "column": 1,
          "position": 1846
        },
        "endLoc": {
          "line": 208,
          "column": 1,
          "position": 2029
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ";\n\n          vectors.push(vectorRecord);\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 294,
        "end": 305,
        "startLoc": {
          "line": 294,
          "column": 2,
          "position": 2915
        },
        "endLoc": {
          "line": 305,
          "column": 6,
          "position": 2978
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 217,
        "end": 228,
        "startLoc": {
          "line": 217,
          "column": 2,
          "position": 2146
        },
        "endLoc": {
          "line": 228,
          "column": 3,
          "position": 2209
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  deleteDocumentFromNamespace: async function (namespace, docId) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) return;\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 333,
        "end": 348,
        "startLoc": {
          "line": 333,
          "column": 13,
          "position": 3237
        },
        "endLoc": {
          "line": 348,
          "column": 1,
          "position": 3404
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 254,
        "end": 268,
        "startLoc": {
          "line": 254,
          "column": 2,
          "position": 2479
        },
        "endLoc": {
          "line": 268,
          "column": 5,
          "position": 2646
        }
      }
    },
    {
      "format": "javascript",
      "lines": 43,
      "fragment": ");\n    return true;\n  },\n  performSimilaritySearch: async function ({\n    namespace = null,\n    input = \"\",\n    LLMConnector = null,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) {\n      return {\n        contextTexts: [],\n        sources: [],\n        message: \"Invalid query - no documents found for workspace!\",\n      };\n    }\n\n    const queryVector = await LLMConnector.embedTextInput(input);\n    const { contextTexts, sourceDocuments } = await this.similarityResponse({\n      client,\n      namespace,\n      queryVector,\n      similarityThreshold,\n      topN,\n      filterIdentifiers,\n    });\n\n    const sources = sourceDocuments.map((metadata, i) => {\n      return { ...metadata, text: contextTexts[i] };\n    });\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  \"namespace-stats\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 360,
        "end": 402,
        "startLoc": {
          "line": 360,
          "column": 8,
          "position": 3532
        },
        "endLoc": {
          "line": 402,
          "column": 18,
          "position": 3872
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 284,
        "end": 326,
        "startLoc": {
          "line": 284,
          "column": 2,
          "position": 2841
        },
        "endLoc": {
          "line": 326,
          "column": 19,
          "position": 3181
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n      );\n\n    return { client };\n  },\n  heartbeat: async function () {\n    await this.connect();\n    return { heartbeat: Number(new Date()) };\n  },\n  totalVectors: async function () {\n    const { client } = await this.connect();\n    const { collections",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 25,
        "end": 36,
        "startLoc": {
          "line": 25,
          "column": 63,
          "position": 289
        },
        "endLoc": {
          "line": 36,
          "column": 12,
          "position": 394
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 40,
        "end": 51,
        "startLoc": {
          "line": 40,
          "column": 63,
          "position": 363
        },
        "endLoc": {
          "line": 51,
          "column": 17,
          "position": 468
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ";\n  },\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const result = {\n      contextTexts: [],\n      sourceDocuments: [],\n      scores: [],\n    };\n\n    const responses",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 48,
        "end": 64,
        "startLoc": {
          "line": 48,
          "column": 2,
          "position": 564
        },
        "endLoc": {
          "line": 64,
          "column": 10,
          "position": 665
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 324,
        "end": 91,
        "startLoc": {
          "line": 324,
          "column": 2,
          "position": 3174
        },
        "endLoc": {
          "line": 91,
          "column": 14,
          "position": 943
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ";\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      let vectorDimension = null;\n      const { pageContent, docId, ...metadata } = documentData;\n      if (!pageContent || pageContent.length == 0) return false;\n\n      console.log(\"Adding new vectorized document into namespace\", namespace);\n      if (skipCache) {\n        const cacheResult = await cachedVectorInformation(fullFilePath);\n        if (cacheResult.exists) {\n          const { client } = await this.connect();\n          const { chunks } = cacheResult;\n          const documentVectors = [];\n          vectorDimension =\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 134,
        "end": 156,
        "startLoc": {
          "line": 134,
          "column": 2,
          "position": 1356
        },
        "endLoc": {
          "line": 156,
          "column": 1,
          "position": 1578
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 177,
        "end": 157,
        "startLoc": {
          "line": 177,
          "column": 5,
          "position": 1913
        },
        "endLoc": {
          "line": 157,
          "column": 2,
          "position": 1556
        }
      }
    },
    {
      "format": "javascript",
      "lines": 27,
      "fragment": "\n      // because we then cannot atomically control our namespace to granularly find/remove documents\n      // from vectordb.\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n      const submission = {\n        ids: [],\n        vectors: [],\n        payloads",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 209,
        "end": 235,
        "startLoc": {
          "line": 209,
          "column": 85,
          "position": 2006
        },
        "endLoc": {
          "line": 235,
          "column": 9,
          "position": 2221
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 250,
        "end": 276,
        "startLoc": {
          "line": 250,
          "column": 85,
          "position": 2523
        },
        "endLoc": {
          "line": 276,
          "column": 11,
          "position": 2738
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ");\n\n          vectors.push(vectorRecord);\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      const { client } = await this.connect();\n      const collection",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 252,
        "end": 264,
        "startLoc": {
          "line": 252,
          "column": 8,
          "position": 2391
        },
        "endLoc": {
          "line": 264,
          "column": 11,
          "position": 2477
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 294,
        "end": 306,
        "startLoc": {
          "line": 294,
          "column": 9,
          "position": 2914
        },
        "endLoc": {
          "line": 306,
          "column": 19,
          "position": 3000
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "\n        await storeVectorResult(chunks, fullFilePath);\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  deleteDocumentFromNamespace: async function (namespace, docId) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) return;\n\n    const knownDocuments = await DocumentVectors.where({ docId });\n    if (knownDocuments.length === 0) return;\n\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 290,
        "end": 309,
        "startLoc": {
          "line": 290,
          "column": 1,
          "position": 2692
        },
        "endLoc": {
          "line": 309,
          "column": 6,
          "position": 2909
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 332,
        "end": 351,
        "startLoc": {
          "line": 332,
          "column": 2,
          "position": 3227
        },
        "endLoc": {
          "line": 351,
          "column": 4,
          "position": 3444
        }
      }
    },
    {
      "format": "javascript",
      "lines": 63,
      "fragment": "\n\n    const indexes = knownDocuments.map((doc) => doc.id);\n    await DocumentVectors.deleteIds(indexes);\n    return true;\n  },\n  performSimilaritySearch: async function ({\n    namespace = null,\n    input = \"\",\n    LLMConnector = null,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) {\n      return {\n        contextTexts: [],\n        sources: [],\n        message: \"Invalid query - no documents found for workspace!\",\n      };\n    }\n\n    const queryVector = await LLMConnector.embedTextInput(input);\n    const { contextTexts, sourceDocuments } = await this.similarityResponse({\n      client,\n      namespace,\n      queryVector,\n      similarityThreshold,\n      topN,\n      filterIdentifiers,\n    });\n\n    const sources = sourceDocuments.map((metadata, i) => {\n      return { ...metadata, text: contextTexts[i] };\n    });\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  \"namespace-stats\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    if (!namespace) throw new Error(\"namespace required\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n    const stats = await this.namespace(client, namespace);\n    return stats\n      ? stats\n      : { message: \"No stats were able to be fetched from DB for namespace\" };\n  },\n  \"delete-namespace\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n\n    const details",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 313,
        "end": 375,
        "startLoc": {
          "line": 313,
          "column": 2,
          "position": 2961
        },
        "endLoc": {
          "line": 375,
          "column": 8,
          "position": 3578
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 357,
        "end": 375,
        "startLoc": {
          "line": 357,
          "column": 2,
          "position": 3499
        },
        "endLoc": {
          "line": 375,
          "column": 11,
          "position": 3686
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ");\n    }\n    return { reset: true };\n  },\n  curateSources: function (sources = []) {\n    const documents = [];\n    for (const source of sources) {\n      if (Object.keys(source).length > 0) {\n        const metadata = source.hasOwnProperty(\"metadata\")\n          ? source.metadata\n          : source;\n        documents.push({\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 385,
        "end": 397,
        "startLoc": {
          "line": 385,
          "column": 5,
          "position": 3716
        },
        "endLoc": {
          "line": 397,
          "column": 1,
          "position": 3835
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 426,
        "end": 437,
        "startLoc": {
          "line": 426,
          "column": 2,
          "position": 4201
        },
        "endLoc": {
          "line": 437,
          "column": 2,
          "position": 4320
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": " || 0;\n  },\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const result = {\n      contextTexts: [],\n      sourceDocuments: [],\n      scores: [],\n    };\n\n    const pineconeNamespace",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 37,
        "end": 53,
        "startLoc": {
          "line": 37,
          "column": 12,
          "position": 468
        },
        "endLoc": {
          "line": 53,
          "column": 18,
          "position": 573
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 48,
        "end": 91,
        "startLoc": {
          "line": 48,
          "column": 12,
          "position": 560
        },
        "endLoc": {
          "line": 91,
          "column": 14,
          "position": 943
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "();\n    return true;\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      const { ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 93,
        "end": 104,
        "startLoc": {
          "line": 93,
          "column": 10,
          "position": 1025
        },
        "endLoc": {
          "line": 104,
          "column": 2,
          "position": 1108
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 176,
        "end": 188,
        "startLoc": {
          "line": 176,
          "column": 3,
          "position": 1905
        },
        "endLoc": {
          "line": 188,
          "column": 1,
          "position": 1988
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n\n      if (!!vectorValues && vectorValues.length > 0) {\n        for (const [i, vector] of vectorValues.entries()) {\n          const vectorRecord",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 136,
        "end": 160,
        "startLoc": {
          "line": 136,
          "column": 134,
          "position": 1417
        },
        "endLoc": {
          "line": 160,
          "column": 13,
          "position": 1649
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 186,
        "end": 281,
        "startLoc": {
          "line": 186,
          "column": 1,
          "position": 1846
        },
        "endLoc": {
          "line": 281,
          "column": 18,
          "position": 2798
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "\n            metadata: { ...metadata, text: textChunks[i] },\n          };\n\n          vectors.push(vectorRecord);\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      if (vectors.length > 0) {\n        const chunks = [];\n        const { pineconeIndex",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 165,
        "end": 180,
        "startLoc": {
          "line": 165,
          "column": 133,
          "position": 1679
        },
        "endLoc": {
          "line": 180,
          "column": 14,
          "position": 1796
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 215,
        "end": 230,
        "startLoc": {
          "line": 215,
          "column": 101,
          "position": 2122
        },
        "endLoc": {
          "line": 230,
          "column": 7,
          "position": 2239
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ");\n        }\n        await storeVectorResult(chunks, fullFilePath);\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  deleteDocumentFromNamespace: async function (namespace, docId) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    const { pineconeIndex",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 185,
        "end": 199,
        "startLoc": {
          "line": 185,
          "column": 2,
          "position": 1876
        },
        "endLoc": {
          "line": 199,
          "column": 14,
          "position": 2020
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 331,
        "end": 266,
        "startLoc": {
          "line": 331,
          "column": 32,
          "position": 3222
        },
        "endLoc": {
          "line": 266,
          "column": 7,
          "position": 2608
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ";\n  },\n  performSimilaritySearch: async function ({\n    namespace = null,\n    input = \"\",\n    LLMConnector = null,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { pineconeIndex",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 237,
        "end": 250,
        "startLoc": {
          "line": 237,
          "column": 2,
          "position": 2516
        },
        "endLoc": {
          "line": 250,
          "column": 14,
          "position": 2623
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 285,
        "end": 298,
        "startLoc": {
          "line": 285,
          "column": 5,
          "position": 2848
        },
        "endLoc": {
          "line": 298,
          "column": 7,
          "position": 2955
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ",\n      namespace,\n      queryVector,\n      similarityThreshold,\n      topN,\n      filterIdentifiers,\n    });\n\n    const sources = sourceDocuments.map((metadata, i) => {\n      return { ...metadata, text: contextTexts[i] };\n    });\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  curateSources",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 258,
        "end": 275,
        "startLoc": {
          "line": 258,
          "column": 14,
          "position": 2718
        },
        "endLoc": {
          "line": 275,
          "column": 14,
          "position": 2830
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 309,
        "end": 326,
        "startLoc": {
          "line": 309,
          "column": 7,
          "position": 3069
        },
        "endLoc": {
          "line": 326,
          "column": 19,
          "position": 3181
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ",\n    };\n  },\n  curateSources: function (sources = []) {\n    const documents = [];\n    for (const source of sources) {\n      const { metadata = {} } = source;\n      if (Object.keys(metadata).length > 0) {\n        documents.push({\n          ...metadata,\n          ...(source.hasOwnProperty(\"pageContent\")\n            ? { text: source.pageContent }\n            : {}),\n        });\n      }\n    }\n\n    return documents;\n  },\n};\n\nmodule.exports.Pinecone",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pinecone/index.js",
        "start": 272,
        "end": 293,
        "startLoc": {
          "line": 272,
          "column": 6,
          "position": 2819
        },
        "endLoc": {
          "line": 293,
          "column": 9,
          "position": 2985
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 379,
        "end": 400,
        "startLoc": {
          "line": 379,
          "column": 11,
          "position": 3759
        },
        "endLoc": {
          "line": 400,
          "column": 7,
          "position": 3925
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "\n      );\n      return result.rows[0].count;\n    } catch (err) {\n      return 0;\n    } finally {\n      if (connection) await connection.end();\n    }\n  },\n\n  /**\n   * Performs a SimilaritySearch on a given PGVector namespace.\n   * @param {Object} params\n   * @param {pgsql.Client} params.client\n   * @param {string} params.namespace\n   * @param {number[]} params.queryVector\n   * @param {number} params.similarityThreshold\n   * @param {number} params.topN\n   * @param {string[]} params.filterIdentifiers\n   * @returns\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 293,
        "end": 313,
        "startLoc": {
          "line": 293,
          "column": 2,
          "position": 2193
        },
        "endLoc": {
          "line": 313,
          "column": 6,
          "position": 2260
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 268,
        "end": 278,
        "startLoc": {
          "line": 268,
          "column": 3,
          "position": 1928
        },
        "endLoc": {
          "line": 278,
          "column": 58,
          "position": 1995
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const result = {\n      contextTexts: [],\n      sourceDocuments: [],\n      scores: [],\n    };\n\n    const embedding",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 313,
        "end": 328,
        "startLoc": {
          "line": 313,
          "column": 6,
          "position": 2261
        },
        "endLoc": {
          "line": 328,
          "column": 10,
          "position": 2357
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 325,
        "end": 91,
        "startLoc": {
          "line": 325,
          "column": 2,
          "position": 3179
        },
        "endLoc": {
          "line": 91,
          "column": 14,
          "position": 943
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ";\n    } catch (err) {\n      return false;\n    } finally {\n      if (connection) await connection.end();\n    }\n  },\n\n  /**\n   * Check if the namespace exists in the database\n   * @param {pgsql.Client} connection\n   * @param {string} namespace\n   * @returns {Promise<boolean>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 437,
        "end": 450,
        "startLoc": {
          "line": 437,
          "column": 2,
          "position": 3211
        },
        "endLoc": {
          "line": 450,
          "column": 6,
          "position": 3262
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 254,
        "end": 262,
        "startLoc": {
          "line": 254,
          "column": 12,
          "position": 1791
        },
        "endLoc": {
          "line": 262,
          "column": 13,
          "position": 1842
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 525,
        "end": 542,
        "startLoc": {
          "line": 525,
          "column": 2,
          "position": 3913
        },
        "endLoc": {
          "line": 542,
          "column": 5,
          "position": 4044
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 186,
        "end": 203,
        "startLoc": {
          "line": 186,
          "column": 1,
          "position": 1846
        },
        "endLoc": {
          "line": 203,
          "column": 8,
          "position": 1977
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ");\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      if (vectors.length > 0) {\n        const chunks = [];\n        for",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 563,
        "end": 574,
        "startLoc": {
          "line": 563,
          "column": 2,
          "position": 4272
        },
        "endLoc": {
          "line": 574,
          "column": 4,
          "position": 4352
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 219,
        "end": 230,
        "startLoc": {
          "line": 219,
          "column": 13,
          "position": 2155
        },
        "endLoc": {
          "line": 230,
          "column": 6,
          "position": 2235
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "const {\n  DataType,\n  MetricType,\n  IndexType,\n  MilvusClient,\n} = require(\"@zilliz/milvus2-sdk-node\");\nconst { TextSplitter } = require(\"../../TextSplitter\");\nconst { SystemSettings } = require(\"../../../models/systemSettings\");\nconst { v4: uuidv4 } = require(\"uuid\");\nconst { storeVectorResult, cachedVectorInformation } = require(\"../../files\");\nconst { toChunks, getEmbeddingEngineSelection } = require(\"../../helpers\");\nconst { sourceIdentifier } = require(\"../../chats\");\n\nconst",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 1,
        "end": 14,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 14,
          "column": 6,
          "position": 136
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 1,
        "end": 14,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 14,
          "column": 78,
          "position": 136
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n  // Milvus/Zilliz only allows letters, numbers, and underscores in collection names\n  // so we need to enforce that by re-normalizing the names when communicating with\n  // the DB.\n  // If the first char of the collection is not an underscore or letter the collection name will be invalid.\n  normalize: function (inputString) {\n    let normalized = inputString.replace(/[^a-zA-Z0-9_]/g, \"_\");\n    if (new RegExp(/^[a-zA-Z_]/).test(normalized.slice(0, 1)))\n      normalized = `anythingllm_${normalized}`;\n    return normalized;\n  },\n  connect: async function () {\n    if (process.env.VECTOR_DB !== \"milvus\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 15,
        "end": 27,
        "startLoc": {
          "line": 15,
          "column": 9,
          "position": 149
        },
        "endLoc": {
          "line": 27,
          "column": 9,
          "position": 265
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 17,
        "end": 29,
        "startLoc": {
          "line": 17,
          "column": 9,
          "position": 153
        },
        "endLoc": {
          "line": 29,
          "column": 9,
          "position": 269
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": "\n      );\n\n    return { client };\n  },\n  heartbeat: async function () {\n    await this.connect();\n    return { heartbeat: Number(new Date()) };\n  },\n  totalVectors: async function () {\n    const { client } = await this.connect();\n    const { collection_names } = await client.listCollections();\n    const total = collection_names.reduce(async (acc, collection_name) => {\n      const statistics = await client.getCollectionStatistics({\n        collection_name: this.normalize(collection_name),\n      });\n      return Number(acc) + Number(statistics?.data?.row_count ?? 0);\n    }, 0);\n    return total;\n  },\n  namespaceCount: async function (_namespace = null) {\n    const { client } = await this.connect();\n    const statistics = await client.getCollectionStatistics({\n      collection_name: this.normalize(_namespace),\n    });\n    return Number(statistics?.data?.row_count ?? 0);\n  },\n  namespace: async function (client, namespace = null) {\n    if (!namespace) throw new Error(\"No namespace value provided.\");\n    const collection = await client\n      .getCollectionStatistics({ collection_name: this.normalize(namespace) })\n      .catch(() => null);\n    return collection;\n  },\n  hasNamespace: async function (namespace = null) {\n    if (!namespace) return false;\n    const { client } = await this.connect();\n    return await this.namespaceExists(client, namespace);\n  },\n  namespaceExists: async function (client, namespace = null) {\n    if (!namespace) throw new Error(\"No namespace value provided.\");\n    const { value } = await client\n      .hasCollection({ collection_name: this.normalize(namespace) })\n      .catch((e) => {\n        console.error(\"MilvusDB::namespaceExists\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 39,
        "end": 83,
        "startLoc": {
          "line": 39,
          "column": 65,
          "position": 370
        },
        "endLoc": {
          "line": 83,
          "column": 28,
          "position": 938
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 40,
        "end": 84,
        "startLoc": {
          "line": 40,
          "column": 63,
          "position": 363
        },
        "endLoc": {
          "line": 84,
          "column": 26,
          "position": 931
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "\n        );\n\n      await client.createCollection({\n        collection_name: this.normalize(namespace),\n        fields: [\n          {\n            name: \"id\",\n            description: \"id\",\n            data_type: DataType.VarChar,\n            max_length: 255,\n            is_primary_key: true,\n          },\n          {\n            name: \"vector\",\n            description: \"vector\",\n            data_type: DataType.FloatVector,\n            dim: dimensions,\n          },\n          {\n            name: \"metadata\",\n            decription",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 100,
        "end": 121,
        "startLoc": {
          "line": 100,
          "column": 113,
          "position": 1110
        },
        "endLoc": {
          "line": 121,
          "column": 11,
          "position": 1235
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 101,
        "end": 122,
        "startLoc": {
          "line": 101,
          "column": 113,
          "position": 1103
        },
        "endLoc": {
          "line": 122,
          "column": 12,
          "position": 1228
        }
      }
    },
    {
      "format": "javascript",
      "lines": 39,
      "fragment": ": \"metadata\",\n            data_type: DataType.JSON,\n          },\n        ],\n      });\n      await client.createIndex({\n        collection_name: this.normalize(namespace),\n        field_name: \"vector\",\n        index_type: IndexType.AUTOINDEX,\n        metric_type: MetricType.COSINE,\n      });\n      await client.loadCollectionSync({\n        collection_name: this.normalize(namespace),\n      });\n    }\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      let vectorDimension = null;\n      const { pageContent, docId, ...metadata } = documentData;\n      if (!pageContent || pageContent.length == 0) return false;\n\n      console.log(\"Adding new vectorized document into namespace\", namespace);\n      if (skipCache) {\n        const cacheResult = await cachedVectorInformation(fullFilePath);\n        if (cacheResult.exists) {\n          const { client } = await this.connect();\n          const { chunks } = cacheResult;\n          const documentVectors = [];\n          vectorDimension = chunks[0][0].values.length || null;\n\n          await this.getOrCreateCollection(client, namespace, vectorDimension);\n          try",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 121,
        "end": 159,
        "startLoc": {
          "line": 121,
          "column": 11,
          "position": 1236
        },
        "endLoc": {
          "line": 159,
          "column": 4,
          "position": 1600
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 122,
        "end": 160,
        "startLoc": {
          "line": 122,
          "column": 12,
          "position": 1229
        },
        "endLoc": {
          "line": 160,
          "column": 4,
          "position": 1593
        }
      }
    },
    {
      "format": "javascript",
      "lines": 51,
      "fragment": "\n        }\n      }\n\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n\n      if (!!vectorValues && vectorValues.length > 0) {\n        for (const [i, vector] of vectorValues.entries()) {\n          if (!vectorDimension) vectorDimension = vector.length;\n          const vectorRecord = {\n            id: uuidv4(),\n            values: vector,\n            // [DO NOT REMOVE]\n            // LangChain will be unable to find your text if you embed manually and dont include the `text` key.\n            metadata: { ...metadata, text: textChunks[i] },\n          };\n\n          vectors.push(vectorRecord);\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      if (vectors.length > 0) {\n        const chunks = [];\n        const { client } = await this.connect();\n        await this.getOrCreateCollection(client, namespace, vectorDimension);\n\n        console.log(\"Inserting vectorized chunks into Milvus.\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 190,
        "end": 240,
        "startLoc": {
          "line": 190,
          "column": 2,
          "position": 1905
        },
        "endLoc": {
          "line": 240,
          "column": 43,
          "position": 2343
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 183,
        "end": 233,
        "startLoc": {
          "line": 183,
          "column": 2,
          "position": 1839
        },
        "endLoc": {
          "line": 233,
          "column": 43,
          "position": 2277
        }
      }
    },
    {
      "format": "javascript",
      "lines": 35,
      "fragment": "${insertResult?.status.reason}`\n            );\n          }\n        }\n        await storeVectorResult(chunks, fullFilePath);\n        await client.flushSync({\n          collection_names: [this.normalize(namespace)],\n        });\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  deleteDocumentFromNamespace: async function (namespace, docId) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) return;\n    const knownDocuments = await DocumentVectors.where({ docId });\n    if (knownDocuments.length === 0) return;\n\n    const vectorIds = knownDocuments.map((doc) => doc.vectorId);\n    const queryIn = vectorIds.map((v) => `'${v}'`).join(\",\");\n    await client.deleteEntities({\n      collection_name: this.normalize(namespace),\n      expr: `id in [${queryIn}]`,\n    });\n\n    const indexes = knownDocuments.map((doc) => doc.id);\n    await DocumentVectors.deleteIds(indexes);\n\n    // Even after flushing Milvus can take some time to re-calc the count",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 254,
        "end": 288,
        "startLoc": {
          "line": 254,
          "column": 38,
          "position": 2488
        },
        "endLoc": {
          "line": 288,
          "column": 70,
          "position": 2877
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 247,
        "end": 281,
        "startLoc": {
          "line": 247,
          "column": 38,
          "position": 2422
        },
        "endLoc": {
          "line": 281,
          "column": 70,
          "position": 2811
        }
      }
    },
    {
      "format": "javascript",
      "lines": 68,
      "fragment": "\n    // so all we can hope to do is flushSync so that the count can be correct\n    // on a later call.\n    await client.flushSync({ collection_names: [this.normalize(namespace)] });\n    return true;\n  },\n  performSimilaritySearch: async function ({\n    namespace = null,\n    input = \"\",\n    LLMConnector = null,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) {\n      return {\n        contextTexts: [],\n        sources: [],\n        message: \"Invalid query - no documents found for workspace!\",\n      };\n    }\n\n    const queryVector = await LLMConnector.embedTextInput(input);\n    const { contextTexts, sourceDocuments } = await this.similarityResponse({\n      client,\n      namespace,\n      queryVector,\n      similarityThreshold,\n      topN,\n      filterIdentifiers,\n    });\n\n    const sources = sourceDocuments.map((metadata, i) => {\n      return { ...metadata, text: contextTexts[i] };\n    });\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const result = {\n      contextTexts: [],\n      sourceDocuments: [],\n      scores: [],\n    };\n    const response = await client.search({\n      collection_name: this.normalize(namespace),\n      vectors: queryVector,\n      limit: topN,\n    });\n    response.results.forEach((match) => {\n      if (match.score < similarityThreshold) return;\n      if (filterIdentifiers.includes(sourceIdentifier(match.metadata))) {\n        console.log(\n          \"Milvus: A source was filtered from context as it's parent document is pinned.\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 288,
        "end": 355,
        "startLoc": {
          "line": 288,
          "column": 70,
          "position": 2878
        },
        "endLoc": {
          "line": 355,
          "column": 80,
          "position": 3440
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 281,
        "end": 348,
        "startLoc": {
          "line": 281,
          "column": 70,
          "position": 2812
        },
        "endLoc": {
          "line": 348,
          "column": 80,
          "position": 3374
        }
      }
    },
    {
      "format": "javascript",
      "lines": 50,
      "fragment": "\n      result.contextTexts.push(match.metadata.text);\n      result.sourceDocuments.push(match);\n      result.scores.push(match.score);\n    });\n    return result;\n  },\n  \"namespace-stats\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    if (!namespace) throw new Error(\"namespace required\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n    const stats = await this.namespace(client, namespace);\n    return stats\n      ? stats\n      : { message: \"No stats were able to be fetched from DB for namespace\" };\n  },\n  \"delete-namespace\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n\n    const statistics = await this.namespace(client, namespace);\n    await this.deleteVectorsInNamespace(client, namespace);\n    const vectorCount = Number(statistics?.data?.row_count ?? 0);\n    return {\n      message: `Namespace ${namespace} was deleted along with ${vectorCount} vectors.`,\n    };\n  },\n  curateSources: function (sources = []) {\n    const documents = [];\n    for (const source of sources) {\n      const { metadata = {} } = source;\n      if (Object.keys(metadata).length > 0) {\n        documents.push({\n          ...metadata,\n          ...(source.hasOwnProperty(\"pageContent\")\n            ? { text: source.pageContent }\n            : {}),\n        });\n      }\n    }\n\n    return documents;\n  },\n};\n\nmodule.exports.Milvus",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/milvus/index.js",
        "start": 359,
        "end": 408,
        "startLoc": {
          "line": 359,
          "column": 1,
          "position": 3453
        },
        "endLoc": {
          "line": 408,
          "column": 7,
          "position": 3992
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 351,
        "end": 400,
        "startLoc": {
          "line": 351,
          "column": 2,
          "position": 3386
        },
        "endLoc": {
          "line": 400,
          "column": 7,
          "position": 3925
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ");\n    return true;\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      const { pageContent, docId, ...metadata } = documentData;\n      if (!pageContent || pageContent.length == 0) return false;\n\n      console.log(\"Adding new vectorized document into namespace\", namespace);\n      if (!skipCache) {\n        const cacheResult = await cachedVectorInformation(fullFilePath);\n        if (cacheResult.exists) {\n          const { client",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 276,
        "end": 294,
        "startLoc": {
          "line": 276,
          "column": 16,
          "position": 2097
        },
        "endLoc": {
          "line": 294,
          "column": 7,
          "position": 2273
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 176,
        "end": 111,
        "startLoc": {
          "line": 176,
          "column": 2,
          "position": 1906
        },
        "endLoc": {
          "line": 111,
          "column": 14,
          "position": 1202
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n          await DocumentVectors.bulkInsert(documentVectors);\n          return { vectorized: true, error: null };\n        }\n      }\n\n      // If we are here then we are going to embed and store a novel document.\n      // We have to do this manually as opposed to using LangChains `xyz.fromDocuments`\n      // because we then cannot atomically control our namespace to granularly find/remove documents\n      // from vectordb.\n      const EmbedderEngine",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 308,
        "end": 318,
        "startLoc": {
          "line": 308,
          "column": 10,
          "position": 2458
        },
        "endLoc": {
          "line": 318,
          "column": 15,
          "position": 2513
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 515,
        "end": 525,
        "startLoc": {
          "line": 515,
          "column": 2,
          "position": 3845
        },
        "endLoc": {
          "line": 525,
          "column": 2,
          "position": 3900
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": "\n      // because we then cannot atomically control our namespace to granularly find/remove documents\n      // from vectordb.\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const submissions",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 315,
        "end": 337,
        "startLoc": {
          "line": 315,
          "column": 82,
          "position": 2503
        },
        "endLoc": {
          "line": 337,
          "column": 12,
          "position": 2678
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 250,
        "end": 206,
        "startLoc": {
          "line": 250,
          "column": 85,
          "position": 2523
        },
        "endLoc": {
          "line": 206,
          "column": 13,
          "position": 2015
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": " = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n\n      if (!!vectorValues && vectorValues.length > 0) {\n        for (const [i, vector] of vectorValues.entries()) {\n          const vectorRecord = {\n            id: uuidv4(),\n            values: vector,\n            // [DO NOT REMOVE]\n            // LangChain will be unable to find your text if you embed manually and dont include the `text` key.\n            // https://github.com/hwchase17/langchainjs/blob/2def486af734c0ca87285a48f1a04c057ab74bdf/langchain/src/vectorstores/pinecone.ts#L64\n            metadata: { ...metadata, text: textChunks[i] },\n          };\n\n          vectors.push(vectorRecord);\n          submissions",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 337,
        "end": 352,
        "startLoc": {
          "line": 337,
          "column": 12,
          "position": 2679
        },
        "endLoc": {
          "line": 352,
          "column": 12,
          "position": 2819
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 205,
        "end": 170,
        "startLoc": {
          "line": 205,
          "column": 8,
          "position": 2005
        },
        "endLoc": {
          "line": 170,
          "column": 16,
          "position": 1716
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n          });\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      if (vectors.length > 0) {\n        const chunks = [];\n        for (const chunk of toChunks(vectors, 500)) chunks.push(chunk);\n\n        console.log(\"Inserting vectorized chunks into LanceDB collection.\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 355,
        "end": 369,
        "startLoc": {
          "line": 355,
          "column": 7,
          "position": 2848
        },
        "endLoc": {
          "line": 369,
          "column": 55,
          "position": 2964
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 562,
        "end": 324,
        "startLoc": {
          "line": 562,
          "column": 9,
          "position": 4268
        },
        "endLoc": {
          "line": 324,
          "column": 56,
          "position": 3148
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ");\n        await storeVectorResult(chunks, fullFilePath);\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  performSimilaritySearch",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 371,
        "end": 382,
        "startLoc": {
          "line": 371,
          "column": 10,
          "position": 3002
        },
        "endLoc": {
          "line": 382,
          "column": 24,
          "position": 3105
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/pgvector/index.js",
        "start": 582,
        "end": 264,
        "startLoc": {
          "line": 582,
          "column": 2,
          "position": 4418
        },
        "endLoc": {
          "line": 264,
          "column": 28,
          "position": 2570
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) {\n      return {\n        contextTexts: [],\n        sources: [],\n        message: \"Invalid query - no documents found for workspace!\",\n      };\n    }\n\n    const queryVector = await LLMConnector.embedTextInput(input);\n    const result",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 389,
        "end": 404,
        "startLoc": {
          "line": 389,
          "column": 6,
          "position": 3170
        },
        "endLoc": {
          "line": 404,
          "column": 7,
          "position": 3306
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 293,
        "end": 308,
        "startLoc": {
          "line": 293,
          "column": 2,
          "position": 2912
        },
        "endLoc": {
          "line": 308,
          "column": 2,
          "position": 3048
        }
      }
    },
    {
      "format": "javascript",
      "lines": 26,
      "fragment": " };\n    });\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  \"namespace-stats\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    if (!namespace) throw new Error(\"namespace required\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n    const stats = await this.namespace(client, namespace);\n    return stats\n      ? stats\n      : { message: \"No stats were able to be fetched from DB for namespace\" };\n  },\n  \"delete-namespace\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n\n    await",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 425,
        "end": 450,
        "startLoc": {
          "line": 425,
          "column": 2,
          "position": 3461
        },
        "endLoc": {
          "line": 450,
          "column": 6,
          "position": 3749
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 394,
        "end": 375,
        "startLoc": {
          "line": 394,
          "column": 2,
          "position": 3826
        },
        "endLoc": {
          "line": 375,
          "column": 6,
          "position": 3684
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "\n    return { reset: true };\n  },\n  curateSources: function (sources = []) {\n    const documents = [];\n    for (const source of sources) {\n      const { text, vector: _v, _distance: _d, ...rest } = source;\n      const metadata = rest.hasOwnProperty(\"metadata\") ? rest.metadata : rest;\n      if (Object.keys(metadata).length > 0) {\n        documents.push({\n          ...metadata,\n          ...(text ? { text } : {}),\n        });\n      }\n    }\n\n    return documents;\n  },\n};\n\nmodule.exports.LanceDb",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 458,
        "end": 478,
        "startLoc": {
          "line": 458,
          "column": 2,
          "position": 3864
        },
        "endLoc": {
          "line": 478,
          "column": 8,
          "position": 4062
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 427,
        "end": 784,
        "startLoc": {
          "line": 427,
          "column": 2,
          "position": 4206
        },
        "endLoc": {
          "line": 784,
          "column": 9,
          "position": 6200
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ");\n    return namespace?.vectorCount || 0;\n  },\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const collection = await client.getCollection",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 108,
        "end": 119,
        "startLoc": {
          "line": 108,
          "column": 2,
          "position": 1069
        },
        "endLoc": {
          "line": 119,
          "column": 14,
          "position": 1154
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 47,
        "end": 165,
        "startLoc": {
          "line": 47,
          "column": 11,
          "position": 550
        },
        "endLoc": {
          "line": 165,
          "column": 10,
          "position": 1230
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ");\n    return true;\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      const { pageContent, docId, ...metadata } = documentData;\n      if (!pageContent || pageContent.length == 0) return false;\n\n      console.log(\"Adding new vectorized document into namespace\", namespace);\n      if (skipCache) {\n        const cacheResult = await cachedVectorInformation(fullFilePath);\n        if (cacheResult.exists) {\n          const { client } = await this.connect();\n          const collection",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 181,
        "end": 200,
        "startLoc": {
          "line": 181,
          "column": 2,
          "position": 1784
        },
        "endLoc": {
          "line": 200,
          "column": 11,
          "position": 1977
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 176,
        "end": 155,
        "startLoc": {
          "line": 176,
          "column": 2,
          "position": 1906
        },
        "endLoc": {
          "line": 155,
          "column": 2,
          "position": 1530
        }
      }
    },
    {
      "format": "javascript",
      "lines": 35,
      "fragment": "\n          }\n\n          await DocumentVectors.bulkInsert(documentVectors);\n          return { vectorized: true, error: null };\n        }\n      }\n\n      // If we are here then we are going to embed and store a novel document.\n      // We have to do this manually as opposed to using LangChains `Chroma.fromDocuments`\n      // because we then cannot atomically control our namespace to granularly find/remove documents\n      // from vectordb.\n      const EmbedderEngine = getEmbeddingEngineSelection();\n      const textSplitter = new TextSplitter({\n        chunkSize: TextSplitter.determineMaxChunkSize(\n          await SystemSettings.getValueOrFallback({\n            label: \"text_splitter_chunk_size\",\n          }),\n          EmbedderEngine?.embeddingMaxChunkLength\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n      const submission = {\n        ids: [],\n        embeddings",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 230,
        "end": 264,
        "startLoc": {
          "line": 230,
          "column": 2,
          "position": 2275
        },
        "endLoc": {
          "line": 264,
          "column": 11,
          "position": 2529
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 241,
        "end": 275,
        "startLoc": {
          "line": 241,
          "column": 2,
          "position": 2476
        },
        "endLoc": {
          "line": 275,
          "column": 8,
          "position": 2730
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ": [],\n      };\n\n      if (!!vectorValues && vectorValues.length > 0) {\n        for (const [i, vector] of vectorValues.entries()) {\n          const vectorRecord = {\n            id: uuidv4(),\n            values: vector,\n            // [DO NOT REMOVE]\n            // LangChain will be unable to find your text if you embed manually and dont include the `text` key.\n            // https://github.com/hwchase17/langchainjs/blob/2def486af734c0ca87285a48f1a04c057ab74bdf/langchain/src/vectorstores/pinecone.ts#L64\n            metadata: { ...metadata, text: textChunks[i] },\n          };\n\n          submission",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 266,
        "end": 280,
        "startLoc": {
          "line": 266,
          "column": 10,
          "position": 2546
        },
        "endLoc": {
          "line": 280,
          "column": 11,
          "position": 2663
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 276,
        "end": 169,
        "startLoc": {
          "line": 276,
          "column": 11,
          "position": 2739
        },
        "endLoc": {
          "line": 169,
          "column": 8,
          "position": 1707
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ");\n\n          vectors.push(vectorRecord);\n          documentVectors.push({ docId, vectorId: vectorRecord.id });\n        }\n      } else {\n        throw new Error(\n          \"Could not embed document chunks! This document will not be recorded.\"\n        );\n      }\n\n      const { client } = await this.connect();\n      const collection = await client",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 283,
        "end": 295,
        "startLoc": {
          "line": 283,
          "column": 2,
          "position": 2710
        },
        "endLoc": {
          "line": 295,
          "column": 7,
          "position": 2802
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 294,
        "end": 264,
        "startLoc": {
          "line": 294,
          "column": 9,
          "position": 2914
        },
        "endLoc": {
          "line": 264,
          "column": 5,
          "position": 2483
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "\n\n        await storeVectorResult(chunks, fullFilePath);\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  deleteDocumentFromNamespace: async function (namespace, docId) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace))) return;\n    const collection",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 313,
        "end": 329,
        "startLoc": {
          "line": 313,
          "column": 2,
          "position": 2991
        },
        "endLoc": {
          "line": 329,
          "column": 11,
          "position": 3172
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 289,
        "end": 268,
        "startLoc": {
          "line": 289,
          "column": 2,
          "position": 2691
        },
        "endLoc": {
          "line": 268,
          "column": 15,
          "position": 2649
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": "});\n\n    const indexes = knownDocuments.map((doc) => doc.id);\n    await DocumentVectors.deleteIds(indexes);\n    return true;\n  },\n  performSimilaritySearch: async function ({\n    namespace = null,\n    input = \"\",\n    LLMConnector = null,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 337,
        "end": 355,
        "startLoc": {
          "line": 337,
          "column": 2,
          "position": 3277
        },
        "endLoc": {
          "line": 355,
          "column": 5,
          "position": 3457
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 313,
        "end": 299,
        "startLoc": {
          "line": 313,
          "column": 5,
          "position": 2958
        },
        "endLoc": {
          "line": 299,
          "column": 10,
          "position": 2985
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  \"namespace-stats\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    if (!namespace) throw new Error(\"namespace required\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 381,
        "end": 392,
        "startLoc": {
          "line": 381,
          "column": 1,
          "position": 3648
        },
        "endLoc": {
          "line": 392,
          "column": 5,
          "position": 3775
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 395,
        "end": 362,
        "startLoc": {
          "line": 395,
          "column": 2,
          "position": 3834
        },
        "endLoc": {
          "line": 362,
          "column": 10,
          "position": 3531
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ");\n    return { reset: true };\n  },\n  curateSources: function (sources = []) {\n    const documents = [];\n    for (const source of sources) {\n      const { metadata = {} } = source;\n      if (Object.keys(metadata).length > 0) {\n        documents.push({\n          ...metadata,\n          ...(source.hasOwnProperty(\"pageContent\")\n            ? { text: source.pageContent }\n            : {}),\n        });\n      }\n    }\n\n    return documents;\n  },\n};\n\nmodule.exports.Chroma",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/chroma/index.js",
        "start": 413,
        "end": 434,
        "startLoc": {
          "line": 413,
          "column": 2,
          "position": 4057
        },
        "endLoc": {
          "line": 434,
          "column": 7,
          "position": 4233
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/lance/index.js",
        "start": 458,
        "end": 400,
        "startLoc": {
          "line": 458,
          "column": 5,
          "position": 3862
        },
        "endLoc": {
          "line": 400,
          "column": 7,
          "position": 3925
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n    };\n  },\n  hasNamespace: async function (namespace = null) {\n    if (!namespace) return false;\n    const { client } = await this.connect();\n    return await this.namespaceExists(client, namespace);\n  },\n  namespaceExists: async function (client, namespace = null) {\n    if (!namespace) throw new Error(\"No namespace value provided.\");\n    const sanitizedNamespace",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 87,
        "end": 97,
        "startLoc": {
          "line": 87,
          "column": 2,
          "position": 944
        },
        "endLoc": {
          "line": 97,
          "column": 19,
          "position": 1067
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/qdrant/index.js",
        "start": 97,
        "end": 81,
        "startLoc": {
          "line": 97,
          "column": 6,
          "position": 988
        },
        "endLoc": {
          "line": 81,
          "column": 2,
          "position": 883
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": ";\n    }\n  },\n  addDocumentToNamespace: async function (\n    namespace,\n    documentData = {},\n    fullFilePath = null,\n    skipCache = false\n  ) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    try {\n      let vectorDimension = null;\n      const { pageContent, docId, ...metadata } = documentData;\n      if (!pageContent || pageContent.length == 0) return false;\n\n      console.log(\"Adding new vectorized document into namespace\", namespace);\n      if (!skipCache) {\n        const cacheResult = await cachedVectorInformation(fullFilePath);\n        if (cacheResult.exists) {\n          const { client } = await this.connect();\n          const { chunks } = cacheResult;\n          const documentVectors = [];\n          vectorDimension = chunks[0][0].values.length || null;\n\n          const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 139,
        "end": 163,
        "startLoc": {
          "line": 139,
          "column": 6,
          "position": 1392
        },
        "endLoc": {
          "line": 163,
          "column": 6,
          "position": 1638
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 135,
        "end": 159,
        "startLoc": {
          "line": 135,
          "column": 2,
          "position": 1331
        },
        "endLoc": {
          "line": 159,
          "column": 6,
          "position": 1576
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "\n        ),\n        chunkOverlap: await SystemSettings.getValueOrFallback(\n          { label: \"text_splitter_chunk_overlap\" },\n          20\n        ),\n        chunkHeaderMeta: TextSplitter.buildHeaderMeta(metadata),\n      });\n      const textChunks = await textSplitter.splitText(pageContent);\n\n      console.log(\"Chunks created from document:\", textChunks.length);\n      const documentVectors = [];\n      const vectors = [];\n      const vectorValues = await EmbedderEngine.embedChunks(textChunks);\n\n      if (!!vectorValues && vectorValues.length > 0) {\n        for (const [i, vector] of vectorValues.entries()) {\n          if (!vectorDimension) vectorDimension = vector.length;\n          const vectorRecord = {\n            _id",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 202,
        "end": 221,
        "startLoc": {
          "line": 202,
          "column": 2,
          "position": 1945
        },
        "endLoc": {
          "line": 221,
          "column": 4,
          "position": 2140
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 193,
        "end": 212,
        "startLoc": {
          "line": 193,
          "column": 24,
          "position": 1907
        },
        "endLoc": {
          "line": 212,
          "column": 3,
          "position": 2102
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n        }\n        await storeVectorResult(chunks, fullFilePath);\n      }\n\n      await DocumentVectors.bulkInsert(documentVectors);\n      return { vectorized: true, error: null };\n    } catch (e) {\n      console.error(\"addDocumentToNamespace\", e.message);\n      return { vectorized: false, error: e.message };\n    }\n  },\n  deleteDocumentFromNamespace: async function (namespace, docId) {\n    const { DocumentVectors } = require(\"../../../models/vectors\");\n    const { client } = await this.connect();\n    namespace",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 260,
        "end": 275,
        "startLoc": {
          "line": 260,
          "column": 6,
          "position": 2463
        },
        "endLoc": {
          "line": 275,
          "column": 10,
          "position": 2623
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 331,
        "end": 267,
        "startLoc": {
          "line": 331,
          "column": 32,
          "position": 3222
        },
        "endLoc": {
          "line": 267,
          "column": 3,
          "position": 2624
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ");\n    }\n\n    const indexes = knownDocuments.map((doc) => doc.id);\n    await DocumentVectors.deleteIds(indexes);\n    return true;\n  },\n  performSimilaritySearch: async function ({\n    namespace = null,\n    input = \"\",\n    LLMConnector = null,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    if (!namespace || !input || !LLMConnector)\n      throw new Error(\"Invalid request to performSimilaritySearch.\");\n\n    const { client } = await this.connect();\n    // Sanitize namespace before checking existence",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 289,
        "end": 308,
        "startLoc": {
          "line": 289,
          "column": 2,
          "position": 2780
        },
        "endLoc": {
          "line": 308,
          "column": 48,
          "position": 2948
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/weaviate/index.js",
        "start": 356,
        "end": 299,
        "startLoc": {
          "line": 356,
          "column": 2,
          "position": 3494
        },
        "endLoc": {
          "line": 299,
          "column": 3,
          "position": 2971
        }
      }
    },
    {
      "format": "javascript",
      "lines": 30,
      "fragment": ",\n      queryVector,\n      similarityThreshold,\n      topN,\n      filterIdentifiers,\n    });\n\n    const sources = sourceDocuments.map((metadata, i) => {\n      return { ...metadata, text: contextTexts[i] };\n    });\n    return {\n      contextTexts,\n      sources: this.curateSources(sources),\n      message: false,\n    };\n  },\n  similarityResponse: async function ({\n    client,\n    namespace,\n    queryVector,\n    similarityThreshold = 0.25,\n    topN = 4,\n    filterIdentifiers = [],\n  }) {\n    const result = {\n      contextTexts: [],\n      sourceDocuments: [],\n      scores: [],\n    };\n    // Namespace should already be sanitized, but let's be defensive",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 323,
        "end": 352,
        "startLoc": {
          "line": 323,
          "column": 19,
          "position": 3071
        },
        "endLoc": {
          "line": 352,
          "column": 65,
          "position": 3270
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 310,
        "end": 339,
        "startLoc": {
          "line": 310,
          "column": 10,
          "position": 3073
        },
        "endLoc": {
          "line": 339,
          "column": 6,
          "position": 3272
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\n  },\n  \"namespace-stats\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    if (!namespace) throw new Error(\"namespace required\");\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n    const stats = await this.namespace(client, namespace);\n    return stats\n      ? stats\n      : { message: \"No stats were able to be fetched from DB for namespace\" };\n  },\n  \"delete-namespace\": async function (reqBody = {}) {\n    const { namespace = null } = reqBody;\n    const { client } = await this.connect();\n    if (!(await this.namespaceExists(client, namespace)))\n      throw new Error(\"Namespace by that name does not exist.\");\n\n    const details = await this.namespace(client, namespace);\n    await this.deleteVectorsInNamespace(client, namespace);\n    return {\n      message: `Namespace ${namespace} was deleted along with ${\n        details",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 404,
        "end": 427,
        "startLoc": {
          "line": 404,
          "column": 2,
          "position": 3732
        },
        "endLoc": {
          "line": 427,
          "column": 16,
          "position": 4028
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 356,
        "end": 378,
        "startLoc": {
          "line": 356,
          "column": 2,
          "position": 3436
        },
        "endLoc": {
          "line": 378,
          "column": 8,
          "position": 3624
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "} vectors.`,\n    };\n  },\n  curateSources: function (sources = []) {\n    const documents = [];\n    for (const source of sources) {\n      if (Object.keys(source).length > 0) {\n        const metadata = source.hasOwnProperty(\"metadata\")\n          ? source.metadata\n          : source;\n        documents.push({\n          ...metadata,\n        });\n      }\n    }\n\n    return documents;\n  },\n};\n\nmodule.exports.AstraDB",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/vectorDbProviders/astra/index.js",
        "start": 428,
        "end": 448,
        "startLoc": {
          "line": 428,
          "column": 7,
          "position": 4036
        },
        "endLoc": {
          "line": 448,
          "column": 8,
          "position": 4180
        }
      },
      "secondFile": {
        "name": "server/utils/vectorDbProviders/zilliz/index.js",
        "start": 379,
        "end": 406,
        "startLoc": {
          "line": 379,
          "column": 12,
          "position": 3757
        },
        "endLoc": {
          "line": 406,
          "column": 7,
          "position": 3871
        }
      }
    },
    {
      "format": "javascript",
      "lines": 72,
      "fragment": ");\n  });\n\n  // Prompt is allowed to take up to 70% of window - we know its under\n  // if we are here, so passthrough.\n  const compressedPrompt = new Promise(async (resolve) => resolve(user));\n\n  // We always aggressively compress history because it is the least\n  // important data to retain in full-fidelity.\n  const compressedHistory = new Promise((resolve) => {\n    const eligibleHistoryItems = [];\n    var historyTokenCount = 0;\n\n    for (const [i, history] of rawHistory.reverse().entries()) {\n      const [user, assistant] = convertToPromptHistory([history]);\n      const [userTokens, assistantTokens] = [\n        tokenManager.countFromString(user.content),\n        tokenManager.countFromString(assistant.content),\n      ];\n      const total = userTokens + assistantTokens;\n\n      // If during the loop the token cost of adding this history\n      // is small, we can add it to history and move onto next.\n      if (historyTokenCount + total < llm.limits.history) {\n        eligibleHistoryItems.unshift(user, assistant);\n        historyTokenCount += total;\n        continue;\n      }\n\n      // If we reach here the overhead of adding this history item will\n      // be too much of the limit. So now, we are prioritizing\n      // the most recent 3 message pairs - if we are already past those - exit loop and stop\n      // trying to make history work.\n      if (i > 2) break;\n\n      // We are over the limit and we are within the first 3 most recent chats.\n      // so now we cannonball them to make them fit into the window.\n      // max size = llm.limit.history; Each component of the message, can at most\n      // be 50% of the history. We cannonball whichever is the problem.\n      // The math isnt perfect for tokens, so we have to add a fudge factor for safety.\n      const maxTargetSize = Math.floor(llm.limits.history / 2.2);\n      if (userTokens > maxTargetSize) {\n        user.content = cannonball({\n          input: user.content,\n          targetTokenSize: maxTargetSize,\n          tiktokenInstance: tokenManager,\n        });\n      }\n\n      if (assistantTokens > maxTargetSize) {\n        assistant.content = cannonball({\n          input: assistant.content,\n          targetTokenSize: maxTargetSize,\n          tiktokenInstance: tokenManager,\n        });\n      }\n\n      const newTotal = tokenManager.statsFrom([user, assistant]);\n      if (historyTokenCount + newTotal > llm.limits.history) continue;\n      eligibleHistoryItems.unshift(user, assistant);\n      historyTokenCount += newTotal;\n    }\n    resolve(eligibleHistoryItems);\n  });\n\n  const [cSystem, cHistory, cPrompt] = await Promise.all([\n    compressedSystem,\n    compressedHistory,\n    compressedPrompt,\n  ]);\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/helpers/chat/index.js",
        "start": 233,
        "end": 304,
        "startLoc": {
          "line": 233,
          "column": 5,
          "position": 1539
        },
        "endLoc": {
          "line": 304,
          "column": 1,
          "position": 2081
        }
      },
      "secondFile": {
        "name": "server/utils/helpers/chat/index.js",
        "start": 119,
        "end": 189,
        "startLoc": {
          "line": 119,
          "column": 7,
          "position": 637
        },
        "endLoc": {
          "line": 189,
          "column": 3,
          "position": 1179
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "\n  async ttsBuffer(textInput) {\n    try {\n      const result = await this.openai.audio.speech.create({\n        model: \"tts-1\",\n        voice: this.voice,\n        input: textInput,\n      });\n      return Buffer.from(await result.arrayBuffer());\n    } catch (e) {\n      console.error(e);\n    }\n    return null;\n  }\n}\n\nmodule.exports = {\n  OpenAiTTS",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/TextToSpeech/openAi/index.js",
        "start": 11,
        "end": 28,
        "startLoc": {
          "line": 11,
          "column": 1,
          "position": 107
        },
        "endLoc": {
          "line": 28,
          "column": 10,
          "position": 233
        }
      },
      "secondFile": {
        "name": "server/utils/TextToSpeech/openAiGeneric/index.js",
        "start": 32,
        "end": 49,
        "startLoc": {
          "line": 32,
          "column": 6,
          "position": 216
        },
        "endLoc": {
          "line": 49,
          "column": 17,
          "position": 342
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": ");\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  /**\n   * This function takes an array of text chunks and embeds them using the Ollama API.\n   * chunks are processed sequentially to avoid overwhelming the API with too many requests\n   * or running out of resources on the endpoint running the ollama instance.\n   *\n   * We will use the num_ctx option to set the maximum context window to the max chunk length defined by the user in the settings\n   * so that the maximum context window is used and content is not truncated.\n   *\n   * We also assume the default keep alive option. This could cause issues with models being unloaded and reloaded\n   * on load memory machines, but that is simply a user-end issue we cannot control. If the LLM and embedder are\n   * constantly being loaded and unloaded, the user should use another LLM or Embedder to avoid this issue.\n   * @param {string[]} textChunks - An array of text chunks to embed.\n   * @returns {Promise<Array<number[]>>} - A promise that resolves to an array of embeddings.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/ollama/index.js",
        "start": 36,
        "end": 59,
        "startLoc": {
          "line": 36,
          "column": 2,
          "position": 317
        },
        "endLoc": {
          "line": 59,
          "column": 6,
          "position": 391
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 21,
        "end": 31,
        "startLoc": {
          "line": 21,
          "column": 5,
          "position": 179
        },
        "endLoc": {
          "line": 31,
          "column": 6,
          "position": 253
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ";\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  // If you are thinking you want to edit this function - you probably don't.",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/native/index.js",
        "start": 124,
        "end": 134,
        "startLoc": {
          "line": 124,
          "column": 6,
          "position": 1029
        },
        "endLoc": {
          "line": 134,
          "column": 76,
          "position": 1102
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 21,
        "end": 31,
        "startLoc": {
          "line": 21,
          "column": 2,
          "position": 180
        },
        "endLoc": {
          "line": 31,
          "column": 6,
          "position": 253
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ");\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  async embedChunks(textChunks = []) {\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/localAi/index.js",
        "start": 18,
        "end": 29,
        "startLoc": {
          "line": 18,
          "column": 2,
          "position": 168
        },
        "endLoc": {
          "line": 29,
          "column": 6,
          "position": 257
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 21,
        "end": 32,
        "startLoc": {
          "line": 21,
          "column": 5,
          "position": 179
        },
        "endLoc": {
          "line": 32,
          "column": 5,
          "position": 268
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ",\n              input: chunk,\n            })\n            .then((result) => {\n              resolve({ data: result?.data, error: null });\n            })\n            .catch((e) => {\n              e.type =\n                e?.response?.data?.error?.code ||\n                e?.response?.status ||\n                \"failed_to_embed\";\n              e.message = e?.response?.data?.error?.message || e.message;\n              resolve({ data: [], error: e });\n            });\n        })\n      );\n    }\n\n    const { data = [], error = null } = await Promise.all(\n      embeddingRequests\n    ).then((results) => {\n      // If any errors were returned from LocalAI abort the entire sequence because the embeddings",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/localAi/index.js",
        "start": 35,
        "end": 56,
        "startLoc": {
          "line": 35,
          "column": 21,
          "position": 331
        },
        "endLoc": {
          "line": 56,
          "column": 93,
          "position": 547
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 43,
        "end": 64,
        "startLoc": {
          "line": 43,
          "column": 6,
          "position": 365
        },
        "endLoc": {
          "line": 64,
          "column": 92,
          "position": 581
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\n      // will be incomplete.\n      const errors = results\n        .filter((res) => !!res.error)\n        .map((res) => res.error)\n        .flat();\n      if (errors.length > 0) {\n        let uniqueErrors = new Set();\n        errors.map((error) =>\n          uniqueErrors.add(`[${error.type}]: ${error.message}`)\n        );\n\n        return {\n          data: [],\n          error: Array.from(uniqueErrors).join(\", \"),\n        };\n      }\n      return {\n        data: results.map((res) => res?.data || []).flat(),\n        error: null,\n      };\n    });\n\n    if (!!error) throw new Error(`LocalAI Failed to embed: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/localAi/index.js",
        "start": 56,
        "end": 79,
        "startLoc": {
          "line": 56,
          "column": 93,
          "position": 548
        },
        "endLoc": {
          "line": 79,
          "column": 27,
          "position": 769
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 64,
        "end": 87,
        "startLoc": {
          "line": 64,
          "column": 92,
          "position": 582
        },
        "endLoc": {
          "line": 87,
          "column": 26,
          "position": 803
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ")\n      .catch((e) => {\n        this.log(e.message);\n        return false;\n      });\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  async embedChunks(textChunks = []) {\n    if",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/lmstudio/index.js",
        "start": 30,
        "end": 45,
        "startLoc": {
          "line": 30,
          "column": 2,
          "position": 285
        },
        "endLoc": {
          "line": 45,
          "column": 3,
          "position": 407
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/ollama/index.js",
        "start": 32,
        "end": 32,
        "startLoc": {
          "line": 32,
          "column": 3,
          "position": 284
        },
        "endLoc": {
          "line": 32,
          "column": 5,
          "position": 268
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ";\n    this.embeddingMaxChunkLength = maximumChunkLength();\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  async embedChunks(textChunks = []) {\n    // Because there is a hard POST limit on how many chunks can be sent at once to LiteLLM (~8mb)",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/liteLLM/index.js",
        "start": 18,
        "end": 30,
        "startLoc": {
          "line": 18,
          "column": 4,
          "position": 167
        },
        "endLoc": {
          "line": 30,
          "column": 95,
          "position": 267
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/localAi/index.js",
        "start": 17,
        "end": 32,
        "startLoc": {
          "line": 17,
          "column": 3,
          "position": 157
        },
        "endLoc": {
          "line": 32,
          "column": 5,
          "position": 268
        }
      }
    },
    {
      "format": "javascript",
      "lines": 31,
      "fragment": "\n    // we concurrently execute each max batch of text chunks possible.\n    // Refer to constructor maxConcurrentChunks for more info.\n    const embeddingRequests = [];\n    for (const chunk of toChunks(textChunks, this.maxConcurrentChunks)) {\n      embeddingRequests.push(\n        new Promise((resolve) => {\n          this.openai.embeddings\n            .create({\n              model: this.model,\n              input: chunk,\n            })\n            .then((result) => {\n              resolve({ data: result?.data, error: null });\n            })\n            .catch((e) => {\n              e.type =\n                e?.response?.data?.error?.code ||\n                e?.response?.status ||\n                \"failed_to_embed\";\n              e.message = e?.response?.data?.error?.message || e.message;\n              resolve({ data: [], error: e });\n            });\n        })\n      );\n    }\n\n    const { data = [], error = null } = await Promise.all(\n      embeddingRequests\n    ).then((results) => {\n      // If any errors were returned from LiteLLM abort the entire sequence because the embeddings",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/liteLLM/index.js",
        "start": 30,
        "end": 60,
        "startLoc": {
          "line": 30,
          "column": 95,
          "position": 268
        },
        "endLoc": {
          "line": 60,
          "column": 93,
          "position": 564
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 34,
        "end": 64,
        "startLoc": {
          "line": 34,
          "column": 94,
          "position": 285
        },
        "endLoc": {
          "line": 64,
          "column": 92,
          "position": 581
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\n      // will be incomplete.\n      const errors = results\n        .filter((res) => !!res.error)\n        .map((res) => res.error)\n        .flat();\n      if (errors.length > 0) {\n        let uniqueErrors = new Set();\n        errors.map((error) =>\n          uniqueErrors.add(`[${error.type}]: ${error.message}`)\n        );\n\n        return {\n          data: [],\n          error: Array.from(uniqueErrors).join(\", \"),\n        };\n      }\n      return {\n        data: results.map((res) => res?.data || []).flat(),\n        error: null,\n      };\n    });\n\n    if (!!error) throw new Error(`LiteLLM Failed to embed: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/liteLLM/index.js",
        "start": 60,
        "end": 83,
        "startLoc": {
          "line": 60,
          "column": 93,
          "position": 565
        },
        "endLoc": {
          "line": 83,
          "column": 27,
          "position": 786
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 64,
        "end": 87,
        "startLoc": {
          "line": 64,
          "column": 92,
          "position": 582
        },
        "endLoc": {
          "line": 87,
          "column": 26,
          "position": 803
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ");\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  async embedChunks(textChunks = []) {\n    // Because there is a hard POST limit on how many chunks can be sent at once to OpenAI (~8mb)",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/genericOpenAi/index.js",
        "start": 43,
        "end": 54,
        "startLoc": {
          "line": 43,
          "column": 48,
          "position": 327
        },
        "endLoc": {
          "line": 54,
          "column": 94,
          "position": 416
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 21,
        "end": 32,
        "startLoc": {
          "line": 21,
          "column": 5,
          "position": 179
        },
        "endLoc": {
          "line": 32,
          "column": 5,
          "position": 268
        }
      }
    },
    {
      "format": "javascript",
      "lines": 55,
      "fragment": "\n    // Because there is a hard POST limit on how many chunks can be sent at once to OpenAI (~8mb)\n    // we concurrently execute each max batch of text chunks possible.\n    // Refer to constructor maxConcurrentChunks for more info.\n    const embeddingRequests = [];\n    for (const chunk of toChunks(textChunks, this.maxConcurrentChunks)) {\n      embeddingRequests.push(\n        new Promise((resolve) => {\n          this.openai.embeddings\n            .create({\n              model: this.model,\n              input: chunk,\n            })\n            .then((result) => {\n              resolve({ data: result?.data, error: null });\n            })\n            .catch((e) => {\n              e.type =\n                e?.response?.data?.error?.code ||\n                e?.response?.status ||\n                \"failed_to_embed\";\n              e.message = e?.response?.data?.error?.message || e.message;\n              resolve({ data: [], error: e });\n            });\n        })\n      );\n    }\n\n    const { data = [], error = null } = await Promise.all(\n      embeddingRequests\n    ).then((results) => {\n      // If any errors were returned from OpenAI abort the entire sequence because the embeddings\n      // will be incomplete.\n      const errors = results\n        .filter((res) => !!res.error)\n        .map((res) => res.error)\n        .flat();\n      if (errors.length > 0) {\n        let uniqueErrors = new Set();\n        errors.map((error) =>\n          uniqueErrors.add(`[${error.type}]: ${error.message}`)\n        );\n\n        return {\n          data: [],\n          error: Array.from(uniqueErrors).join(\", \"),\n        };\n      }\n      return {\n        data: results.map((res) => res?.data || []).flat(),\n        error: null,\n      };\n    });\n\n    if (!!error) throw new Error(`GenericOpenAI Failed to embed: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/genericOpenAi/index.js",
        "start": 53,
        "end": 107,
        "startLoc": {
          "line": 53,
          "column": 2,
          "position": 414
        },
        "endLoc": {
          "line": 107,
          "column": 33,
          "position": 935
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 33,
        "end": 87,
        "startLoc": {
          "line": 33,
          "column": 1,
          "position": 282
        },
        "endLoc": {
          "line": 87,
          "column": 26,
          "position": 803
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  /**\n   * Embeds a list of text inputs\n   * @param {string[]} textChunks - The list of text to embed\n   * @returns {Promise<Array<Array<number>>>} The embedding values\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/gemini/index.js",
        "start": 39,
        "end": 51,
        "startLoc": {
          "line": 39,
          "column": 6,
          "position": 263
        },
        "endLoc": {
          "line": 51,
          "column": 6,
          "position": 331
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 23,
        "end": 31,
        "startLoc": {
          "line": 23,
          "column": 1,
          "position": 185
        },
        "endLoc": {
          "line": 31,
          "column": 6,
          "position": 253
        }
      }
    },
    {
      "format": "javascript",
      "lines": 58,
      "fragment": "\n  async embedChunks(textChunks = []) {\n    this.log(`Embedding ${textChunks.length} chunks...`);\n\n    // Because there is a hard POST limit on how many chunks can be sent at once to OpenAI (~8mb)\n    // we concurrently execute each max batch of text chunks possible.\n    // Refer to constructor maxConcurrentChunks for more info.\n    const embeddingRequests = [];\n    for (const chunk of toChunks(textChunks, this.maxConcurrentChunks)) {\n      embeddingRequests.push(\n        new Promise((resolve) => {\n          this.openai.embeddings\n            .create({\n              model: this.model,\n              input: chunk,\n            })\n            .then((result) => {\n              resolve({ data: result?.data, error: null });\n            })\n            .catch((e) => {\n              e.type =\n                e?.response?.data?.error?.code ||\n                e?.response?.status ||\n                \"failed_to_embed\";\n              e.message = e?.response?.data?.error?.message || e.message;\n              resolve({ data: [], error: e });\n            });\n        })\n      );\n    }\n\n    const { data = [], error = null } = await Promise.all(\n      embeddingRequests\n    ).then((results) => {\n      // If any errors were returned from OpenAI abort the entire sequence because the embeddings\n      // will be incomplete.\n      const errors = results\n        .filter((res) => !!res.error)\n        .map((res) => res.error)\n        .flat();\n      if (errors.length > 0) {\n        let uniqueErrors = new Set();\n        errors.map((error) =>\n          uniqueErrors.add(`[${error.type}]: ${error.message}`)\n        );\n\n        return {\n          data: [],\n          error: Array.from(uniqueErrors).join(\", \"),\n        };\n      }\n      return {\n        data: results.map((res) => res?.data || []).flat(),\n        error: null,\n      };\n    });\n\n    if (!!error) throw new Error(`Gemini Failed to embed: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/gemini/index.js",
        "start": 51,
        "end": 108,
        "startLoc": {
          "line": 51,
          "column": 6,
          "position": 332
        },
        "endLoc": {
          "line": 108,
          "column": 26,
          "position": 884
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 30,
        "end": 87,
        "startLoc": {
          "line": 30,
          "column": 1,
          "position": 251
        },
        "endLoc": {
          "line": 87,
          "column": 26,
          "position": 803
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ", error: null });\n            })\n            .catch((e) => {\n              e.type =\n                e?.response?.data?.error?.code ||\n                e?.response?.status ||\n                \"failed_to_embed\";\n              e.message = e?.response?.data?.error?.message || e.message;\n              resolve({ data: [], error: e });\n            });\n        })\n      );\n    }\n\n    const { data = [], error = null } = await Promise.all(\n      embeddingRequests\n    ).then((results) => {\n      const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/cohere/index.js",
        "start": 42,
        "end": 59,
        "startLoc": {
          "line": 42,
          "column": 11,
          "position": 372
        },
        "endLoc": {
          "line": 59,
          "column": 6,
          "position": 551
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 47,
        "end": 64,
        "startLoc": {
          "line": 47,
          "column": 5,
          "position": 402
        },
        "endLoc": {
          "line": 64,
          "column": 92,
          "position": 581
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "${text}`, ...args);\n  }\n\n  async embedTextInput(textInput) {\n    const result = await this.embedChunks(\n      Array.isArray(textInput) ? textInput : [textInput]\n    );\n    return result?.[0] || [];\n  }\n\n  async embedChunks(textChunks = []) {\n    if (!this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/azureOpenAi/index.js",
        "start": 32,
        "end": 43,
        "startLoc": {
          "line": 32,
          "column": 39,
          "position": 237
        },
        "endLoc": {
          "line": 43,
          "column": 5,
          "position": 338
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 21,
        "end": 45,
        "startLoc": {
          "line": 21,
          "column": 34,
          "position": 171
        },
        "endLoc": {
          "line": 45,
          "column": 2,
          "position": 411
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n    // we concurrently execute each max batch of text chunks possible.\n    // Refer to constructor maxConcurrentChunks for more info.\n    const embeddingRequests = [];\n    for (const chunk of toChunks(textChunks, this.maxConcurrentChunks)) {\n      embeddingRequests.push(\n        new Promise((resolve) => {\n          this.openai.embeddings\n            .create({\n              model: this.model,\n              input: chunk,\n            })\n            .then((res",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/azureOpenAi/index.js",
        "start": 46,
        "end": 58,
        "startLoc": {
          "line": 46,
          "column": 83,
          "position": 371
        },
        "endLoc": {
          "line": 58,
          "column": 4,
          "position": 469
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 34,
        "end": 46,
        "startLoc": {
          "line": 34,
          "column": 94,
          "position": 285
        },
        "endLoc": {
          "line": 46,
          "column": 7,
          "position": 383
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ".data, error: null });\n            })\n            .catch((e) => {\n              e.type =\n                e?.response?.data?.error?.code ||\n                e?.response?.status ||\n                \"failed_to_embed\";\n              e.message = e?.response?.data?.error?.message || e.message;\n              resolve({ data: [], error: e });\n            });\n        })\n      );\n    }\n\n    const { data = [], error = null } = await Promise.all(\n      embeddingRequests\n    ).then((results) => {\n      // If any errors were returned from Azure abort the entire sequence because the embeddings",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/azureOpenAi/index.js",
        "start": 59,
        "end": 76,
        "startLoc": {
          "line": 59,
          "column": 4,
          "position": 485
        },
        "endLoc": {
          "line": 76,
          "column": 91,
          "position": 666
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 47,
        "end": 64,
        "startLoc": {
          "line": 47,
          "column": 2,
          "position": 400
        },
        "endLoc": {
          "line": 64,
          "column": 92,
          "position": 581
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\n      // will be incomplete.\n      const errors = results\n        .filter((res) => !!res.error)\n        .map((res) => res.error)\n        .flat();\n      if (errors.length > 0) {\n        let uniqueErrors = new Set();\n        errors.map((error) =>\n          uniqueErrors.add(`[${error.type}]: ${error.message}`)\n        );\n\n        return {\n          data: [],\n          error: Array.from(uniqueErrors).join(\", \"),\n        };\n      }\n      return {\n        data: results.map((res) => res?.data || []).flat(),\n        error: null,\n      };\n    });\n\n    if (!!error) throw new Error(`Azure OpenAI Failed to embed: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/EmbeddingEngines/azureOpenAi/index.js",
        "start": 76,
        "end": 99,
        "startLoc": {
          "line": 76,
          "column": 91,
          "position": 667
        },
        "endLoc": {
          "line": 99,
          "column": 32,
          "position": 888
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/openAi/index.js",
        "start": 64,
        "end": 87,
        "startLoc": {
          "line": 64,
          "column": 92,
          "position": 582
        },
        "endLoc": {
          "line": 87,
          "column": 26,
          "position": 803
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ";\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  #",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 97,
        "end": 112,
        "startLoc": {
          "line": 97,
          "column": 4,
          "position": 941
        },
        "endLoc": {
          "line": 112,
          "column": 2,
          "position": 1047
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 52,
        "startLoc": {
          "line": 37,
          "column": 2,
          "position": 355
        },
        "endLoc": {
          "line": 52,
          "column": 17,
          "position": 461
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 111,
        "end": 123,
        "startLoc": {
          "line": 111,
          "column": 1,
          "position": 1045
        },
        "endLoc": {
          "line": 123,
          "column": 9,
          "position": 1158
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 72,
        "end": 84,
        "startLoc": {
          "line": 72,
          "column": 6,
          "position": 572
        },
        "endLoc": {
          "line": 84,
          "column": 11,
          "position": 685
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 183,
        "end": 207,
        "startLoc": {
          "line": 183,
          "column": 19,
          "position": 1696
        },
        "endLoc": {
          "line": 207,
          "column": 2,
          "position": 1871
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 144,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 144,
          "column": 2,
          "position": 1106
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages,\n      false\n    );\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 219,
        "end": 232,
        "startLoc": {
          "line": 219,
          "column": 19,
          "position": 2011
        },
        "endLoc": {
          "line": 232,
          "column": 5,
          "position": 2090
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 170,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 170,
          "column": 1,
          "position": 1317
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  TogetherAiLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 231,
        "end": 255,
        "startLoc": {
          "line": 231,
          "column": 2,
          "position": 2089
        },
        "endLoc": {
          "line": 255,
          "column": 14,
          "position": 2285
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 169,
        "end": 193,
        "startLoc": {
          "line": 169,
          "column": 1,
          "position": 1317
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "}`);\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 32,
        "end": 55,
        "startLoc": {
          "line": 32,
          "column": 6,
          "position": 294
        },
        "endLoc": {
          "line": 55,
          "column": 11,
          "position": 469
        }
      },
      "secondFile": {
        "name": "server/utils/MCP/hypervisor/index.js",
        "start": 87,
        "end": 56,
        "startLoc": {
          "line": 87,
          "column": 18,
          "position": 413
        },
        "endLoc": {
          "line": 56,
          "column": 10,
          "position": 486
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": "\n  isValidChatCompletionModel(_modelName = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 72,
        "end": 103,
        "startLoc": {
          "line": 72,
          "column": 39,
          "position": 612
        },
        "endLoc": {
          "line": 103,
          "column": 6,
          "position": 777
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 63,
        "end": 129,
        "startLoc": {
          "line": 63,
          "column": 1,
          "position": 547
        },
        "endLoc": {
          "line": 129,
          "column": 6,
          "position": 1185
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 92,
        "end": 110,
        "startLoc": {
          "line": 92,
          "column": 14,
          "position": 748
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 826
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 84,
        "end": 101,
        "startLoc": {
          "line": 84,
          "column": 7,
          "position": 690
        },
        "endLoc": {
          "line": 101,
          "column": 2,
          "position": 768
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 103,
        "end": 126,
        "startLoc": {
          "line": 103,
          "column": 6,
          "position": 778
        },
        "endLoc": {
          "line": 126,
          "column": 6,
          "position": 963
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 158,
        "end": 118,
        "startLoc": {
          "line": 158,
          "column": 1,
          "position": 1491
        },
        "endLoc": {
          "line": 118,
          "column": 3,
          "position": 907
        }
      }
    },
    {
      "format": "javascript",
      "lines": 33,
      "fragment": "\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps: result.output.usage?.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 125,
        "end": 157,
        "startLoc": {
          "line": 125,
          "column": 2,
          "position": 961
        },
        "endLoc": {
          "line": 157,
          "column": 6,
          "position": 1237
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 122,
        "end": 154,
        "startLoc": {
          "line": 122,
          "column": 1,
          "position": 942
        },
        "endLoc": {
          "line": 154,
          "column": 3,
          "position": 1214
        }
      }
    },
    {
      "format": "javascript",
      "lines": 26,
      "fragment": "\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  TextGenWebUILLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 164,
        "end": 189,
        "startLoc": {
          "line": 164,
          "column": 9,
          "position": 1294
        },
        "endLoc": {
          "line": 189,
          "column": 16,
          "position": 1494
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 230,
        "end": 193,
        "startLoc": {
          "line": 230,
          "column": 6,
          "position": 2085
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 34,
        "end": 44,
        "startLoc": {
          "line": 34,
          "column": 28,
          "position": 315
        },
        "endLoc": {
          "line": 44,
          "column": 1,
          "position": 405
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 31,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 31,
          "column": 5,
          "position": 289
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ";\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  models",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 70,
        "end": 85,
        "startLoc": {
          "line": 70,
          "column": 10,
          "position": 690
        },
        "endLoc": {
          "line": 85,
          "column": 7,
          "position": 796
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 52,
        "startLoc": {
          "line": 37,
          "column": 2,
          "position": 355
        },
        "endLoc": {
          "line": 52,
          "column": 17,
          "position": 461
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ";\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 106,
        "end": 125,
        "startLoc": {
          "line": 106,
          "column": 2,
          "position": 996
        },
        "endLoc": {
          "line": 125,
          "column": 7,
          "position": 1121
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 65,
        "end": 84,
        "startLoc": {
          "line": 65,
          "column": 5,
          "position": 564
        },
        "endLoc": {
          "line": 84,
          "column": 7,
          "position": 689
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !Object",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 149,
        "end": 165,
        "startLoc": {
          "line": 149,
          "column": 13,
          "position": 1324
        },
        "endLoc": {
          "line": 165,
          "column": 7,
          "position": 1427
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 136,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 136,
          "column": 7,
          "position": 1034
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `PPIO chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 165,
        "end": 188,
        "startLoc": {
          "line": 165,
          "column": 2,
          "position": 1440
        },
        "endLoc": {
          "line": 188,
          "column": 22,
          "position": 1657
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 136,
        "end": 152,
        "startLoc": {
          "line": 136,
          "column": 2,
          "position": 1040
        },
        "endLoc": {
          "line": 152,
          "column": 7,
          "position": 1339
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  async",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 185,
        "end": 204,
        "startLoc": {
          "line": 185,
          "column": 13,
          "position": 1642
        },
        "endLoc": {
          "line": 204,
          "column": 6,
          "position": 1761
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 173,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 173,
          "column": 89,
          "position": 1343
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nasync",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 203,
        "end": 218,
        "startLoc": {
          "line": 203,
          "column": 1,
          "position": 1759
        },
        "endLoc": {
          "line": 218,
          "column": 6,
          "position": 1900
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 177,
        "end": 192,
        "startLoc": {
          "line": 177,
          "column": 89,
          "position": 1363
        },
        "endLoc": {
          "line": 192,
          "column": 7,
          "position": 1504
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ";\n    this.defaultTemp = 0.7;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  allModelInformation",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 36,
        "end": 52,
        "startLoc": {
          "line": 36,
          "column": 2,
          "position": 328
        },
        "endLoc": {
          "line": 52,
          "column": 20,
          "position": 444
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 96,
        "end": 52,
        "startLoc": {
          "line": 96,
          "column": 9,
          "position": 931
        },
        "endLoc": {
          "line": 52,
          "column": 17,
          "position": 461
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [prompt, ...chatHistory, { role: \"user\", content: userPrompt }];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Perplexity chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 79,
        "end": 91,
        "startLoc": {
          "line": 79,
          "column": 3,
          "position": 648
        },
        "endLoc": {
          "line": 91,
          "column": 19,
          "position": 781
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 164,
        "end": 183,
        "startLoc": {
          "line": 164,
          "column": 2,
          "position": 1538
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps: result.output.usage?.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Perplexity chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 91,
        "end": 130,
        "startLoc": {
          "line": 91,
          "column": 19,
          "position": 782
        },
        "endLoc": {
          "line": 130,
          "column": 22,
          "position": 1112
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 94,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 94,
          "column": 7,
          "position": 797
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  /**\n   * Enrich a token with citations if available for in-line citations.\n   * @param {string} token - The token to enrich.\n   * @param {Array} citations - The citations to enrich the token with.\n   * @returns {string} The enriched token.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 127,
        "end": 147,
        "startLoc": {
          "line": 127,
          "column": 19,
          "position": 1097
        },
        "endLoc": {
          "line": 147,
          "column": 6,
          "position": 1183
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 169,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 169,
          "column": 13,
          "position": 1310
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ");\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  PerplexityLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 276,
        "end": 295,
        "startLoc": {
          "line": 276,
          "column": 2,
          "position": 2276
        },
        "endLoc": {
          "line": 295,
          "column": 14,
          "position": 2435
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 174,
        "end": 193,
        "startLoc": {
          "line": 174,
          "column": 14,
          "position": 1354
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n} = require(\"../../helpers/chat/responses\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst { safeJsonParse } = require(\"../../http\");\nconst {\n  LLMPerformanceMonitor,\n} = require(\"../../helpers/chat/LLMPerformanceMonitor\");\nconst cacheFolder = path.resolve(\n  process.env.STORAGE_DIR\n    ? path.resolve(process.env.STORAGE_DIR, \"models\", \"openrouter\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 6,
        "end": 16,
        "startLoc": {
          "line": 6,
          "column": 18,
          "position": 49
        },
        "endLoc": {
          "line": 16,
          "column": 13,
          "position": 154
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 3,
        "end": 13,
        "startLoc": {
          "line": 3,
          "column": 30,
          "position": 22
        },
        "endLoc": {
          "line": 13,
          "column": 7,
          "position": 127
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ") {\n    if (!Array.isArray(citations) || citations.length === 0) return token;\n    return token.replace(/\\[(\\d+)\\]/g, (match, index) => {\n      const citationIndex = parseInt(index) - 1;\n      return citations[citationIndex]\n        ? `[[${index}](${citations[citationIndex]})]`\n        : match;\n    });\n  }\n\n  log",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 70,
        "end": 80,
        "startLoc": {
          "line": 70,
          "column": 2,
          "position": 581
        },
        "endLoc": {
          "line": 80,
          "column": 4,
          "position": 691
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 148,
        "end": 158,
        "startLoc": {
          "line": 148,
          "column": 10,
          "position": 1192
        },
        "endLoc": {
          "line": 158,
          "column": 13,
          "position": 1302
        }
      }
    },
    {
      "format": "javascript",
      "lines": 28,
      "fragment": ";\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  models() {\n    if (!fs.existsSync(this.cacheModelPath)) return {};\n    return safeJsonParse(\n      fs.readFileSync(this.cacheModelPath, { encoding: \"utf-8\" }),\n      {}\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 124,
        "end": 151,
        "startLoc": {
          "line": 124,
          "column": 7,
          "position": 1016
        },
        "endLoc": {
          "line": 151,
          "column": 7,
          "position": 1210
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 97,
        "startLoc": {
          "line": 37,
          "column": 2,
          "position": 355
        },
        "endLoc": {
          "line": 97,
          "column": 18,
          "position": 884
        }
      }
    },
    {
      "format": "javascript",
      "lines": 31,
      "fragment": "model);\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Parses and prepends reasoning from the response and returns the full text response.\n   * @param {Object} response\n   * @returns {string}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 170,
        "end": 200,
        "startLoc": {
          "line": 170,
          "column": 2,
          "position": 1399
        },
        "endLoc": {
          "line": 200,
          "column": 6,
          "position": 1556
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 106,
        "end": 132,
        "startLoc": {
          "line": 106,
          "column": 2,
          "position": 994
        },
        "endLoc": {
          "line": 132,
          "column": 16,
          "position": 1151
        }
      }
    },
    {
      "format": "javascript",
      "lines": 28,
      "fragment": ";\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `OpenRouter chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 205,
        "end": 232,
        "startLoc": {
          "line": 205,
          "column": 13,
          "position": 1634
        },
        "endLoc": {
          "line": 232,
          "column": 19,
          "position": 1851
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 156,
        "end": 183,
        "startLoc": {
          "line": 156,
          "column": 7,
          "position": 1486
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ",\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `OpenRouter chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 259,
        "end": 276,
        "startLoc": {
          "line": 259,
          "column": 2,
          "position": 2069
        },
        "endLoc": {
          "line": 276,
          "column": 22,
          "position": 2237
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 142,
        "end": 235,
        "startLoc": {
          "line": 142,
          "column": 8,
          "position": 1089
        },
        "endLoc": {
          "line": 235,
          "column": 7,
          "position": 1867
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "${timeoutThresholdMs}ms. Closing response stream.`\n          );\n          writeResponseChunk(response, {\n            uuid,\n            sources,\n            type: \"textResponseChunk\",\n            textResponse: \"\",\n            close: true,\n            error: false,\n          });\n          clearInterval(timeoutCheck);\n          response.removeListener(\"close\", handleAbort);\n          stream?.endMeasurement({",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 343,
        "end": 355,
        "startLoc": {
          "line": 343,
          "column": 63,
          "position": 2655
        },
        "endLoc": {
          "line": 355,
          "column": 2,
          "position": 2738
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 184,
        "end": 196,
        "startLoc": {
          "line": 184,
          "column": 63,
          "position": 1569
        },
        "endLoc": {
          "line": 196,
          "column": 6,
          "position": 1652
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n            writeResponseChunk(response, {\n              uuid,\n              sources,\n              type: \"textResponseChunk\",\n              textResponse: \"\",\n              close: true,\n              error: false,\n            });\n            response.removeListener(\"close\", handleAbort);\n            clearInterval",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 444,
        "end": 454,
        "startLoc": {
          "line": 444,
          "column": 2,
          "position": 3362
        },
        "endLoc": {
          "line": 454,
          "column": 14,
          "position": 3425
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 246,
        "end": 256,
        "startLoc": {
          "line": 246,
          "column": 2,
          "position": 2066
        },
        "endLoc": {
          "line": 256,
          "column": 7,
          "position": 2129
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nasync function fetchOpenRouterModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 475,
        "end": 495,
        "startLoc": {
          "line": 475,
          "column": 2,
          "position": 3581
        },
        "endLoc": {
          "line": 495,
          "column": 22,
          "position": 3741
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 274,
        "end": 218,
        "startLoc": {
          "line": 274,
          "column": 48,
          "position": 2270
        },
        "endLoc": {
          "line": 218,
          "column": 16,
          "position": 1904
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": "\n      if (!fs.existsSync(cacheFolder))\n        fs.mkdirSync(cacheFolder, { recursive: true });\n      fs.writeFileSync(\n        path.resolve(cacheFolder, \"models.json\"),\n        JSON.stringify(models),\n        {\n          encoding: \"utf-8\",\n        }\n      );\n      fs.writeFileSync(\n        path.resolve(cacheFolder, \".cached_at\"),\n        String(Number(new Date())),\n        {\n          encoding: \"utf-8\",\n        }\n      );\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 516,
        "end": 534,
        "startLoc": {
          "line": 516,
          "column": 34,
          "position": 3947
        },
        "endLoc": {
          "line": 534,
          "column": 1,
          "position": 4073
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 238,
        "end": 255,
        "startLoc": {
          "line": 238,
          "column": 1,
          "position": 2122
        },
        "endLoc": {
          "line": 255,
          "column": 7,
          "position": 2248
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n      return models;\n    })\n    .catch((e) => {\n      console.error(e);\n      return {};\n    });\n}\n\nmodule.exports = {\n  OpenRouterLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 533,
        "end": 543,
        "startLoc": {
          "line": 533,
          "column": 1,
          "position": 4073
        },
        "endLoc": {
          "line": 543,
          "column": 14,
          "position": 4129
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 254,
        "end": 264,
        "startLoc": {
          "line": 254,
          "column": 2,
          "position": 2247
        },
        "endLoc": {
          "line": 264,
          "column": 8,
          "position": 2303
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.log(\n      `Initialized ${this.model} with context window ${this.promptWindowLimit()}`\n    );\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  /**\n   * Check if the model is an o1 model.\n   * @returns {boolean}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 20,
        "end": 41,
        "startLoc": {
          "line": 20,
          "column": 9,
          "position": 191
        },
        "endLoc": {
          "line": 41,
          "column": 6,
          "position": 354
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 29,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 29,
          "column": 6,
          "position": 247
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ");\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    // o3-mini is the only o-type model that supports streaming",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 43,
        "end": 59,
        "startLoc": {
          "line": 43,
          "column": 4,
          "position": 375
        },
        "endLoc": {
          "line": 59,
          "column": 60,
          "position": 489
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 53,
        "startLoc": {
          "line": 37,
          "column": 5,
          "position": 354
        },
        "endLoc": {
          "line": 53,
          "column": 7,
          "position": 468
        }
      }
    },
    {
      "format": "javascript",
      "lines": 39,
      "fragment": ";\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"high\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [], // This is the specific attachment for only this prompt\n  }) {\n    // o1 Models do not support the \"system\" role",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 87,
        "end": 125,
        "startLoc": {
          "line": 87,
          "column": 6,
          "position": 726
        },
        "endLoc": {
          "line": 125,
          "column": 46,
          "position": 940
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 65,
        "end": 103,
        "startLoc": {
          "line": 65,
          "column": 5,
          "position": 564
        },
        "endLoc": {
          "line": 103,
          "column": 6,
          "position": 778
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ": \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `OpenAI chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 129,
        "end": 145,
        "startLoc": {
          "line": 129,
          "column": 2,
          "position": 969
        },
        "endLoc": {
          "line": 145,
          "column": 15,
          "position": 1115
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 104,
        "end": 183,
        "startLoc": {
          "line": 104,
          "column": 5,
          "position": 788
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": "\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `OpenAI chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 153,
        "end": 184,
        "startLoc": {
          "line": 153,
          "column": 39,
          "position": 1188
        },
        "endLoc": {
          "line": 184,
          "column": 22,
          "position": 1457
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 128,
        "end": 148,
        "startLoc": {
          "line": 128,
          "column": 2,
          "position": 988
        },
        "endLoc": {
          "line": 148,
          "column": 7,
          "position": 1131
        }
      }
    },
    {
      "format": "javascript",
      "lines": 27,
      "fragment": "\n    );\n\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  OpenAiLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 194,
        "end": 220,
        "startLoc": {
          "line": 194,
          "column": 92,
          "position": 1536
        },
        "endLoc": {
          "line": 220,
          "column": 10,
          "position": 1737
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 167,
        "end": 193,
        "startLoc": {
          "line": 167,
          "column": 6,
          "position": 1312
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.OLLAMA_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 43,
        "end": 63,
        "startLoc": {
          "line": 43,
          "column": 26,
          "position": 436
        },
        "endLoc": {
          "line": 63,
          "column": 25,
          "position": 592
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 56,
        "startLoc": {
          "line": 37,
          "column": 10,
          "position": 346
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent,",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 107,
        "end": 128,
        "startLoc": {
          "line": 107,
          "column": 2,
          "position": 901
        },
        "endLoc": {
          "line": 128,
          "column": 2,
          "position": 1022
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 88,
        "end": 109,
        "startLoc": {
          "line": 88,
          "column": 2,
          "position": 713
        },
        "endLoc": {
          "line": 109,
          "column": 2,
          "position": 836
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ";\n            writeResponseChunk(response, {\n              uuid,\n              sources,\n              type: \"textResponseChunk\",\n              textResponse: \"\",\n              close: true,\n              error: false,\n            });\n            response.removeListener(\"close\", handleAbort);\n            stream?.endMeasurement(usage);\n            resolve",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 245,
        "end": 256,
        "startLoc": {
          "line": 245,
          "column": 11,
          "position": 1907
        },
        "endLoc": {
          "line": 256,
          "column": 8,
          "position": 1981
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 246,
        "end": 257,
        "startLoc": {
          "line": 246,
          "column": 2,
          "position": 2065
        },
        "endLoc": {
          "line": 257,
          "column": 14,
          "position": 2139
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ");\n        resolve(fullText);\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  OllamaAILLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 285,
        "end": 307,
        "startLoc": {
          "line": 285,
          "column": 6,
          "position": 2181
        },
        "endLoc": {
          "line": 307,
          "column": 12,
          "position": 2355
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 474,
        "end": 193,
        "startLoc": {
          "line": 474,
          "column": 2,
          "position": 3572
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  /**\n   * Set the model token limit `NVIDIA_NIM_LLM_MODEL_TOKEN_LIMIT` for the given model ID\n   * @param {string} modelId\n   * @param {string} basePath\n   * @returns {Promise<void>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 35,
        "end": 56,
        "startLoc": {
          "line": 35,
          "column": 2,
          "position": 306
        },
        "endLoc": {
          "line": 56,
          "column": 6,
          "position": 446
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 36,
        "end": 52,
        "startLoc": {
          "line": 36,
          "column": 3,
          "position": 321
        },
        "endLoc": {
          "line": 52,
          "column": 17,
          "position": 461
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": " = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 101,
        "end": 132,
        "startLoc": {
          "line": 101,
          "column": 2,
          "position": 853
        },
        "endLoc": {
          "line": 132,
          "column": 6,
          "position": 1020
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 64,
        "end": 132,
        "startLoc": {
          "line": 64,
          "column": 11,
          "position": 552
        },
        "endLoc": {
          "line": 132,
          "column": 16,
          "position": 1151
        }
      }
    },
    {
      "format": "javascript",
      "lines": 35,
      "fragment": ",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!this.model",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 121,
        "end": 155,
        "startLoc": {
          "line": 121,
          "column": 7,
          "position": 991
        },
        "endLoc": {
          "line": 155,
          "column": 6,
          "position": 1212
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 84,
        "end": 118,
        "startLoc": {
          "line": 84,
          "column": 7,
          "position": 690
        },
        "endLoc": {
          "line": 118,
          "column": 27,
          "position": 913
        }
      }
    },
    {
      "format": "javascript",
      "lines": 31,
      "fragment": ".chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!this.model",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 161,
        "end": 191,
        "startLoc": {
          "line": 161,
          "column": 10,
          "position": 1255
        },
        "endLoc": {
          "line": 191,
          "column": 6,
          "position": 1514
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 124,
        "end": 154,
        "startLoc": {
          "line": 124,
          "column": 7,
          "position": 961
        },
        "endLoc": {
          "line": 154,
          "column": 27,
          "position": 1220
        }
      }
    },
    {
      "format": "javascript",
      "lines": 36,
      "fragment": ".chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\n/**\n * Parse the base path for the Nvidia NIM container API. Since the base path must end in /v1 and cannot have a trailing slash,\n * and the user can possibly set it to anything and likely incorrectly due to pasting behaviors, we need to ensure it is in the correct format.\n * @param {string} basePath\n * @returns {string}\n */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 197,
        "end": 232,
        "startLoc": {
          "line": 197,
          "column": 10,
          "position": 1557
        },
        "endLoc": {
          "line": 232,
          "column": 4,
          "position": 1788
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 158,
        "end": 192,
        "startLoc": {
          "line": 158,
          "column": 7,
          "position": 1254
        },
        "endLoc": {
          "line": 192,
          "column": 7,
          "position": 1504
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "const { NativeEmbedder } = require(\"../../EmbeddingEngines/native\");\nconst { v4: uuidv4 } = require(\"uuid\");\nconst {\n  writeResponseChunk,\n  clientAbortedHandler,\n  formatChatHistory,\n} = require(\"../../helpers/chat/responses\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst { safeJsonParse } = require(\"../../http\");\nconst {\n  LLMPerformanceMonitor,\n} = require(\"../../helpers/chat/LLMPerformanceMonitor\");\nconst cacheFolder = path.resolve(\n  process.env.STORAGE_DIR\n    ? path.resolve(process.env.STORAGE_DIR, \"models\", \"novita\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 1,
        "end": 16,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 16,
          "column": 9,
          "position": 154
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 1,
        "end": 13,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 13,
          "column": 7,
          "position": 127
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.timeout = this.#parseTimeout();\n\n    if (!fs.existsSync(cacheFolder))\n      fs.mkdirSync(cacheFolder, { recursive: true });\n    this.cacheModelPath = path.resolve(cacheFolder, \"models.json\");\n    this.cacheAtPath = path.resolve(cacheFolder, \".cached_at\");\n\n    this.log(`Loaded with model: ${this.model}`);\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  /**\n   * Novita has various models that never return `finish_reasons` and thus leave the stream open\n   * which causes issues in subsequent messages. This timeout value forces us to close the stream after\n   * x milliseconds. This is a configurable value via the NOVITA_LLM_TIMEOUT_MS value\n   * @returns {number} The timeout value in milliseconds (default: 500)\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 38,
        "end": 66,
        "startLoc": {
          "line": 38,
          "column": 23,
          "position": 343
        },
        "endLoc": {
          "line": 66,
          "column": 6,
          "position": 579
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 97,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 97,
          "column": 6,
          "position": 464
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ");\n    if (setValue < 500) return 500;\n    return setValue;\n  }\n\n  // This checks if the .cached_at file has a timestamp that is more than 1Week (in millis)\n  // from the current date. If it is, then we will refetch the API so that all the models are up\n  // to date.\n  #cacheIsStale() {\n    const MAX_STALE = 6.048e8; // 1 Week in MS\n    if (!fs.existsSync(this.cacheAtPath)) return true;\n    const now = Number(new Date());\n    const timestampMs = Number(fs.readFileSync(this.cacheAtPath));\n    return now - timestampMs > MAX_STALE;\n  }\n\n  // The Novita model API has a lot of models, so we cache this locally in the directory",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 69,
        "end": 85,
        "startLoc": {
          "line": 69,
          "column": 22,
          "position": 625
        },
        "endLoc": {
          "line": 85,
          "column": 87,
          "position": 759
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 95,
        "end": 73,
        "startLoc": {
          "line": 95,
          "column": 22,
          "position": 804
        },
        "endLoc": {
          "line": 73,
          "column": 2,
          "position": 697
        }
      }
    },
    {
      "format": "javascript",
      "lines": 79,
      "fragment": "();\n    return;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  models() {\n    if (!fs.existsSync(this.cacheModelPath)) return {};\n    return safeJsonParse(\n      fs.readFileSync(this.cacheModelPath, { encoding: \"utf-8\" }),\n      {}\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(modelName) {\n    const cacheModelPath = path.resolve(cacheFolder, \"models.json\");\n    const availableModels = fs.existsSync(cacheModelPath)\n      ? safeJsonParse(\n          fs.readFileSync(cacheModelPath, { encoding: \"utf-8\" }),\n          {}\n        )\n      : {};\n    return availableModels[modelName]?.maxLength || 4096;\n  }\n\n  promptWindowLimit() {\n    const availableModels = this.models();\n    return availableModels[this.model]?.maxLength || 4096;\n  }\n\n  async isValidChatCompletionModel(model = \"\") {\n    await this.#syncModels();\n    const availableModels = this.models();\n    return availableModels.hasOwnProperty(model);\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 95,
        "end": 173,
        "startLoc": {
          "line": 95,
          "column": 18,
          "position": 827
        },
        "endLoc": {
          "line": 173,
          "column": 12,
          "position": 1412
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 123,
        "end": 137,
        "startLoc": {
          "line": 123,
          "column": 22,
          "position": 1010
        },
        "endLoc": {
          "line": 137,
          "column": 37,
          "position": 1190
        }
      }
    },
    {
      "format": "javascript",
      "lines": 28,
      "fragment": ";\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Novita chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 165,
        "end": 192,
        "startLoc": {
          "line": 165,
          "column": 2,
          "position": 1366
        },
        "endLoc": {
          "line": 192,
          "column": 15,
          "position": 1583
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/togetherAi/index.js",
        "start": 156,
        "end": 183,
        "startLoc": {
          "line": 156,
          "column": 7,
          "position": 1486
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Novita chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 192,
        "end": 231,
        "startLoc": {
          "line": 192,
          "column": 15,
          "position": 1584
        },
        "endLoc": {
          "line": 231,
          "column": 22,
          "position": 1910
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 195,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 195,
          "column": 7,
          "position": 1599
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  /**\n   * Handles the default stream response for a chat.\n   * @param {import(\"express\").Response} response\n   * @param {import('../../helpers/chat/LLMPerformanceMonitor').MonitoredStream} stream\n   * @param {Object} responseProps\n   * @returns {Promise<string>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 228,
        "end": 249,
        "startLoc": {
          "line": 228,
          "column": 15,
          "position": 1895
        },
        "endLoc": {
          "line": 249,
          "column": 6,
          "position": 1981
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 169,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 169,
          "column": 13,
          "position": 1310
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "\n    return measuredStreamRequest;\n  }\n\n  /**\n   * Handles the default stream response for a chat.\n   * @param {import(\"express\").Response} response\n   * @param {import('../../helpers/chat/LLMPerformanceMonitor').MonitoredStream} stream\n   * @param {Object} responseProps\n   * @returns {Promise<string>}\n   */\n  handleStream(response, stream, responseProps) {\n    const timeoutThresholdMs = this.timeout;\n    const { uuid = uuidv4(), sources = [] } = responseProps;\n\n    return new Promise(async (resolve) => {\n      let fullText = \"\";\n      let lastChunkTime",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 239,
        "end": 256,
        "startLoc": {
          "line": 239,
          "column": 2,
          "position": 1969
        },
        "endLoc": {
          "line": 256,
          "column": 14,
          "position": 2068
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 294,
        "end": 311,
        "startLoc": {
          "line": 294,
          "column": 1,
          "position": 2328
        },
        "endLoc": {
          "line": 311,
          "column": 14,
          "position": 2427
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "\n\n      // Establish listener to early-abort a streaming response\n      // in case things go sideways or the user does not like the response.\n      // We preserve the generated text but continue as if chat was completed\n      // to preserve previously generated content.\n      const handleAbort = () => {\n        stream?.endMeasurement({\n          completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n        });\n        clientAbortedHandler(resolve, fullText);\n      };\n      response.on(\"close\", handleAbort);\n\n      // NOTICE: Not all Novita models will return a stop reason",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 256,
        "end": 270,
        "startLoc": {
          "line": 256,
          "column": 48,
          "position": 2076
        },
        "endLoc": {
          "line": 270,
          "column": 59,
          "position": 2157
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 314,
        "end": 328,
        "startLoc": {
          "line": 314,
          "column": 2,
          "position": 2470
        },
        "endLoc": {
          "line": 328,
          "column": 63,
          "position": 2551
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "${timeoutThresholdMs}ms. Closing response stream.`\n          );\n          writeResponseChunk(response, {\n            uuid,\n            sources,\n            type: \"textResponseChunk\",\n            textResponse: \"\",\n            close: true,\n            error: false,\n          });\n          clearInterval(timeoutCheck);\n          response.removeListener(\"close\", handleAbort);\n          stream?.endMeasurement({\n            completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n          });\n          resolve(fullText);\n        }\n      }, 500);\n\n      try {\n        for await (const chunk of stream) {\n          const message = chunk?.choices?.[0];\n          const token = message?.delta?.content;\n          lastChunkTime",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 284,
        "end": 307,
        "startLoc": {
          "line": 284,
          "column": 59,
          "position": 2260
        },
        "endLoc": {
          "line": 307,
          "column": 14,
          "position": 2438
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 184,
        "end": 366,
        "startLoc": {
          "line": 184,
          "column": 63,
          "position": 1569
        },
        "endLoc": {
          "line": 366,
          "column": 6,
          "position": 2833
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ",\n              close: false,\n              error: false,\n            });\n          }\n\n          if (message.finish_reason !== null) {\n            writeResponseChunk(response, {\n              uuid,\n              sources,\n              type: \"textResponseChunk\",\n              textResponse: \"\",\n              close: true,\n              error: false,\n            });\n            response.removeListener(\"close\", handleAbort);\n            stream?.endMeasurement({",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 315,
        "end": 331,
        "startLoc": {
          "line": 315,
          "column": 6,
          "position": 2502
        },
        "endLoc": {
          "line": 331,
          "column": 2,
          "position": 2609
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 438,
        "end": 256,
        "startLoc": {
          "line": 438,
          "column": 15,
          "position": 3323
        },
        "endLoc": {
          "line": 256,
          "column": 6,
          "position": 2134
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ");\n            stream?.endMeasurement({\n              completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n            });\n            resolve(fullText);\n          }\n        }\n      } catch (e) {\n        writeResponseChunk(response, {\n          uuid,\n          sources,\n          type: \"abort\",\n          textResponse: null,\n          close: true,\n          error: e.message,\n        });\n        response.removeListener(\"close\", handleAbort);\n        stream",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 330,
        "end": 347,
        "startLoc": {
          "line": 330,
          "column": 12,
          "position": 2600
        },
        "endLoc": {
          "line": 347,
          "column": 7,
          "position": 2716
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 454,
        "end": 471,
        "startLoc": {
          "line": 454,
          "column": 13,
          "position": 3428
        },
        "endLoc": {
          "line": 471,
          "column": 14,
          "position": 3544
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": ");\n        stream?.endMeasurement({\n          completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n        });\n        resolve(fullText);\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nasync function fetchNovitaModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 346,
        "end": 370,
        "startLoc": {
          "line": 346,
          "column": 12,
          "position": 2712
        },
        "endLoc": {
          "line": 370,
          "column": 18,
          "position": 2906
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 471,
        "end": 218,
        "startLoc": {
          "line": 471,
          "column": 13,
          "position": 3547
        },
        "endLoc": {
          "line": 218,
          "column": 16,
          "position": 1904
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ", {\n    method: \"GET\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  })\n    .then((res) => res.json())\n    .then(({ data = [] }) => {\n      const models = {};\n      data.forEach((model) => {\n        models[model.id] = {\n          id: model.id,\n          name: model.title",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 371,
        "end": 383,
        "startLoc": {
          "line": 371,
          "column": 41,
          "position": 2920
        },
        "endLoc": {
          "line": 383,
          "column": 6,
          "position": 3041
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 496,
        "end": 508,
        "startLoc": {
          "line": 496,
          "column": 38,
          "position": 3755
        },
        "endLoc": {
          "line": 508,
          "column": 5,
          "position": 3876
        }
      }
    },
    {
      "format": "javascript",
      "lines": 31,
      "fragment": ",\n        };\n      });\n\n      // Cache all response information\n      if (!fs.existsSync(cacheFolder))\n        fs.mkdirSync(cacheFolder, { recursive: true });\n      fs.writeFileSync(\n        path.resolve(cacheFolder, \"models.json\"),\n        JSON.stringify(models),\n        {\n          encoding: \"utf-8\",\n        }\n      );\n      fs.writeFileSync(\n        path.resolve(cacheFolder, \".cached_at\"),\n        String(Number(new Date())),\n        {\n          encoding: \"utf-8\",\n        }\n      );\n      return models;\n    })\n    .catch((e) => {\n      console.error(e);\n      return {};\n    });\n}\n\nmodule.exports = {\n  NovitaLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 387,
        "end": 417,
        "startLoc": {
          "line": 387,
          "column": 13,
          "position": 3098
        },
        "endLoc": {
          "line": 417,
          "column": 10,
          "position": 3293
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 512,
        "end": 264,
        "startLoc": {
          "line": 512,
          "column": 15,
          "position": 3933
        },
        "endLoc": {
          "line": 264,
          "column": 8,
          "position": 2303
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ") {\n    if (!process.env.MISTRAL_API_KEY)\n      throw new Error(\"No Mistral API key was set.\");\n\n    const { OpenAI: OpenAIApi } = require(\"openai\");\n    this.openai = new OpenAIApi({\n      baseURL: \"https://api.mistral.ai/v1\",\n      apiKey: process.env.MISTRAL_API_KEY ?? null,\n    });\n    this.model =\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 11,
        "end": 21,
        "startLoc": {
          "line": 11,
          "column": 5,
          "position": 78
        },
        "endLoc": {
          "line": 21,
          "column": 1,
          "position": 173
        }
      },
      "secondFile": {
        "name": "server/utils/EmbeddingEngines/mistral/index.js",
        "start": 2,
        "end": 11,
        "startLoc": {
          "line": 2,
          "column": 2,
          "position": 9
        },
        "endLoc": {
          "line": 11,
          "column": 2,
          "position": 104
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": ");\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit()",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 30,
        "end": 53,
        "startLoc": {
          "line": 30,
          "column": 6,
          "position": 289
        },
        "endLoc": {
          "line": 53,
          "column": 2,
          "position": 462
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 33,
        "end": 56,
        "startLoc": {
          "line": 33,
          "column": 5,
          "position": 313
        },
        "endLoc": {
          "line": 56,
          "column": 10,
          "position": 486
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": " = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) return",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 61,
        "end": 71,
        "startLoc": {
          "line": 61,
          "column": 10,
          "position": 499
        },
        "endLoc": {
          "line": 71,
          "column": 7,
          "position": 551
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 64,
        "end": 74,
        "startLoc": {
          "line": 64,
          "column": 11,
          "position": 552
        },
        "endLoc": {
          "line": 74,
          "column": 2,
          "position": 604
        }
      }
    },
    {
      "format": "javascript",
      "lines": 36,
      "fragment": ",\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [], // This is the specific attachment for only this prompt\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Mistral chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 77,
        "end": 112,
        "startLoc": {
          "line": 77,
          "column": 14,
          "position": 618
        },
        "endLoc": {
          "line": 112,
          "column": 16,
          "position": 858
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 85,
        "end": 183,
        "startLoc": {
          "line": 85,
          "column": 2,
          "position": 694
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Mistral chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 112,
        "end": 151,
        "startLoc": {
          "line": 112,
          "column": 16,
          "position": 859
        },
        "endLoc": {
          "line": 151,
          "column": 22,
          "position": 1185
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 115,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 115,
          "column": 7,
          "position": 874
        }
      }
    },
    {
      "format": "javascript",
      "lines": 37,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages,\n      false\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  MistralLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 148,
        "end": 184,
        "startLoc": {
          "line": 148,
          "column": 16,
          "position": 1170
        },
        "endLoc": {
          "line": 184,
          "column": 11,
          "position": 1444
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 193,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.LOCAL_AI_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 20,
        "end": 48,
        "startLoc": {
          "line": 20,
          "column": 20,
          "position": 187
        },
        "endLoc": {
          "line": 48,
          "column": 27,
          "position": 422
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 56,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 60,
      "fragment": ");\n    return Number(limit);\n  }\n\n  async isValidChatCompletionModel(_ = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `LocalAI chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 59,
        "end": 118,
        "startLoc": {
          "line": 59,
          "column": 42,
          "position": 528
        },
        "endLoc": {
          "line": 118,
          "column": 16,
          "position": 923
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 97,
        "end": 183,
        "startLoc": {
          "line": 97,
          "column": 45,
          "position": 831
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 36,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  LocalAiLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 155,
        "end": 190,
        "startLoc": {
          "line": 155,
          "column": 16,
          "position": 1218
        },
        "endLoc": {
          "line": 190,
          "column": 11,
          "position": 1488
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 193,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.LMSTUDIO_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/lmStudio/index.js",
        "start": 31,
        "end": 59,
        "startLoc": {
          "line": 31,
          "column": 22,
          "position": 211
        },
        "endLoc": {
          "line": 59,
          "column": 27,
          "position": 446
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 56,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 57,
      "fragment": "\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!this.model)\n      throw new Error(\n        `LMStudio chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/lmStudio/index.js",
        "start": 76,
        "end": 132,
        "startLoc": {
          "line": 76,
          "column": 59,
          "position": 587
        },
        "endLoc": {
          "line": 132,
          "column": 17,
          "position": 951
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 64,
        "end": 157,
        "startLoc": {
          "line": 64,
          "column": 2,
          "position": 559
        },
        "endLoc": {
          "line": 157,
          "column": 19,
          "position": 1224
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ".chat.completions.create({\n        model: this.model,\n        messages,\n        temperature,\n      })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps: result.output.usage?.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!this.model)\n      throw new Error(\n        `LMStudio chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/lmStudio/index.js",
        "start": 136,
        "end": 164,
        "startLoc": {
          "line": 136,
          "column": 9,
          "position": 982
        },
        "endLoc": {
          "line": 164,
          "column": 17,
          "position": 1226
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 122,
        "end": 193,
        "startLoc": {
          "line": 122,
          "column": 7,
          "position": 954
        },
        "endLoc": {
          "line": 193,
          "column": 19,
          "position": 1526
        }
      }
    },
    {
      "format": "javascript",
      "lines": 36,
      "fragment": ".chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\n/**\n * Parse the base path for the LMStudio API. Since the base path must end in /v1 and cannot have a trailing slash,\n * and the user can possibly set it to anything and likely incorrectly due to pasting behaviors, we need to ensure it is in the correct format.\n * @param {string} basePath\n * @returns {string}\n */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/lmStudio/index.js",
        "start": 168,
        "end": 203,
        "startLoc": {
          "line": 168,
          "column": 9,
          "position": 1257
        },
        "endLoc": {
          "line": 203,
          "column": 4,
          "position": 1488
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 158,
        "end": 192,
        "startLoc": {
          "line": 158,
          "column": 7,
          "position": 1254
        },
        "endLoc": {
          "line": 192,
          "column": 7,
          "position": 1504
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "(providedBasePath = \"\") {\n  try {\n    const baseURL = new URL(providedBasePath);\n    const basePath = `${baseURL.origin}/v1`;\n    return basePath;\n  } catch (e) {\n    return providedBasePath;\n  }\n}\n\nmodule.exports = {\n  LMStudioLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/lmStudio/index.js",
        "start": 204,
        "end": 215,
        "startLoc": {
          "line": 204,
          "column": 22,
          "position": 1493
        },
        "endLoc": {
          "line": 215,
          "column": 12,
          "position": 1577
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 233,
        "end": 244,
        "startLoc": {
          "line": 233,
          "column": 23,
          "position": 1793
        },
        "endLoc": {
          "line": 244,
          "column": 13,
          "position": 1877
        }
      }
    },
    {
      "format": "javascript",
      "lines": 34,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.log(`Inference API: ${this.basePath} Model: ${this.model}`);\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.LITE_LLM_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 25,
        "end": 58,
        "startLoc": {
          "line": 25,
          "column": 2,
          "position": 248
        },
        "endLoc": {
          "line": 58,
          "column": 27,
          "position": 545
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 56,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 69,
      "fragment": ") {\n    const limit = process.env.LITE_LLM_MODEL_TOKEN_LIMIT || 4096;\n    if (!limit || isNaN(Number(limit)))\n      throw new Error(\"No token context limit was set.\");\n    return Number(limit);\n  }\n\n  // Short circuit since we have no idea if the model is valid or not\n  // in pre-flight for generic endpoints\n  isValidChatCompletionModel(_modelName = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n          ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 66,
        "end": 134,
        "startLoc": {
          "line": 66,
          "column": 2,
          "position": 603
        },
        "endLoc": {
          "line": 134,
          "column": 11,
          "position": 1068
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 57,
        "end": 132,
        "startLoc": {
          "line": 57,
          "column": 11,
          "position": 530
        },
        "endLoc": {
          "line": 132,
          "column": 9,
          "position": 1008
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": "\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps:\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 134,
        "end": 154,
        "startLoc": {
          "line": 134,
          "column": 24,
          "position": 1081
        },
        "endLoc": {
          "line": 154,
          "column": 1,
          "position": 1247
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 128,
        "end": 210,
        "startLoc": {
          "line": 128,
          "column": 2,
          "position": 988
        },
        "endLoc": {
          "line": 210,
          "column": 2,
          "position": 1919
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": " / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n        max_tokens",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 154,
        "end": 167,
        "startLoc": {
          "line": 154,
          "column": 2,
          "position": 1263
        },
        "endLoc": {
          "line": 167,
          "column": 11,
          "position": 1369
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 147,
        "end": 282,
        "startLoc": {
          "line": 147,
          "column": 18,
          "position": 1159
        },
        "endLoc": {
          "line": 282,
          "column": 82,
          "position": 2286
        }
      }
    },
    {
      "format": "javascript",
      "lines": 27,
      "fragment": "\n    );\n\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  LiteLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 171,
        "end": 197,
        "startLoc": {
          "line": 171,
          "column": 117,
          "position": 1395
        },
        "endLoc": {
          "line": 197,
          "column": 8,
          "position": 1596
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 167,
        "end": 193,
        "startLoc": {
          "line": 167,
          "column": 6,
          "position": 1312
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 26,
      "fragment": ";\n    this.log(`Inference API: ${this.basePath} Model: ${this.model}`);\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.KOBOLD_CPP_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 35,
        "end": 60,
        "startLoc": {
          "line": 35,
          "column": 5,
          "position": 352
        },
        "endLoc": {
          "line": 60,
          "column": 29,
          "position": 561
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 31,
        "end": 56,
        "startLoc": {
          "line": 31,
          "column": 4,
          "position": 276
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 69,
      "fragment": ") {\n    const limit = process.env.KOBOLD_CPP_MODEL_TOKEN_LIMIT || 4096;\n    if (!limit || isNaN(Number(limit)))\n      throw new Error(\"No token context limit was set.\");\n    return Number(limit);\n  }\n\n  // Short circuit since we have no idea if the model is valid or not\n  // in pre-flight for generic endpoints\n  isValidChatCompletionModel(_modelName = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n          max_tokens: this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 68,
        "end": 136,
        "startLoc": {
          "line": 68,
          "column": 2,
          "position": 619
        },
        "endLoc": {
          "line": 136,
          "column": 5,
          "position": 1088
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 59,
        "end": 134,
        "startLoc": {
          "line": 59,
          "column": 11,
          "position": 546
        },
        "endLoc": {
          "line": 134,
          "column": 9,
          "position": 1072
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    const promptTokens = LLMPerformanceMonitor.countTokens(messages);\n    const completionTokens = LLMPerformanceMonitor.countTokens([",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 136,
        "end": 150,
        "startLoc": {
          "line": 136,
          "column": 10,
          "position": 1091
        },
        "endLoc": {
          "line": 150,
          "column": 2,
          "position": 1198
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 128,
        "end": 137,
        "startLoc": {
          "line": 128,
          "column": 12,
          "position": 987
        },
        "endLoc": {
          "line": 137,
          "column": 1,
          "position": 1056
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ");\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: promptTokens,\n        completion_tokens: completionTokens,\n        total_tokens: promptTokens + completionTokens,\n        outputTps: completionTokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n        max_tokens: this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 152,
        "end": 173,
        "startLoc": {
          "line": 152,
          "column": 2,
          "position": 1224
        },
        "endLoc": {
          "line": 173,
          "column": 5,
          "position": 1396
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 138,
        "end": 167,
        "startLoc": {
          "line": 138,
          "column": 5,
          "position": 1072
        },
        "endLoc": {
          "line": 167,
          "column": 9,
          "position": 1372
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ";\n          writeResponseChunk(response, {\n            uuid,\n            sources: [],\n            type: \"textResponseChunk\",\n            textResponse: token,\n            close: false,\n            error: false,\n          });\n        }\n\n        // KoboldCPP finishes with \"length\" or \"stop\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 204,
        "end": 215,
        "startLoc": {
          "line": 204,
          "column": 6,
          "position": 1680
        },
        "endLoc": {
          "line": 215,
          "column": 46,
          "position": 1740
        }
      },
      "secondFile": {
        "name": "server/utils/helpers/chat/responses.js",
        "start": 75,
        "end": 86,
        "startLoc": {
          "line": 75,
          "column": 3,
          "position": 502
        },
        "endLoc": {
          "line": 86,
          "column": 91,
          "position": 562
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n        ) {\n          writeResponseChunk(response, {\n            uuid,\n            sources,\n            type: \"textResponseChunk\",\n            textResponse: \"\",\n            close: true,\n            error: false,\n          });\n          response.removeListener(\"close\", handleAbort);\n          usage",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 219,
        "end": 230,
        "startLoc": {
          "line": 219,
          "column": 2,
          "position": 1779
        },
        "endLoc": {
          "line": 230,
          "column": 6,
          "position": 1847
        }
      },
      "secondFile": {
        "name": "server/utils/helpers/chat/responses.js",
        "start": 91,
        "end": 102,
        "startLoc": {
          "line": 91,
          "column": 5,
          "position": 604
        },
        "endLoc": {
          "line": 102,
          "column": 7,
          "position": 672
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  KoboldCPPLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 235,
        "end": 256,
        "startLoc": {
          "line": 235,
          "column": 2,
          "position": 1894
        },
        "endLoc": {
          "line": 256,
          "column": 13,
          "position": 2059
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 274,
        "end": 193,
        "startLoc": {
          "line": 274,
          "column": 48,
          "position": 2270
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ";\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.HUGGING_FACE_LLM_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/huggingface/index.js",
        "start": 32,
        "end": 52,
        "startLoc": {
          "line": 32,
          "column": 4,
          "position": 294
        },
        "endLoc": {
          "line": 52,
          "column": 29,
          "position": 441
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 56,
        "startLoc": {
          "line": 37,
          "column": 2,
          "position": 355
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 70,
      "fragment": "},\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps:\n          (result.output.usage?.completion_tokens || 0) / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  HuggingFaceLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/huggingface/index.js",
        "start": 88,
        "end": 157,
        "startLoc": {
          "line": 88,
          "column": 2,
          "position": 728
        },
        "endLoc": {
          "line": 157,
          "column": 15,
          "position": 1303
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 121,
        "end": 193,
        "startLoc": {
          "line": 121,
          "column": 7,
          "position": 926
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  #log",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/groq/index.js",
        "start": 20,
        "end": 43,
        "startLoc": {
          "line": 20,
          "column": 23,
          "position": 194
        },
        "endLoc": {
          "line": 43,
          "column": 4,
          "position": 389
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 112,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 112,
          "column": 16,
          "position": 1048
        }
      }
    },
    {
      "format": "javascript",
      "lines": 35,
      "fragment": "\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) return userPrompt;\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Last Updated: October 21, 2024\n   * According to https://console.groq.com/docs/vision\n   * the vision models supported all make a mess of prompting depending on the model.\n   * Currently the llama3.2 models are only in preview and subject to change and the llava model is deprecated - so we will not support attachments for that at all.\n   *\n   * Since we can only explicitly support the current models, this is a temporary solution.\n   * If the attachments are empty or the model is not a vision model, we will return the default prompt structure which will work for all models.\n   * If the attachments are present and the model is a vision model - we only return the user prompt with attachments - see comment at end of function for more.\n   *\n   * Historical attachments are also omitted from prompt chat history for the reasons above. (TDC: Dec 30, 2024)\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/groq/index.js",
        "start": 60,
        "end": 94,
        "startLoc": {
          "line": 60,
          "column": 28,
          "position": 530
        },
        "endLoc": {
          "line": 94,
          "column": 6,
          "position": 671
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 62,
        "end": 129,
        "startLoc": {
          "line": 62,
          "column": 2,
          "position": 512
        },
        "endLoc": {
          "line": 129,
          "column": 6,
          "position": 1185
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ";\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [], // This is the specific attachment for only this prompt\n  }) {\n    // NOTICE: SEE GroqLLM.#conditionalPromptStruct for more information on how attachments are handled with Groq.",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/groq/index.js",
        "start": 147,
        "end": 162,
        "startLoc": {
          "line": 147,
          "column": 2,
          "position": 981
        },
        "endLoc": {
          "line": 162,
          "column": 111,
          "position": 1047
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 88,
        "end": 103,
        "startLoc": {
          "line": 88,
          "column": 2,
          "position": 712
        },
        "endLoc": {
          "line": 103,
          "column": 6,
          "position": 778
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps:\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/groq/index.js",
        "start": 175,
        "end": 203,
        "startLoc": {
          "line": 175,
          "column": 25,
          "position": 1142
        },
        "endLoc": {
          "line": 203,
          "column": 1,
          "position": 1362
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 147,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 147,
          "column": 2,
          "position": 1151
        }
      }
    },
    {
      "format": "javascript",
      "lines": 38,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages,\n      false\n    );\n\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  GroqLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/groq/index.js",
        "start": 213,
        "end": 250,
        "startLoc": {
          "line": 213,
          "column": 31,
          "position": 1463
        },
        "endLoc": {
          "line": 250,
          "column": 8,
          "position": 1738
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 193,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 34,
      "fragment": ");\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.log(`Inference API: ${this.basePath} Model: ${this.model}`);\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.GENERIC_OPEN_AI_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 31,
        "end": 64,
        "startLoc": {
          "line": 31,
          "column": 45,
          "position": 284
        },
        "endLoc": {
          "line": 64,
          "column": 34,
          "position": 582
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 25,
        "end": 56,
        "startLoc": {
          "line": 25,
          "column": 39,
          "position": 247
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 30,
      "fragment": ") {\n    const limit = process.env.GENERIC_OPEN_AI_MODEL_TOKEN_LIMIT || 4096;\n    if (!limit || isNaN(Number(limit)))\n      throw new Error(\"No token context limit was set.\");\n    return Number(limit);\n  }\n\n  // Short circuit since we have no idea if the model is valid or not\n  // in pre-flight for generic endpoints\n  isValidChatCompletionModel(_modelName = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   *\n   * ## Developer Note\n   * This function assumes the generic OpenAI provider is _actually_ OpenAI compatible.\n   * For example, Ollama is \"OpenAI compatible\" but does not support images as a content array.\n   * The contentString also is the base64 string WITH `data:image/xxx;base64,` prefix, which may not be the case for all providers.\n   * If your provider does not work exactly this way, then attachments will not function or potentially break vision requests.\n   * If you encounter this issue, you are welcome to open an issue asking for your specific provider to be supported.\n   *\n   * This function will **not** be updated for providers that **do not** support images as a content array like OpenAI does.\n   * Do not open issues to update this function due to your specific provider not being compatible. Open an issue to request support for your specific provider.\n   * @param {Object} props\n   * @param {string} props.userPrompt - the user prompt to be sent to the model\n   * @param {import(\"../../helpers\").Attachment[]} props.attachments - the array of attachments to be sent to the model\n   * @returns {string|object[]}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 72,
        "end": 101,
        "startLoc": {
          "line": 72,
          "column": 2,
          "position": 640
        },
        "endLoc": {
          "line": 101,
          "column": 6,
          "position": 733
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 63,
        "end": 81,
        "startLoc": {
          "line": 63,
          "column": 11,
          "position": 567
        },
        "endLoc": {
          "line": 81,
          "column": 6,
          "position": 636
        }
      }
    },
    {
      "format": "javascript",
      "lines": 50,
      "fragment": "\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"high\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  /**\n   * Parses and prepends reasoning from the response and returns the full text response.\n   * @param {Object} response\n   * @returns {string}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 101,
        "end": 150,
        "startLoc": {
          "line": 101,
          "column": 6,
          "position": 734
        },
        "endLoc": {
          "line": 150,
          "column": 6,
          "position": 1042
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 72,
        "end": 117,
        "startLoc": {
          "line": 72,
          "column": 6,
          "position": 572
        },
        "endLoc": {
          "line": 117,
          "column": 6,
          "position": 882
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": ";\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n          max_tokens: this.maxTokens,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: this",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 158,
        "end": 182,
        "startLoc": {
          "line": 158,
          "column": 13,
          "position": 1125
        },
        "endLoc": {
          "line": 182,
          "column": 5,
          "position": 1299
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 122,
        "end": 142,
        "startLoc": {
          "line": 122,
          "column": 2,
          "position": 931
        },
        "endLoc": {
          "line": 142,
          "column": 7,
          "position": 1077
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ".usage?.completion_tokens || 0) / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n        max_tokens: this.maxTokens,\n      }),\n      messages\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 188,
        "end": 204,
        "startLoc": {
          "line": 188,
          "column": 2,
          "position": 1388
        },
        "endLoc": {
          "line": 204,
          "column": 7,
          "position": 1520
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/liteLLM/index.js",
        "start": 154,
        "end": 176,
        "startLoc": {
          "line": 154,
          "column": 7,
          "position": 1253
        },
        "endLoc": {
          "line": 176,
          "column": 5,
          "position": 1409
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ";\n\n      // Establish listener to early-abort a streaming response\n      // in case things go sideways or the user does not like the response.\n      // We preserve the generated text but continue as if chat was completed\n      // to preserve previously generated content.\n      const handleAbort = () => {\n        stream?.endMeasurement(usage);\n        clientAbortedHandler(resolve, fullText);\n      };\n      response.on(\"close\", handleAbort);\n\n      try {\n        for await (const chunk of stream) {\n          const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 222,
        "end": 236,
        "startLoc": {
          "line": 222,
          "column": 3,
          "position": 1657
        },
        "endLoc": {
          "line": 236,
          "column": 6,
          "position": 1746
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 224,
        "end": 238,
        "startLoc": {
          "line": 224,
          "column": 2,
          "position": 1759
        },
        "endLoc": {
          "line": 238,
          "column": 3,
          "position": 1848
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "\n          if (\n            chunk.hasOwnProperty(\"usage\") && // exists\n            !!chunk.usage && // is not null\n            Object.values(chunk.usage).length > 0 // has values\n          ) {\n            if (chunk.usage.hasOwnProperty(\"prompt_tokens\")) {\n              usage.prompt_tokens = Number(chunk.usage.prompt_tokens);\n            }\n\n            if (chunk.usage.hasOwnProperty(\"completion_tokens\")) {\n              hasUsageMetrics = true; // to stop estimating counter\n              usage.completion_tokens = Number(chunk.usage.completion_tokens);\n            }\n          }\n\n          // Reasoning models will always return the reasoning text before the token text.",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 239,
        "end": 255,
        "startLoc": {
          "line": 239,
          "column": 1,
          "position": 1795
        },
        "endLoc": {
          "line": 255,
          "column": 81,
          "position": 1935
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 214,
        "end": 230,
        "startLoc": {
          "line": 214,
          "column": 67,
          "position": 1800
        },
        "endLoc": {
          "line": 230,
          "column": 3,
          "position": 1940
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ";\n            }\n          }\n\n          // If the reasoning text is not empty, but the reasoning token is empty\n          // and the token text is not empty we need to close the reasoning text and begin sending the token text.\n          if (!!reasoningText && !reasoningToken && token) {\n            writeResponseChunk(response, {\n              uuid,\n              sources: [],\n              type: \"textResponseChunk\",\n              textResponse: `</think>`,\n              close: false,\n              error: false,\n            });\n            fullText += `${reasoningText}</think>`;\n            reasoningText = \"\";\n          }\n\n          if (token) {\n            fullText",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 279,
        "end": 299,
        "startLoc": {
          "line": 279,
          "column": 15,
          "position": 2106
        },
        "endLoc": {
          "line": 299,
          "column": 9,
          "position": 2228
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 409,
        "end": 429,
        "startLoc": {
          "line": 409,
          "column": 24,
          "position": 3133
        },
        "endLoc": {
          "line": 429,
          "column": 6,
          "position": 3255
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ";\n            writeResponseChunk(response, {\n              uuid,\n              sources: [],\n              type: \"textResponseChunk\",\n              textResponse: token,\n              close: false,\n              error: false,\n            });\n          }\n\n          if (\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 301,
        "end": 313,
        "startLoc": {
          "line": 301,
          "column": 3,
          "position": 2250
        },
        "endLoc": {
          "line": 313,
          "column": 1,
          "position": 2313
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 310,
        "end": 321,
        "startLoc": {
          "line": 310,
          "column": 6,
          "position": 2468
        },
        "endLoc": {
          "line": 321,
          "column": 8,
          "position": 2531
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ") {\n            writeResponseChunk(response, {\n              uuid,\n              sources,\n              type: \"textResponseChunk\",\n              textResponse: \"\",\n              close: true,\n              error: false,\n            });\n            response.removeListener(\"close\", handleAbort);\n            stream?.endMeasurement(usage);\n            resolve(fullText);\n            break; ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 316,
        "end": 328,
        "startLoc": {
          "line": 316,
          "column": 11,
          "position": 2348
        },
        "endLoc": {
          "line": 328,
          "column": 2,
          "position": 2433
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 444,
        "end": 258,
        "startLoc": {
          "line": 444,
          "column": 5,
          "position": 3359
        },
        "endLoc": {
          "line": 258,
          "column": 1,
          "position": 1990
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ");\n            resolve(fullText);\n            break; // Break streaming when a valid finish_reason is first encountered\n          }\n        }\n      } catch (e) {\n        console.log(`\\x1b[43m\\x1b[34m[STREAMING ERROR]\\x1b[0m ${e.message}`);\n        writeResponseChunk(response, {\n          uuid,\n          type: \"abort\",\n          textResponse: null,\n          sources: [],\n          close: true,\n          error: e.message,\n        });\n        stream?.endMeasurement(usage);\n        resolve",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 326,
        "end": 342,
        "startLoc": {
          "line": 326,
          "column": 6,
          "position": 2420
        },
        "endLoc": {
          "line": 342,
          "column": 8,
          "position": 2534
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 257,
        "end": 273,
        "startLoc": {
          "line": 257,
          "column": 13,
          "position": 2142
        },
        "endLoc": {
          "line": 273,
          "column": 14,
          "position": 2256
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": ");\n        stream?.endMeasurement(usage);\n        resolve(fullText);\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  GenericOpenAiLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 340,
        "end": 363,
        "startLoc": {
          "line": 340,
          "column": 2,
          "position": 2520
        },
        "endLoc": {
          "line": 363,
          "column": 17,
          "position": 2704
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 284,
        "end": 193,
        "startLoc": {
          "line": 284,
          "column": 12,
          "position": 2171
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n\n    if (!fs.existsSync(cacheFolder))\n      fs.mkdirSync(cacheFolder, { recursive: true });\n    this.cacheModelPath = path.resolve(cacheFolder, \"models.json\");\n    this.cacheAtPath = path.resolve(cacheFolder, \".cached_at\");\n    this.#",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 44,
        "end": 58,
        "startLoc": {
          "line": 44,
          "column": 1,
          "position": 365
        },
        "endLoc": {
          "line": 58,
          "column": 2,
          "position": 526
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 51,
        "startLoc": {
          "line": 22,
          "column": 2,
          "position": 200
        },
        "endLoc": {
          "line": 51,
          "column": 4,
          "position": 518
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ");\n    return now - timestampMs > MAX_STALE;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(modelName) {\n    try",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 86,
        "end": 107,
        "startLoc": {
          "line": 86,
          "column": 5,
          "position": 730
        },
        "endLoc": {
          "line": 107,
          "column": 4,
          "position": 882
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 69,
        "end": 57,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 675
        },
        "endLoc": {
          "line": 57,
          "column": 7,
          "position": 492
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "\n      );\n      url.searchParams.set(\"pageSize\", limit);\n      url.searchParams.set(\"key\", apiKey);\n      if (pageToken) url.searchParams.set(\"pageToken\", pageToken);\n      await fetch(url.toString(), {\n        method: \"GET\",\n        headers: { \"Content-Type\": \"application/json\" },\n      })\n        .then((res) => res.json())\n        .then((data) => {\n          if (data.error) throw new Error(data.error.message);\n          return data.models ?? [];\n        })\n        .then((models) => {\n          return models\n            .filter((",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 236,
        "end": 252,
        "startLoc": {
          "line": 236,
          "column": 58,
          "position": 2002
        },
        "endLoc": {
          "line": 252,
          "column": 2,
          "position": 2185
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 188,
        "end": 205,
        "startLoc": {
          "line": 188,
          "column": 54,
          "position": 1557
        },
        "endLoc": {
          "line": 205,
          "column": 1,
          "position": 1740
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "\n            .filter(\n              (model) => !model.displayName?.toLowerCase()?.includes(\"tuning\")\n            ) // remove tuning models\n            .filter(\n              (model) =>\n                !model.description?.toLowerCase()?.includes(\"deprecated\")\n            ) // remove deprecated models (in comment)\n            .filter((model) =>\n              //  Only generateContent is supported\n              model.supportedGenerationMethods.includes(\"generateContent\")\n            )\n            .map((model) => {\n              allModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 252,
        "end": 265,
        "startLoc": {
          "line": 252,
          "column": 56,
          "position": 2203
        },
        "endLoc": {
          "line": 265,
          "column": 10,
          "position": 2310
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 203,
        "end": 216,
        "startLoc": {
          "line": 203,
          "column": 7,
          "position": 1735
        },
        "endLoc": {
          "line": 216,
          "column": 13,
          "position": 1842
        }
      }
    },
    {
      "format": "javascript",
      "lines": 37,
      "fragment": ";\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) return userPrompt;\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"high\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [], // This is the specific attachment for only this prompt\n  }) {\n    let",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 311,
        "end": 347,
        "startLoc": {
          "line": 311,
          "column": 2,
          "position": 2655
        },
        "endLoc": {
          "line": 347,
          "column": 4,
          "position": 2863
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/mistral/index.js",
        "start": 62,
        "end": 103,
        "startLoc": {
          "line": 62,
          "column": 5,
          "position": 511
        },
        "endLoc": {
          "line": 103,
          "column": 6,
          "position": 778
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature:",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 370,
        "end": 385,
        "startLoc": {
          "line": 370,
          "column": 4,
          "position": 3025
        },
        "endLoc": {
          "line": 385,
          "column": 2,
          "position": 3152
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 108,
        "end": 131,
        "startLoc": {
          "line": 108,
          "column": 7,
          "position": 823
        },
        "endLoc": {
          "line": 131,
          "column": 2,
          "position": 1006
        }
      }
    },
    {
      "format": "javascript",
      "lines": 30,
      "fragment": "\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature: temperature",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 388,
        "end": 417,
        "startLoc": {
          "line": 388,
          "column": 2,
          "position": 3181
        },
        "endLoc": {
          "line": 417,
          "column": 12,
          "position": 3441
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 130,
        "end": 189,
        "startLoc": {
          "line": 130,
          "column": 2,
          "position": 1004
        },
        "endLoc": {
          "line": 189,
          "column": 5,
          "position": 1505
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n    );\n\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  async",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 420,
        "end": 430,
        "startLoc": {
          "line": 420,
          "column": 5,
          "position": 3455
        },
        "endLoc": {
          "line": 430,
          "column": 6,
          "position": 3505
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 167,
        "end": 177,
        "startLoc": {
          "line": 167,
          "column": 6,
          "position": 1312
        },
        "endLoc": {
          "line": 177,
          "column": 89,
          "position": 1362
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n}",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/gemini/index.js",
        "start": 433,
        "end": 443,
        "startLoc": {
          "line": 433,
          "column": 11,
          "position": 3573
        },
        "endLoc": {
          "line": 443,
          "column": 2,
          "position": 3644
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 174,
        "end": 185,
        "startLoc": {
          "line": 174,
          "column": 14,
          "position": 1354
        },
        "endLoc": {
          "line": 185,
          "column": 1,
          "position": 1425
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = !embedder ? new NativeEmbedder() : embedder;\n    this.defaultTemp = 0.7;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  allModelInformation() {\n    return fireworksAiModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/fireworksAi/index.js",
        "start": 23,
        "end": 47,
        "startLoc": {
          "line": 23,
          "column": 28,
          "position": 217
        },
        "endLoc": {
          "line": 47,
          "column": 18,
          "position": 424
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 53,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 53,
          "column": 17,
          "position": 453
        }
      }
    },
    {
      "format": "javascript",
      "lines": 28,
      "fragment": "\n  promptWindowLimit() {\n    const availableModels = this.allModelInformation();\n    return availableModels[this.model]?.maxLength || 4096;\n  }\n\n  async isValidChatCompletionModel(model = \"\") {\n    const availableModels = this.allModelInformation();\n    return availableModels.hasOwnProperty(model);\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [prompt, ...chatHistory, { role: \"user\", content: userPrompt }];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `FireworksAI chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/fireworksAi/index.js",
        "start": 60,
        "end": 87,
        "startLoc": {
          "line": 60,
          "column": 42,
          "position": 501
        },
        "endLoc": {
          "line": 87,
          "column": 20,
          "position": 758
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 64,
        "end": 183,
        "startLoc": {
          "line": 64,
          "column": 1,
          "position": 524
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 36,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions.create({\n        model: this.model,\n        messages,\n        temperature,\n      })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `FireworksAI chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/fireworksAi/index.js",
        "start": 87,
        "end": 122,
        "startLoc": {
          "line": 87,
          "column": 20,
          "position": 759
        },
        "endLoc": {
          "line": 122,
          "column": 22,
          "position": 1054
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 118,
        "end": 90,
        "startLoc": {
          "line": 118,
          "column": 16,
          "position": 924
        },
        "endLoc": {
          "line": 90,
          "column": 7,
          "position": 774
        }
      }
    },
    {
      "format": "javascript",
      "lines": 37,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages,\n      false\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  FireworksAiLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/fireworksAi/index.js",
        "start": 119,
        "end": 155,
        "startLoc": {
          "line": 119,
          "column": 20,
          "position": 1039
        },
        "endLoc": {
          "line": 155,
          "column": 15,
          "position": 1313
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 193,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.log(\n      `Dell Pro AI Studio LLM initialized with ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/dellProAiStudio/index.js",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 21,
          "position": 181
        },
        "endLoc": {
          "line": 32,
          "column": 42,
          "position": 278
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 32,
          "column": 14,
          "position": 296
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(_modelName) {\n    const limit = process.env.DPAIS_LLM_MODEL_TOKEN_LIMIT",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/dellProAiStudio/index.js",
        "start": 49,
        "end": 73,
        "startLoc": {
          "line": 49,
          "column": 2,
          "position": 384
        },
        "endLoc": {
          "line": 73,
          "column": 28,
          "position": 571
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 33,
        "end": 56,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 315
        },
        "endLoc": {
          "line": 56,
          "column": 34,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": ");\n    return Number(limit);\n  }\n\n  async isValidChatCompletionModel(_ = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) return userPrompt;\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  /**\n   * Construct the user prompt for this model.\n   * @param {{attachments: import(\"../../helpers\").Attachment[]}} param0\n   * @returns\n   */\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    _attachments",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/dellProAiStudio/index.js",
        "start": 84,
        "end": 123,
        "startLoc": {
          "line": 84,
          "column": 53,
          "position": 677
        },
        "endLoc": {
          "line": 123,
          "column": 13,
          "position": 902
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/nvidiaNim/index.js",
        "start": 97,
        "end": 101,
        "startLoc": {
          "line": 97,
          "column": 45,
          "position": 831
        },
        "endLoc": {
          "line": 101,
          "column": 12,
          "position": 761
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, _attachments",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/dellProAiStudio/index.js",
        "start": 123,
        "end": 134,
        "startLoc": {
          "line": 123,
          "column": 72,
          "position": 911
        },
        "endLoc": {
          "line": 134,
          "column": 13,
          "position": 1004
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 101,
        "end": 112,
        "startLoc": {
          "line": 101,
          "column": 56,
          "position": 770
        },
        "endLoc": {
          "line": 112,
          "column": 12,
          "position": 863
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ".chat.completions.create({\n        model: this.model,\n        messages,\n        temperature,\n      })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps: result.output.usage?.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!this.model)\n      throw new Error(\n        `Dell Pro AI Studio chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/dellProAiStudio/index.js",
        "start": 146,
        "end": 174,
        "startLoc": {
          "line": 146,
          "column": 6,
          "position": 1097
        },
        "endLoc": {
          "line": 174,
          "column": 27,
          "position": 1341
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 122,
        "end": 193,
        "startLoc": {
          "line": 122,
          "column": 7,
          "position": 954
        },
        "endLoc": {
          "line": 193,
          "column": 19,
          "position": 1526
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": ".chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  DellProAiStudioLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/dellProAiStudio/index.js",
        "start": 178,
        "end": 209,
        "startLoc": {
          "line": 178,
          "column": 6,
          "position": 1372
        },
        "endLoc": {
          "line": 209,
          "column": 19,
          "position": 1612
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/textGenWebUI/index.js",
        "start": 158,
        "end": 193,
        "startLoc": {
          "line": 158,
          "column": 7,
          "position": 1254
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 36,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.log(\n      `Initialized ${this.model} with context window ${this.promptWindowLimit()}`\n    );\n  }\n\n  log(text, ...args) {\n    console.log(`\\x1b[36m[${this.constructor.name}]\\x1b[0m ${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(modelName) {\n    return MODEL_MAP.get(\"deepseek\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 23,
        "end": 58,
        "startLoc": {
          "line": 23,
          "column": 16,
          "position": 218
        },
        "endLoc": {
          "line": 58,
          "column": 11,
          "position": 517
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 57,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 57,
          "column": 6,
          "position": 498
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ");\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [prompt, ...chatHistory, { role: \"user\", content: userPrompt }];\n  }\n\n  /**\n   * Parses and prepends reasoning from the response and returns the full text response.\n   * @param {Object} response\n   * @returns {string}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 67,
        "end": 87,
        "startLoc": {
          "line": 67,
          "column": 10,
          "position": 641
        },
        "endLoc": {
          "line": 87,
          "column": 6,
          "position": 766
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 72,
        "end": 146,
        "startLoc": {
          "line": 72,
          "column": 6,
          "position": 604
        },
        "endLoc": {
          "line": 146,
          "column": 6,
          "position": 1271
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "];\n  }\n\n  /**\n   * Parses and prepends reasoning from the response and returns the full text response.\n   * @param {Object} response\n   * @returns {string}\n   */\n  #parseReasoningFromResponse({ message }) {\n    let textResponse = message?.content;\n    if (\n      !!message?.reasoning_content &&\n      message.reasoning_content.trim().length > 0\n    )\n      textResponse = `<think>${message.reasoning_content}</think>${textResponse}`;\n    return textResponse;\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 80,
        "end": 99,
        "startLoc": {
          "line": 80,
          "column": 2,
          "position": 758
        },
        "endLoc": {
          "line": 99,
          "column": 3,
          "position": 881
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 143,
        "end": 162,
        "startLoc": {
          "line": 143,
          "column": 5,
          "position": 1034
        },
        "endLoc": {
          "line": 162,
          "column": 6,
          "position": 1157
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result?",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 101,
        "end": 117,
        "startLoc": {
          "line": 101,
          "column": 17,
          "position": 909
        },
        "endLoc": {
          "line": 117,
          "column": 2,
          "position": 1013
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 136,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 136,
          "column": 2,
          "position": 1035
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result?.output?.hasOwnProperty(\"choices\") ||\n      result?.output?.choices?.length === 0\n    )\n      throw new Error(\n        `Invalid response body returned from DeepSeek: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 109,
        "end": 121,
        "startLoc": {
          "line": 109,
          "column": 12,
          "position": 965
        },
        "endLoc": {
          "line": 121,
          "column": 48,
          "position": 1053
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 243,
        "end": 255,
        "startLoc": {
          "line": 243,
          "column": 5,
          "position": 1921
        },
        "endLoc": {
          "line": 255,
          "column": 50,
          "position": 2009
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "}`\n      );\n\n    return {\n      textResponse: this.#parseReasoningFromResponse(result.output.choices[0]),\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `DeepSeek chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 121,
        "end": 142,
        "startLoc": {
          "line": 121,
          "column": 2,
          "position": 1063
        },
        "endLoc": {
          "line": 142,
          "column": 22,
          "position": 1262
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 255,
        "end": 104,
        "startLoc": {
          "line": 255,
          "column": 15,
          "position": 2038
        },
        "endLoc": {
          "line": 104,
          "column": 7,
          "position": 924
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages,\n      false\n    );\n\n    return measuredStreamRequest;\n  }\n\n  // TODO: This is a copy of the generic handleStream function in responses.js",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 139,
        "end": 156,
        "startLoc": {
          "line": 139,
          "column": 17,
          "position": 1247
        },
        "endLoc": {
          "line": 156,
          "column": 77,
          "position": 1338
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 173,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 173,
          "column": 13,
          "position": 1329
        }
      }
    },
    {
      "format": "javascript",
      "lines": 107,
      "fragment": "\n    return measuredStreamRequest;\n  }\n\n  // TODO: This is a copy of the generic handleStream function in responses.js\n  // to specifically handle the DeepSeek reasoning model `reasoning_content` field.\n  // When or if ever possible, we should refactor this to be in the generic function.\n  handleStream(response, stream, responseProps) {\n    const { uuid = uuidv4(), sources = [] } = responseProps;\n    let hasUsageMetrics = false;\n    let usage = {\n      completion_tokens: 0,\n    };\n\n    return new Promise(async (resolve) => {\n      let fullText = \"\";\n      let reasoningText = \"\";\n\n      // Establish listener to early-abort a streaming response\n      // in case things go sideways or the user does not like the response.\n      // We preserve the generated text but continue as if chat was completed\n      // to preserve previously generated content.\n      const handleAbort = () => {\n        stream?.endMeasurement(usage);\n        clientAbortedHandler(resolve, fullText);\n      };\n      response.on(\"close\", handleAbort);\n\n      try {\n        for await (const chunk of stream) {\n          const message = chunk?.choices?.[0];\n          const token = message?.delta?.content;\n          const reasoningToken = message?.delta?.reasoning_content;\n\n          if (\n            chunk.hasOwnProperty(\"usage\") && // exists\n            !!chunk.usage && // is not null\n            Object.values(chunk.usage).length > 0 // has values\n          ) {\n            if (chunk.usage.hasOwnProperty(\"prompt_tokens\")) {\n              usage.prompt_tokens = Number(chunk.usage.prompt_tokens);\n            }\n\n            if (chunk.usage.hasOwnProperty(\"completion_tokens\")) {\n              hasUsageMetrics = true; // to stop estimating counter\n              usage.completion_tokens = Number(chunk.usage.completion_tokens);\n            }\n          }\n\n          // Reasoning models will always return the reasoning text before the token text.\n          if (reasoningToken) {\n            // If the reasoning text is empty (''), we need to initialize it\n            // and send the first chunk of reasoning text.\n            if (reasoningText.length === 0) {\n              writeResponseChunk(response, {\n                uuid,\n                sources: [],\n                type: \"textResponseChunk\",\n                textResponse: `<think>${reasoningToken}`,\n                close: false,\n                error: false,\n              });\n              reasoningText += `<think>${reasoningToken}`;\n              continue;\n            } else {\n              writeResponseChunk(response, {\n                uuid,\n                sources: [],\n                type: \"textResponseChunk\",\n                textResponse: reasoningToken,\n                close: false,\n                error: false,\n              });\n              reasoningText += reasoningToken;\n            }\n          }\n\n          // If the reasoning text is not empty, but the reasoning token is empty\n          // and the token text is not empty we need to close the reasoning text and begin sending the token text.\n          if (!!reasoningText && !reasoningToken && token) {\n            writeResponseChunk(response, {\n              uuid,\n              sources: [],\n              type: \"textResponseChunk\",\n              textResponse: `</think>`,\n              close: false,\n              error: false,\n            });\n            fullText += `${reasoningText}</think>`;\n            reasoningText = \"\";\n          }\n\n          if (token) {\n            fullText += token;\n            // If we never saw a usage metric, we can estimate them by number of completion chunks\n            if (!hasUsageMetrics) usage.completion_tokens++;\n            writeResponseChunk(response, {\n              uuid,\n              sources: [],\n              type: \"textResponseChunk\",\n              textResponse: token,\n              close: false,\n              error: false,\n            });\n          }\n\n          // LocalAi returns '' and others return null on chunks - the last chunk is not \"\" or null.",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 152,
        "end": 258,
        "startLoc": {
          "line": 152,
          "column": 1,
          "position": 1326
        },
        "endLoc": {
          "line": 258,
          "column": 91,
          "position": 2107
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 206,
        "end": 321,
        "startLoc": {
          "line": 206,
          "column": 2,
          "position": 1529
        },
        "endLoc": {
          "line": 321,
          "column": 3,
          "position": 2528
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": "\n          if (\n            message?.hasOwnProperty(\"finish_reason\") && // Got valid message and it is an object with finish_reason\n            message.finish_reason !== \"\" &&\n            message.finish_reason !== null\n          ) {\n            writeResponseChunk(response, {\n              uuid,\n              sources,\n              type: \"textResponseChunk\",\n              textResponse: \"\",\n              close: true,\n              error: false,\n            });\n            response.removeListener(\"close\", handleAbort);\n            stream?.endMeasurement(usage);\n            resolve(fullText);\n            break; // Break streaming when a valid finish_reason is first encountered\n          }\n        }\n      } catch (e) {\n        console.log(`\\x1b[43m\\x1b[34m[STREAMING ERROR]\\x1b[0m ${e.message}`);\n        writeResponseChunk(response, {\n          uuid,\n          type: \"abort\",\n          textResponse: null,\n          sources: [],\n          close: true,\n          error: e.message,\n        });\n        stream?.endMeasurement(usage);\n        resolve(fullText); ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 259,
        "end": 290,
        "startLoc": {
          "line": 259,
          "column": 82,
          "position": 2111
        },
        "endLoc": {
          "line": 290,
          "column": 2,
          "position": 2342
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/genericOpenAi/index.js",
        "start": 311,
        "end": 343,
        "startLoc": {
          "line": 311,
          "column": 1,
          "position": 2308
        },
        "endLoc": {
          "line": 343,
          "column": 1,
          "position": 2539
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ");\n  }\n\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  DeepSeekLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/deepseek/index.js",
        "start": 292,
        "end": 310,
        "startLoc": {
          "line": 292,
          "column": 2,
          "position": 2350
        },
        "endLoc": {
          "line": 310,
          "column": 12,
          "position": 2506
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 201,
        "end": 193,
        "startLoc": {
          "line": 201,
          "column": 14,
          "position": 1753
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  #convertChatHistoryCohere",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/cohere/index.js",
        "start": 27,
        "end": 42,
        "startLoc": {
          "line": 27,
          "column": 2,
          "position": 271
        },
        "endLoc": {
          "line": 42,
          "column": 25,
          "position": 379
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 112,
        "startLoc": {
          "line": 37,
          "column": 5,
          "position": 354
        },
        "endLoc": {
          "line": 112,
          "column": 16,
          "position": 1048
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": "(model);\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [prompt, ...chatHistory, { role: \"user\", content: userPrompt }];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Cohere chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/cohere/index.js",
        "start": 82,
        "end": 101,
        "startLoc": {
          "line": 82,
          "column": 9,
          "position": 692
        },
        "endLoc": {
          "line": 101,
          "column": 15,
          "position": 871
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 72,
        "end": 183,
        "startLoc": {
          "line": 72,
          "column": 15,
          "position": 602
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ",\n      metrics: {\n        prompt_tokens: promptTokens,\n        completion_tokens: completionTokens,\n        total_tokens: promptTokens + completionTokens,\n        outputTps: completionTokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `Cohere chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const message = messages[messages.length - 1].content; // Get the last message\n    const cohereHistory = this.#convertChatHistoryCohere(messages.slice(0, -1)); // Remove the last message and convert to Cohere\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/cohere/index.js",
        "start": 125,
        "end": 144,
        "startLoc": {
          "line": 125,
          "column": 5,
          "position": 1097
        },
        "endLoc": {
          "line": 144,
          "column": 5,
          "position": 1280
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 141,
        "end": 107,
        "startLoc": {
          "line": 141,
          "column": 8,
          "position": 1097
        },
        "endLoc": {
          "line": 107,
          "column": 1,
          "position": 934
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ".endMeasurement(usage);\n        resolve(fullText);\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  CohereLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/cohere/index.js",
        "start": 233,
        "end": 255,
        "startLoc": {
          "line": 233,
          "column": 7,
          "position": 1909
        },
        "endLoc": {
          "line": 255,
          "column": 10,
          "position": 2087
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 285,
        "end": 193,
        "startLoc": {
          "line": 285,
          "column": 2,
          "position": 2177
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": ";\n  }\n\n  /**\n   * Gets the credentials for the AWS Bedrock LLM based on the authentication method provided.\n   * @returns {object} The credentials object.\n   */\n  get credentials() {\n    switch (this.authMethod) {\n      case \"iam\": // explicit credentials\n        return {\n          accessKeyId: process.env.AWS_BEDROCK_LLM_ACCESS_KEY_ID,\n          secretAccessKey: process.env.AWS_BEDROCK_LLM_ACCESS_KEY,\n        };\n      case \"sessionToken\": // Session token is used for temporary credentials\n        return {\n          accessKeyId: process.env.AWS_BEDROCK_LLM_ACCESS_KEY_ID,\n          secretAccessKey: process.env.AWS_BEDROCK_LLM_ACCESS_KEY,\n          sessionToken: process.env.AWS_BEDROCK_LLM_SESSION_TOKEN,\n        };\n      // IAM role is used for long-term credentials implied by system process\n      // is filled by the AWS SDK automatically if we pass in no credentials\n      case \"iam_role\":\n        return {};\n      default:\n        return {};\n    }\n  }\n\n  /**\n   * Gets the configured AWS authentication method ('iam' or 'sessionToken').\n   * Defaults to 'iam' if the environment variable is invalid.\n   * @returns {\"iam\" | \"iam_role\" | \"sessionToken\"} The authentication method.\n   */\n  get authMethod() {\n    const method = process.env.AWS_BEDROCK_LLM_CONNECTION_METHOD || \"iam\";\n    return SUPPORTED_CONNECTION_METHODS.includes(method) ? method : \"iam\";\n  }\n\n  /**\n   * Appends context texts to a string with standard formatting.\n   * @param {string[]} contextTexts - An array of context text snippets.\n   * @returns {string} Formatted context string or empty string if no context provided.\n   * @private\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/bedrock/index.js",
        "start": 87,
        "end": 131,
        "startLoc": {
          "line": 87,
          "column": 2,
          "position": 538
        },
        "endLoc": {
          "line": 131,
          "column": 6,
          "position": 747
        }
      },
      "secondFile": {
        "name": "server/utils/agents/aibitat/providers/bedrock.js",
        "start": 31,
        "end": 70,
        "startLoc": {
          "line": 31,
          "column": 5,
          "position": 231
        },
        "endLoc": {
          "line": 70,
          "column": 4,
          "position": 440
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  AWSBedrockLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/bedrock/index.js",
        "start": 729,
        "end": 750,
        "startLoc": {
          "line": 729,
          "column": 37,
          "position": 4803
        },
        "endLoc": {
          "line": 750,
          "column": 14,
          "position": 4968
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/perplexity/index.js",
        "start": 274,
        "end": 193,
        "startLoc": {
          "line": 274,
          "column": 48,
          "position": 2270
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n    this.#log(\n      `Initialized. Model \"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 26,
        "end": 36,
        "startLoc": {
          "line": 26,
          "column": 6,
          "position": 245
        },
        "endLoc": {
          "line": 36,
          "column": 22,
          "position": 343
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 31,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 31,
          "column": 21,
          "position": 280
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "${text}`, ...args);\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  streamingEnabled() {\n    // Streaming of reasoning models is not supported",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 41,
        "end": 57,
        "startLoc": {
          "line": 41,
          "column": 31,
          "position": 405
        },
        "endLoc": {
          "line": 57,
          "column": 50,
          "position": 527
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 53,
        "startLoc": {
          "line": 37,
          "column": 10,
          "position": 346
        },
        "endLoc": {
          "line": 53,
          "column": 7,
          "position": 468
        }
      }
    },
    {
      "format": "javascript",
      "lines": 27,
      "fragment": "\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  constructPrompt",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 85,
        "end": 111,
        "startLoc": {
          "line": 85,
          "column": 12,
          "position": 689
        },
        "endLoc": {
          "line": 111,
          "column": 16,
          "position": 842
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 64,
        "end": 129,
        "startLoc": {
          "line": 64,
          "column": 2,
          "position": 559
        },
        "endLoc": {
          "line": 129,
          "column": 6,
          "position": 1185
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [], ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 104,
        "end": 116,
        "startLoc": {
          "line": 104,
          "column": 14,
          "position": 813
        },
        "endLoc": {
          "line": 116,
          "column": 2,
          "position": 888
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 125,
        "end": 165,
        "startLoc": {
          "line": 125,
          "column": 7,
          "position": 1122
        },
        "endLoc": {
          "line": 165,
          "column": 1,
          "position": 1539
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "\n    const prompt = {\n      role: this.isOTypeModel ? \"user\" : \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = [",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 117,
        "end": 132,
        "startLoc": {
          "line": 117,
          "column": 2,
          "position": 896
        },
        "endLoc": {
          "line": 132,
          "column": 2,
          "position": 1020
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openAi/index.js",
        "start": 127,
        "end": 117,
        "startLoc": {
          "line": 127,
          "column": 97,
          "position": 947
        },
        "endLoc": {
          "line": 117,
          "column": 5,
          "position": 890
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage.prompt_tokens || 0,\n        completion_tokens: result.output.usage.completion_tokens || 0,\n        total_tokens: result.output.usage.total_tokens || 0,\n        outputTps: result.output.usage.completion_tokens / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = [",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 142,
        "end": 164,
        "startLoc": {
          "line": 142,
          "column": 2,
          "position": 1123
        },
        "endLoc": {
          "line": 164,
          "column": 2,
          "position": 1304
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/localAi/index.js",
        "start": 125,
        "end": 153,
        "startLoc": {
          "line": 125,
          "column": 12,
          "position": 978
        },
        "endLoc": {
          "line": 153,
          "column": 5,
          "position": 1197
        }
      }
    },
    {
      "format": "javascript",
      "lines": 27,
      "fragment": "\n    );\n\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    return handleDefaultStreamResponseV2(response, stream, responseProps);\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nmodule.exports = {\n  AzureOpenAiLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/azureOpenAi/index.js",
        "start": 178,
        "end": 204,
        "startLoc": {
          "line": 178,
          "column": 9,
          "position": 1432
        },
        "endLoc": {
          "line": 204,
          "column": 15,
          "position": 1633
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 167,
        "end": 193,
        "startLoc": {
          "line": 167,
          "column": 6,
          "position": 1312
        },
        "endLoc": {
          "line": 193,
          "column": 7,
          "position": 1513
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "const { NativeEmbedder } = require(\"../../EmbeddingEngines/native\");\nconst { v4: uuidv4 } = require(\"uuid\");\nconst {\n  writeResponseChunk,\n  clientAbortedHandler,\n  formatChatHistory,\n} = require(\"../../helpers/chat/responses\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst { safeJsonParse } = require(\"../../http\");\nconst {\n  LLMPerformanceMonitor,\n} = require(\"../../helpers/chat/LLMPerformanceMonitor\");\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 1,
        "end": 15,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 15,
          "column": 1,
          "position": 119
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 11,
          "column": 6,
          "position": 92
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ";\n    this.limits = {\n      history: this.promptWindowLimit() * 0.15,\n      system: this.promptWindowLimit() * 0.15,\n      user: this.promptWindowLimit() * 0.7,\n    };\n\n    this.embedder = embedder ?? new NativeEmbedder();\n    this.defaultTemp = 0.7;\n\n    if (!fs.existsSync(cacheFolder))\n      fs.mkdirSync(cacheFolder, { recursive: true });\n    this.cacheModelPath = path.resolve(cacheFolder, \"models.json\");\n    this.cacheAtPath = path.resolve(cacheFolder, \".cached_at\");\n  ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 35,
        "end": 49,
        "startLoc": {
          "line": 35,
          "column": 33,
          "position": 320
        },
        "endLoc": {
          "line": 49,
          "column": 3,
          "position": 479
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 22,
        "end": 49,
        "startLoc": {
          "line": 22,
          "column": 12,
          "position": 199
        },
        "endLoc": {
          "line": 49,
          "column": 1,
          "position": 474
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ";\n  }\n\n  // This checks if the .cached_at file has a timestamp that is more than 1Week (in millis)\n  // from the current date. If it is, then we will refetch the API so that all the models are up\n  // to date.\n  #cacheIsStale() {\n    const MAX_STALE = 6.048e8; // 1 Week in MS\n    if (!fs.existsSync(this.cacheAtPath)) return true;\n    const now = Number(new Date());\n    const timestampMs = Number(fs.readFileSync(this.cacheAtPath));\n    return now - timestampMs > MAX_STALE;\n  }\n\n  // This function fetches the models from the ApiPie API and caches them locally.",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 52,
        "end": 66,
        "startLoc": {
          "line": 52,
          "column": 2,
          "position": 518
        },
        "endLoc": {
          "line": 66,
          "column": 81,
          "position": 629
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 97,
        "end": 73,
        "startLoc": {
          "line": 97,
          "column": 9,
          "position": 827
        },
        "endLoc": {
          "line": 73,
          "column": 2,
          "position": 697
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "();\n    return;\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  models() {\n    if (!fs.existsSync(this.cacheModelPath)) return {};\n    return safeJsonParse(\n      fs.readFileSync(this.cacheModelPath, { encoding: \"utf-8\" }),\n      {}\n    );\n  }\n\n  chatModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 77,
        "end": 101,
        "startLoc": {
          "line": 77,
          "column": 18,
          "position": 700
        },
        "endLoc": {
          "line": 101,
          "column": 11,
          "position": 879
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 123,
        "end": 93,
        "startLoc": {
          "line": 123,
          "column": 22,
          "position": 1010
        },
        "endLoc": {
          "line": 93,
          "column": 17,
          "position": 863
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ",\n      {}\n    );\n  }\n\n  streamingEnabled() {\n    return \"streamGetChatCompletion\" in this;\n  }\n\n  static promptWindowLimit(modelName) {\n    const cacheModelPath = path.resolve(cacheFolder, \"models.json\");\n    const availableModels = fs.existsSync(cacheModelPath)\n      ? safeJsonParse(\n          fs.readFileSync(cacheModelPath, { encoding: \"utf-8\" }),\n          {}\n        )\n      : {};\n    return availableModels[modelName]?.maxLength || 4096;\n  }\n\n  promptWindowLimit() {\n    const availableModels = this.chatModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 114,
        "end": 135,
        "startLoc": {
          "line": 114,
          "column": 2,
          "position": 995
        },
        "endLoc": {
          "line": 135,
          "column": 11,
          "position": 1147
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 142,
        "end": 163,
        "startLoc": {
          "line": 142,
          "column": 2,
          "position": 1174
        },
        "endLoc": {
          "line": 163,
          "column": 7,
          "position": 1326
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "();\n    return availableModels.hasOwnProperty(model);\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image_url\",\n        image_url: {\n          url: attachment.contentString,\n          detail: \"auto\",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [],\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `ApiPie chat: ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 141,
        "end": 192,
        "startLoc": {
          "line": 141,
          "column": 11,
          "position": 1209
        },
        "endLoc": {
          "line": 192,
          "column": 15,
          "position": 1587
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 169,
        "end": 183,
        "startLoc": {
          "line": 169,
          "column": 7,
          "position": 1388
        },
        "endLoc": {
          "line": 183,
          "column": 19,
          "position": 1695
        }
      }
    },
    {
      "format": "javascript",
      "lines": 41,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const result = await LLMPerformanceMonitor.measureAsyncFunction(\n      this.openai.chat.completions\n        .create({\n          model: this.model,\n          messages,\n          temperature,\n        })\n        .catch((e) => {\n          throw new Error(e.message);\n        })\n    );\n\n    if (\n      !result.output.hasOwnProperty(\"choices\") ||\n      result.output.choices.length === 0\n    )\n      return null;\n\n    return {\n      textResponse: result.output.choices[0].message.content,\n      metrics: {\n        prompt_tokens: result.output.usage?.prompt_tokens || 0,\n        completion_tokens: result.output.usage?.completion_tokens || 0,\n        total_tokens: result.output.usage?.total_tokens || 0,\n        outputTps:\n          (result.output.usage?.completion_tokens || 0) / result.duration,\n        duration: result.duration,\n      },\n    };\n  }\n\n  async streamGetChatCompletion(messages = null, { temperature = 0.7 }) {\n    if (!(await this.isValidChatCompletionModel(this.model)))\n      throw new Error(\n        `ApiPie chat: ${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 192,
        "end": 232,
        "startLoc": {
          "line": 192,
          "column": 15,
          "position": 1588
        },
        "endLoc": {
          "line": 232,
          "column": 22,
          "position": 1925
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 120,
        "end": 195,
        "startLoc": {
          "line": 120,
          "column": 12,
          "position": 931
        },
        "endLoc": {
          "line": 195,
          "column": 7,
          "position": 1603
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "${this.model} is not valid for chat completion!`\n      );\n\n    const measuredStreamRequest = await LLMPerformanceMonitor.measureStream(\n      this.openai.chat.completions.create({\n        model: this.model,\n        stream: true,\n        messages,\n        temperature,\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 229,
        "end": 245,
        "startLoc": {
          "line": 229,
          "column": 15,
          "position": 1910
        },
        "endLoc": {
          "line": 245,
          "column": 6,
          "position": 2010
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 156,
        "end": 170,
        "startLoc": {
          "line": 156,
          "column": 12,
          "position": 1238
        },
        "endLoc": {
          "line": 170,
          "column": 7,
          "position": 1324
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      }),\n      messages\n    );\n    return measuredStreamRequest;\n  }\n\n  handleStream(response, stream, responseProps) {\n    const { uuid = uuidv4(), sources = [] } = responseProps;\n\n    return new Promise(async (resolve) => {\n      let fullText = \"\";\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 237,
        "end": 250,
        "startLoc": {
          "line": 237,
          "column": 12,
          "position": 1971
        },
        "endLoc": {
          "line": 250,
          "column": 1,
          "position": 2065
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 173,
        "end": 311,
        "startLoc": {
          "line": 173,
          "column": 10,
          "position": 1399
        },
        "endLoc": {
          "line": 311,
          "column": 7,
          "position": 2424
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ";\n\n      // Establish listener to early-abort a streaming response\n      // in case things go sideways or the user does not like the response.\n      // We preserve the generated text but continue as if chat was completed\n      // to preserve previously generated content.\n      const handleAbort = () => {\n        stream?.endMeasurement({\n          completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n        });\n        clientAbortedHandler(resolve, fullText);\n      };\n      response.on(\"close\", handleAbort);\n\n      try",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 248,
        "end": 262,
        "startLoc": {
          "line": 248,
          "column": 3,
          "position": 2063
        },
        "endLoc": {
          "line": 262,
          "column": 4,
          "position": 2145
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 314,
        "end": 328,
        "startLoc": {
          "line": 314,
          "column": 18,
          "position": 2469
        },
        "endLoc": {
          "line": 328,
          "column": 63,
          "position": 2551
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        clientAbortedHandler(resolve, fullText);\n      };\n      response.on(\"close\", handleAbort);\n\n      try {\n        for await (const chunk of stream) {\n          const message = chunk?.choices?.[0];\n          const token = message?.delta?.content;\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 257,
        "end": 267,
        "startLoc": {
          "line": 257,
          "column": 2,
          "position": 2114
        },
        "endLoc": {
          "line": 267,
          "column": 1,
          "position": 2200
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 231,
        "end": 366,
        "startLoc": {
          "line": 231,
          "column": 6,
          "position": 1795
        },
        "endLoc": {
          "line": 366,
          "column": 11,
          "position": 2832
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ";\n\n          if (token) {\n            fullText += token;\n            writeResponseChunk(response, {\n              uuid,\n              sources: [],\n              type: \"textResponseChunk\",\n              textResponse: token,\n              close: false,\n              error: false,\n            });\n          }\n\n          if (message ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 265,
        "end": 279,
        "startLoc": {
          "line": 265,
          "column": 8,
          "position": 2198
        },
        "endLoc": {
          "line": 279,
          "column": 2,
          "position": 2280
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/novita/index.js",
        "start": 307,
        "end": 321,
        "startLoc": {
          "line": 307,
          "column": 2,
          "position": 2450
        },
        "endLoc": {
          "line": 321,
          "column": 2,
          "position": 2532
        }
      }
    },
    {
      "format": "javascript",
      "lines": 50,
      "fragment": "message.finish_reason !== null) {\n            writeResponseChunk(response, {\n              uuid,\n              sources,\n              type: \"textResponseChunk\",\n              textResponse: \"\",\n              close: true,\n              error: false,\n            });\n            response.removeListener(\"close\", handleAbort);\n            stream?.endMeasurement({\n              completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n            });\n            resolve(fullText);\n          }\n        }\n      } catch (e) {\n        writeResponseChunk(response, {\n          uuid,\n          sources,\n          type: \"abort\",\n          textResponse: null,\n          close: true,\n          error: e.message,\n        });\n        response.removeListener(\"close\", handleAbort);\n        stream?.endMeasurement({\n          completion_tokens: LLMPerformanceMonitor.countTokens(fullText),\n        });\n        resolve(fullText);\n      }\n    });\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n\n  async compressMessages(promptArgs = {}, rawHistory = []) {\n    const { messageArrayCompressor } = require(\"../../helpers/chat\");\n    const messageArray = this.constructPrompt(promptArgs);\n    return await messageArrayCompressor(this, messageArray, rawHistory);\n  }\n}\n\nasync function fetchApiPieModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 279,
        "end": 328,
        "startLoc": {
          "line": 279,
          "column": 2,
          "position": 2287
        },
        "endLoc": {
          "line": 328,
          "column": 18,
          "position": 2662
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 444,
        "end": 218,
        "startLoc": {
          "line": 444,
          "column": 2,
          "position": 3352
        },
        "endLoc": {
          "line": 218,
          "column": 16,
          "position": 1904
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": ",\n        };\n      });\n\n      // Cache all response information\n      if (!fs.existsSync(cacheFolder))\n        fs.mkdirSync(cacheFolder, { recursive: true });\n      fs.writeFileSync(\n        path.resolve(cacheFolder, \"models.json\"),\n        JSON.stringify(models),\n        {\n          encoding: \"utf-8\",\n        }\n      );\n      fs.writeFileSync(\n        path.resolve(cacheFolder, \".cached_at\"),\n        String(Number(new Date())),\n        {\n          encoding: \"utf-8\",\n        }\n      );\n\n      return models;\n    })\n    .catch((e) => {\n      console.error(e);\n      return {};\n    });\n}\n\nmodule.exports = {\n  ApiPieLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/apipie/index.js",
        "start": 346,
        "end": 377,
        "startLoc": {
          "line": 346,
          "column": 11,
          "position": 2909
        },
        "endLoc": {
          "line": 377,
          "column": 10,
          "position": 3105
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/openRouter/index.js",
        "start": 512,
        "end": 264,
        "startLoc": {
          "line": 512,
          "column": 15,
          "position": 3933
        },
        "endLoc": {
          "line": 264,
          "column": 8,
          "position": 2303
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ";\n  }\n\n  isValidChatCompletionModel(_modelName = \"\") {\n    return true;\n  }\n\n  /**\n   * Generates appropriate content array for a message + attachments.\n   * @param {{userPrompt:string, attachments: import(\"../../helpers\").Attachment[]}}\n   * @returns {string|object[]}\n   */\n  #generateContent({ userPrompt, attachments = [] }) {\n    if (!attachments.length) {\n      return userPrompt;\n    }\n\n    const content = [{ type: \"text\", text: userPrompt }];\n    for (let attachment of attachments) {\n      content.push({\n        type: \"image\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 52,
        "end": 72,
        "startLoc": {
          "line": 52,
          "column": 5,
          "position": 452
        },
        "endLoc": {
          "line": 72,
          "column": 8,
          "position": 577
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 61,
        "end": 81,
        "startLoc": {
          "line": 61,
          "column": 5,
          "position": 542
        },
        "endLoc": {
          "line": 81,
          "column": 12,
          "position": 667
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ",\n        },\n      });\n    }\n    return content.flat();\n  }\n\n  constructPrompt({\n    systemPrompt = \"\",\n    contextTexts = [],\n    chatHistory = [],\n    userPrompt = \"\",\n    attachments = [], // This is the specific attachment for only this prompt\n  }) {\n    const prompt = {\n      role: \"system\",\n      content: `${systemPrompt}${this.#appendContext(contextTexts)}`,\n    };\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 76,
        "end": 95,
        "startLoc": {
          "line": 76,
          "column": 2,
          "position": 617
        },
        "endLoc": {
          "line": 95,
          "column": 1,
          "position": 741
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ppio/index.js",
        "start": 125,
        "end": 107,
        "startLoc": {
          "line": 125,
          "column": 7,
          "position": 1122
        },
        "endLoc": {
          "line": 107,
          "column": 5,
          "position": 817
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n    return [\n      prompt,\n      ...formatChatHistory(chatHistory, this.#generateContent),\n      {\n        role: \"user\",\n        content: this.#generateContent({ userPrompt, attachments }),\n      },\n    ];\n  }\n\n  async getChatCompletion(messages = null, { temperature = 0.7 }) {\n    try",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 94,
        "end": 106,
        "startLoc": {
          "line": 94,
          "column": 1,
          "position": 741
        },
        "endLoc": {
          "line": 106,
          "column": 4,
          "position": 832
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 106,
        "end": 118,
        "startLoc": {
          "line": 106,
          "column": 2,
          "position": 816
        },
        "endLoc": {
          "line": 118,
          "column": 3,
          "position": 907
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ";\n      let usage = {\n        prompt_tokens: 0,\n        completion_tokens: 0,\n      };\n\n      // Establish listener to early-abort a streaming response\n      // in case things go sideways or the user does not like the response.\n      // We preserve the generated text but continue as if chat was completed\n      // to preserve previously generated content.\n      const handleAbort = () => {\n        stream?.endMeasurement(usage);\n        clientAbortedHandler(resolve, fullText);\n      };\n      response.on(\"close\", handleAbort);\n\n      stream",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 161,
        "end": 177,
        "startLoc": {
          "line": 161,
          "column": 14,
          "position": 1298
        },
        "endLoc": {
          "line": 177,
          "column": 7,
          "position": 1392
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/ollama/index.js",
        "start": 220,
        "end": 177,
        "startLoc": {
          "line": 220,
          "column": 3,
          "position": 1732
        },
        "endLoc": {
          "line": 177,
          "column": 6,
          "position": 1487
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ")\n        ) {\n          writeResponseChunk(response, {\n            uuid,\n            sources,\n            type: \"textResponseChunk\",\n            textResponse: \"\",\n            close: true,\n            error: false,\n          });\n          response.removeListener(\"close\", handleAbort);\n          stream?.endMeasurement(usage);\n          resolve(fullText);\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 227,
        "end": 240,
        "startLoc": {
          "line": 227,
          "column": 11,
          "position": 1806
        },
        "endLoc": {
          "line": 240,
          "column": 9,
          "position": 1891
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/koboldCPP/index.js",
        "start": 219,
        "end": 104,
        "startLoc": {
          "line": 219,
          "column": 7,
          "position": 1778
        },
        "endLoc": {
          "line": 104,
          "column": 11,
          "position": 688
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n  }\n\n  #appendContext(contextTexts = []) {\n    if (!contextTexts || !contextTexts.length) return \"\";\n    return (\n      \"\\nContext:\\n\" +\n      contextTexts\n        .map((text, i) => {\n          return `[CONTEXT ${i}]:\\n${text}\\n[END CONTEXT ${i}]\\n\\n`;\n        })\n        .join(\"\")\n    );\n  }\n\n  async",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 242,
        "end": 257,
        "startLoc": {
          "line": 242,
          "column": 2,
          "position": 1901
        },
        "endLoc": {
          "line": 257,
          "column": 6,
          "position": 2008
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 37,
        "end": 52,
        "startLoc": {
          "line": 37,
          "column": 5,
          "position": 354
        },
        "endLoc": {
          "line": 52,
          "column": 17,
          "position": 461
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ";\n  }\n\n  // Simple wrapper for dynamic embedder & normalize interface for all LLM implementations\n  async embedTextInput(textInput) {\n    return await this.embedder.embedTextInput(textInput);\n  }\n  async embedChunks(textChunks = []) {\n    return await this.embedder.embedChunks(textChunks);\n  }\n}\n\nmodule.exports = {\n  AnthropicLLM",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/AiProviders/anthropic/index.js",
        "start": 264,
        "end": 277,
        "startLoc": {
          "line": 264,
          "column": 17,
          "position": 2078
        },
        "endLoc": {
          "line": 277,
          "column": 13,
          "position": 2160
        }
      },
      "secondFile": {
        "name": "server/utils/AiProviders/xai/index.js",
        "start": 174,
        "end": 446,
        "startLoc": {
          "line": 174,
          "column": 2,
          "position": 1355
        },
        "endLoc": {
          "line": 446,
          "column": 10,
          "position": 3656
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ";\n        const workspace = await Workspace.get({ slug });\n        const thread = await WorkspaceThread.get({\n          slug: threadSlug,\n          workspace_id: workspace.id,\n        });\n\n        if (!workspace || !thread) {\n          response.sendStatus(400).end();\n          return;\n        }\n\n        const history",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 290,
        "end": 302,
        "startLoc": {
          "line": 290,
          "column": 7,
          "position": 1200
        },
        "endLoc": {
          "line": 302,
          "column": 8,
          "position": 1299
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 168,
        "end": 180,
        "startLoc": {
          "line": 168,
          "column": 2,
          "position": 735
        },
        "endLoc": {
          "line": 180,
          "column": 2,
          "position": 834
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": "\n      try {\n        const { slug, threadSlug } = request.params;\n        const {\n          message,\n          mode = \"query\",\n          userId,\n          attachments = [],\n          reset = false,\n        } = reqBody(request);\n        const workspace = await Workspace.get({ slug });\n        const thread = await WorkspaceThread.get({\n          slug: threadSlug,\n          workspace_id: workspace.id,\n        });\n\n        if (!workspace || !thread) {\n          response.status(400).json({\n            id: uuidv4(),\n            type: \"abort\",\n            textResponse: null,\n            sources: [],\n            close: true,\n            error: `Workspace ${slug} or thread ${threadSlug} is not valid.`,\n          });\n          return;\n        }\n\n        if ((!message?.length || !VALID_CHAT_MODE.includes(mode)) && !reset) {\n          response.status(400).json({\n            id: uuidv4(),\n            type: \"abort\",\n            textResponse: null,\n            sources: [],\n            close: true,\n            error: !message?.length\n              ? \"Message is empty\"\n              : `${mode} is not a valid mode.`,\n          });\n          return;\n        }\n\n        const user = userId ? await User.get({ id: Number(userId) }) : null;\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 546,
        "end": 590,
        "startLoc": {
          "line": 546,
          "column": 9,
          "position": 2199
        },
        "endLoc": {
          "line": 590,
          "column": 1,
          "position": 2577
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 383,
        "end": 426,
        "startLoc": {
          "line": 383,
          "column": 9,
          "position": 1475
        },
        "endLoc": {
          "line": 426,
          "column": 9,
          "position": 1853
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": "\n          workspace,\n          message,\n          mode,\n          user,\n          thread,\n          attachments,\n          reset,\n        });\n        await Telemetry.sendTelemetry(\"sent_chat\", {\n          LLMSelection: process.env.LLM_PROVIDER || \"openai\",\n          Embedder: process.env.EMBEDDING_ENGINE || \"inherit\",\n          VectorDbSelection: process.env.VECTOR_DB || \"lancedb\",\n          TTSSelection: process.env.TTS_PROVIDER || \"native\",\n          LLMModel: getModelTag(),\n        });\n        await EventLogs.logEvent(\"api_sent_chat\", {\n          workspaceName: workspace?.name,\n          chatModel: workspace?.chatModel || \"System Default\",\n          threadName: thread?.name,\n          userId: user?.id,\n        });\n        response.end",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 597,
        "end": 619,
        "startLoc": {
          "line": 597,
          "column": 2,
          "position": 2647
        },
        "endLoc": {
          "line": 619,
          "column": 4,
          "position": 2831
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 426,
        "end": 448,
        "startLoc": {
          "line": 426,
          "column": 2,
          "position": 1867
        },
        "endLoc": {
          "line": 448,
          "column": 7,
          "position": 2051
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n        });\n        await Telemetry.sendTelemetry(\"sent_chat\", {\n          LLMSelection: process.env.LLM_PROVIDER || \"openai\",\n          Embedder: process.env.EMBEDDING_ENGINE || \"inherit\",\n          VectorDbSelection: process.env.VECTOR_DB || \"lancedb\",\n          TTSSelection: process.env.TTS_PROVIDER || \"native\",\n          LLMModel: getModelTag(),\n        });\n        await EventLogs.logEvent(\"api_sent_chat\", {\n          workspaceName: workspace?.name,\n          chatModel: workspace?.chatModel || \"System Default\",\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/api/openai/index.js",
        "start": 178,
        "end": 190,
        "startLoc": {
          "line": 178,
          "column": 9,
          "position": 1052
        },
        "endLoc": {
          "line": 190,
          "column": 9,
          "position": 1181
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 433,
        "end": 445,
        "startLoc": {
          "line": 433,
          "column": 6,
          "position": 1894
        },
        "endLoc": {
          "line": 445,
          "column": 11,
          "position": 2023
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n        });\n        response.status(200).json({ chats });\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\"/v1/embed/new\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/api/embed/index.js",
        "start": 191,
        "end": 201,
        "startLoc": {
          "line": 191,
          "column": 2,
          "position": 589
        },
        "endLoc": {
          "line": 201,
          "column": 16,
          "position": 668
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/embed/index.js",
        "start": 130,
        "end": 112,
        "startLoc": {
          "line": 130,
          "column": 2,
          "position": 418
        },
        "endLoc": {
          "line": 112,
          "column": 1,
          "position": 668
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        response.status(200).json({ success, error });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/v1/admin/workspaces/:workspaceSlug/manage-users\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 538,
        "end": 548,
        "startLoc": {
          "line": 538,
          "column": 9,
          "position": 1902
        },
        "endLoc": {
          "line": 548,
          "column": 51,
          "position": 1977
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 416,
        "end": 481,
        "startLoc": {
          "line": 416,
          "column": 3,
          "position": 1533
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const valid",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/middleware/validatedRequest.js",
        "start": 71,
        "end": 82,
        "startLoc": {
          "line": 71,
          "column": 2,
          "position": 541
        },
        "endLoc": {
          "line": 82,
          "column": 6,
          "position": 629
        }
      },
      "secondFile": {
        "name": "server/utils/middleware/validatedRequest.js",
        "start": 30,
        "end": 41,
        "startLoc": {
          "line": 30,
          "column": 1,
          "position": 254
        },
        "endLoc": {
          "line": 41,
          "column": 7,
          "position": 342
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": " } = request.params;\n  const user = await userFromSession(request, response);\n  const workspace = multiUserMode(response)\n    ? await Workspace.getWithUser(user, { slug })\n    : await Workspace.get({ slug });\n\n  if (!workspace) {\n    response.status(404).send(\"Workspace does not exist.\");\n    return;\n  }\n\n  const",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/middleware/validWorkspace.js",
        "start": 24,
        "end": 35,
        "startLoc": {
          "line": 24,
          "column": 11,
          "position": 235
        },
        "endLoc": {
          "line": 35,
          "column": 6,
          "position": 345
        }
      },
      "secondFile": {
        "name": "server/utils/middleware/validWorkspace.js",
        "start": 7,
        "end": 18,
        "startLoc": {
          "line": 7,
          "column": 5,
          "position": 77
        },
        "endLoc": {
          "line": 18,
          "column": 9,
          "position": 187
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n\n    const user =\n      response.locals?.user ?? (await userFromSession(request, response));\n    if (allowedRoles.includes(user?.role)) {\n      next();\n      return;\n    }\n    return response.sendStatus(401).end();\n  };\n}\n\n// Middleware check on a public route if the instance is in a valid",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/middleware/multiUserProtected.js",
        "start": 62,
        "end": 74,
        "startLoc": {
          "line": 62,
          "column": 2,
          "position": 418
        },
        "endLoc": {
          "line": 74,
          "column": 68,
          "position": 503
        }
      },
      "secondFile": {
        "name": "server/utils/middleware/multiUserProtected.js",
        "start": 28,
        "end": 45,
        "startLoc": {
          "line": 28,
          "column": 2,
          "position": 208
        },
        "endLoc": {
          "line": 45,
          "column": 4,
          "position": 293
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": " });\n  if (!embed) {\n    response.sendStatus(404).end();\n    return;\n  }\n\n  response.locals.embedConfig = embed;\n  next();\n}\n\nasync",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/middleware/embedMiddleware.js",
        "start": 33,
        "end": 43,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 318
        },
        "endLoc": {
          "line": 43,
          "column": 6,
          "position": 375
        }
      },
      "secondFile": {
        "name": "server/utils/middleware/embedMiddleware.js",
        "start": 12,
        "end": 22,
        "startLoc": {
          "line": 12,
          "column": 8,
          "position": 144
        },
        "endLoc": {
          "line": 22,
          "column": 9,
          "position": 201
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "();\n  if (!Object.keys(knownModels).length === 0)\n    return { models: [], error: null };\n\n  const models = Object.values(knownModels).map((model) => {\n    return {\n      id: model.id,\n      organization: model.organization,\n      name: model.name,\n    };\n  });\n  return { models, error: null };\n}\n\nasync function getNovitaModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/helpers/customModels.js",
        "start": 422,
        "end": 436,
        "startLoc": {
          "line": 422,
          "column": 22,
          "position": 3947
        },
        "endLoc": {
          "line": 436,
          "column": 16,
          "position": 4079
        }
      },
      "secondFile": {
        "name": "server/utils/helpers/customModels.js",
        "start": 393,
        "end": 407,
        "startLoc": {
          "line": 393,
          "column": 18,
          "position": 3662
        },
        "endLoc": {
          "line": 407,
          "column": 20,
          "position": 3794
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n  const models = Object.values(knownModels).map((model) => {\n    return {\n      id: model.id,\n      organization: model.organization,\n      name: model.name,\n    };\n  });\n  return { models, error: null };\n}\n\nasync function getAPIPieModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/helpers/customModels.js",
        "start": 439,
        "end": 450,
        "startLoc": {
          "line": 439,
          "column": 2,
          "position": 4137
        },
        "endLoc": {
          "line": 450,
          "column": 16,
          "position": 4226
        }
      },
      "secondFile": {
        "name": "server/utils/helpers/customModels.js",
        "start": 396,
        "end": 407,
        "startLoc": {
          "line": 396,
          "column": 1,
          "position": 3705
        },
        "endLoc": {
          "line": 407,
          "column": 20,
          "position": 3794
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ").map((model) => {\n    return {\n      id: model.id,\n      organization: model.organization,\n      name: model.name,\n    };\n  });\n  return { models, error: null };\n}\n\nasync function getDellProAiStudioModels",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/helpers/customModels.js",
        "start": 631,
        "end": 641,
        "startLoc": {
          "line": 631,
          "column": 11,
          "position": 5930
        },
        "endLoc": {
          "line": 641,
          "column": 25,
          "position": 6006
        }
      },
      "secondFile": {
        "name": "server/utils/helpers/customModels.js",
        "start": 397,
        "end": 407,
        "startLoc": {
          "line": 397,
          "column": 12,
          "position": 3718
        },
        "endLoc": {
          "line": 407,
          "column": 20,
          "position": 3794
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "?.pfpFilename || null;\n  if (!pfpFilename) return null;\n\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets/pfp\")\n    : path.join(__dirname, \"../../storage/assets/pfp\");\n  const pfpFilepath = path.join(basePath, normalizePath(pfpFilename));\n\n  if (!isWithin(path.resolve(basePath), path.resolve(pfpFilepath))) return null;\n  if (!fs.existsSync(pfpFilepath)) return null;\n  return pfpFilepath;\n}\n\nmodule",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/files/pfp.js",
        "start": 46,
        "end": 59,
        "startLoc": {
          "line": 46,
          "column": 10,
          "position": 462
        },
        "endLoc": {
          "line": 59,
          "column": 7,
          "position": 607
        }
      },
      "secondFile": {
        "name": "server/utils/files/pfp.js",
        "start": 31,
        "end": 44,
        "startLoc": {
          "line": 31,
          "column": 5,
          "position": 277
        },
        "endLoc": {
          "line": 44,
          "column": 6,
          "position": 422
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": " = multer.diskStorage({\n  destination: function (_, __, cb) {\n    const baseStoragePath =\n      process.env.NODE_ENV === \"development\"\n        ? path.resolve(__dirname, \"../../\")\n        : process.env.STORAGE_DIR || path.resolve(__dirname, \"../../\");\n    const uploadOutput = path.resolve(baseStoragePath, \"collector/hotdir\");\n    cb(null, uploadOutput);\n  },\n  filename: function (_, file, cb) {\n    file.originalname = normalizePath(\n      Buffer.from(file.originalname, \"latin1\").toString(\"utf8\")\n    );\n    cb(null, file.originalname);\n  },\n});\n\n// Asset storage for logos",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/files/multer.js",
        "start": 32,
        "end": 49,
        "startLoc": {
          "line": 32,
          "column": 21,
          "position": 262
        },
        "endLoc": {
          "line": 49,
          "column": 27,
          "position": 445
        }
      },
      "secondFile": {
        "name": "server/utils/files/multer.js",
        "start": 11,
        "end": 31,
        "startLoc": {
          "line": 11,
          "column": 18,
          "position": 74
        },
        "endLoc": {
          "line": 31,
          "column": 4,
          "position": 257
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "cb(null, uploadOutput);\n  },\n  filename: function (_, file, cb) {\n    file.originalname = normalizePath(\n      Buffer.from(file.originalname, \"latin1\").toString(\"utf8\")\n    );\n    cb(null, file.originalname);\n  },\n});\n\n/**\n * Handle PFP file upload as logos\n */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/files/multer.js",
        "start": 58,
        "end": 70,
        "startLoc": {
          "line": 58,
          "column": 2,
          "position": 570
        },
        "endLoc": {
          "line": 70,
          "column": 4,
          "position": 654
        }
      },
      "secondFile": {
        "name": "server/utils/files/multer.js",
        "start": 18,
        "end": 31,
        "startLoc": {
          "line": 18,
          "column": 5,
          "position": 173
        },
        "endLoc": {
          "line": 31,
          "column": 4,
          "position": 257
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": " }).single(\"file\");\n  upload(request, response, function (err) {\n    if (err) {\n      response\n        .status(500)\n        .json({\n          success: false,\n          error: `Invalid file upload. ${err.message}`,\n        })\n        .end();\n      return;\n    }\n    next();\n  });\n}\n\n/**\n * Handle logo asset uploads\n */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/files/multer.js",
        "start": 121,
        "end": 139,
        "startLoc": {
          "line": 121,
          "column": 21,
          "position": 1038
        },
        "endLoc": {
          "line": 139,
          "column": 4,
          "position": 1142
        }
      },
      "secondFile": {
        "name": "server/utils/files/multer.js",
        "start": 97,
        "end": 119,
        "startLoc": {
          "line": 97,
          "column": 18,
          "position": 902
        },
        "endLoc": {
          "line": 119,
          "column": 4,
          "position": 1006
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ");\n  upload(request, response, function (err) {\n    if (err) {\n      response\n        .status(500)\n        .json({\n          success: false,\n          error: `Invalid file upload. ${err.message}`,\n        })\n        .end();\n      return;\n    }\n    next();\n  });\n}\n\n/**\n * Handle PFP file upload as logos\n */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/files/multer.js",
        "start": 141,
        "end": 159,
        "startLoc": {
          "line": 141,
          "column": 7,
          "position": 1181
        },
        "endLoc": {
          "line": 159,
          "column": 4,
          "position": 1278
        }
      },
      "secondFile": {
        "name": "server/utils/files/multer.js",
        "start": 97,
        "end": 119,
        "startLoc": {
          "line": 97,
          "column": 7,
          "position": 909
        },
        "endLoc": {
          "line": 119,
          "column": 4,
          "position": 1006
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": " }).single(\"file\");\n  upload(request, response, function (err) {\n    if (err) {\n      response\n        .status(500)\n        .json({\n          success: false,\n          error: `Invalid file upload. ${err.message}`,\n        })\n        .end();\n      return;\n    }\n    next();\n  });\n}\n\nmodule",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/files/multer.js",
        "start": 161,
        "end": 177,
        "startLoc": {
          "line": 161,
          "column": 17,
          "position": 1310
        },
        "endLoc": {
          "line": 177,
          "column": 7,
          "position": 1414
        }
      },
      "secondFile": {
        "name": "server/utils/files/multer.js",
        "start": 97,
        "end": 119,
        "startLoc": {
          "line": 97,
          "column": 18,
          "position": 902
        },
        "endLoc": {
          "line": 119,
          "column": 4,
          "position": 1006
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n\n// Telemetry is anonymized and your data is never read. This can be disabled by setting\n// DISABLE_TELEMETRY=true in the `.env` of however you setup. Telemetry helps us determine use\n// of how AnythingLLM is used and how to improve this product!\n// You can see all Telemetry events by ctrl+f `Telemetry.sendTelemetry` calls to verify this claim.\nasync function setupTelemetry() {\n  if (process.env.DISABLE_TELEMETRY === \"true\") {\n    console.log(\n      `\\x1b[31m[TELEMETRY DISABLED]\\x1b[0m Telemetry is marked as disabled - no events will send. Telemetry helps Mintplex Labs Inc improve AnythingLLM.`\n    );\n    return true;\n  }\n\n  if (Telemetry.isDev()) {\n    console.log(\n      `\\x1b[33m[TELEMETRY STUBBED]\\x1b[0m Anonymous Telemetry stubbed in development.`\n    );\n    return;\n  }\n\n  console.log(\n    `\\x1b[32m[TELEMETRY ENABLED]\\x1b[0m Anonymous Telemetry enabled. Telemetry helps Mintplex Labs Inc improve AnythingLLM.`\n  );\n  await",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/database/index.js",
        "start": 81,
        "end": 105,
        "startLoc": {
          "line": 81,
          "column": 2,
          "position": 713
        },
        "endLoc": {
          "line": 105,
          "column": 6,
          "position": 821
        }
      },
      "secondFile": {
        "name": "server/utils/telemetry/index.js",
        "start": 2,
        "end": 26,
        "startLoc": {
          "line": 2,
          "column": 2,
          "position": 31
        },
        "endLoc": {
          "line": 26,
          "column": 4,
          "position": 139
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": ", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"X-Integrity\": this.comkey.sign(data),\n        \"X-Payload-Signer\": this.comkey.encrypt(\n          new EncryptionManager().xPayload\n        ),\n      },\n      body: data,\n    })\n      .then((res) => {\n        if (!res.ok) throw new Error(\"Response could not be completed\");\n        return res.json();\n      })\n      .then((res) => res)\n      .catch((e) => {\n        this.log(e.message);\n        return { success: false, reason: e.message, documents: [] };\n      });\n  }\n\n  /**\n   * Process raw text as a document for the collector\n   * - Will append the options to the request body\n   * @param {string} textContent - The text to process\n   * @param {Object} metadata - The metadata to process\n   * @returns {Promise<Object>} - The response from the collector API\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/collectorApi/index.js",
        "start": 116,
        "end": 144,
        "startLoc": {
          "line": 116,
          "column": 15,
          "position": 790
        },
        "endLoc": {
          "line": 144,
          "column": 6,
          "position": 987
        }
      },
      "secondFile": {
        "name": "server/utils/collectorApi/index.js",
        "start": 78,
        "end": 106,
        "startLoc": {
          "line": 78,
          "column": 10,
          "position": 502
        },
        "endLoc": {
          "line": 106,
          "column": 6,
          "position": 699
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"X-Integrity\": this.comkey.sign(data),\n        \"X-Payload-Signer\": this.comkey.encrypt(\n          new EncryptionManager().xPayload\n        ),\n      },\n      body: data,\n    })\n      .then((res) => {\n        if (!res.ok) throw new Error(\"Response could not be completed\");\n        return res.json();\n      })\n      .then((res) => res)\n      .catch((e) => {\n        this.log(e.message);\n        return { success: false, reason: e.message, documents: [] };\n      });\n  }\n\n  // We will not ever expose the document processor to the frontend API so instead we relay",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/collectorApi/index.js",
        "start": 151,
        "end": 173,
        "startLoc": {
          "line": 151,
          "column": 19,
          "position": 1063
        },
        "endLoc": {
          "line": 173,
          "column": 90,
          "position": 1260
        }
      },
      "secondFile": {
        "name": "server/utils/collectorApi/index.js",
        "start": 78,
        "end": 106,
        "startLoc": {
          "line": 78,
          "column": 10,
          "position": 502
        },
        "endLoc": {
          "line": 106,
          "column": 6,
          "position": 699
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"X-Integrity\": this.comkey.sign(data),\n        \"X-Payload-Signer\": this.comkey.encrypt(\n          new EncryptionManager().xPayload\n        ),\n      },\n      body: data,\n    })\n      .then((res) => {\n        if (!res.ok) throw new Error(\"Response could not be completed\");\n        return res.json();\n      })\n      .then((res) => res)\n      .catch((e) => {\n        this.log(e.message);\n        return { success: false, content",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/collectorApi/index.js",
        "start": 214,
        "end": 232,
        "startLoc": {
          "line": 214,
          "column": 16,
          "position": 1587
        },
        "endLoc": {
          "line": 232,
          "column": 8,
          "position": 1757
        }
      },
      "secondFile": {
        "name": "server/utils/collectorApi/index.js",
        "start": 78,
        "end": 96,
        "startLoc": {
          "line": 78,
          "column": 10,
          "position": 502
        },
        "endLoc": {
          "line": 96,
          "column": 7,
          "position": 672
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: message,\n      response: {\n        text: textResponse,\n        sources: [],\n        type: chatMode,\n        attachments,\n      },\n      threadId: thread?.id || null,\n      include: false,\n      user,\n    });\n    return;\n  }\n\n  // Compress & Assemble message to ensure prompt passes token limit with room for response",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/stream.js",
        "start": 195,
        "end": 212,
        "startLoc": {
          "line": 195,
          "column": 1,
          "position": 1390
        },
        "endLoc": {
          "line": 212,
          "column": 90,
          "position": 1491
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 76,
        "end": 93,
        "startLoc": {
          "line": 76,
          "column": 2,
          "position": 587
        },
        "endLoc": {
          "line": 93,
          "column": 62,
          "position": 688
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ";\n  const hasVectorizedSpace = await VectorDb.hasNamespace(workspace.slug);\n  const embeddingsCount = await VectorDb.namespaceCount(workspace.slug);\n\n  // User is trying to query-mode chat a workspace that has no data in it - so\n  // we should exit early as no information can be found under these conditions.\n  if ((!hasVectorizedSpace || embeddingsCount === 0) && chatMode === \"query\") {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 23,
        "end": 34,
        "startLoc": {
          "line": 23,
          "column": 2,
          "position": 249
        },
        "endLoc": {
          "line": 34,
          "column": 1,
          "position": 344
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 58,
        "end": 68,
        "startLoc": {
          "line": 58,
          "column": 3,
          "position": 436
        },
        "endLoc": {
          "line": 68,
          "column": 5,
          "position": 531
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n  await new DocumentManager({\n    workspace,\n    maxTokens: LLMConnector.promptWindowLimit(),\n  })\n    .pinnedDocs()\n    .then((pinnedDocs) => {\n      pinnedDocs.forEach((doc) => {\n        const { pageContent, ...metadata } = doc;\n        pinnedDocIdentifiers.push(sourceIdentifier(doc));\n        contextTexts.push(doc.pageContent);\n        sources.push({\n          text:\n            pageContent.slice(0, 1_000) +\n            \"...continued on in source document...\",\n          ...metadata,\n        });\n      });\n    });\n\n  const vectorSearchResults =\n    embeddingsCount !== 0\n      ? await VectorDb.performSimilaritySearch({\n          namespace: workspace.slug,\n          input: prompt",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 63,
        "end": 87,
        "startLoc": {
          "line": 63,
          "column": 2,
          "position": 538
        },
        "endLoc": {
          "line": 87,
          "column": 7,
          "position": 727
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 113,
        "end": 137,
        "startLoc": {
          "line": 113,
          "column": 35,
          "position": 805
        },
        "endLoc": {
          "line": 137,
          "column": 15,
          "position": 994
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n          LLMConnector,\n          similarityThreshold: workspace?.similarityThreshold,\n          topN: workspace?.topN,\n          filterIdentifiers: pinnedDocIdentifiers,\n          rerank: workspace?.vectorSearchMode === \"rerank\",\n        })\n      : {\n          contextTexts: [],\n          sources: [],\n          message: null,\n        };\n\n  // Failed similarity search if it was run at all and failed.\n  if (!!vectorSearchResults.message) {\n    return",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 87,
        "end": 102,
        "startLoc": {
          "line": 87,
          "column": 7,
          "position": 728
        },
        "endLoc": {
          "line": 102,
          "column": 7,
          "position": 829
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 137,
        "end": 152,
        "startLoc": {
          "line": 137,
          "column": 15,
          "position": 995
        },
        "endLoc": {
          "line": 152,
          "column": 19,
          "position": 1096
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ".contextTexts];\n  sources = [...sources, ...vectorSearchResults.sources];\n\n  // If in query mode and no context chunks are found from search, backfill, or pins -  do not\n  // let the LLM try to hallucinate a response or use general knowledge and exit early\n  if (chatMode === \"query\" && contextTexts.length === 0) {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 116,
        "end": 126,
        "startLoc": {
          "line": 116,
          "column": 20,
          "position": 927
        },
        "endLoc": {
          "line": 126,
          "column": 1,
          "position": 999
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 178,
        "end": 187,
        "startLoc": {
          "line": 178,
          "column": 14,
          "position": 1265
        },
        "endLoc": {
          "line": 187,
          "column": 5,
          "position": 1337
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ",\n      response: {\n        text: textResponse,\n        sources: [],\n        type: chatMode,\n      },\n      include: false,\n    });\n\n    return formatJSON(\n      {\n        id: uuid,\n        type: \"textResponse\",\n        sources: [],\n        close: true,\n        error: null,\n        textResponse,\n      },\n      { model: workspace.slug, finish_reason: \"no_content\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 128,
        "end": 146,
        "startLoc": {
          "line": 128,
          "column": 7,
          "position": 1023
        },
        "endLoc": {
          "line": 146,
          "column": 13,
          "position": 1137
        }
      },
      "secondFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 36,
        "end": 54,
        "startLoc": {
          "line": 36,
          "column": 2,
          "position": 371
        },
        "endLoc": {
          "line": 54,
          "column": 8,
          "position": 485
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ",\n  systemPrompt = null,\n  history = [],\n  prompt = null,\n  temperature = null,\n}) {\n  const uuid = uuidv4();\n  const chatMode = workspace?.chatMode ?? \"chat\";\n  const LLMConnector = getLLMProvider({\n    provider: workspace?.chatProvider,\n    model: workspace?.chatModel,\n  });\n  const VectorDb = getVectorDbClass();\n  const hasVectorizedSpace = await VectorDb.hasNamespace(workspace.slug);\n  const embeddingsCount = await VectorDb.namespaceCount(workspace.slug);\n\n  // We don't want to write a new method for every LLM to support openAI calls",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 204,
        "end": 220,
        "startLoc": {
          "line": 204,
          "column": 9,
          "position": 1543
        },
        "endLoc": {
          "line": 220,
          "column": 77,
          "position": 1701
        }
      },
      "secondFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 11,
        "end": 27,
        "startLoc": {
          "line": 11,
          "column": 10,
          "position": 133
        },
        "endLoc": {
          "line": 27,
          "column": 77,
          "position": 291
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ");\n\n  // User is trying to query-mode chat a workspace that has no data in it - so\n  // we should exit early as no information can be found under these conditions.\n  if ((!hasVectorizedSpace || embeddingsCount === 0) && chatMode === \"query\") {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: String(prompt),\n      response: {\n        text: textResponse,\n        sources: [],\n        type: chatMode,\n      },\n      include: false,\n    });\n\n    writeResponseChunk",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 237,
        "end": 257,
        "startLoc": {
          "line": 237,
          "column": 2,
          "position": 1859
        },
        "endLoc": {
          "line": 257,
          "column": 19,
          "position": 1992
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 60,
        "end": 45,
        "startLoc": {
          "line": 60,
          "column": 5,
          "position": 473
        },
        "endLoc": {
          "line": 45,
          "column": 7,
          "position": 419
        }
      }
    },
    {
      "format": "javascript",
      "lines": 49,
      "fragment": ";\n  }\n\n  // If we are here we know that we are in a workspace that is:\n  // 1. Chatting in \"chat\" mode and may or may _not_ have embeddings\n  // 2. Chatting in \"query\" mode and has at least 1 embedding\n  let contextTexts = [];\n  let sources = [];\n  let pinnedDocIdentifiers = [];\n  await new DocumentManager({\n    workspace,\n    maxTokens: LLMConnector.promptWindowLimit(),\n  })\n    .pinnedDocs()\n    .then((pinnedDocs) => {\n      pinnedDocs.forEach((doc) => {\n        const { pageContent, ...metadata } = doc;\n        pinnedDocIdentifiers.push(sourceIdentifier(doc));\n        contextTexts.push(doc.pageContent);\n        sources.push({\n          text:\n            pageContent.slice(0, 1_000) +\n            \"...continued on in source document...\",\n          ...metadata,\n        });\n      });\n    });\n\n  const vectorSearchResults =\n    embeddingsCount !== 0\n      ? await VectorDb.performSimilaritySearch({\n          namespace: workspace.slug,\n          input: prompt,\n          LLMConnector,\n          similarityThreshold: workspace?.similarityThreshold,\n          topN: workspace?.topN,\n          filterIdentifiers: pinnedDocIdentifiers,\n          rerank: workspace?.vectorSearchMode === \"rerank\",\n        })\n      : {\n          contextTexts: [],\n          sources: [],\n          message: null,\n        };\n\n  // Failed similarity search if it was run at all and failed.\n  if (!!vectorSearchResults.message) {\n    writeResponseChunk(\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 271,
        "end": 319,
        "startLoc": {
          "line": 271,
          "column": 7,
          "position": 2083
        },
        "endLoc": {
          "line": 319,
          "column": 1,
          "position": 2423
        }
      },
      "secondFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 55,
        "end": 152,
        "startLoc": {
          "line": 55,
          "column": 2,
          "position": 491
        },
        "endLoc": {
          "line": 152,
          "column": 9,
          "position": 1098
        }
      }
    },
    {
      "format": "javascript",
      "lines": 26,
      "fragment": ";\n  }\n\n  // For OpenAI Compatible chats, we cannot do backfilling so we simply aggregate results here.\n  contextTexts = [...contextTexts, ...vectorSearchResults.contextTexts];\n  sources = [...sources, ...vectorSearchResults.sources];\n\n  // If in query mode and no context chunks are found from search, backfill, or pins -  do not\n  // let the LLM try to hallucinate a response or use general knowledge and exit early\n  if (chatMode === \"query\" && contextTexts.length === 0) {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: prompt,\n      response: {\n        text: textResponse,\n        sources: [],\n        type: chatMode,\n      },\n      include: false,\n    });\n\n    writeResponseChunk",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 332,
        "end": 357,
        "startLoc": {
          "line": 332,
          "column": 7,
          "position": 2517
        },
        "endLoc": {
          "line": 357,
          "column": 19,
          "position": 2682
        }
      },
      "secondFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 112,
        "end": 137,
        "startLoc": {
          "line": 112,
          "column": 2,
          "position": 906
        },
        "endLoc": {
          "line": 137,
          "column": 7,
          "position": 1071
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ",\n      response: {\n        text: textResponse,\n        sources: [],\n        type: chatMode,\n      },\n      include: false,\n    });\n\n    writeResponseChunk(\n      response,\n      formatJSON(\n        {\n          id: uuid,\n          type: \"textResponse\",\n          sources: [],\n          close: true,\n          error: null,\n          textResponse,\n        },\n        { chunked: true, model: workspace.slug, finish_reason: \"no_content\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 348,
        "end": 368,
        "startLoc": {
          "line": 348,
          "column": 7,
          "position": 2634
        },
        "endLoc": {
          "line": 368,
          "column": 13,
          "position": 2760
        }
      },
      "secondFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 248,
        "end": 268,
        "startLoc": {
          "line": 248,
          "column": 2,
          "position": 1944
        },
        "endLoc": {
          "line": 268,
          "column": 8,
          "position": 2070
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ";\n  }\n\n  // Compress & Assemble message to ensure prompt passes token limit with room for response\n  // and build system messages based on inputs and history.\n  const messages = await LLMConnector.compressMessages({\n    systemPrompt: systemPrompt ?? (await chatPrompt(workspace)),\n    userPrompt: prompt,\n    contextTexts,\n    chatHistory: history,\n  });\n\n  if",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 371,
        "end": 383,
        "startLoc": {
          "line": 371,
          "column": 7,
          "position": 2773
        },
        "endLoc": {
          "line": 383,
          "column": 3,
          "position": 2844
        }
      },
      "secondFile": {
        "name": "server/utils/chats/openaiCompatible.js",
        "start": 147,
        "end": 159,
        "startLoc": {
          "line": 147,
          "column": 2,
          "position": 1143
        },
        "endLoc": {
          "line": 159,
          "column": 29,
          "position": 1214
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ") {\n    const regex = new RegExp(\n      `(?:\\\\b\\\\s|^)(${preset.command})(?:\\\\b\\\\s|$)`,\n      \"g\"\n    );\n    updatedMessage = updatedMessage.replace(regex, preset.prompt);\n  }\n\n  return updatedMessage;\n}\n\nasync",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/index.js",
        "start": 50,
        "end": 61,
        "startLoc": {
          "line": 50,
          "column": 11,
          "position": 416
        },
        "endLoc": {
          "line": 61,
          "column": 6,
          "position": 480
        }
      },
      "secondFile": {
        "name": "server/utils/chats/index.js",
        "start": 28,
        "end": 43,
        "startLoc": {
          "line": 28,
          "column": 12,
          "position": 293
        },
        "endLoc": {
          "line": 43,
          "column": 4,
          "position": 357
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": "workspace,\n    maxTokens: LLMConnector.promptWindowLimit(),\n  })\n    .pinnedDocs()\n    .then((pinnedDocs) => {\n      pinnedDocs.forEach((doc) => {\n        const { pageContent, ...metadata } = doc;\n        pinnedDocIdentifiers.push(sourceIdentifier(doc));\n        contextTexts.push(doc.pageContent);\n        sources.push({\n          text:\n            pageContent.slice(0, 1_000) +\n            \"...continued on in source document...\",\n          ...metadata,\n        });\n      });\n    });\n\n  const vectorSearchResults =\n    embeddingsCount !== 0\n      ? await VectorDb.performSimilaritySearch({\n          namespace: embed",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/embed.js",
        "start": 69,
        "end": 90,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 572
        },
        "endLoc": {
          "line": 90,
          "column": 6,
          "position": 741
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 115,
        "end": 136,
        "startLoc": {
          "line": 115,
          "column": 5,
          "position": 816
        },
        "endLoc": {
          "line": 136,
          "column": 10,
          "position": 985
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "workspace?.vectorSearchMode === \"rerank\",\n        })\n      : {\n          contextTexts: [],\n          sources: [],\n          message: null,\n        };\n\n  // Failed similarity search if it was run at all and failed.\n  if (!!vectorSearchResults.message) {\n    writeResponseChunk(response, {\n      id: uuid,\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error: \"Failed to connect to vector database provider.\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/embed.js",
        "start": 96,
        "end": 112,
        "startLoc": {
          "line": 96,
          "column": 2,
          "position": 796
        },
        "endLoc": {
          "line": 112,
          "column": 49,
          "position": 907
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 142,
        "end": 158,
        "startLoc": {
          "line": 142,
          "column": 2,
          "position": 1032
        },
        "endLoc": {
          "line": 158,
          "column": 20,
          "position": 1143
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "workspace?.topN || 4,\n    searchResults: vectorSearchResults.sources,\n    history: rawHistory,\n    filterIdentifiers: pinnedDocIdentifiers,\n  });\n\n  // Why does contextTexts get all the info, but sources only get current search?\n  // This is to give the ability of the LLM to \"comprehend\" a contextual response without\n  // populating the Citations under a response with documents the user \"thinks\" are irrelevant\n  // due to how we manage backfilling of the context to keep chats with the LLM more correct in responses.\n  // If a past citation was used to answer the question - that is visible in the history so it logically makes sense\n  // and does not appear to the user that a new response used information that is otherwise irrelevant for a given prompt.\n  // TLDR; reduces GitHub issues for \"LLM citing document that has no answer in it\" while keep answers highly accurate.\n  contextTexts = [...contextTexts, ...filledSources.contextTexts];\n  sources = [...sources, ...vectorSearchResults.sources];\n\n  // If in query mode and no sources are found in current search or backfilled from history, do not",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/embed.js",
        "start": 119,
        "end": 135,
        "startLoc": {
          "line": 119,
          "column": 2,
          "position": 957
        },
        "endLoc": {
          "line": 135,
          "column": 98,
          "position": 1053
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 165,
        "end": 181,
        "startLoc": {
          "line": 165,
          "column": 2,
          "position": 1193
        },
        "endLoc": {
          "line": 181,
          "column": 93,
          "position": 1289
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n    },\n    rawHistory\n  );\n\n  // If streaming is not explicitly enabled for connector\n  // we do regular waiting of a response and send a single chunk.\n  if (LLMConnector.streamingEnabled() !== true) {\n    console.log(\n      `\\x1b[31m[STREAMING DISABLED]\\x1b[0m Streaming is not available for ${LLMConnector.constructor.name}. Will use regular chat method.`\n    );\n    const { textResponse, metrics: performanceMetrics } =\n      await LLMConnector.getChatCompletion(messages, {\n        temperature: embed",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/embed.js",
        "start": 158,
        "end": 171,
        "startLoc": {
          "line": 158,
          "column": 12,
          "position": 1210
        },
        "endLoc": {
          "line": 171,
          "column": 6,
          "position": 1301
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 220,
        "end": 233,
        "startLoc": {
          "line": 220,
          "column": 12,
          "position": 1545
        },
        "endLoc": {
          "line": 233,
          "column": 10,
          "position": 1636
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "\n  const messageLimit = workspace?.openAiHistory || 20;\n  const hasVectorizedSpace = await VectorDb.hasNamespace(workspace.slug);\n  const embeddingsCount = await VectorDb.namespaceCount(workspace.slug);\n\n  // User is trying to query-mode chat a workspace that has no data in it - so\n  // we should exit early as no information can be found under these conditions.\n  if ((!hasVectorizedSpace || embeddingsCount === 0) && chatMode === \"query\") {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: String(message",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 141,
        "end": 155,
        "startLoc": {
          "line": 141,
          "column": 2,
          "position": 841
        },
        "endLoc": {
          "line": 155,
          "column": 8,
          "position": 977
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 57,
        "end": 36,
        "startLoc": {
          "line": 57,
          "column": 1,
          "position": 420
        },
        "endLoc": {
          "line": 36,
          "column": 7,
          "position": 369
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n  await new DocumentManager({\n    workspace,\n    maxTokens: LLMConnector.promptWindowLimit(),\n  })\n    .pinnedDocs()\n    .then((pinnedDocs) => {\n      pinnedDocs.forEach((doc) => {\n        const { pageContent, ...metadata } = doc;\n        pinnedDocIdentifiers.push(sourceIdentifier(doc));\n        contextTexts.push(doc.pageContent);\n        sources.push({\n          text:\n            pageContent.slice(0, 1_000) +\n            \"...continued on in source document...\",\n          ...metadata,\n        });\n      });\n    });\n\n  const vectorSearchResults =\n    embeddingsCount !== 0\n      ? await VectorDb.performSimilaritySearch({\n          namespace: workspace.slug,\n          input: message",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 191,
        "end": 215,
        "startLoc": {
          "line": 191,
          "column": 1,
          "position": 1199
        },
        "endLoc": {
          "line": 215,
          "column": 8,
          "position": 1388
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 113,
        "end": 137,
        "startLoc": {
          "line": 113,
          "column": 35,
          "position": 805
        },
        "endLoc": {
          "line": 137,
          "column": 15,
          "position": 994
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n          LLMConnector,\n          similarityThreshold: workspace?.similarityThreshold,\n          topN: workspace?.topN,\n          filterIdentifiers: pinnedDocIdentifiers,\n          rerank: workspace?.vectorSearchMode === \"rerank\",\n        })\n      : {\n          contextTexts: [],\n          sources: [],\n          message: null,\n        };\n\n  // Failed similarity search if it was run at all and failed.\n  if (!!vectorSearchResults.message) {\n    return {",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 215,
        "end": 230,
        "startLoc": {
          "line": 215,
          "column": 8,
          "position": 1389
        },
        "endLoc": {
          "line": 230,
          "column": 2,
          "position": 1492
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 137,
        "end": 102,
        "startLoc": {
          "line": 137,
          "column": 15,
          "position": 995
        },
        "endLoc": {
          "line": 102,
          "column": 11,
          "position": 831
        }
      }
    },
    {
      "format": "javascript",
      "lines": 31,
      "fragment": ";\n  }\n\n  const { fillSourceWindow } = require(\"../helpers/chat\");\n  const filledSources = fillSourceWindow({\n    nDocs: workspace?.topN || 4,\n    searchResults: vectorSearchResults.sources,\n    history: rawHistory,\n    filterIdentifiers: pinnedDocIdentifiers,\n  });\n\n  // Why does contextTexts get all the info, but sources only get current search?\n  // This is to give the ability of the LLM to \"comprehend\" a contextual response without\n  // populating the Citations under a response with documents the user \"thinks\" are irrelevant\n  // due to how we manage backfilling of the context to keep chats with the LLM more correct in responses.\n  // If a past citation was used to answer the question - that is visible in the history so it logically makes sense\n  // and does not appear to the user that a new response used information that is otherwise irrelevant for a given prompt.\n  // TLDR; reduces GitHub issues for \"LLM citing document that has no answer in it\" while keep answers highly accurate.\n  contextTexts = [...contextTexts, ...filledSources.contextTexts];\n  sources = [...sources, ...vectorSearchResults.sources];\n\n  // If in query mode and no context chunks are found from search, backfill, or pins -  do not\n  // let the LLM try to hallucinate a response or use general knowledge and exit early\n  if (chatMode === \"query\" && contextTexts.length === 0) {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: message",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 238,
        "end": 268,
        "startLoc": {
          "line": 238,
          "column": 2,
          "position": 1549
        },
        "endLoc": {
          "line": 268,
          "column": 8,
          "position": 1754
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 160,
        "end": 128,
        "startLoc": {
          "line": 160,
          "column": 7,
          "position": 1155
        },
        "endLoc": {
          "line": 128,
          "column": 7,
          "position": 1022
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    });\n\n    return {\n      id: uuid,\n      type: \"textResponse\",\n      sources: [],\n      close: true,\n      error: null,\n      textResponse,\n      metrics: {},\n    };\n  }\n\n  // Compress & Assemble message to ensure prompt passes token limit with room for response",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 279,
        "end": 293,
        "startLoc": {
          "line": 279,
          "column": 5,
          "position": 1834
        },
        "endLoc": {
          "line": 293,
          "column": 90,
          "position": 1904
        }
      },
      "secondFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 164,
        "end": 178,
        "startLoc": {
          "line": 164,
          "column": 10,
          "position": 1040
        },
        "endLoc": {
          "line": 178,
          "column": 62,
          "position": 1110
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "\n  workspace,\n  message = null,\n  mode = \"chat\",\n  user = null,\n  thread = null,\n  sessionId = null,\n  attachments = [],\n  reset = false,\n}) {\n  const uuid = uuidv4();\n  const chatMode = mode ?? \"chat\";\n\n  // If the user wants to reset the chat history we do so pre-flight\n  // and continue execution. If no message is provided then the user intended\n  // to reset the chat history only and we can exit early with a confirmation.\n  if (reset) {\n    await WorkspaceChats.markThreadHistoryInvalidV2({\n      workspaceId: workspace.id,\n      user_id: user?.id,\n      thread_id: thread?.id,\n      api_session_id: sessionId,\n    });\n    if (!message?.length) {\n      writeResponseChunk",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 367,
        "end": 391,
        "startLoc": {
          "line": 367,
          "column": 2,
          "position": 2282
        },
        "endLoc": {
          "line": 391,
          "column": 19,
          "position": 2459
        }
      },
      "secondFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 43,
        "end": 67,
        "startLoc": {
          "line": 43,
          "column": 2,
          "position": 167
        },
        "endLoc": {
          "line": 67,
          "column": 7,
          "position": 344
        }
      }
    },
    {
      "format": "javascript",
      "lines": 29,
      "fragment": "\n  // Since preset commands are not supported in API calls, we can just process the message here\n  const processedMessage = await grepAllSlashCommands(message);\n  message = processedMessage;\n\n  if (EphemeralAgentHandler.isAgentInvocation({ message })) {\n    await Telemetry.sendTelemetry(\"agent_chat_started\");\n\n    // Initialize the EphemeralAgentHandler to handle non-continuous\n    // conversations with agents since this is over REST.\n    const agentHandler = new EphemeralAgentHandler({\n      uuid,\n      workspace,\n      prompt: message,\n      userId: user?.id || null,\n      threadId: thread?.id || null,\n      sessionId,\n    });\n\n    // Establish event listener that emulates websocket calls\n    // in Aibitat so that we can keep the same interface in Aibitat\n    // but use HTTP.\n    const eventListener = new EphemeralEventListener();\n    await agentHandler.init();\n    await agentHandler.createAIbitat({ handler: eventListener });\n    agentHandler.startAgentCluster();\n\n    // The cluster has started and now we wait for close event since\n    // and stream back any results we get from agents as they come in.",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 405,
        "end": 433,
        "startLoc": {
          "line": 405,
          "column": 40,
          "position": 2543
        },
        "endLoc": {
          "line": 433,
          "column": 67,
          "position": 2737
        }
      },
      "secondFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 79,
        "end": 107,
        "startLoc": {
          "line": 79,
          "column": 26,
          "position": 412
        },
        "endLoc": {
          "line": 107,
          "column": 77,
          "position": 606
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": "\n  const VectorDb = getVectorDbClass();\n  const messageLimit = workspace?.openAiHistory || 20;\n  const hasVectorizedSpace = await VectorDb.hasNamespace(workspace.slug);\n  const embeddingsCount = await VectorDb.namespaceCount(workspace.slug);\n\n  // User is trying to query-mode chat a workspace that has no data in it - so\n  // we should exit early as no information can be found under these conditions.\n  if ((!hasVectorizedSpace || embeddingsCount === 0) && chatMode === \"query\") {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n    writeResponseChunk(response, {\n      id: uuid,\n      type: \"textResponse\",\n      textResponse,\n      sources: [],\n      attachments:",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 466,
        "end": 483,
        "startLoc": {
          "line": 466,
          "column": 1,
          "position": 2970
        },
        "endLoc": {
          "line": 483,
          "column": 2,
          "position": 3129
        }
      },
      "secondFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 140,
        "end": 73,
        "startLoc": {
          "line": 140,
          "column": 2,
          "position": 829
        },
        "endLoc": {
          "line": 73,
          "column": 2,
          "position": 567
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: message,\n      response: {\n        text: textResponse,\n        sources: [],\n        attachments: attachments,\n        type: chatMode,\n        metrics: {},\n      },\n      threadId: thread?.id || null,\n      apiSessionId",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 487,
        "end": 499,
        "startLoc": {
          "line": 487,
          "column": 2,
          "position": 3161
        },
        "endLoc": {
          "line": 499,
          "column": 13,
          "position": 3249
        }
      },
      "secondFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 265,
        "end": 277,
        "startLoc": {
          "line": 265,
          "column": 1,
          "position": 1731
        },
        "endLoc": {
          "line": 277,
          "column": 8,
          "position": 1819
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": ",\n      include: false,\n      user,\n    });\n    return;\n  }\n\n  // If we are here we know that we are in a workspace that is:\n  // 1. Chatting in \"chat\" mode and may or may _not_ have embeddings\n  // 2. Chatting in \"query\" mode and has at least 1 embedding\n  let completeText;\n  let metrics = {};\n  let contextTexts = [];\n  let sources = [];\n  let pinnedDocIdentifiers = [];\n  const { rawHistory, chatHistory } = await recentChatHistory({\n    user,\n    workspace,\n    thread,\n    messageLimit,\n    apiSessionId: sessionId,\n  });\n\n  // Look for pinned documents and see if the user decided to use this feature. We will also do a vector search",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 499,
        "end": 522,
        "startLoc": {
          "line": 499,
          "column": 10,
          "position": 3253
        },
        "endLoc": {
          "line": 522,
          "column": 110,
          "position": 3388
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 86,
        "end": 192,
        "startLoc": {
          "line": 86,
          "column": 5,
          "position": 661
        },
        "endLoc": {
          "line": 192,
          "column": 6,
          "position": 1201
        }
      }
    },
    {
      "format": "javascript",
      "lines": 55,
      "fragment": ",\n  });\n\n  // Look for pinned documents and see if the user decided to use this feature. We will also do a vector search\n  // as pinning is a supplemental tool but it should be used with caution since it can easily blow up a context window.\n  // However we limit the maximum of appended context to 80% of its overall size, mostly because if it expands beyond this\n  // it will undergo prompt compression anyway to make it work. If there is so much pinned that the context here is bigger than\n  // what the model can support - it would get compressed anyway and that really is not the point of pinning. It is really best\n  // suited for high-context models.\n  await new DocumentManager({\n    workspace,\n    maxTokens: LLMConnector.promptWindowLimit(),\n  })\n    .pinnedDocs()\n    .then((pinnedDocs) => {\n      pinnedDocs.forEach((doc) => {\n        const { pageContent, ...metadata } = doc;\n        pinnedDocIdentifiers.push(sourceIdentifier(doc));\n        contextTexts.push(doc.pageContent);\n        sources.push({\n          text:\n            pageContent.slice(0, 1_000) +\n            \"...continued on in source document...\",\n          ...metadata,\n        });\n      });\n    });\n\n  const vectorSearchResults =\n    embeddingsCount !== 0\n      ? await VectorDb.performSimilaritySearch({\n          namespace: workspace.slug,\n          input: message,\n          LLMConnector,\n          similarityThreshold: workspace?.similarityThreshold,\n          topN: workspace?.topN,\n          filterIdentifiers: pinnedDocIdentifiers,\n          rerank: workspace?.vectorSearchMode === \"rerank\",\n        })\n      : {\n          contextTexts: [],\n          sources: [],\n          message: null,\n        };\n\n  // Failed similarity search if it was run at all and failed.\n  if (!!vectorSearchResults.message) {\n    writeResponseChunk(response, {\n      id: uuid,\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error: vectorSearchResults.message,\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 519,
        "end": 573,
        "startLoc": {
          "line": 519,
          "column": 10,
          "position": 3379
        },
        "endLoc": {
          "line": 573,
          "column": 7,
          "position": 3747
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 105,
        "end": 159,
        "startLoc": {
          "line": 105,
          "column": 13,
          "position": 780
        },
        "endLoc": {
          "line": 159,
          "column": 5,
          "position": 1148
        }
      }
    },
    {
      "format": "javascript",
      "lines": 37,
      "fragment": ",\n    });\n    return;\n  }\n\n  const { fillSourceWindow } = require(\"../helpers/chat\");\n  const filledSources = fillSourceWindow({\n    nDocs: workspace?.topN || 4,\n    searchResults: vectorSearchResults.sources,\n    history: rawHistory,\n    filterIdentifiers: pinnedDocIdentifiers,\n  });\n\n  // Why does contextTexts get all the info, but sources only get current search?\n  // This is to give the ability of the LLM to \"comprehend\" a contextual response without\n  // populating the Citations under a response with documents the user \"thinks\" are irrelevant\n  // due to how we manage backfilling of the context to keep chats with the LLM more correct in responses.\n  // If a past citation was used to answer the question - that is visible in the history so it logically makes sense\n  // and does not appear to the user that a new response used information that is otherwise irrelevant for a given prompt.\n  // TLDR; reduces GitHub issues for \"LLM citing document that has no answer in it\" while keep answers highly accurate.\n  contextTexts = [...contextTexts, ...filledSources.contextTexts];\n  sources = [...sources, ...vectorSearchResults.sources];\n\n  // If in query mode and no context chunks are found from search, backfill, or pins -  do not\n  // let the LLM try to hallucinate a response or use general knowledge and exit early\n  if (chatMode === \"query\" && contextTexts.length === 0) {\n    const textResponse =\n      workspace?.queryRefusalResponse ??\n      \"There is no relevant information in this workspace to answer your query.\";\n    writeResponseChunk(response, {\n      id: uuid,\n      type: \"textResponse\",\n      textResponse,\n      sources: [],\n      close: true,\n      error: null,\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 573,
        "end": 609,
        "startLoc": {
          "line": 573,
          "column": 2,
          "position": 3753
        },
        "endLoc": {
          "line": 609,
          "column": 7,
          "position": 3992
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 158,
        "end": 194,
        "startLoc": {
          "line": 158,
          "column": 8,
          "position": 1146
        },
        "endLoc": {
          "line": 194,
          "column": 5,
          "position": 1385
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ",\n    });\n\n    await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: message,\n      response: {\n        text: textResponse,\n        sources: [],\n        attachments: attachments,\n        type: chatMode,\n        metrics: {},\n      },\n      threadId: thread?.id || null,\n      apiSessionId: sessionId,\n      include: false,\n      user,\n    });\n    return;\n  }\n\n  // Compress & Assemble message to ensure prompt passes token limit with room for response",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 609,
        "end": 630,
        "startLoc": {
          "line": 609,
          "column": 2,
          "position": 3998
        },
        "endLoc": {
          "line": 630,
          "column": 90,
          "position": 4124
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 193,
        "end": 506,
        "startLoc": {
          "line": 193,
          "column": 5,
          "position": 1383
        },
        "endLoc": {
          "line": 506,
          "column": 62,
          "position": 3280
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n      include: false,\n      user,\n    });\n    return;\n  }\n\n  // Compress & Assemble message to ensure prompt passes token limit with room for response\n  // and build system messages based on inputs and history.\n  const messages = await LLMConnector.compressMessages(\n    {\n      systemPrompt: await chatPrompt(workspace, user),\n      userPrompt: message",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 623,
        "end": 635,
        "startLoc": {
          "line": 623,
          "column": 10,
          "position": 4097
        },
        "endLoc": {
          "line": 635,
          "column": 8,
          "position": 4165
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 205,
        "end": 217,
        "startLoc": {
          "line": 205,
          "column": 5,
          "position": 1464
        },
        "endLoc": {
          "line": 217,
          "column": 15,
          "position": 1532
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ";\n  }\n\n  // Compress & Assemble message to ensure prompt passes token limit with room for response\n  // and build system messages based on inputs and history.\n  const messages = await LLMConnector.compressMessages(\n    {\n      systemPrompt: await chatPrompt(workspace, user),\n      userPrompt: message,\n      contextTexts,\n      chatHistory,\n      attachments,\n    },\n    rawHistory\n  );\n\n  // If streaming is not explicitly enabled for connector",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 627,
        "end": 643,
        "startLoc": {
          "line": 627,
          "column": 7,
          "position": 4117
        },
        "endLoc": {
          "line": 643,
          "column": 56,
          "position": 4193
        }
      },
      "secondFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 290,
        "end": 306,
        "startLoc": {
          "line": 290,
          "column": 2,
          "position": 1897
        },
        "endLoc": {
          "line": 306,
          "column": 29,
          "position": 1973
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ",\n      contextTexts,\n      chatHistory,\n      attachments,\n    },\n    rawHistory\n  );\n\n  // If streaming is not explicitly enabled for connector\n  // we do regular waiting of a response and send a single chunk.\n  if (LLMConnector.streamingEnabled() !== true) {\n    console.log(\n      `\\x1b[31m[STREAMING DISABLED]\\x1b[0m Streaming is not available for ${LLMConnector.constructor.name}. Will use regular chat method.`\n    );\n    const { textResponse, metrics: performanceMetrics } =\n      await LLMConnector.getChatCompletion(messages, {\n        temperature: workspace?.openAiTemp ?? LLMConnector.defaultTemp,\n      });\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 635,
        "end": 653,
        "startLoc": {
          "line": 635,
          "column": 8,
          "position": 4166
        },
        "endLoc": {
          "line": 653,
          "column": 5,
          "position": 4287
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 217,
        "end": 236,
        "startLoc": {
          "line": 217,
          "column": 15,
          "position": 1533
        },
        "endLoc": {
          "line": 236,
          "column": 1,
          "position": 1654
        }
      }
    },
    {
      "format": "javascript",
      "lines": 32,
      "fragment": "\n    completeText = textResponse;\n    metrics = performanceMetrics;\n    writeResponseChunk(response, {\n      uuid,\n      sources,\n      type: \"textResponseChunk\",\n      textResponse: completeText,\n      close: true,\n      error: false,\n      metrics,\n    });\n  } else {\n    const stream = await LLMConnector.streamGetChatCompletion(messages, {\n      temperature: workspace?.openAiTemp ?? LLMConnector.defaultTemp,\n    });\n    completeText = await LLMConnector.handleStream(response, stream, {\n      uuid,\n      sources,\n    });\n    metrics = stream.metrics;\n  }\n\n  if (completeText?.length > 0) {\n    const { chat } = await WorkspaceChats.new({\n      workspaceId: workspace.id,\n      prompt: message,\n      response: {\n        text: completeText,\n        sources,\n        type: chatMode,\n        metrics",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 652,
        "end": 683,
        "startLoc": {
          "line": 652,
          "column": 2,
          "position": 4286
        },
        "endLoc": {
          "line": 683,
          "column": 8,
          "position": 4525
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 235,
        "end": 266,
        "startLoc": {
          "line": 235,
          "column": 1,
          "position": 1654
        },
        "endLoc": {
          "line": 266,
          "column": 12,
          "position": 1893
        }
      }
    },
    {
      "format": "javascript",
      "lines": 21,
      "fragment": ",\n      user,\n    });\n\n    writeResponseChunk(response, {\n      uuid,\n      type: \"finalizeResponseStream\",\n      close: true,\n      error: false,\n      chatId: chat.id,\n      metrics,\n    });\n    return;\n  }\n\n  writeResponseChunk(response, {\n    uuid,\n    type: \"finalizeResponseStream\",\n    close: true,\n    error: false,\n  ",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/chats/apiChatHandler.js",
        "start": 687,
        "end": 707,
        "startLoc": {
          "line": 687,
          "column": 10,
          "position": 4555
        },
        "endLoc": {
          "line": 707,
          "column": 3,
          "position": 4659
        }
      },
      "secondFile": {
        "name": "server/utils/chats/stream.js",
        "start": 269,
        "end": 289,
        "startLoc": {
          "line": 269,
          "column": 5,
          "position": 1916
        },
        "endLoc": {
          "line": 289,
          "column": 5,
          "position": 2020
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n    const folders = fs.readdirSync(path.resolve(pluginsPath));\n    for (const folder of folders) {\n      const configLocation = path.resolve(\n        pluginsPath,\n        normalizePath(folder),\n        \"plugin.json\"\n      );\n      if (!this.isValidLocation(configLocation)) continue;\n      const config = safeJsonParse(fs.readFileSync(configLocation, \"utf8\"));\n      plugins",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/imported.js",
        "start": 91,
        "end": 101,
        "startLoc": {
          "line": 91,
          "column": 1,
          "position": 723
        },
        "endLoc": {
          "line": 101,
          "column": 8,
          "position": 827
        }
      },
      "secondFile": {
        "name": "server/utils/agents/imported.js",
        "start": 68,
        "end": 78,
        "startLoc": {
          "line": 68,
          "column": 2,
          "position": 535
        },
        "endLoc": {
          "line": 78,
          "column": 3,
          "position": 639
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "${text}`, ...args);\n  }\n\n  closeAlert() {\n    this.log(`End ${this.#invocationUUID}::${this.provider}:${this.model}`);\n  }\n\n  async #chatHistory(limit = 10) {\n    try {\n      const rawHistory = (\n        await WorkspaceChats.where(\n          {\n            workspaceId: this.#workspace",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/ephemeral.js",
        "start": 78,
        "end": 90,
        "startLoc": {
          "line": 78,
          "column": 41,
          "position": 453
        },
        "endLoc": {
          "line": 90,
          "column": 11,
          "position": 552
        }
      },
      "secondFile": {
        "name": "server/utils/agents/index.js",
        "start": 27,
        "end": 39,
        "startLoc": {
          "line": 27,
          "column": 32,
          "position": 238
        },
        "endLoc": {
          "line": 39,
          "column": 11,
          "position": 337
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": ",\n            include: true,\n          },\n          limit,\n          { id: \"desc\" }\n        )\n      ).reverse();\n\n      const agentHistory = [];\n      rawHistory.forEach((chatLog) => {\n        agentHistory.push(\n          {\n            from: USER_AGENT.name,\n            to: WORKSPACE_AGENT.name,\n            content: chatLog.prompt,\n            state: \"success\",\n          },\n          {\n            from: WORKSPACE_AGENT.name,\n            to: USER_AGENT.name,\n            content: safeJsonParse(chatLog.response)?.text || \"\",\n            state: \"success\",\n          }\n        );\n      });\n      return agentHistory;\n    } catch (e) {\n      this.log(\"Error loading chat history\", e.message);\n      return [];\n    }\n  }\n\n  /**\n   * Attempts to find a fallback provider and model to use if the workspace\n   * does not have an explicit `agentProvider` and `agentModel` set.\n   * 1. Fallback to the workspace `chatProvider` and `chatModel` if they exist.\n   * 2. Fallback to the system `LLM_PROVIDER` and try to load the associated default model via ENV params or a base available model.\n   * 3. Otherwise, return null - will likely throw an error the user can act on.\n   * @returns {object|null} - An object with provider and model keys.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/ephemeral.js",
        "start": 93,
        "end": 132,
        "startLoc": {
          "line": 93,
          "column": 11,
          "position": 590
        },
        "endLoc": {
          "line": 132,
          "column": 6,
          "position": 805
        }
      },
      "secondFile": {
        "name": "server/utils/agents/index.js",
        "start": 42,
        "end": 74,
        "startLoc": {
          "line": 42,
          "column": 5,
          "position": 377
        },
        "endLoc": {
          "line": 74,
          "column": 11,
          "position": 592
        }
      }
    },
    {
      "format": "javascript",
      "lines": 37,
      "fragment": ".chatModel,\n      };\n    }\n\n    // If workspace does not have chat provider and model fallback\n    // to system provider and try to load provider default model\n    const systemProvider = process.env.LLM_PROVIDER;\n    const systemModel = this.providerDefault(systemProvider);\n    if (systemProvider && systemModel) {\n      return {\n        provider: systemProvider,\n        model: systemModel,\n      };\n    }\n\n    return null;\n  }\n\n  /**\n   * Finds or assumes the model preference value to use for API calls.\n   * If multi-model loading is supported, we use their agent model selection of the workspace\n   * If not supported, we attempt to fallback to the system provider value for the LLM preference\n   * and if that fails - we assume a reasonable base model to exist.\n   * @returns {string|null} the model preference value to use in API calls\n   */\n  #fetchModel() {\n    // Provider was not explicitly set for workspace, so we are going to run our fallback logic\n    // that will set a provider and model for us to use.\n    if (!this.provider) {\n      const fallback = this.#getFallbackProvider();\n      if (!fallback) throw new Error(\"No valid provider found for the agent.\");\n      this.provider = fallback.provider; // re-set the provider to the fallback provider so it is not null.\n      return fallback.model; // set its defined model based on fallback logic.\n    }\n\n    // The provider was explicitly set, so check if the workspace has an agent model set.\n    if (this.#workspace",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/ephemeral.js",
        "start": 138,
        "end": 174,
        "startLoc": {
          "line": 138,
          "column": 11,
          "position": 862
        },
        "endLoc": {
          "line": 174,
          "column": 11,
          "position": 1058
        }
      },
      "secondFile": {
        "name": "server/utils/agents/index.js",
        "start": 292,
        "end": 328,
        "startLoc": {
          "line": 292,
          "column": 10,
          "position": 2184
        },
        "endLoc": {
          "line": 328,
          "column": 11,
          "position": 2380
        }
      }
    },
    {
      "format": "javascript",
      "lines": 107,
      "fragment": "parent)) {\n          this.log(\n            `${parent} is not a valid plugin. Skipping inclusion to agent cluster.`\n          );\n          continue;\n        }\n\n        const childPlugin = AgentPlugins[parent].plugin.find(\n          (child) => child.name === childPluginName\n        );\n        if (!childPlugin) {\n          this.log(\n            `${parent} does not have child plugin named ${childPluginName}. Skipping inclusion to agent cluster.`\n          );\n          continue;\n        }\n\n        const callOpts = this.parseCallOptions(\n          args,\n          childPlugin?.startupConfig?.params,\n          name\n        );\n        this.aibitat.use(childPlugin.plugin(callOpts));\n        this.log(\n          `Attached ${parent}:${childPluginName} plugin to Agent cluster`\n        );\n        continue;\n      }\n\n      // Load flow plugin. This is marked by `@@flow_` in the array of functions to load.\n      if (name.startsWith(\"@@flow_\")) {\n        const uuid = name.replace(\"@@flow_\", \"\");\n        const plugin = AgentFlows.loadFlowPlugin(uuid, this.aibitat);\n        if (!plugin) {\n          this.log(\n            `Flow ${uuid} not found in flows directory. Skipping inclusion to agent cluster.`\n          );\n          continue;\n        }\n\n        this.aibitat.use(plugin.plugin());\n        this.log(\n          `Attached flow ${plugin.name} (${plugin.flowName}) plugin to Agent cluster`\n        );\n        continue;\n      }\n\n      // Load MCP plugin. This is marked by `@@mcp_` in the array of functions to load.\n      // All sub-tools are loaded here and are denoted by `pluginName:toolName` as their identifier.\n      // This will replace the parent MCP server plugin with the sub-tools as child plugins so they\n      // can be called directly by the agent when invoked.\n      // Since to get to this point, the `activeMCPServers` method has already been called, we can\n      // safely assume that the MCP server is running and the tools are available/loaded.\n      if (name.startsWith(\"@@mcp_\")) {\n        const mcpPluginName = name.replace(\"@@mcp_\", \"\");\n        const plugins =\n          await new MCPCompatibilityLayer().convertServerToolsToPlugins(\n            mcpPluginName,\n            this.aibitat\n          );\n        if (!plugins) {\n          this.log(\n            `MCP ${mcpPluginName} not found in MCP server config. Skipping inclusion to agent cluster.`\n          );\n          continue;\n        }\n\n        // Remove the old function from the agent functions directly\n        // and push the new ones onto the end of the array so that they are loaded properly.\n        this.aibitat.agents.get(\"@agent\").functions = this.aibitat.agents\n          .get(\"@agent\")\n          .functions.filter((f) => f.name !== name);\n        for (const plugin of plugins)\n          this.aibitat.agents.get(\"@agent\").functions.push(plugin.name);\n\n        plugins.forEach((plugin) => {\n          this.aibitat.use(plugin.plugin());\n          this.log(\n            `Attached MCP::${plugin.toolName} MCP tool to Agent cluster`\n          );\n        });\n        continue;\n      }\n\n      // Load imported plugin. This is marked by `@@` in the array of functions to load.\n      // and is the @@hubID of the plugin.\n      if (name.startsWith(\"@@\")) {\n        const hubId = name.replace(\"@@\", \"\");\n        const valid = ImportedPlugin.validateImportedPluginHandler(hubId);\n        if (!valid) {\n          this.log(\n            `Imported plugin by hubId ${hubId} not found in plugin directory. Skipping inclusion to agent cluster.`\n          );\n          continue;\n        }\n\n        const plugin = ImportedPlugin.loadPluginByHubId(hubId);\n        const callOpts = plugin.parseCallOptions();\n        this.aibitat.use(plugin.plugin(callOpts));\n        this.log(\n          `Attached ${plugin.name} (${hubId}) imported plugin to Agent cluster`\n        );\n        continue;\n      }\n\n      // Load single-stage plugin.\n      if (!AgentPlugins",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/ephemeral.js",
        "start": 196,
        "end": 302,
        "startLoc": {
          "line": 196,
          "column": 2,
          "position": 1270
        },
        "endLoc": {
          "line": 302,
          "column": 13,
          "position": 2034
        }
      },
      "secondFile": {
        "name": "server/utils/agents/index.js",
        "start": 380,
        "end": 486,
        "startLoc": {
          "line": 380,
          "column": 2,
          "position": 2875
        },
        "endLoc": {
          "line": 486,
          "column": 7,
          "position": 3639
        }
      }
    },
    {
      "format": "javascript",
      "lines": 28,
      "fragment": "name)) {\n        this.log(\n          `${name} is not a valid plugin. Skipping inclusion to agent cluster.`\n        );\n        continue;\n      }\n\n      const callOpts = this.parseCallOptions(\n        args,\n        AgentPlugins[name].startupConfig.params\n      );\n      const AIbitatPlugin = AgentPlugins[name];\n      this.aibitat.use(AIbitatPlugin.plugin(callOpts));\n      this.log(`Attached ${name} plugin to Agent cluster`);\n    }\n  }\n\n  async #loadAgents() {\n    // Default User agent and workspace agent\n    this.log(`Attaching user and default agent to Agent cluster.`);\n    this.aibitat.agent(USER_AGENT.name, await USER_AGENT.getDefinition());\n    this.aibitat.agent(\n      WORKSPACE_AGENT.name,\n      await WORKSPACE_AGENT.getDefinition(this.provider)\n    );\n\n    this.#funcsToLoad = [\n      ...(await",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/ephemeral.js",
        "start": 302,
        "end": 329,
        "startLoc": {
          "line": 302,
          "column": 2,
          "position": 2038
        },
        "endLoc": {
          "line": 329,
          "column": 6,
          "position": 2235
        }
      },
      "secondFile": {
        "name": "server/utils/agents/index.js",
        "start": 486,
        "end": 513,
        "startLoc": {
          "line": 486,
          "column": 2,
          "position": 3650
        },
        "endLoc": {
          "line": 513,
          "column": 2,
          "position": 3847
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ");\n\n    // Load required agents (Default + custom)\n    await this.#loadAgents();\n\n    // Attach all required plugins for functions to operate.\n    await this.#attachPlugins(args);\n  }\n\n  startAgentCluster() {\n    return this.aibitat.start({\n      from: USER_AGENT.name,\n      to: this.channel ?? WORKSPACE_AGENT.name,\n      content: this.#prompt",
      "tokens": 0,
      "firstFile": {
        "name": "server/utils/agents/ephemeral.js",
        "start": 367,
        "end": 380,
        "startLoc": {
          "line": 367,
          "column": 5,
          "position": 2511
        },
        "endLoc": {
          "line": 380,
          "column": 8,
          "position": 2598
        }
      },
      "secondFile": {
        "name": "server/utils/agents/index.js",
        "start": 553,
        "end": 566,
        "startLoc": {
          "line": 553,
          "column": 2,
          "position": 4159
        },
        "endLoc": {
          "line": 566,
          "column": 11,
          "position": 4246
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n    [\n      validatedRequest,\n      flexUserRoleValid([ROLES.admin, ROLES.manager]),\n      isSupportedRepoProvider,\n    ],\n    async (request, response) => {\n      try {\n        const { repo_platform } = request.params;\n        const responseFromProcessor =\n          await new CollectorApi().forwardExtensionRequest({\n            endpoint: `/ext/${repo_platform}-repo`",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 40,
        "end": 51,
        "startLoc": {
          "line": 40,
          "column": 27,
          "position": 304
        },
        "endLoc": {
          "line": 51,
          "column": 7,
          "position": 400
        }
      },
      "secondFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 16,
        "end": 27,
        "startLoc": {
          "line": 16,
          "column": 31,
          "position": 118
        },
        "endLoc": {
          "line": 27,
          "column": 16,
          "position": 214
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "});\n        response.status(200).json(responseFromProcessor);\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/ext/youtube/transcript\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 57,
        "end": 67,
        "startLoc": {
          "line": 57,
          "column": 9,
          "position": 448
        },
        "endLoc": {
          "line": 67,
          "column": 26,
          "position": 517
        }
      },
      "secondFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 30,
        "end": 481,
        "startLoc": {
          "line": 30,
          "column": 11,
          "position": 234
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n        });\n        response.status(200).json(responseFromProcessor);\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/ext/confluence\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 78,
        "end": 89,
        "startLoc": {
          "line": 78,
          "column": 21,
          "position": 625
        },
        "endLoc": {
          "line": 89,
          "column": 18,
          "position": 697
        }
      },
      "secondFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 56,
        "end": 481,
        "startLoc": {
          "line": 56,
          "column": 7,
          "position": 445
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n        });\n        response.status(200).json(responseFromProcessor);\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n  app.post(\n    \"/ext/drupalwiki\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 121,
        "end": 131,
        "startLoc": {
          "line": 121,
          "column": 16,
          "position": 984
        },
        "endLoc": {
          "line": 131,
          "column": 18,
          "position": 1055
        }
      },
      "secondFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 56,
        "end": 110,
        "startLoc": {
          "line": 56,
          "column": 7,
          "position": 445
        },
        "endLoc": {
          "line": 110,
          "column": 21,
          "position": 876
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n        });\n        response.status(200).json(responseFromProcessor);\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/ext/obsidian/vault\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 142,
        "end": 153,
        "startLoc": {
          "line": 142,
          "column": 13,
          "position": 1163
        },
        "endLoc": {
          "line": 153,
          "column": 22,
          "position": 1235
        }
      },
      "secondFile": {
        "name": "server/endpoints/extensions/index.js",
        "start": 56,
        "end": 481,
        "startLoc": {
          "line": 56,
          "column": 7,
          "position": 445
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n        );\n\n        response.status(200).json({ history: convertToChatHistory(history) });\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.delete(\n    \"/embed/:embedId/:sessionId\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/embed/index.js",
        "start": 81,
        "end": 93,
        "startLoc": {
          "line": 81,
          "column": 5,
          "position": 646
        },
        "endLoc": {
          "line": 93,
          "column": 29,
          "position": 732
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 310,
        "end": 193,
        "startLoc": {
          "line": 310,
          "column": 2,
          "position": 1364
        },
        "endLoc": {
          "line": 193,
          "column": 41,
          "position": 950
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n        },\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : { orderBy: { id: \"asc\" } }),\n      });\n      return chats;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  forWorkspace",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceChats.js",
        "start": 71,
        "end": 83,
        "startLoc": {
          "line": 71,
          "column": 5,
          "position": 607
        },
        "endLoc": {
          "line": 83,
          "column": 13,
          "position": 726
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 46,
        "end": 58,
        "startLoc": {
          "line": 46,
          "column": 5,
          "position": 370
        },
        "endLoc": {
          "line": 58,
          "column": 27,
          "position": 489
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "\n          api_session_id: null, // do not include api-session chats in the frontend for anyone.\n          include: true,\n        },\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : { orderBy: { id: \"asc\" } }),\n      });\n      return chats;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  /**\n   * @deprecated Use markThreadHistoryInvalidV2 instead.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceChats.js",
        "start": 93,
        "end": 109,
        "startLoc": {
          "line": 93,
          "column": 71,
          "position": 817
        },
        "endLoc": {
          "line": 109,
          "column": 6,
          "position": 951
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 44,
        "end": 58,
        "startLoc": {
          "line": 44,
          "column": 81,
          "position": 355
        },
        "endLoc": {
          "line": 58,
          "column": 27,
          "position": 489
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": "\n        },\n        data: {\n          include: false,\n        },\n      });\n      return;\n    } catch (error) {\n      console.error(error.message);\n    }\n  },\n\n  /**\n   * @description This function is used to mark a thread's history as invalid.\n   * and works with an arbitrary where clause.\n   * @param {Object} whereClause - The where clause to update the chats.\n   * @param {Object} data - The data to update the chats with.\n   * @returns {Promise<void>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceChats.js",
        "start": 143,
        "end": 161,
        "startLoc": {
          "line": 143,
          "column": 2,
          "position": 1193
        },
        "endLoc": {
          "line": 161,
          "column": 6,
          "position": 1255
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 117,
        "end": 131,
        "startLoc": {
          "line": 117,
          "column": 71,
          "position": 1033
        },
        "endLoc": {
          "line": 131,
          "column": 6,
          "position": 1095
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n        data: {\n          include: false,\n        },\n      });\n      return;\n    } catch (error) {\n      console.error(error.message);\n    }\n  },\n\n  get",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceChats.js",
        "start": 166,
        "end": 177,
        "startLoc": {
          "line": 166,
          "column": 12,
          "position": 1308
        },
        "endLoc": {
          "line": 177,
          "column": 4,
          "position": 1367
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 118,
        "end": 131,
        "startLoc": {
          "line": 118,
          "column": 2,
          "position": 1036
        },
        "endLoc": {
          "line": 131,
          "column": 6,
          "position": 1095
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ".deleteMany({\n        where: clause,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  where: async function (\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceChats.js",
        "start": 193,
        "end": 204,
        "startLoc": {
          "line": 193,
          "column": 16,
          "position": 1560
        },
        "endLoc": {
          "line": 204,
          "column": 1,
          "position": 1628
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 93,
        "end": 103,
        "startLoc": {
          "line": 93,
          "column": 18,
          "position": 818
        },
        "endLoc": {
          "line": 103,
          "column": 7,
          "position": 886
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n      });\n\n      return invocation || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  delete",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceAgentInvocation.js",
        "start": 60,
        "end": 70,
        "startLoc": {
          "line": 60,
          "column": 2,
          "position": 550
        },
        "endLoc": {
          "line": 70,
          "column": 7,
          "position": 605
        }
      },
      "secondFile": {
        "name": "server/models/workspaceAgentInvocation.js",
        "start": 44,
        "end": 54,
        "startLoc": {
          "line": 44,
          "column": 7,
          "position": 433
        },
        "endLoc": {
          "line": 54,
          "column": 17,
          "position": 488
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "({\n        where: clause,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  where: async function (clause = {}, limit = null, orderBy = null) {\n    try {\n      const results = await prisma.workspace_agent_invocations",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceAgentInvocation.js",
        "start": 72,
        "end": 84,
        "startLoc": {
          "line": 72,
          "column": 7,
          "position": 636
        },
        "endLoc": {
          "line": 84,
          "column": 28,
          "position": 742
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 93,
        "end": 105,
        "startLoc": {
          "line": 93,
          "column": 11,
          "position": 820
        },
        "endLoc": {
          "line": 105,
          "column": 18,
          "position": 926
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ".findMany({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n}",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspaceAgentInvocation.js",
        "start": 84,
        "end": 95,
        "startLoc": {
          "line": 84,
          "column": 28,
          "position": 743
        },
        "endLoc": {
          "line": 95,
          "column": 2,
          "position": 853
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 105,
        "end": 83,
        "startLoc": {
          "line": 105,
          "column": 18,
          "position": 927
        },
        "endLoc": {
          "line": 83,
          "column": 1,
          "position": 653
        }
      }
    },
    {
      "format": "javascript",
      "lines": 24,
      "fragment": "\n  slugify: function (...args) {\n    slugifyModule.extend({\n      \"+\": \" plus \",\n      \"!\": \" bang \",\n      \"@\": \" at \",\n      \"*\": \" splat \",\n      \".\": \" dot \",\n      \":\": \"\",\n      \"~\": \"\",\n      \"(\": \"\",\n      \")\": \"\",\n      \"'\": \"\",\n      '\"': \"\",\n      \"|\": \"\",\n    });\n    return slugifyModule(...args);\n  },\n\n  /**\n   * Validate the fields for a workspace update.\n   * @param {Object} updates - The updates to validate - should be writable fields\n   * @returns {Object} The validated updates. Only valid fields are returned.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspace.js",
        "start": 140,
        "end": 163,
        "startLoc": {
          "line": 140,
          "column": 6,
          "position": 1127
        },
        "endLoc": {
          "line": 163,
          "column": 6,
          "position": 1253
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 15,
        "end": 34,
        "startLoc": {
          "line": 15,
          "column": 6,
          "position": 71
        },
        "endLoc": {
          "line": 34,
          "column": 4,
          "position": 197
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ".delete({\n        where: clause,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  where: async function (clause = {}, limit = null, orderBy = null) {\n    try {\n      const results = await prisma.workspaces",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspace.js",
        "start": 311,
        "end": 323,
        "startLoc": {
          "line": 311,
          "column": 11,
          "position": 2476
        },
        "endLoc": {
          "line": 323,
          "column": 11,
          "position": 2584
        }
      },
      "secondFile": {
        "name": "server/models/workspaceAgentInvocation.js",
        "start": 72,
        "end": 105,
        "startLoc": {
          "line": 72,
          "column": 28,
          "position": 634
        },
        "endLoc": {
          "line": 105,
          "column": 18,
          "position": 926
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ".findMany({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  whereWithUser",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/workspace.js",
        "start": 323,
        "end": 335,
        "startLoc": {
          "line": 323,
          "column": 11,
          "position": 2585
        },
        "endLoc": {
          "line": 335,
          "column": 14,
          "position": 2697
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 105,
        "end": 83,
        "startLoc": {
          "line": 105,
          "column": 18,
          "position": 927
        },
        "endLoc": {
          "line": 83,
          "column": 6,
          "position": 655
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ".findFirst({\n        where: clause,\n      });\n      return message || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  where: async function (clause = {}, limit) {\n    try {\n      const messages = await prisma.welcome_messages",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/welcomeMessages.js",
        "start": 6,
        "end": 18,
        "startLoc": {
          "line": 6,
          "column": 17,
          "position": 57
        },
        "endLoc": {
          "line": 18,
          "column": 17,
          "position": 158
        }
      },
      "secondFile": {
        "name": "server/models/workspacesSuggestedMessages.js",
        "start": 6,
        "end": 18,
        "startLoc": {
          "line": 6,
          "column": 29,
          "position": 57
        },
        "endLoc": {
          "line": 18,
          "column": 29,
          "position": 158
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ".findMany({\n        where: clause,\n        take: limit || undefined,\n      });\n      return messages;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  saveAll: async function (messages)",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/welcomeMessages.js",
        "start": 18,
        "end": 29,
        "startLoc": {
          "line": 18,
          "column": 17,
          "position": 159
        },
        "endLoc": {
          "line": 29,
          "column": 2,
          "position": 240
        }
      },
      "secondFile": {
        "name": "server/models/workspacesSuggestedMessages.js",
        "start": 18,
        "end": 29,
        "startLoc": {
          "line": 18,
          "column": 29,
          "position": 159
        },
        "endLoc": {
          "line": 29,
          "column": 2,
          "position": 240
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ".count({ where: clause });\n      return count;\n    } catch (error) {\n      console.error(error.message);\n      return 0;\n    }\n  },\n\n  delete: async function (clause = {}) {\n    try {\n      await prisma.users",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/user.js",
        "start": 241,
        "end": 251,
        "startLoc": {
          "line": 241,
          "column": 6,
          "position": 2156
        },
        "endLoc": {
          "line": 251,
          "column": 6,
          "position": 2241
        }
      },
      "secondFile": {
        "name": "server/models/workspaceUsers.js",
        "start": 85,
        "end": 95,
        "startLoc": {
          "line": 85,
          "column": 16,
          "position": 690
        },
        "endLoc": {
          "line": 95,
          "column": 16,
          "position": 775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ".deleteMany({ where: clause });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  /**\n   * Utility method to handle prompt changes and create history entries\n   * @param {import('./workspace').Workspace} workspaceData - The workspace object (previous state)\n   * @param {{id: number, role: string}|null} user - The user making the change\n   * @returns {Promise<void>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/promptHistory.js",
        "start": 80,
        "end": 93,
        "startLoc": {
          "line": 80,
          "column": 15,
          "position": 683
        },
        "endLoc": {
          "line": 93,
          "column": 6,
          "position": 740
        }
      },
      "secondFile": {
        "name": "server/models/user.js",
        "start": 251,
        "end": 259,
        "startLoc": {
          "line": 251,
          "column": 6,
          "position": 2242
        },
        "endLoc": {
          "line": 259,
          "column": 6,
          "position": 2299
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ".count({ where: clause });\n      return count;\n    } catch (error) {\n      console.error(error.message);\n      return 0;\n    }\n  },\n\n  delete: async function (clause = {}) {\n    try {\n      await prisma.invites",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/invite.js",
        "start": 84,
        "end": 94,
        "startLoc": {
          "line": 84,
          "column": 8,
          "position": 879
        },
        "endLoc": {
          "line": 94,
          "column": 8,
          "position": 964
        }
      },
      "secondFile": {
        "name": "server/models/workspaceUsers.js",
        "start": 85,
        "end": 95,
        "startLoc": {
          "line": 85,
          "column": 16,
          "position": 690
        },
        "endLoc": {
          "line": 95,
          "column": 16,
          "position": 775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": " },\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null\n          ? { orderBy }\n          : { orderBy: { occurredAt: \"desc\" } }),\n      });\n      return logs;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  where",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 44,
        "end": 57,
        "startLoc": {
          "line": 44,
          "column": 7,
          "position": 464
        },
        "endLoc": {
          "line": 57,
          "column": 6,
          "position": 583
        }
      },
      "secondFile": {
        "name": "server/models/promptHistory.js",
        "start": 35,
        "end": 41,
        "startLoc": {
          "line": 35,
          "column": 2,
          "position": 283
        },
        "endLoc": {
          "line": 41,
          "column": 12,
          "position": 408
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ";\n    }\n  },\n\n  where: async function (\n    clause = {},\n    limit = null,\n    orderBy = null,\n    offset = null\n  ) {\n    try {\n      const logs",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 53,
        "end": 64,
        "startLoc": {
          "line": 53,
          "column": 2,
          "position": 572
        },
        "endLoc": {
          "line": 64,
          "column": 5,
          "position": 637
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 199,
        "end": 210,
        "startLoc": {
          "line": 199,
          "column": 6,
          "position": 1609
        },
        "endLoc": {
          "line": 210,
          "column": 6,
          "position": 1674
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": " } : {}),\n        ...(orderBy !== null\n          ? { orderBy }\n          : { orderBy: { occurredAt: \"desc\" } }),\n      });\n      return logs;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  whereWithData",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 67,
        "end": 79,
        "startLoc": {
          "line": 67,
          "column": 7,
          "position": 702
        },
        "endLoc": {
          "line": 79,
          "column": 14,
          "position": 800
        }
      },
      "secondFile": {
        "name": "server/models/eventLogs.js",
        "start": 29,
        "end": 41,
        "startLoc": {
          "line": 29,
          "column": 6,
          "position": 310
        },
        "endLoc": {
          "line": 41,
          "column": 12,
          "position": 408
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ";\n    }\n  },\n\n  whereWithData: async function (\n    clause = {},\n    limit = null,\n    offset = null,\n    orderBy = null\n  ) {\n    const { User",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 75,
        "end": 85,
        "startLoc": {
          "line": 75,
          "column": 2,
          "position": 789
        },
        "endLoc": {
          "line": 85,
          "column": 5,
          "position": 851
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 231,
        "end": 241,
        "startLoc": {
          "line": 231,
          "column": 2,
          "position": 1906
        },
        "endLoc": {
          "line": 241,
          "column": 10,
          "position": 1968
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ": \"unknown user\" };\n      }\n\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 94,
        "end": 104,
        "startLoc": {
          "line": 94,
          "column": 9,
          "position": 976
        },
        "endLoc": {
          "line": 104,
          "column": 1,
          "position": 1029
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 256,
        "end": 265,
        "startLoc": {
          "line": 256,
          "column": 2,
          "position": 2201
        },
        "endLoc": {
          "line": 265,
          "column": 3,
          "position": 2254
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  count: async function (clause = {}) {\n    try {\n      const count = await prisma.event_logs",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 96,
        "end": 106,
        "startLoc": {
          "line": 96,
          "column": 1,
          "position": 986
        },
        "endLoc": {
          "line": 106,
          "column": 11,
          "position": 1065
        }
      },
      "secondFile": {
        "name": "server/models/workspaceUsers.js",
        "start": 75,
        "end": 85,
        "startLoc": {
          "line": 75,
          "column": 2,
          "position": 610
        },
        "endLoc": {
          "line": 85,
          "column": 16,
          "position": 689
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ".count({\n        where: clause,\n      });\n      return count;\n    } catch (error) {\n      console.error(error.message);\n      return 0;\n    }\n  },\n\n  delete",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 106,
        "end": 116,
        "startLoc": {
          "line": 106,
          "column": 11,
          "position": 1066
        },
        "endLoc": {
          "line": 116,
          "column": 7,
          "position": 1126
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 225,
        "end": 235,
        "startLoc": {
          "line": 225,
          "column": 16,
          "position": 1857
        },
        "endLoc": {
          "line": 235,
          "column": 14,
          "position": 1917
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "});\n      return count;\n    } catch (error) {\n      console.error(error.message);\n      return 0;\n    }\n  },\n\n  delete: async function (clause = {}) {\n    try {\n      await prisma.event_logs",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/eventLogs.js",
        "start": 108,
        "end": 118,
        "startLoc": {
          "line": 108,
          "column": 7,
          "position": 1079
        },
        "endLoc": {
          "line": 118,
          "column": 11,
          "position": 1154
        }
      },
      "secondFile": {
        "name": "server/models/workspaceUsers.js",
        "start": 85,
        "end": 95,
        "startLoc": {
          "line": 85,
          "column": 2,
          "position": 700
        },
        "endLoc": {
          "line": 95,
          "column": 16,
          "position": 775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n      });\n      return { success: true, error: null };\n    } catch (error) {\n      console.error(error.message);\n      return { success: false, error: error.message };\n    }\n  },\n\n  get: async function (clause = {}) {\n    try {\n      const embedConfig",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedConfig.js",
        "start": 79,
        "end": 90,
        "startLoc": {
          "line": 79,
          "column": 8,
          "position": 635
        },
        "endLoc": {
          "line": 90,
          "column": 12,
          "position": 739
        }
      },
      "secondFile": {
        "name": "server/models/invite.js",
        "start": 30,
        "end": 74,
        "startLoc": {
          "line": 30,
          "column": 2,
          "position": 308
        },
        "endLoc": {
          "line": 74,
          "column": 7,
          "position": 774
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n      });\n\n      return embedConfig || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  delete",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedConfig.js",
        "start": 107,
        "end": 117,
        "startLoc": {
          "line": 107,
          "column": 2,
          "position": 875
        },
        "endLoc": {
          "line": 117,
          "column": 7,
          "position": 930
        }
      },
      "secondFile": {
        "name": "server/models/embedConfig.js",
        "start": 91,
        "end": 101,
        "startLoc": {
          "line": 91,
          "column": 7,
          "position": 758
        },
        "endLoc": {
          "line": 101,
          "column": 17,
          "position": 813
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ".delete({\n        where: clause,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  where: async function (clause = {}, limit = null, orderBy = null) {\n    try {\n      const results = await prisma.embed_configs",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedConfig.js",
        "start": 119,
        "end": 131,
        "startLoc": {
          "line": 119,
          "column": 14,
          "position": 959
        },
        "endLoc": {
          "line": 131,
          "column": 14,
          "position": 1067
        }
      },
      "secondFile": {
        "name": "server/models/workspaceAgentInvocation.js",
        "start": 72,
        "end": 105,
        "startLoc": {
          "line": 72,
          "column": 28,
          "position": 634
        },
        "endLoc": {
          "line": 105,
          "column": 18,
          "position": 926
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ".findMany({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  whereWithWorkspace",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedConfig.js",
        "start": 131,
        "end": 143,
        "startLoc": {
          "line": 131,
          "column": 14,
          "position": 1068
        },
        "endLoc": {
          "line": 143,
          "column": 19,
          "position": 1180
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 105,
        "end": 83,
        "startLoc": {
          "line": 105,
          "column": 18,
          "position": 927
        },
        "endLoc": {
          "line": 83,
          "column": 6,
          "position": 655
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "},\n          },\n        },\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  // Will return null if process should be skipped",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedConfig.js",
        "start": 154,
        "end": 167,
        "startLoc": {
          "line": 154,
          "column": 2,
          "position": 1277
        },
        "endLoc": {
          "line": 167,
          "column": 49,
          "position": 1388
        }
      },
      "secondFile": {
        "name": "server/models/workspace.js",
        "start": 351,
        "end": 83,
        "startLoc": {
          "line": 351,
          "column": 13,
          "position": 2837
        },
        "endLoc": {
          "line": 83,
          "column": 6,
          "position": 655
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ",\n        },\n      });\n      return { chat, message: null };\n    } catch (error) {\n      console.error(error.message);\n      return { chat: null, message: error.message };\n    }\n  },\n\n  /**\n   * Loops through each chat and filters out the sources from the response object.\n   * We do this when returning /history of an embed to the frontend to prevent inadvertent leaking\n   * of private sources the user may not have intended to share with users.\n   * @param {EmbedChat[]} chats\n   * @returns {EmbedChat[]} Returns a new array of chats with the sources filtered out of responses\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedChats.js",
        "start": 30,
        "end": 46,
        "startLoc": {
          "line": 30,
          "column": 2,
          "position": 161
        },
        "endLoc": {
          "line": 46,
          "column": 6,
          "position": 240
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 8,
          "position": 165
        },
        "endLoc": {
          "line": 32,
          "column": 19,
          "position": 244
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n        },\n        data: {\n          include: false,\n        },\n      });\n      return;\n    } catch (error) {\n      console.error(error.message);\n    }\n  },\n\n  get: async function (clause = {}, limit = null, orderBy = null) {\n    try {\n      const chat = await prisma.embed_chats",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedChats.js",
        "start": 97,
        "end": 111,
        "startLoc": {
          "line": 97,
          "column": 2,
          "position": 686
        },
        "endLoc": {
          "line": 111,
          "column": 12,
          "position": 797
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 143,
        "end": 179,
        "startLoc": {
          "line": 143,
          "column": 3,
          "position": 1192
        },
        "endLoc": {
          "line": 179,
          "column": 16,
          "position": 1415
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ".findFirst({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return chat || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  delete: async function (clause = {}) {\n    try {\n      await prisma.embed_chats",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedChats.js",
        "start": 111,
        "end": 125,
        "startLoc": {
          "line": 111,
          "column": 12,
          "position": 798
        },
        "endLoc": {
          "line": 125,
          "column": 12,
          "position": 941
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 179,
        "end": 93,
        "startLoc": {
          "line": 179,
          "column": 16,
          "position": 1416
        },
        "endLoc": {
          "line": 93,
          "column": 18,
          "position": 817
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ".deleteMany({\n        where: clause,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  where: async function (\n    clause = {},\n    limit = null,\n    orderBy = null,\n    offset = null\n  ) {\n    try {\n      const chats = await prisma.embed_chats",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedChats.js",
        "start": 125,
        "end": 142,
        "startLoc": {
          "line": 125,
          "column": 12,
          "position": 942
        },
        "endLoc": {
          "line": 142,
          "column": 12,
          "position": 1064
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 93,
        "end": 210,
        "startLoc": {
          "line": 93,
          "column": 18,
          "position": 818
        },
        "endLoc": {
          "line": 210,
          "column": 16,
          "position": 1682
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ".findMany({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n        ...(offset !== null ? { skip: offset } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return chats;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  whereWithEmbedAndWorkspace",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedChats.js",
        "start": 142,
        "end": 155,
        "startLoc": {
          "line": 142,
          "column": 12,
          "position": 1065
        },
        "endLoc": {
          "line": 155,
          "column": 27,
          "position": 1204
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 210,
        "end": 58,
        "startLoc": {
          "line": 210,
          "column": 16,
          "position": 1683
        },
        "endLoc": {
          "line": 58,
          "column": 27,
          "position": 489
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n        ...(limit !== null ? { take: limit } : {}),\n        ...(offset !== null ? { skip: offset } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n      });\n      return chats;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  count: async function (clause = {}) {\n    try {\n      const count = await prisma.embed_chats",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/embedChats.js",
        "start": 174,
        "end": 188,
        "startLoc": {
          "line": 174,
          "column": 2,
          "position": 1334
        },
        "endLoc": {
          "line": 188,
          "column": 12,
          "position": 1497
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 211,
        "end": 85,
        "startLoc": {
          "line": 211,
          "column": 7,
          "position": 1693
        },
        "endLoc": {
          "line": 85,
          "column": 16,
          "position": 689
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": " || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  where: async function (\n    clause = {},\n    limit = null,\n    orderBy = null,\n    include = {",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncRun.js",
        "start": 36,
        "end": 47,
        "startLoc": {
          "line": 36,
          "column": 6,
          "position": 299
        },
        "endLoc": {
          "line": 47,
          "column": 2,
          "position": 381
        }
      },
      "secondFile": {
        "name": "server/models/workspacesSuggestedMessages.js",
        "start": 9,
        "end": 65,
        "startLoc": {
          "line": 9,
          "column": 8,
          "position": 78
        },
        "endLoc": {
          "line": 65,
          "column": 5,
          "position": 591
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ");\n      return queue || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  /**\n   * Deletes Queue record and updates document watch status to false on Document record\n   * @param {import(\"@prisma/client\").workspace_documents} document - document record to unwatch, must have `id`\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 99,
        "end": 110,
        "startLoc": {
          "line": 99,
          "column": 7,
          "position": 756
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 806
        }
      },
      "secondFile": {
        "name": "server/models/documentSyncRun.js",
        "start": 35,
        "end": 43,
        "startLoc": {
          "line": 35,
          "column": 2,
          "position": 292
        },
        "endLoc": {
          "line": 43,
          "column": 6,
          "position": 342
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ".update({\n        where: { id },\n        data,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 137,
        "end": 148,
        "startLoc": {
          "line": 137,
          "column": 21,
          "position": 1077
        },
        "endLoc": {
          "line": 148,
          "column": 1,
          "position": 1143
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 290,
        "end": 300,
        "startLoc": {
          "line": 290,
          "column": 16,
          "position": 2467
        },
        "endLoc": {
          "line": 300,
          "column": 3,
          "position": 2533
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "});\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  get: async function (clause = {}) {\n    try {\n      const queue",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 140,
        "end": 150,
        "startLoc": {
          "line": 140,
          "column": 7,
          "position": 1098
        },
        "endLoc": {
          "line": 150,
          "column": 6,
          "position": 1171
        }
      },
      "secondFile": {
        "name": "server/models/documents.js",
        "start": 41,
        "end": 51,
        "startLoc": {
          "line": 41,
          "column": 2,
          "position": 406
        },
        "endLoc": {
          "line": 51,
          "column": 9,
          "position": 479
        }
      }
    },
    {
      "format": "javascript",
      "lines": 18,
      "fragment": ".findFirst({\n        where: clause,\n      });\n      return queue || null;\n    } catch (error) {\n      console.error(error.message);\n      return null;\n    }\n  },\n\n  where: async function (\n    clause = {},\n    limit = null,\n    orderBy = null,\n    include = {}\n  ) {\n    try {\n      const results = await prisma.document_sync_queues",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 150,
        "end": 167,
        "startLoc": {
          "line": 150,
          "column": 21,
          "position": 1180
        },
        "endLoc": {
          "line": 167,
          "column": 21,
          "position": 1307
        }
      },
      "secondFile": {
        "name": "server/models/documentSyncRun.js",
        "start": 33,
        "end": 50,
        "startLoc": {
          "line": 33,
          "column": 25,
          "position": 278
        },
        "endLoc": {
          "line": 50,
          "column": 25,
          "position": 405
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ".findMany({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n        ...(orderBy !== null ? { orderBy } : {}),\n        ...(include !== null ? { include } : {}),\n      });\n      return results;\n    } catch (error) {\n      console.error(error.message);\n      return [];\n    }\n  },\n\n  count: async function (clause = {}, limit = null)",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 167,
        "end": 180,
        "startLoc": {
          "line": 167,
          "column": 21,
          "position": 1308
        },
        "endLoc": {
          "line": 180,
          "column": 2,
          "position": 1465
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 105,
        "end": 63,
        "startLoc": {
          "line": 105,
          "column": 18,
          "position": 927
        },
        "endLoc": {
          "line": 63,
          "column": 2,
          "position": 563
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ".count({\n        where: clause,\n        ...(limit !== null ? { take: limit } : {}),\n      });\n      return count;\n    } catch (error) {\n      console.error(\"FAILED TO COUNT DOCUMENTS.\", error.message);\n      return 0;\n    }\n  },\n\n  delete: async function (clause = {}) {\n    try {\n      await prisma.document_sync_queues",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 182,
        "end": 195,
        "startLoc": {
          "line": 182,
          "column": 21,
          "position": 1486
        },
        "endLoc": {
          "line": 195,
          "column": 21,
          "position": 1604
        }
      },
      "secondFile": {
        "name": "server/models/documents.js",
        "start": 187,
        "end": 79,
        "startLoc": {
          "line": 187,
          "column": 20,
          "position": 1749
        },
        "endLoc": {
          "line": 79,
          "column": 25,
          "position": 734
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ".deleteMany({ where: clause });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  /**\n   * Gets the \"stale\" queues where the queue's nextSyncAt is less than the current time\n   * @returns {Promise<(\n   *  import(\"@prisma/client\").document_sync_queues &\n   * { workspaceDoc: import(\"@prisma/client\").workspace_documents &\n   *  { workspace: import(\"@prisma/client\").workspaces }\n   * })[]}>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/documentSyncQueue.js",
        "start": 195,
        "end": 210,
        "startLoc": {
          "line": 195,
          "column": 21,
          "position": 1605
        },
        "endLoc": {
          "line": 210,
          "column": 6,
          "position": 1662
        }
      },
      "secondFile": {
        "name": "server/models/user.js",
        "start": 251,
        "end": 259,
        "startLoc": {
          "line": 251,
          "column": 6,
          "position": 2242
        },
        "endLoc": {
          "line": 259,
          "column": 6,
          "position": 2299
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ".deleteMany({\n        where: clause,\n      });\n      return true;\n    } catch (error) {\n      console.error(error.message);\n      return false;\n    }\n  },\n\n  where: async function (clause = {}, limit = null, orderBy = null) {\n    try {\n      const caches",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/cacheData.js",
        "start": 32,
        "end": 44,
        "startLoc": {
          "line": 32,
          "column": 11,
          "position": 335
        },
        "endLoc": {
          "line": 44,
          "column": 7,
          "position": 435
        }
      },
      "secondFile": {
        "name": "server/models/workspaceThread.js",
        "start": 93,
        "end": 105,
        "startLoc": {
          "line": 93,
          "column": 18,
          "position": 818
        },
        "endLoc": {
          "line": 105,
          "column": 8,
          "position": 918
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ".count({\n        where: clause,\n      });\n      return count;\n    } catch (error) {\n      console.error(error.message);\n      return 0;\n    }\n  },\n};\n\nmodule.exports = { CacheData",
      "tokens": 0,
      "firstFile": {
        "name": "server/models/cacheData.js",
        "start": 58,
        "end": 69,
        "startLoc": {
          "line": 58,
          "column": 11,
          "position": 591
        },
        "endLoc": {
          "line": 69,
          "column": 10,
          "position": 661
        }
      },
      "secondFile": {
        "name": "server/models/workspaceChats.js",
        "start": 225,
        "end": 199,
        "startLoc": {
          "line": 225,
          "column": 16,
          "position": 1857
        },
        "endLoc": {
          "line": 199,
          "column": 11,
          "position": 1568
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        response.status(200).json({ thread, message });\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/workspace/:slug/threads\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 56,
        "end": 66,
        "startLoc": {
          "line": 56,
          "column": 9,
          "position": 472
        },
        "endLoc": {
          "line": 66,
          "column": 27,
          "position": 552
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 102,
        "end": 242,
        "startLoc": {
          "line": 102,
          "column": 2,
          "position": 590
        },
        "endLoc": {
          "line": 242,
          "column": 47,
          "position": 1152
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "});\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.delete(\n    \"/workspace/:slug/thread-bulk-delete\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 94,
        "end": 104,
        "startLoc": {
          "line": 94,
          "column": 2,
          "position": 820
        },
        "endLoc": {
          "line": 104,
          "column": 38,
          "position": 893
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 232,
        "end": 193,
        "startLoc": {
          "line": 232,
          "column": 9,
          "position": 1079
        },
        "endLoc": {
          "line": 193,
          "column": 41,
          "position": 950
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n          workspace_id: workspace.id,\n        });\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/workspace/:slug/thread/:threadSlug/chats\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 115,
        "end": 127,
        "startLoc": {
          "line": 115,
          "column": 5,
          "position": 1052
        },
        "endLoc": {
          "line": 127,
          "column": 44,
          "position": 1137
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 230,
        "end": 242,
        "startLoc": {
          "line": 230,
          "column": 11,
          "position": 1067
        },
        "endLoc": {
          "line": 242,
          "column": 47,
          "position": 1152
        }
      }
    },
    {
      "format": "javascript",
      "lines": 19,
      "fragment": ",\n            thread_id: thread.id,\n            api_session_id: null, // Do not include API session chats.\n            include: true,\n          },\n          null,\n          { id: \"asc\" }\n        );\n\n        response.status(200).json({ history: convertToChatHistory(history) });\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/workspace/:slug/thread/:threadSlug/update\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 141,
        "end": 159,
        "startLoc": {
          "line": 141,
          "column": 5,
          "position": 1269
        },
        "endLoc": {
          "line": 159,
          "column": 45,
          "position": 1399
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 304,
        "end": 112,
        "startLoc": {
          "line": 304,
          "column": 3,
          "position": 1320
        },
        "endLoc": {
          "line": 112,
          "column": 48,
          "position": 670
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n        );\n        response.status(200).json({ thread, message });\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.delete(\n    \"/workspace/:slug/thread/:threadSlug/delete-edited-chats\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 171,
        "end": 182,
        "startLoc": {
          "line": 171,
          "column": 5,
          "position": 1501
        },
        "endLoc": {
          "line": 182,
          "column": 58,
          "position": 1583
        }
      },
      "secondFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 55,
        "end": 193,
        "startLoc": {
          "line": 55,
          "column": 3,
          "position": 470
        },
        "endLoc": {
          "line": 193,
          "column": 41,
          "position": 950
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/workspace/:slug/thread/:threadSlug/update-chat\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 201,
        "end": 211,
        "startLoc": {
          "line": 201,
          "column": 1,
          "position": 1760
        },
        "endLoc": {
          "line": 211,
          "column": 50,
          "position": 1830
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 232,
        "end": 112,
        "startLoc": {
          "line": 232,
          "column": 2,
          "position": 1082
        },
        "endLoc": {
          "line": 112,
          "column": 48,
          "position": 670
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ",\n        });\n\n        response.sendStatus(200).end();\n      } catch (e) {\n        console.error(e.message, e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n}\n\nmodule.exports = { workspaceThreadEndpoints",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 241,
        "end": 253,
        "startLoc": {
          "line": 241,
          "column": 2,
          "position": 2136
        },
        "endLoc": {
          "line": 253,
          "column": 25,
          "position": 2216
        }
      },
      "secondFile": {
        "name": "server/endpoints/workspaceThreads.js",
        "start": 199,
        "end": 124,
        "startLoc": {
          "line": 199,
          "column": 2,
          "position": 1753
        },
        "endLoc": {
          "line": 124,
          "column": 27,
          "position": 577
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ", error);\n        return response.status(500).json({\n          success: false,\n          error: error.message,\n        });\n      }\n    }\n  );\n\n  app.post(\n    \"/mcp-servers/delete\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/mcpServers.js",
        "start": 69,
        "end": 79,
        "startLoc": {
          "line": 69,
          "column": 29,
          "position": 585
        },
        "endLoc": {
          "line": 79,
          "column": 22,
          "position": 644
        }
      },
      "secondFile": {
        "name": "server/endpoints/mcpServers.js",
        "start": 46,
        "end": 56,
        "startLoc": {
          "line": 46,
          "column": 29,
          "position": 392
        },
        "endLoc": {
          "line": 56,
          "column": 22,
          "position": 451
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        response.status(200).json({ success: true, error: null });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/embed/chats\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/embedManagement.js",
        "start": 84,
        "end": 94,
        "startLoc": {
          "line": 84,
          "column": 9,
          "position": 840
        },
        "endLoc": {
          "line": 94,
          "column": 15,
          "position": 921
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 261,
        "end": 481,
        "startLoc": {
          "line": 261,
          "column": 2,
          "position": 1019
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "});\n        response.status(200).json({ success: true, error: null });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n}\n\nmodule.exports = { embedManagementEndpoints",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/embedManagement.js",
        "start": 121,
        "end": 131,
        "startLoc": {
          "line": 121,
          "column": 2,
          "position": 1224
        },
        "endLoc": {
          "line": 131,
          "column": 25,
          "position": 1309
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 261,
        "end": 775,
        "startLoc": {
          "line": 261,
          "column": 9,
          "position": 1018
        },
        "endLoc": {
          "line": 775,
          "column": 18,
          "position": 2970
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "\n        response.status(200).json({ success: true, error: null });\n      } catch (error) {\n        console.error(error);\n        response.status(500).json({ success: false, error: error.message });\n      }\n    }\n  );\n\n  /**\n   * Import a bundle item to the AnythingLLM instance by downloading the zip file and importing it.\n   * or whatever the item type requires. This is not used if the item is a simple text responses like\n   * slash commands or system prompts.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/communityHub.js",
        "start": 116,
        "end": 129,
        "startLoc": {
          "line": 116,
          "column": 1,
          "position": 1069
        },
        "endLoc": {
          "line": 129,
          "column": 6,
          "position": 1158
        }
      },
      "secondFile": {
        "name": "server/endpoints/communityHub.js",
        "start": 40,
        "end": 33,
        "startLoc": {
          "line": 40,
          "column": 2,
          "position": 406
        },
        "endLoc": {
          "line": 33,
          "column": 4,
          "position": 312
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ");\n\n        await Telemetry.sendTelemetry(\"community_hub_import\", {\n          itemType: response.locals.bundleItem.itemType,\n          visibility: response.locals.bundleItem.visibility,\n        });\n        await EventLogs.logEvent(\n          \"community_hub_import\",\n          {\n            itemId: response.locals.bundleItem.id,\n            itemType: response.locals.bundleItem.itemType,\n          },\n          response.locals?.user?.id\n        );\n\n        response.status(200).json({ success: true, error: null });\n      } catch (error) {\n        console.error(error);\n        response.status(500).json({\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/communityHub.js",
        "start": 144,
        "end": 163,
        "startLoc": {
          "line": 144,
          "column": 12,
          "position": 1282
        },
        "endLoc": {
          "line": 163,
          "column": 1,
          "position": 1448
        }
      },
      "secondFile": {
        "name": "server/endpoints/communityHub.js",
        "start": 102,
        "end": 44,
        "startLoc": {
          "line": 102,
          "column": 11,
          "position": 962
        },
        "endLoc": {
          "line": 44,
          "column": 2,
          "position": 465
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "e);\n        writeResponseChunk(response, {\n          id: uuidv4(),\n          type: \"abort\",\n          textResponse: null,\n          sources: [],\n          close: true,\n          error: e.message,\n        });\n        response.end();\n      }\n    }\n  );\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/chat.js",
        "start": 92,
        "end": 106,
        "startLoc": {
          "line": 92,
          "column": 2,
          "position": 840
        },
        "endLoc": {
          "line": 106,
          "column": 1,
          "position": 922
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/workspaceThread/index.js",
        "start": 621,
        "end": 634,
        "startLoc": {
          "line": 621,
          "column": 2,
          "position": 2857
        },
        "endLoc": {
          "line": 634,
          "column": 2,
          "position": 2939
        }
      }
    },
    {
      "format": "javascript",
      "lines": 39,
      "fragment": ";\n\n        if (!message?.length) {\n          response.status(400).json({\n            id: uuidv4(),\n            type: \"abort\",\n            textResponse: null,\n            sources: [],\n            close: true,\n            error: !message?.length ? \"Message is empty.\" : null,\n          });\n          return;\n        }\n\n        response.setHeader(\"Cache-Control\", \"no-cache\");\n        response.setHeader(\"Content-Type\", \"text/event-stream\");\n        response.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n        response.setHeader(\"Connection\", \"keep-alive\");\n        response.flushHeaders();\n\n        if (multiUserMode(response) && !(await User.canSendChat(user))) {\n          writeResponseChunk(response, {\n            id: uuidv4(),\n            type: \"abort\",\n            textResponse: null,\n            sources: [],\n            close: true,\n            error: `You have met your maximum 24 hour chat quota of ${user.dailyMessageLimit} chats. Try again later.`,\n          });\n          return;\n        }\n\n        await streamChatWithWorkspace(\n          response,\n          workspace,\n          message,\n          workspace?.chatMode,\n          user,\n          thread",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/chat.js",
        "start": 118,
        "end": 156,
        "startLoc": {
          "line": 118,
          "column": 7,
          "position": 1047
        },
        "endLoc": {
          "line": 156,
          "column": 7,
          "position": 1330
        }
      },
      "secondFile": {
        "name": "server/endpoints/chat.js",
        "start": 31,
        "end": 69,
        "startLoc": {
          "line": 31,
          "column": 10,
          "position": 350
        },
        "endLoc": {
          "line": 69,
          "column": 5,
          "position": 633
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "\n        await Telemetry.sendTelemetry(\"sent_chat\", {\n          multiUserMode: multiUserMode(response),\n          LLMSelection: process.env.LLM_PROVIDER || \"openai\",\n          Embedder: process.env.EMBEDDING_ENGINE || \"inherit\",\n          VectorDbSelection: process.env.VECTOR_DB || \"lancedb\",\n          multiModal: Array.isArray(attachments) && attachments?.length !== 0,\n          TTSSelection: process.env.TTS_PROVIDER || \"native\",\n          LLMModel: getModelTag(),\n        });\n\n        await EventLogs.logEvent(\n          \"sent_chat\",\n          {\n            workspaceName: workspace.",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/chat.js",
        "start": 176,
        "end": 190,
        "startLoc": {
          "line": 176,
          "column": 1,
          "position": 1447
        },
        "endLoc": {
          "line": 190,
          "column": 2,
          "position": 1588
        }
      },
      "secondFile": {
        "name": "server/endpoints/chat.js",
        "start": 71,
        "end": 85,
        "startLoc": {
          "line": 71,
          "column": 2,
          "position": 642
        },
        "endLoc": {
          "line": 85,
          "column": 2,
          "position": 783
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ".name,\n            chatModel: workspace?.chatModel || \"System Default\",\n          },\n          user?.id\n        );\n        response.end();\n      } catch (e) {\n        console.error(e);\n        writeResponseChunk(response, {\n          id: uuidv4(),\n          type: \"abort\",\n          textResponse: null,\n          sources: [],\n          close: true,\n          error: e.message,\n        });\n        response.end();\n      }\n    }\n  );\n}\n\nmodule.exports = { chatEndpoints",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/chat.js",
        "start": 191,
        "end": 213,
        "startLoc": {
          "line": 191,
          "column": 7,
          "position": 1597
        },
        "endLoc": {
          "line": 213,
          "column": 14,
          "position": 1746
        }
      },
      "secondFile": {
        "name": "server/endpoints/chat.js",
        "start": 85,
        "end": 636,
        "startLoc": {
          "line": 85,
          "column": 2,
          "position": 784
        },
        "endLoc": {
          "line": 636,
          "column": 28,
          "position": 2950
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": " } = await Collector.processRawText(\n          textContent,\n          metadata\n        );\n\n        if (!success) {\n          response.status(500).json({ success: false, error: reason });\n          return;\n        }\n\n        await",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/browserExtension.js",
        "start": 135,
        "end": 145,
        "startLoc": {
          "line": 135,
          "column": 7,
          "position": 1254
        },
        "endLoc": {
          "line": 145,
          "column": 6,
          "position": 1324
        }
      },
      "secondFile": {
        "name": "server/endpoints/browserExtension.js",
        "start": 98,
        "end": 108,
        "startLoc": {
          "line": 98,
          "column": 10,
          "position": 913
        },
        "endLoc": {
          "line": 108,
          "column": 6,
          "position": 983
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n        response.status(200).json({ users });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/admin/users/new\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 37,
        "end": 47,
        "startLoc": {
          "line": 37,
          "column": 2,
          "position": 371
        },
        "endLoc": {
          "line": 47,
          "column": 19,
          "position": 441
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 471,
        "end": 481,
        "startLoc": {
          "line": 471,
          "column": 1,
          "position": 1705
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        response.status(200).json({ success, error });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.delete(\n    \"/admin/user/:id\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 114,
        "end": 124,
        "startLoc": {
          "line": 114,
          "column": 8,
          "position": 1095
        },
        "endLoc": {
          "line": 124,
          "column": 18,
          "position": 1170
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 416,
        "end": 74,
        "startLoc": {
          "line": 416,
          "column": 3,
          "position": 1533
        },
        "endLoc": {
          "line": 74,
          "column": 18,
          "position": 729
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ".id\n        );\n        response.status(200).json({ success: true, error: null });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/admin/invites\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 145,
        "end": 156,
        "startLoc": {
          "line": 145,
          "column": 9,
          "position": 1400
        },
        "endLoc": {
          "line": 156,
          "column": 17,
          "position": 1485
        }
      },
      "secondFile": {
        "name": "server/endpoints/embedManagement.js",
        "start": 83,
        "end": 426,
        "startLoc": {
          "line": 83,
          "column": 2,
          "position": 836
        },
        "endLoc": {
          "line": 426,
          "column": 42,
          "position": 1608
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n        );\n        response.status(200).json({ success, error });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/admin/workspaces\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 207,
        "end": 218,
        "startLoc": {
          "line": 207,
          "column": 3,
          "position": 1993
        },
        "endLoc": {
          "line": 218,
          "column": 20,
          "position": 2070
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 537,
        "end": 426,
        "startLoc": {
          "line": 537,
          "column": 8,
          "position": 1900
        },
        "endLoc": {
          "line": 426,
          "column": 42,
          "position": 1608
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        response.status(200).json({ users });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.post(\n    \"/admin/workspaces/new\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 237,
        "end": 247,
        "startLoc": {
          "line": 237,
          "column": 12,
          "position": 2271
        },
        "endLoc": {
          "line": 247,
          "column": 24,
          "position": 2343
        }
      },
      "secondFile": {
        "name": "server/endpoints/admin.js",
        "start": 37,
        "end": 481,
        "startLoc": {
          "line": 37,
          "column": 2,
          "position": 369
        },
        "endLoc": {
          "line": 481,
          "column": 49,
          "position": 1775
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "\n        const { workspaceId } = request.params;\n        const { userIds } = reqBody(request);\n        const { success, error } = await Workspace.updateUsers(\n          workspaceId,\n          userIds\n        );\n        response.status(200).json({ success, error });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.delete(\n    \"/admin/workspaces/:id\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 269,
        "end": 285,
        "startLoc": {
          "line": 269,
          "column": 2,
          "position": 2572
        },
        "endLoc": {
          "line": 285,
          "column": 24,
          "position": 2710
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 532,
        "end": 74,
        "startLoc": {
          "line": 532,
          "column": 1,
          "position": 1839
        },
        "endLoc": {
          "line": 74,
          "column": 18,
          "position": 729
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "\n        const updates = reqBody(request);\n        await SystemSettings.updateSettings(updates);\n        response.status(200).json({ success: true, error: null });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.get(\n    \"/admin/api-keys\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 478,
        "end": 490,
        "startLoc": {
          "line": 478,
          "column": 2,
          "position": 4440
        },
        "endLoc": {
          "line": 490,
          "column": 18,
          "position": 4543
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 763,
        "end": 426,
        "startLoc": {
          "line": 763,
          "column": 1,
          "position": 2864
        },
        "endLoc": {
          "line": 426,
          "column": 42,
          "position": 1608
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n        });\n      } catch (e) {\n        console.error(e);\n        response.sendStatus(500).end();\n      }\n    }\n  );\n\n  app.delete(\n    \"/admin/delete-api-key/:id\"",
      "tokens": 0,
      "firstFile": {
        "name": "server/endpoints/admin.js",
        "start": 523,
        "end": 533,
        "startLoc": {
          "line": 523,
          "column": 6,
          "position": 4836
        },
        "endLoc": {
          "line": 533,
          "column": 28,
          "position": 4894
        }
      },
      "secondFile": {
        "name": "server/endpoints/api/admin/index.js",
        "start": 653,
        "end": 74,
        "startLoc": {
          "line": 653,
          "column": 2,
          "position": 2527
        },
        "endLoc": {
          "line": 74,
          "column": 18,
          "position": 729
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\">\n            Created by{\" \"}\n            <a\n              href={paths.communityHub.profile(item.creatorUsername)}\n              target=\"_blank\"\n              className=\"hover:text-blue-500 hover:underline\"\n              rel=\"noreferrer\"\n            >\n              @{item.creatorUsername}\n            </a>\n          </p>\n        )}\n      </div>\n      <div className=\"flex flex-col gap-y-[25px] text-white/80 light:text-theme-text-secondary text-sm\">\n        <p>\n          Slash",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SlashCommand.jsx",
        "start": 32,
        "end": 47,
        "startLoc": {
          "line": 32,
          "column": 32,
          "position": 281
        },
        "endLoc": {
          "line": 47,
          "column": 6,
          "position": 375
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SystemPrompt.jsx",
        "start": 46,
        "end": 61,
        "startLoc": {
          "line": 46,
          "column": 64,
          "position": 411
        },
        "endLoc": {
          "line": 61,
          "column": 7,
          "position": 505
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": " \"{item.name}\"\n        </h2>\n        {item.creatorUsername && (\n          <p className=\"text-white/60 light:text-theme-text-secondary text-xs font-mono\">\n            Created by{\" \"}\n            <a\n              href={paths.communityHub.profile(item.creatorUsername)}\n              target=\"_blank\"\n              className=\"hover:text-blue-500 hover:underline\"\n              rel=\"noreferrer\"\n            >\n              @{item.creatorUsername}\n            </a>\n          </p>\n        )}\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentSkill.jsx",
        "start": 60,
        "end": 75,
        "startLoc": {
          "line": 60,
          "column": 6,
          "position": 572
        },
        "endLoc": {
          "line": 75,
          "column": 9,
          "position": 670
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SystemPrompt.jsx",
        "start": 43,
        "end": 58,
        "startLoc": {
          "line": 43,
          "column": 7,
          "position": 385
        },
        "endLoc": {
          "line": 58,
          "column": 7,
          "position": 483
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "${e.message}`, \"error\");\n    } finally {\n      setLoading(false);\n    }\n  }\n\n  return (\n    <div className=\"flex flex-col mt-4 gap-y-4\">\n      <div className=\"flex flex-col gap-y-1\">\n        <h2 className=\"text-base text-theme-text-primary font-semibold\">\n          Import",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentFlow.jsx",
        "start": 28,
        "end": 38,
        "startLoc": {
          "line": 28,
          "column": 31,
          "position": 303
        },
        "endLoc": {
          "line": 38,
          "column": 7,
          "position": 375
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SlashCommand.jsx",
        "start": 19,
        "end": 29,
        "startLoc": {
          "line": 19,
          "column": 34,
          "position": 178
        },
        "endLoc": {
          "line": 29,
          "column": 7,
          "position": 250
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\n        </h2>\n        {item.creatorUsername && (\n          <p className=\"text-white/60 light:text-theme-text-secondary text-xs font-mono\">\n            Created by{\" \"}\n            <a\n              href={paths.communityHub.profile(item.creatorUsername)}\n              target=\"_blank\"\n              className=\"hover:text-blue-500 hover:underline\"\n              rel=\"noreferrer\"\n            >\n              @{item.creatorUsername}\n            </a>\n          </p>\n        )}\n      </div>\n      <div className=\"flex flex-col gap-y-[25px] text-white/80 light:text-theme-text-secondary text-sm\">\n        <p>\n          Agent",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/AgentFlow.jsx",
        "start": 38,
        "end": 56,
        "startLoc": {
          "line": 38,
          "column": 7,
          "position": 388
        },
        "endLoc": {
          "line": 56,
          "column": 6,
          "position": 506
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/ImportItem/Steps/PullAndReview/HubItem/SystemPrompt.jsx",
        "start": 43,
        "end": 61,
        "startLoc": {
          "line": 43,
          "column": 14,
          "position": 387
        },
        "endLoc": {
          "line": 61,
          "column": 7,
          "position": 505
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n        data-auto-play-chat-id={chatId}\n        data-tooltip-id=\"message-to-speech\"\n        data-tooltip-content={\n          speaking ? \"Pause TTS speech of message\" : \"TTS Speak message\"\n        }\n        className=\"border-none text-[var(--theme-sidebar-footer-icon-fill)]\"\n        aria-label={speaking ? \"Pause speech\" : \"Speak message\"}\n      >\n        {speaking ? (\n          <PauseCircle size={18} className=\"mb-1\" />\n        ) : (\n          <",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/native.jsx",
        "start": 38,
        "end": 50,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 316
        },
        "endLoc": {
          "line": 50,
          "column": 2,
          "position": 398
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/piperTTS.jsx",
        "start": 55,
        "end": 67,
        "startLoc": {
          "line": 55,
          "column": 2,
          "position": 485
        },
        "endLoc": {
          "line": 67,
          "column": 2,
          "position": 567
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": ");\n      } else {\n        playerRef.current.play();\n      }\n    } catch (e) {\n      console.error(e);\n      setLoading(false);\n      setSpeaking(false);\n    }\n  }\n\n  useEffect(() => {\n    function setupPlayer() {\n      if (!playerRef?.current) return;\n      playerRef.current.addEventListener(\"play\", () => {\n        setSpeaking(true);\n      });\n\n      playerRef.current.addEventListener(\"pause\", () => {\n        playerRef.current.currentTime = 0;\n        setSpeaking(false);\n      });\n    }\n    setupPlayer();\n  }, []);\n\n  if",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/asyncTts.jsx",
        "start": 30,
        "end": 56,
        "startLoc": {
          "line": 30,
          "column": 2,
          "position": 331
        },
        "endLoc": {
          "line": 56,
          "column": 3,
          "position": 519
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/piperTTS.jsx",
        "start": 24,
        "end": 50,
        "startLoc": {
          "line": 24,
          "column": 6,
          "position": 261
        },
        "endLoc": {
          "line": 50,
          "column": 7,
          "position": 449
        }
      }
    },
    {
      "format": "jsx",
      "lines": 38,
      "fragment": ") return null;\n  return (\n    <div className=\"mt-3 relative\">\n      <button\n        onClick={speakMessage}\n        data-auto-play-chat-id={chatId}\n        data-tooltip-id=\"message-to-speech\"\n        data-tooltip-content={\n          speaking\n            ? t(\"pause_tts_speech_message\")\n            : t(\"chat_window.tts_speak_message\")\n        }\n        className=\"border-none text-[var(--theme-sidebar-footer-icon-fill)]\"\n        aria-label={speaking ? \"Pause speech\" : \"Speak message\"}\n      >\n        {speaking ? (\n          <PauseCircle size={18} className=\"mb-1\" />\n        ) : (\n          <>\n            {loading ? (\n              <CircleNotch size={18} className=\"mb-1 animate-spin\" />\n            ) : (\n              <SpeakerHigh size={18} className=\"mb-1\" />\n            )}\n          </>\n        )}\n        <audio\n          ref={playerRef}\n          hidden={true}\n          src={audioSrc}\n          autoPlay={true}\n          controls={false}\n        />\n      </button>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/asyncTts.jsx",
        "start": 56,
        "end": 93,
        "startLoc": {
          "line": 56,
          "column": 7,
          "position": 524
        },
        "endLoc": {
          "line": 93,
          "column": 1,
          "position": 762
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/native.jsx",
        "start": 34,
        "end": 86,
        "startLoc": {
          "line": 34,
          "column": 10,
          "position": 284
        },
        "endLoc": {
          "line": 86,
          "column": 1,
          "position": 685
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "({ item }) {\n  return (\n    <>\n      <Link\n        key={item.id}\n        to={paths.communityHub.importItem(item.importId)}\n        className=\"bg-black/70 light:bg-slate-100 rounded-lg p-3 hover:bg-black/60 light:hover:bg-slate-200 transition-all duration-200 cursor-pointer group border border-transparent hover:border-slate-400\"\n      >\n        <div className=\"flex gap-x-2 items-center\">\n          <p className=\"text-white text-sm font-medium\">{item.name}</p>\n          <VisibilityIcon visibility={item.visibility} />\n        </div>\n        <div className=\"flex flex-col gap-2\">\n          <p className=\"text-white/60 text-xs mt-1\">{item.description}</p>\n          <label className=\"text-white/60 text-xs font-semibold mt-4\">\n            Command",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/slashCommand.jsx",
        "start": 6,
        "end": 21,
        "startLoc": {
          "line": 6,
          "column": 20,
          "position": 52
        },
        "endLoc": {
          "line": 21,
          "column": 8,
          "position": 197
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/systemPrompt.jsx",
        "start": 6,
        "end": 21,
        "startLoc": {
          "line": 6,
          "column": 20,
          "position": 52
        },
        "endLoc": {
          "line": 21,
          "column": 7,
          "position": 197
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": "\n          <label className=\"text-white/60 text-xs font-semibold mt-4\">\n            Prompt\n          </label>\n          <p className=\"text-white/60 text-xs bg-zinc-900 light:bg-slate-200 px-2 py-1 rounded-md font-mono border border-slate-800 light:border-slate-300\">\n            {truncate(item.prompt, 90)}\n          </p>\n        </div>\n        <div className=\"flex justify-end mt-2\">\n          <Link\n            to={paths.communityHub.importItem(item.importId)}\n            className=\"text-primary-button hover:text-primary-button/80 text-sm font-medium px-3 py-1.5 rounded-md bg-black/30 light:bg-slate-200 group-hover:bg-black/50 light:group-hover:bg-slate-300 transition-all\"\n          >\n            Import →\n          </Link>\n        </div>\n      </Link>\n    </>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/slashCommand.jsx",
        "start": 26,
        "end": 46,
        "startLoc": {
          "line": 26,
          "column": 1,
          "position": 227
        },
        "endLoc": {
          "line": 46,
          "column": 1,
          "position": 349
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/systemPrompt.jsx",
        "start": 19,
        "end": 39,
        "startLoc": {
          "line": 19,
          "column": 2,
          "position": 184
        },
        "endLoc": {
          "line": 39,
          "column": 1,
          "position": 306
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "({ item }) {\n  return (\n    <>\n      <Link\n        key={item.id}\n        to={paths.communityHub.importItem(item.importId)}\n        className=\"bg-black/70 light:bg-slate-100 rounded-lg p-3 hover:bg-black/60 light:hover:bg-slate-200 transition-all duration-200 cursor-pointer group border border-transparent hover:border-slate-400\"\n      >\n        <div className=\"flex gap-x-2 items-center\">\n          <p className=\"text-white text-sm font-medium\">{item.name}</p>\n          <VisibilityIcon visibility={item.visibility} />\n        </div>\n        <div className=\"flex flex-col gap-2\">\n          <p className=\"text-white/60 text-xs mt-1\">{item.description}</p>\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/agentSkill.jsx",
        "start": 6,
        "end": 21,
        "startLoc": {
          "line": 6,
          "column": 18,
          "position": 52
        },
        "endLoc": {
          "line": 21,
          "column": 1,
          "position": 185
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/systemPrompt.jsx",
        "start": 6,
        "end": 20,
        "startLoc": {
          "line": 6,
          "column": 20,
          "position": 52
        },
        "endLoc": {
          "line": 20,
          "column": 11,
          "position": 185
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n          </p>\n        </div>\n        <div className=\"flex justify-end mt-2\">\n          <Link\n            to={paths.communityHub.importItem(item.importId)}\n            className=\"text-primary-button hover:text-primary-button/80 text-sm font-medium px-3 py-1.5 rounded-md bg-black/30 light:bg-slate-200 group-hover:bg-black/50 light:group-hover:bg-slate-300 transition-all\"\n          >\n            Import →\n          </Link>\n        </div>\n      </Link>\n    </>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/agentSkill.jsx",
        "start": 31,
        "end": 46,
        "startLoc": {
          "line": 31,
          "column": 6,
          "position": 312
        },
        "endLoc": {
          "line": 46,
          "column": 1,
          "position": 391
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/HubItemCard/systemPrompt.jsx",
        "start": 24,
        "end": 39,
        "startLoc": {
          "line": 24,
          "column": 2,
          "position": 227
        },
        "endLoc": {
          "line": 39,
          "column": 1,
          "position": 306
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"px-7 py-6\">\n          <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/CodeSnippetModal/index.jsx",
        "start": 15,
        "end": 27,
        "startLoc": {
          "line": 15,
          "column": 5,
          "position": 152
        },
        "endLoc": {
          "line": 27,
          "column": 4,
          "position": 234
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 50,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 50,
          "column": 5,
          "position": 438
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={onClose}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div\n          ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/EditPresetModal.jsx",
        "start": 54,
        "end": 66,
        "startLoc": {
          "line": 54,
          "column": 7,
          "position": 482
        },
        "endLoc": {
          "line": 66,
          "column": 11,
          "position": 554
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 49,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 49,
          "column": 2,
          "position": 428
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "}\n            </h3>\n          </div>\n          <button\n            onClick={onClose}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div\n          className=\"h-full w-full overflow-y-auto\"\n          style={{ maxHeight: \"calc(100vh - 200px)\" }}\n        >\n          <form onSubmit={handleSubmit}>\n            <div className=\"py-7 px-9 space-y-2 flex-col\">\n              <div className=\"w-full flex flex-col gap-y-4\">\n                <div>\n                  <label\n                    htmlFor=\"command\"\n                    className=\"block mb-2 text-sm font-medium text-white\"\n                  >\n                    {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/AddPresetModal.jsx",
        "start": 34,
        "end": 57,
        "startLoc": {
          "line": 34,
          "column": 2,
          "position": 366
        },
        "endLoc": {
          "line": 57,
          "column": 2,
          "position": 517
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 77,
        "startLoc": {
          "line": 38,
          "column": 3,
          "position": 355
        },
        "endLoc": {
          "line": 77,
          "column": 8,
          "position": 632
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n                      required={true}\n                      className=\"border-none bg-theme-settings-input-bg w-full text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                    />\n                  </div>\n                </div>\n                <div>\n                  <label\n                    htmlFor=\"prompt\"\n                    className=\"block mb-2 text-sm font-medium text-white\"\n                  >\n                    Prompt\n                  </label>\n                  <textarea\n                    name=\"prompt\"\n                    id",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/AddPresetModal.jsx",
        "start": 69,
        "end": 84,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 609
        },
        "endLoc": {
          "line": 84,
          "column": 3,
          "position": 675
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/EditPresetModal.jsx",
        "start": 86,
        "end": 101,
        "startLoc": {
          "line": 86,
          "column": 2,
          "position": 698
        },
        "endLoc": {
          "line": 101,
          "column": 12,
          "position": 764
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": ") {\n    return (\n      <div\n        className={`${\n          isFadingOut ? \"file-upload-fadeout\" : \"file-upload\"\n        } h-14 px-2 py-2 flex items-center gap-x-4 rounded-lg bg-error/40 light:bg-error/30 light:border-solid light:border-error/40 border border-transparent`}\n      >\n        <div className=\"w-6 h-6 flex-shrink-0\">\n          <XCircle\n            color=\"var(--theme-bg-primary)\"\n            className=\"w-6 h-6 stroke-white bg-error rounded-full p-1 w-full h-full\"\n          />\n        </div>\n        <div className=\"flex flex-col\">\n          <p className=\"text-white light:text-red-600 text-xs font-semibold\">\n            {truncate(file.name, 30)}\n          </p>\n          <p className=\"text-red-100 light:text-red-600 text-xs font-medium\">\n            {error",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/UploadFile/FileUploadProgress/index.jsx",
        "start": 96,
        "end": 114,
        "startLoc": {
          "line": 96,
          "column": 9,
          "position": 799
        },
        "endLoc": {
          "line": 114,
          "column": 6,
          "position": 919
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/UploadFile/FileUploadProgress/index.jsx",
        "start": 71,
        "end": 89,
        "startLoc": {
          "line": 71,
          "column": 9,
          "position": 640
        },
        "endLoc": {
          "line": 89,
          "column": 7,
          "position": 760
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx",
        "start": 37,
        "end": 48,
        "startLoc": {
          "line": 37,
          "column": 7,
          "position": 340
        },
        "endLoc": {
          "line": 48,
          "column": 4,
          "position": 416
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 49,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 49,
          "column": 10,
          "position": 432
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Create",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx",
        "start": 69,
        "end": 83,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 572
        },
        "endLoc": {
          "line": 83,
          "column": 7,
          "position": 640
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 100,
        "end": 114,
        "startLoc": {
          "line": 100,
          "column": 2,
          "position": 790
        },
        "endLoc": {
          "line": 114,
          "column": 7,
          "position": 858
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "() {\n  const { t } = useTranslation();\n  const [loading, setLoading] = useState(false);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = new FormData(e.target);\n\n    try {\n      setLoading(true);\n      showToast(\"Scraping website - this may take a while.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx",
        "start": 7,
        "end": 17,
        "startLoc": {
          "line": 7,
          "column": 20,
          "position": 64
        },
        "endLoc": {
          "line": 17,
          "column": 44,
          "position": 162
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 6,
        "end": 16,
        "startLoc": {
          "line": 6,
          "column": 15,
          "position": 55
        },
        "endLoc": {
          "line": 16,
          "column": 41,
          "position": 153
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "),\n      });\n\n      if (!!error) {\n        showToast(error, \"error\", { clear: true });\n        setLoading(false);\n        return;\n      }\n\n      showToast(\n        `Successfully scraped ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx",
        "start": 25,
        "end": 35,
        "startLoc": {
          "line": 25,
          "column": 2,
          "position": 255
        },
        "endLoc": {
          "line": 35,
          "column": 23,
          "position": 315
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 6,
          "position": 216
        },
        "endLoc": {
          "line": 32,
          "column": 2,
          "position": 276
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": ";\n    } catch (e) {\n      console.error(e);\n      showToast(e.message, \"error\", { clear: true });\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pb-6 pb-16\">\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white text-sm font-bold\">\n                    {t(\"connectors.website-depth.URL\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx",
        "start": 43,
        "end": 60,
        "startLoc": {
          "line": 43,
          "column": 2,
          "position": 369
        },
        "endLoc": {
          "line": 60,
          "column": 31,
          "position": 531
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 38,
        "end": 55,
        "startLoc": {
          "line": 38,
          "column": 7,
          "position": 334
        },
        "endLoc": {
          "line": 55,
          "column": 25,
          "position": 496
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n                />\n              </div>\n            </div>\n          </div>\n\n          <div className=\"flex flex-col gap-y-2 w-full pr-10\">\n            <button\n              type=\"submit\"\n              disabled={loading}\n              className=\"mt-2 w-full justify-center border-none px-4 py-2 rounded-lg text-dark-text light:text-white text-sm font-bold items-center flex gap-x-2 bg-theme-home-button-primary hover:bg-theme-home-button-primary-hover disabled:bg-theme-home-button-primary-hover disabled:cursor-not-allowed\"\n            >\n              {loading ? \"Scraping website...\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx",
        "start": 111,
        "end": 123,
        "startLoc": {
          "line": 111,
          "column": 2,
          "position": 869
        },
        "endLoc": {
          "line": 123,
          "column": 22,
          "position": 929
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 78,
        "end": 90,
        "startLoc": {
          "line": 78,
          "column": 2,
          "position": 645
        },
        "endLoc": {
          "line": 90,
          "column": 27,
          "position": 705
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n      setLoading(false);\n    } catch (e) {\n      console.error(e);\n      showToast(e.message, \"error\", { clear: true });\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pb-6 pb-16\">\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col md:flex-row md:items-center gap-x-2 text-white mb-4 bg-blue-800/30 w-fit rounded-lg px-4 py-2",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Obsidian/index.jsx",
        "start": 81,
        "end": 96,
        "startLoc": {
          "line": 81,
          "column": 1,
          "position": 696
        },
        "endLoc": {
          "line": 96,
          "column": 108,
          "position": 834
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx",
        "start": 42,
        "end": 52,
        "startLoc": {
          "line": 42,
          "column": 2,
          "position": 363
        },
        "endLoc": {
          "line": 52,
          "column": 20,
          "position": 466
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "),\n      });\n\n      if (!!error) {\n        showToast(error, \"error\", { clear: true });\n        setLoading(false);\n        return;\n      }\n\n      showToast(\n        `${data.files",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 39,
        "end": 49,
        "startLoc": {
          "line": 39,
          "column": 13,
          "position": 430
        },
        "endLoc": {
          "line": 49,
          "column": 6,
          "position": 494
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 6,
          "position": 216
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 280
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "${data.destination}.`,\n        \"success\",\n        { clear: true }\n      );\n      e.target.reset();\n      setLoading(false);\n      return;\n    } catch (e) {\n      console.error(e);\n      showToast(e.message, \"error\", { clear: true });\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pb-6 pb-16\">\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white text-sm font-bold\">\n                    {t(\"connectors.gitlab.URL\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 51,
        "end": 74,
        "startLoc": {
          "line": 51,
          "column": 20,
          "position": 526
        },
        "endLoc": {
          "line": 74,
          "column": 24,
          "position": 733
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 32,
        "end": 55,
        "startLoc": {
          "line": 32,
          "column": 44,
          "position": 289
        },
        "endLoc": {
          "line": 55,
          "column": 25,
          "position": 496
        }
      }
    },
    {
      "format": "javascript",
      "lines": 55,
      "fragment": "={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white text-sm font-bold\">\n                    {t(\"connectors.github.URL\")}\n                  </label>\n                  <p className=\"text-xs font-normal text-theme-text-secondary\">\n                    {t(\"connectors.github.URL_explained\")}\n                  </p>\n                </div>\n                <input\n                  type=\"url\"\n                  name=\"repo\"\n                  className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                  placeholder=\"https://github.com/Mintplex-Labs/anything-llm\"\n                  required={true}\n                  autoComplete=\"off\"\n                  onChange={(e) => setRepo(e.target.value)}\n                  onBlur={() => setSettings({ ...settings, repo })}\n                  spellCheck={false}\n                />\n              </div>\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white font-bold text-sm flex gap-x-2 items-center\">\n                    <p className=\"font-bold text-white\">\n                      {t(\"connectors.github.token\")}\n                    </p>{\" \"}\n                    <p className=\"text-xs font-light flex items-center\">\n                      <span className=\"text-theme-text-secondary\">\n                        {t(\"connectors.github.optional\")}\n                      </span>\n                      <PATTooltip accessToken={accessToken} />\n                    </p>\n                  </label>\n                  <p className=\"text-xs font-normal text-theme-text-secondary\">\n                    {t(\"connectors.github.token_explained\")}\n                  </p>\n                </div>\n                <input\n                  type=\"text\"\n                  name=\"accessToken\"\n                  className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                  placeholder=\"github_pat_1234_abcdefg\"\n                  required={false}\n                  autoComplete=\"off\"\n                  spellCheck={false}\n                  onChange={(e) => setAccessToken(e.target.value)}\n                  onBlur={() => setSettings({ ...settings, accessToken })}\n                />\n              </div>\n              <GitHubBranchSelection\n                repo={settings",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 67,
        "end": 121,
        "startLoc": {
          "line": 67,
          "column": 9,
          "position": 645
        },
        "endLoc": {
          "line": 121,
          "column": 9,
          "position": 1085
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 68,
        "end": 135,
        "startLoc": {
          "line": 68,
          "column": 9,
          "position": 668
        },
        "endLoc": {
          "line": 135,
          "column": 5,
          "position": 1224
        }
      }
    },
    {
      "format": "javascript",
      "lines": 137,
      "fragment": "}\n                />\n              </div>\n              <GitHubBranchSelection\n                repo={settings.repo}\n                accessToken={settings.accessToken}\n              />\n            </div>\n\n            <div className=\"flex flex-col w-full py-4 pr-10\">\n              <div className=\"flex flex-col gap-y-1 mb-4\">\n                <label className=\"text-white text-sm flex gap-x-2 items-center\">\n                  <p className=\"text-white text-sm font-bold\">\n                    {t(\"connectors.github.ignores\")}\n                  </p>\n                </label>\n                <p className=\"text-xs font-normal text-theme-text-secondary\">\n                  {t(\"connectors.github.git_ignore\")}\n                </p>\n              </div>\n              <TagsInput\n                value={ignores}\n                onChange={setIgnores}\n                name=\"ignores\"\n                placeholder=\"!*.js, images/*, .DS_Store, bin/*\"\n                classNames={{\n                  tag: \"bg-theme-settings-input-bg light:bg-black/10 bg-blue-300/10 text-zinc-800\",\n                  input:\n                    \"flex p-1 !bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none\",\n                }}\n              />\n            </div>\n          </div>\n\n          <div className=\"flex flex-col gap-y-2 w-full pr-10\">\n            <PATAlert accessToken={accessToken} />\n            <button\n              type=\"submit\"\n              disabled={loading}\n              className=\"mt-2 w-full justify-center border-none px-4 py-2 rounded-lg text-dark-text light:text-white text-sm font-bold items-center flex gap-x-2 bg-theme-home-button-primary hover:bg-theme-home-button-primary-hover disabled:bg-theme-home-button-primary-hover disabled:cursor-not-allowed\"\n            >\n              {loading ? \"Collecting files...\" : \"Submit\"}\n            </button>\n            {loading && (\n              <p className=\"text-xs text-white/50\">\n                {t(\"connectors.github.task_explained\")}\n              </p>\n            )}\n          </div>\n        </form>\n      </div>\n    </div>\n  );\n}\n\nfunction GitHubBranchSelection({ repo, accessToken }) {\n  const { t } = useTranslation();\n  const [allBranches, setAllBranches] = useState(DEFAULT_BRANCHES);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function fetchAllBranches() {\n      if (!repo) {\n        setAllBranches(DEFAULT_BRANCHES);\n        setLoading(false);\n        return;\n      }\n\n      setLoading(true);\n      const { branches } = await System.dataConnectors.github.branches({\n        repo,\n        accessToken,\n      });\n      setAllBranches(branches.length > 0 ? branches : DEFAULT_BRANCHES);\n      setLoading(false);\n    }\n    fetchAllBranches();\n  }, [repo, accessToken]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <div className=\"flex flex-col gap-y-1 mb-4\">\n          <label className=\"text-white text-sm font-bold\">Branch</label>\n          <p className=\"text-xs font-normal text-theme-text-secondary\">\n            {t(\"connectors.github.branch\")}\n          </p>\n        </div>\n        <select\n          name=\"branch\"\n          required={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white focus:outline-primary-button active:outline-primary-button outline-none text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {t(\"connectors.github.branch_loading\")}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <div className=\"flex flex-col gap-y-1 mb-4\">\n        <label className=\"text-white text-sm font-bold\">Branch</label>\n        <p className=\"text-xs font-normal text-theme-text-secondary\">\n          {t(\"connectors.github.branch_explained\")}\n        </p>\n      </div>\n      <select\n        name=\"branch\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white focus:outline-primary-button active:outline-primary-button outline-none text-sm rounded-lg block w-full p-2.5\"\n      >\n        {allBranches.map((branch) => {\n          return (\n            <option key={branch} value={branch}>\n              {branch}\n            </option>\n          );\n        })}\n      </select>\n    </div>\n  );\n}\n\nfunction PATAlert({ accessToken }) {\n  const { t } = useTranslation();\n  if (!!accessToken) return null;\n  return (\n    <div className=\"flex flex-col md:flex-row md:items-center gap-x-2 text-white mb-4 bg-blue-800/30 w-fit rounded-lg px-4 py-2\">\n      <div className=\"gap-x-2 flex items-center\">\n        <Info className=\"shrink-0\" size={25} />\n        <p className=\"text-sm\">\n          <span\n            dangerouslySetInnerHTML={{\n              __html: t(\"connectors.github.token_information\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 117,
        "end": 253,
        "startLoc": {
          "line": 117,
          "column": 2,
          "position": 1069
        },
        "endLoc": {
          "line": 253,
          "column": 38,
          "position": 2033
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 149,
        "end": 294,
        "startLoc": {
          "line": 149,
          "column": 5,
          "position": 1328
        },
        "endLoc": {
          "line": 294,
          "column": 38,
          "position": 2359
        }
      }
    },
    {
      "format": "javascript",
      "lines": 58,
      "fragment": "),\n            }}\n          />\n          <br />\n          <br />\n          <a\n            href=\"https://github.com/settings/personal-access-tokens/new\"\n            rel=\"noreferrer\"\n            target=\"_blank\"\n            className=\"underline\"\n            onClick={(e) => e.stopPropagation()}\n          >\n            {\" \"}\n            {t(\"connectors.github.token_personal\")}\n          </a>\n        </p>\n      </div>\n    </div>\n  );\n}\n\nfunction PATTooltip({ accessToken }) {\n  const { t } = useTranslation();\n  if (!!accessToken) return null;\n  return (\n    <>\n      {!accessToken && (\n        <Warning\n          size={14}\n          className=\"ml-1 text-orange-500 cursor-pointer\"\n          data-tooltip-id=\"access-token-tooltip\"\n          data-tooltip-place=\"right\"\n        />\n      )}\n      <Tooltip\n        delayHide={300}\n        id=\"access-token-tooltip\"\n        className=\"max-w-xs z-99\"\n        clickable={true}\n      >\n        <p className=\"text-sm\">\n          {t(\"connectors.github.token_explained_start\")}\n          <a\n            href=\"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\"\n            rel=\"noreferrer\"\n            target=\"_blank\"\n            className=\"underline\"\n            onClick={(e) => e.stopPropagation()}\n          >\n            {t(\"connectors.github.token_explained_link1\")}\n          </a>\n          {t(\"connectors.github.token_explained_middle\")}\n          <a\n            href=\"https://github.com/settings/personal-access-tokens/new\"\n            rel=\"noreferrer\"\n            target=\"_blank\"\n            className=\"underline\"\n            onClick={(e) => e.stopPropagation()}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 253,
        "end": 310,
        "startLoc": {
          "line": 253,
          "column": 38,
          "position": 2034
        },
        "endLoc": {
          "line": 310,
          "column": 2,
          "position": 2390
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 294,
        "end": 350,
        "startLoc": {
          "line": 294,
          "column": 38,
          "position": 2360
        },
        "endLoc": {
          "line": 350,
          "column": 2,
          "position": 2711
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\n  const [settings, setSettings] = useState({\n    repo: null,\n    accessToken: null,\n  });\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = new FormData(e.target);\n\n    try {\n      setLoading(true);\n      showToast(\n        \"Fetching all files for repo - this may take a while.\",\n        \"info\",\n        { clear: true, autoClose: false }\n      );\n      const { data, error } = await System.dataConnectors.github",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 17,
        "end": 34,
        "startLoc": {
          "line": 17,
          "column": 1,
          "position": 217
        },
        "endLoc": {
          "line": 34,
          "column": 7,
          "position": 361
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 16,
        "end": 33,
        "startLoc": {
          "line": 16,
          "column": 2,
          "position": 216
        },
        "endLoc": {
          "line": 33,
          "column": 7,
          "position": 360
        }
      }
    },
    {
      "format": "jsx",
      "lines": 36,
      "fragment": ",\n      });\n\n      if (!!error) {\n        showToast(error, \"error\", { clear: true });\n        setLoading(false);\n        return;\n      }\n\n      showToast(\n        `${data.files} ${pluralize(\"file\", data.files)} collected from ${\n          data.author\n        }/${data.repo}:${data.branch}. Output folder is ${data.destination}.`,\n        \"success\",\n        { clear: true }\n      );\n      e.target.reset();\n      setLoading(false);\n      return;\n    } catch (e) {\n      console.error(e);\n      showToast(e.message, \"error\", { clear: true });\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pb-6 pb-16\">\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white text-sm font-bold\">\n                    {t(\"connectors.github.URL\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 38,
        "end": 73,
        "startLoc": {
          "line": 38,
          "column": 8,
          "position": 408
        },
        "endLoc": {
          "line": 73,
          "column": 24,
          "position": 710
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 22,
        "end": 55,
        "startLoc": {
          "line": 22,
          "column": 2,
          "position": 217
        },
        "endLoc": {
          "line": 55,
          "column": 25,
          "position": 496
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\"\n                  required={true}\n                  autoComplete=\"off\"\n                  onChange={(e) => setRepo(e.target.value)}\n                  onBlur={() => setSettings({ ...settings, repo })}\n                  spellCheck={false}\n                />\n              </div>\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white font-bold text-sm flex gap-x-2 items-center\">\n                    <p className=\"font-bold text-white\">\n                      {t(\"connectors.github.token\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 83,
        "end": 95,
        "startLoc": {
          "line": 83,
          "column": 46,
          "position": 774
        },
        "endLoc": {
          "line": 95,
          "column": 26,
          "position": 888
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 84,
        "end": 96,
        "startLoc": {
          "line": 84,
          "column": 37,
          "position": 797
        },
        "endLoc": {
          "line": 96,
          "column": 26,
          "position": 911
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n                repo={settings.repo}\n                accessToken={settings.accessToken}\n              />\n            </div>\n\n            <div className=\"flex flex-col w-full py-4 pr-10\">\n              <div className=\"flex flex-col gap-y-1 mb-4\">\n                <label className=\"text-white text-sm flex gap-x-2 items-center\">\n                  <p className=\"text-white text-sm font-bold\">\n                    {t(\"connectors.github.ignores\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 120,
        "end": 130,
        "startLoc": {
          "line": 120,
          "column": 22,
          "position": 1081
        },
        "endLoc": {
          "line": 130,
          "column": 28,
          "position": 1154
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 159,
        "end": 169,
        "startLoc": {
          "line": 159,
          "column": 22,
          "position": 1398
        },
        "endLoc": {
          "line": 169,
          "column": 28,
          "position": 1471
        }
      }
    },
    {
      "format": "jsx",
      "lines": 29,
      "fragment": ")}\n                </p>\n              </div>\n              <TagsInput\n                value={ignores}\n                onChange={setIgnores}\n                name=\"ignores\"\n                placeholder=\"!*.js, images/*, .DS_Store, bin/*\"\n                classNames={{\n                  tag: \"bg-theme-settings-input-bg light:bg-black/10 bg-blue-300/10 text-zinc-800\",\n                  input:\n                    \"flex p-1 !bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none\",\n                }}\n              />\n            </div>\n          </div>\n\n          <div className=\"flex flex-col gap-y-2 w-full pr-10\">\n            <PATAlert accessToken={accessToken} />\n            <button\n              type=\"submit\"\n              disabled={loading}\n              className=\"mt-2 w-full justify-center border-none px-4 py-2 rounded-lg text-dark-text light:text-white text-sm font-bold items-center flex gap-x-2 bg-theme-home-button-primary hover:bg-theme-home-button-primary-hover disabled:bg-theme-home-button-primary-hover disabled:cursor-not-allowed\"\n            >\n              {loading ? \"Collecting files...\" : \"Submit\"}\n            </button>\n            {loading && (\n              <p className=\"text-xs text-white/50\">\n                {t(\"connectors.github.task_explained\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 134,
        "end": 162,
        "startLoc": {
          "line": 134,
          "column": 31,
          "position": 1184
        },
        "endLoc": {
          "line": 162,
          "column": 35,
          "position": 1346
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 173,
        "end": 201,
        "startLoc": {
          "line": 173,
          "column": 31,
          "position": 1501
        },
        "endLoc": {
          "line": 201,
          "column": 35,
          "position": 1663
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "({ repo, accessToken }) {\n  const { t } = useTranslation();\n  const [allBranches, setAllBranches] = useState(DEFAULT_BRANCHES);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function fetchAllBranches() {\n      if (!repo) {\n        setAllBranches(DEFAULT_BRANCHES);\n        setLoading(false);\n        return;\n      }\n\n      setLoading(true);\n      const { branches } = await System.dataConnectors.github",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 172,
        "end": 186,
        "startLoc": {
          "line": 172,
          "column": 22,
          "position": 1389
        },
        "endLoc": {
          "line": 186,
          "column": 7,
          "position": 1532
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 211,
        "end": 225,
        "startLoc": {
          "line": 211,
          "column": 22,
          "position": 1706
        },
        "endLoc": {
          "line": 225,
          "column": 7,
          "position": 1849
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ".branches({\n        repo,\n        accessToken,\n      });\n      setAllBranches(branches.length > 0 ? branches : DEFAULT_BRANCHES);\n      setLoading(false);\n    }\n    fetchAllBranches();\n  }, [repo, accessToken]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <div className=\"flex flex-col gap-y-1 mb-4\">\n          <label className=\"text-white text-sm font-bold\">Branch",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 186,
        "end": 200,
        "startLoc": {
          "line": 186,
          "column": 7,
          "position": 1533
        },
        "endLoc": {
          "line": 200,
          "column": 7,
          "position": 1648
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 225,
        "end": 240,
        "startLoc": {
          "line": 225,
          "column": 7,
          "position": 1850
        },
        "endLoc": {
          "line": 240,
          "column": 1,
          "position": 1965
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": ")}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <div className=\"flex flex-col gap-y-1 mb-4\">\n        <label className=\"text-white text-sm font-bold\">Branch</label>\n        <p className=\"text-xs font-normal text-theme-text-secondary\">\n          {t(\"connectors.github.branch_explained\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 211,
        "end": 223,
        "startLoc": {
          "line": 211,
          "column": 35,
          "position": 1728
        },
        "endLoc": {
          "line": 223,
          "column": 37,
          "position": 1811
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 252,
        "end": 264,
        "startLoc": {
          "line": 252,
          "column": 35,
          "position": 2054
        },
        "endLoc": {
          "line": 264,
          "column": 37,
          "position": 2137
        }
      }
    },
    {
      "format": "jsx",
      "lines": 37,
      "fragment": ")}\n        </p>\n      </div>\n      <select\n        name=\"branch\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white focus:outline-primary-button active:outline-primary-button outline-none text-sm rounded-lg block w-full p-2.5\"\n      >\n        {allBranches.map((branch) => {\n          return (\n            <option key={branch} value={branch}>\n              {branch}\n            </option>\n          );\n        })}\n      </select>\n    </div>\n  );\n}\n\nfunction PATAlert({ accessToken }) {\n  const { t } = useTranslation();\n  if (!!accessToken) return null;\n  return (\n    <div className=\"flex flex-col md:flex-row md:items-center gap-x-2 text-white mb-4 bg-blue-800/30 w-fit rounded-lg px-4 py-2\">\n      <div className=\"gap-x-2 flex items-center\">\n        <Info className=\"shrink-0\" size={25} />\n        <p className=\"text-sm\">\n          <span\n            dangerouslySetInnerHTML={{\n              __html: t(\"connectors.github.token_information\"),\n            }}\n          />\n          <br />\n          <br />\n          <a\n            href=\"https://github.com/settings/personal-access-tokens/new",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 223,
        "end": 259,
        "startLoc": {
          "line": 223,
          "column": 37,
          "position": 1812
        },
        "endLoc": {
          "line": 259,
          "column": 55,
          "position": 2061
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 264,
        "end": 300,
        "startLoc": {
          "line": 264,
          "column": 37,
          "position": 2138
        },
        "endLoc": {
          "line": 300,
          "column": 58,
          "position": 2387
        }
      }
    },
    {
      "format": "jsx",
      "lines": 29,
      "fragment": ")}\n          </a>\n        </p>\n      </div>\n    </div>\n  );\n}\n\nfunction PATTooltip({ accessToken }) {\n  const { t } = useTranslation();\n  if (!!accessToken) return null;\n  return (\n    <>\n      {!accessToken && (\n        <Warning\n          size={14}\n          className=\"ml-1 text-orange-500 cursor-pointer\"\n          data-tooltip-id=\"access-token-tooltip\"\n          data-tooltip-place=\"right\"\n        />\n      )}\n      <Tooltip\n        delayHide={300}\n        id=\"access-token-tooltip\"\n        className=\"max-w-xs z-99\"\n        clickable={true}\n      >\n        <p className=\"text-sm\">\n          {t(\"connectors.github.token_explained_start\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Github/index.jsx",
        "start": 266,
        "end": 294,
        "startLoc": {
          "line": 266,
          "column": 35,
          "position": 2109
        },
        "endLoc": {
          "line": 294,
          "column": 42,
          "position": 2279
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Gitlab/index.jsx",
        "start": 306,
        "end": 334,
        "startLoc": {
          "line": 306,
          "column": 35,
          "position": 2430
        },
        "endLoc": {
          "line": 334,
          "column": 42,
          "position": 2600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n  const [loading, setLoading] = useState(false);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = new FormData(e.target);\n\n    try {\n      setLoading(true);\n      showToast(\n        \"Fetching all pages for the given Drupal Wiki spaces - this may take a while.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx",
        "start": 14,
        "end": 24,
        "startLoc": {
          "line": 14,
          "column": 2,
          "position": 72
        },
        "endLoc": {
          "line": 24,
          "column": 79,
          "position": 152
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 7,
        "end": 29,
        "startLoc": {
          "line": 7,
          "column": 2,
          "position": 75
        },
        "endLoc": {
          "line": 29,
          "column": 55,
          "position": 313
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "),\n      });\n\n      if (!!error) {\n        showToast(error, \"error\", { clear: true });\n        setLoading(false);\n        return;\n      }\n\n      showToast(\n        `Pages collected from Drupal Wiki spaces ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx",
        "start": 34,
        "end": 44,
        "startLoc": {
          "line": 34,
          "column": 14,
          "position": 242
        },
        "endLoc": {
          "line": 44,
          "column": 42,
          "position": 302
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 6,
          "position": 216
        },
        "endLoc": {
          "line": 32,
          "column": 2,
          "position": 276
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": ",\n        \"success\",\n        { clear: true }\n      );\n      e.target.reset();\n      setLoading(false);\n    } catch (e) {\n      console.error(e);\n      showToast(e.message, \"error\", { clear: true });\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pb-6 pb-16\">\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white text-sm font-bold flex gap-x-2 items-center",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx",
        "start": 44,
        "end": 65,
        "startLoc": {
          "line": 44,
          "column": 3,
          "position": 315
        },
        "endLoc": {
          "line": 65,
          "column": 55,
          "position": 504
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/WebsiteDepth/index.jsx",
        "start": 38,
        "end": 54,
        "startLoc": {
          "line": 38,
          "column": 3,
          "position": 334
        },
        "endLoc": {
          "line": 54,
          "column": 29,
          "position": 488
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\"\n                  required={true}\n                  autoComplete=\"off\"\n                  spellCheck={false}\n                />\n              </div>\n            </div>\n          </div>\n\n          <div className=\"flex flex-col gap-y-2 w-full pr-10\">\n            <button\n              type=\"submit\"\n              disabled={loading}\n              className=\"mt-2 w-full justify-center border-none px-4 py-2 rounded-lg text-dark-text light:text-white text-sm font-bold items-center flex gap-x-2 bg-theme-home-button-primary hover:bg-theme-home-button-primary-hover disabled:bg-theme-home-button-primary-hover disabled:cursor-not-allowed\"\n            >\n              {loading ? \"Collecting pages...\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx",
        "start": 162,
        "end": 177,
        "startLoc": {
          "line": 162,
          "column": 8,
          "position": 1196
        },
        "endLoc": {
          "line": 177,
          "column": 22,
          "position": 1275
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 75,
        "end": 90,
        "startLoc": {
          "line": 75,
          "column": 35,
          "position": 626
        },
        "endLoc": {
          "line": 90,
          "column": 27,
          "position": 705
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "),\n      });\n\n      if (!!error) {\n        showToast(error, \"error\", { clear: true });\n        setLoading(false);\n        return;\n      }\n\n      showToast(\n        `Pages collected from Confluence space ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Confluence/index.jsx",
        "start": 33,
        "end": 43,
        "startLoc": {
          "line": 33,
          "column": 22,
          "position": 326
        },
        "endLoc": {
          "line": 43,
          "column": 40,
          "position": 386
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Youtube/index.jsx",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 6,
          "position": 216
        },
        "endLoc": {
          "line": 32,
          "column": 2,
          "position": 276
        }
      }
    },
    {
      "format": "jsx",
      "lines": 23,
      "fragment": "}. Output folder is ${data.destination}.`,\n        \"success\",\n        { clear: true }\n      );\n      e.target.reset();\n      setLoading(false);\n    } catch (e) {\n      console.error(e);\n      showToast(e.message, \"error\", { clear: true });\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pb-6 pb-16\">\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"w-full flex flex-col py-2\">\n            <div className=\"w-full flex flex-col gap-4\">\n              <div className=\"flex flex-col pr-10\">\n                <div className=\"flex flex-col gap-y-1 mb-4\">\n                  <label className=\"text-white text-sm font-bold flex gap-x-2 items-center\">\n                    <p className=\"font-bold text-theme-text-primary",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Confluence/index.jsx",
        "start": 43,
        "end": 65,
        "startLoc": {
          "line": 43,
          "column": 9,
          "position": 391
        },
        "endLoc": {
          "line": 65,
          "column": 34,
          "position": 599
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx",
        "start": 44,
        "end": 66,
        "startLoc": {
          "line": 44,
          "column": 9,
          "position": 307
        },
        "endLoc": {
          "line": 66,
          "column": 21,
          "position": 515
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </div>\n          </div>\n\n          <div className=\"flex flex-col gap-y-2 w-full pr-10\">\n            <button\n              type=\"submit\"\n              disabled={loading}\n              className=\"mt-2 w-full justify-center border-none px-4 py-2 rounded-lg text-dark-text light:text-white text-sm font-bold items-center flex gap-x-2 bg-theme-home-button-primary hover:bg-theme-home-button-primary-hover disabled:bg-theme-home-button-primary-hover disabled:cursor-not-allowed\"\n            >\n              {loading ? \"Collecting pages...\" : \"Submit\"}\n            </button>\n            {loading && (\n              <p className=\"text-xs text-theme-text-secondary\">\n                {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/Confluence/index.jsx",
        "start": 249,
        "end": 263,
        "startLoc": {
          "line": 249,
          "column": 2,
          "position": 1839
        },
        "endLoc": {
          "line": 263,
          "column": 2,
          "position": 1924
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/DataConnectors/Connectors/DrupalWiki/index.jsx",
        "start": 167,
        "end": 181,
        "startLoc": {
          "line": 167,
          "column": 2,
          "position": 1222
        },
        "endLoc": {
          "line": 181,
          "column": 5,
          "position": 1307
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ") return null;\n\n  async function handleUpdate(e) {\n    e.preventDefault();\n    e.stopPropagation();\n    const data = {};\n    const form = new FormData(e.target);\n    for (var [key, value] of form.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    if (error) {\n      showToast(`Failed to save ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 113,
        "end": 123,
        "startLoc": {
          "line": 113,
          "column": 10,
          "position": 802
        },
        "endLoc": {
          "line": 123,
          "column": 17,
          "position": 931
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx",
        "start": 15,
        "end": 26,
        "startLoc": {
          "line": 15,
          "column": 7,
          "position": 108
        },
        "endLoc": {
          "line": 26,
          "column": 1,
          "position": 237
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ".name} Settings\n              </h3>\n            </div>\n            <button\n              onClick={closeModal}\n              type=\"button\"\n              className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n            >\n              <X size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          </div>\n          <form id=\"provider-form\" onSubmit={handleUpdate}>\n            <div className=\"px-7 py-6\">\n              <div className=\"space-y-6 max-h-[60vh] overflow-y-auto p-1\">\n                <p className=\"text-sm text-white/60\">\n                  To use {LLMOption",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 141,
        "end": 156,
        "startLoc": {
          "line": 141,
          "column": 10,
          "position": 1059
        },
        "endLoc": {
          "line": 156,
          "column": 10,
          "position": 1189
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx",
        "start": 44,
        "end": 59,
        "startLoc": {
          "line": 44,
          "column": 12,
          "position": 364
        },
        "endLoc": {
          "line": 59,
          "column": 12,
          "position": 494
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": ".options(settings, { credentialsOnly: true })}\n                </div>\n              </div>\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border px-7 pb-6\">\n              <button\n                type=\"button\"\n                onClick={closeModal}\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                form=\"provider-form\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Save settings\n              </button>\n            </div>\n          </form>\n        </div>\n      </div>\n    </ModalWrapper>,\n    document.getElementById",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 160,
        "end": 184,
        "startLoc": {
          "line": 160,
          "column": 10,
          "position": 1231
        },
        "endLoc": {
          "line": 184,
          "column": 15,
          "position": 1369
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx",
        "start": 63,
        "end": 87,
        "startLoc": {
          "line": 63,
          "column": 12,
          "position": 536
        },
        "endLoc": {
          "line": 87,
          "column": 5,
          "position": 674
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ",\n}) {\n  const { defaultModels, customModels, loading } =\n    useGetProviderModels(provider);\n  const { t } = useTranslation();\n  if (DISABLED_PROVIDERS.includes(provider)) return null;\n\n  if (loading) {\n    return (\n      <div>\n        <div className=\"flex flex-col mt-6",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx",
        "start": 9,
        "end": 19,
        "startLoc": {
          "line": 9,
          "column": 14,
          "position": 52
        },
        "endLoc": {
          "line": 19,
          "column": 19,
          "position": 143
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 10,
        "end": 20,
        "startLoc": {
          "line": 10,
          "column": 20,
          "position": 56
        },
        "endLoc": {
          "line": 20,
          "column": 14,
          "position": 147
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\"\n        >\n          <option disabled={true} selected={true}>\n            -- waiting for models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div>\n      <div className=\"flex flex-col mt-6",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx",
        "start": 31,
        "end": 43,
        "startLoc": {
          "line": 31,
          "column": 210,
          "position": 232
        },
        "endLoc": {
          "line": 43,
          "column": 19,
          "position": 304
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 35,
        "end": 47,
        "startLoc": {
          "line": 35,
          "column": 244,
          "position": 244
        },
        "endLoc": {
          "line": 47,
          "column": 14,
          "position": 316
        }
      }
    },
    {
      "format": "jsx",
      "lines": 56,
      "fragment": "\"\n      >\n        {defaultModels.length > 0 && (\n          <optgroup label=\"General models\">\n            {defaultModels.map((model) => {\n              return (\n                <option\n                  key={model}\n                  value={model}\n                  selected={workspace?.chatModel === model}\n                >\n                  {model}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n        {Array.isArray(customModels) && customModels.length > 0 && (\n          <optgroup label=\"Discovered models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={workspace?.chatModel === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n        {/* For providers like TogetherAi where we partition model by creator entity. */}\n        {!Array.isArray(customModels) &&\n          Object.keys(customModels).length > 0 && (\n            <>\n              {Object.entries(customModels).map(([organization, models]) => (\n                <optgroup key={organization} label={organization}>\n                  {models.map((model) => (\n                    <option\n                      key={model.id}\n                      value={model.id}\n                      selected={workspace?.chatModel === model.id}\n                    >\n                      {model.name}\n                    </option>\n                  ))}\n                </optgroup>\n              ))}\n            </>\n          )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx",
        "start": 58,
        "end": 113,
        "startLoc": {
          "line": 58,
          "column": 160,
          "position": 407
        },
        "endLoc": {
          "line": 113,
          "column": 1,
          "position": 810
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 66,
        "end": 121,
        "startLoc": {
          "line": 66,
          "column": 194,
          "position": 446
        },
        "endLoc": {
          "line": 121,
          "column": 1,
          "position": 840
        }
      }
    },
    {
      "format": "javascript",
      "lines": 31,
      "fragment": "={handleProviderSelection}\n        className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n          checked ? \"bg-theme-bg-secondary\" : \"\"\n        }`}\n      >\n        <input\n          type=\"checkbox\"\n          value={value}\n          className=\"peer hidden\"\n          checked={checked}\n          readOnly={true}\n          formNoValidate={true}\n        />\n        <div className=\"flex gap-x-4 items-center justify-between\">\n          <div className=\"flex gap-x-4 items-center\">\n            <img\n              src={logo}\n              alt={`${name} logo`}\n              className=\"w-10 h-10 rounded-md\"\n            />\n            <div className=\"flex flex-col\">\n              <div className=\"text-sm font-semibold text-white\">{name}</div>\n              <div className=\"mt-1 text-xs text-white/60\">{description}</div>\n            </div>\n          </div>\n          {checked &&\n            value !== \"none\" &&\n            !NO_SETTINGS_NEEDED.includes(value) && (\n              <button\n                onClick={(e) => {\n                  e",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx",
        "start": 52,
        "end": 82,
        "startLoc": {
          "line": 52,
          "column": 8,
          "position": 400
        },
        "endLoc": {
          "line": 82,
          "column": 20,
          "position": 614
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 52,
        "end": 80,
        "startLoc": {
          "line": 52,
          "column": 8,
          "position": 397
        },
        "endLoc": {
          "line": 80,
          "column": 18,
          "position": 601
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "// This component differs from the main LLMItem in that it shows if a provider is\n// \"ready for use\" and if not - will then highjack the click handler to show a modal\n// of the provider options that must be saved to continue.\nimport { createPortal } from \"react-dom\";\nimport ModalWrapper from \"@/components/ModalWrapper\";\nimport { useModal } from \"@/hooks/useModal\";\nimport { X, Gear } from \"@phosphor-icons/react\";\nimport System from \"@/models/system\";\nimport showToast from \"@/utils/toast\";\nimport { useEffect, useState } from \"react\";\n\nconst NO_SETTINGS_NEEDED = [\"default\",",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx",
        "start": 1,
        "end": 12,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 12,
          "column": 2,
          "position": 100
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 1,
        "end": 12,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 12,
          "column": 2,
          "position": 100
        }
      }
    },
    {
      "format": "jsx",
      "lines": 66,
      "fragment": "({\n  llm,\n  availableLLMs,\n  settings,\n  checked,\n  onClick,\n}) {\n  const { isOpen, openModal, closeModal } = useModal();\n  const { name, value, logo, description } = llm;\n  const [currentSettings, setCurrentSettings] = useState(settings);\n\n  useEffect(() => {\n    async function getSettings() {\n      if (isOpen) {\n        const _settings = await System.keys();\n        setCurrentSettings(_settings ?? {});\n      }\n    }\n    getSettings();\n  }, [isOpen]);\n\n  function handleProviderSelection() {\n    // Determine if provider needs additional setup because its minimum required keys are\n    // not yet set in settings.\n    if (!checked) {\n      const requiresAdditionalSetup = (llm.requiredConfig || []).some(\n        (key) => !currentSettings[key]\n      );\n      if (requiresAdditionalSetup) {\n        openModal();\n        return;\n      }\n      onClick(value);\n    }\n  }\n\n  return (\n    <>\n      <div\n        onClick={handleProviderSelection}\n        className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n          checked ? \"bg-theme-bg-secondary\" : \"\"\n        }`}\n      >\n        <input\n          type=\"checkbox\"\n          value={value}\n          className=\"peer hidden\"\n          checked={checked}\n          readOnly={true}\n          formNoValidate={true}\n        />\n        <div className=\"flex gap-x-4 items-center justify-between\">\n          <div className=\"flex gap-x-4 items-center\">\n            <img\n              src={logo}\n              alt={`${name} logo`}\n              className=\"w-10 h-10 rounded-md\"\n            />\n            <div className=\"flex flex-col\">\n              <div className=\"text-sm font-semibold text-white\">{name}</div>\n              <div className=\"mt-1 text-xs text-white/60\">{description}</div>\n            </div>\n          </div>\n          {checked &&\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx",
        "start": 13,
        "end": 78,
        "startLoc": {
          "line": 13,
          "column": 13,
          "position": 113
        },
        "endLoc": {
          "line": 78,
          "column": 1,
          "position": 577
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 13,
        "end": 77,
        "startLoc": {
          "line": 13,
          "column": 13,
          "position": 110
        },
        "endLoc": {
          "line": 77,
          "column": 2,
          "position": 574
        }
      }
    },
    {
      "format": "jsx",
      "lines": 69,
      "fragment": ")}\n        </div>\n      </div>\n      <SetupProvider\n        availableLLMs={availableLLMs}\n        isOpen={isOpen}\n        provider={value}\n        closeModal={closeModal}\n        postSubmit={onClick}\n        settings={currentSettings}\n      />\n    </>\n  );\n}\n\nfunction SetupProvider({\n  availableLLMs,\n  isOpen,\n  provider,\n  closeModal,\n  postSubmit,\n  settings,\n}) {\n  if (!isOpen) return null;\n  const LLMOption = availableLLMs.find((llm) => llm.value === provider);\n  if (!LLMOption) return null;\n\n  async function handleUpdate(e) {\n    e.preventDefault();\n    e.stopPropagation();\n    const data = {};\n    const form = new FormData(e.target);\n    for (var [key, value] of form.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    if (error) {\n      showToast(`Failed to save ${LLMOption.name} settings: ${error}`, \"error\");\n      return;\n    }\n\n    closeModal();\n    postSubmit();\n    return false;\n  }\n\n  // Cannot do nested forms, it will cause all sorts of issues, so we portal this out\n  // to the parent container form so we don't have nested forms.\n  return createPortal(\n    <ModalWrapper isOpen={isOpen}>\n      <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n        <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n          <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n            <div className=\"w-full flex gap-x-2 items-center\">\n              <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n                {LLMOption.name} Settings\n              </h3>\n            </div>\n            <button\n              onClick={closeModal}\n              type=\"button\"\n              className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n            >\n              <X size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          </div>\n          <form id=\"provider-form\" onSubmit={handleUpdate}>\n            <div className=\"px-7 py-6\">\n              <div className=\"space-y-6 max-h-[60vh] overflow-y-auto p-1\">\n                <p className=\"text-sm text-white/60\">\n                  To use {LLMOption.name} as this workspace's agent",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx",
        "start": 90,
        "end": 158,
        "startLoc": {
          "line": 90,
          "column": 13,
          "position": 667
        },
        "endLoc": {
          "line": 158,
          "column": 6,
          "position": 1213
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 88,
        "end": 156,
        "startLoc": {
          "line": 88,
          "column": 11,
          "position": 654
        },
        "endLoc": {
          "line": 156,
          "column": 4,
          "position": 1200
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": "set it up first.\n                </p>\n                <div>\n                  {LLMOption.options(settings, { credentialsOnly: true })}\n                </div>\n              </div>\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border px-7 pb-6\">\n              <button\n                type=\"button\"\n                onClick={closeModal}\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                form=\"provider-form\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Save {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/AgentLLMItem/index.jsx",
        "start": 159,
        "end": 179,
        "startLoc": {
          "line": 159,
          "column": 2,
          "position": 1224
        },
        "endLoc": {
          "line": 179,
          "column": 2,
          "position": 1348
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 157,
        "end": 80,
        "startLoc": {
          "line": 157,
          "column": 19,
          "position": 1209
        },
        "endLoc": {
          "line": 80,
          "column": 9,
          "position": 638
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\"\n            value=\"yes\"\n            checked={showScrollbar}\n            onChange={handleChange}\n            disabled={saving}\n            className=\"peer sr-only\"\n          />\n          <div className=\"pointer-events-none peer h-6 w-11 rounded-full bg-[#CFCFD0] after:absolute after:left-[2px] after:top-[2px] after:h-5 after:w-5 after:rounded-full after:shadow-xl after:border-none after:bg-white after:box-shadow-md after:transition-all after:content-[''] peer-checked:bg-[#32D583] peer-checked:after:translate-x-full peer-checked:after:border-white peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-transparent\"></div>\n        </label>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/ShowScrollbar/index.jsx",
        "start": 44,
        "end": 57,
        "startLoc": {
          "line": 44,
          "column": 15,
          "position": 386
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 457
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/SpellCheck/index.jsx",
        "start": 38,
        "end": 51,
        "startLoc": {
          "line": 38,
          "column": 11,
          "position": 330
        },
        "endLoc": {
          "line": 51,
          "column": 1,
          "position": 401
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": " !== \"\" && (\n          <button\n            type=\"button\"\n            onClick={(e) => updateCustomAppName(e, \"\")}\n            className=\"text-white text-base font-medium hover:text-opacity-60\"\n          >\n            Clear\n          </button>\n        )}\n      </div>\n      {hasChanges && (\n        <button\n          type=\"submit\"\n          className=\"transition-all mt-2 w-fit duration-300 border border-slate-200 px-5 py-2.5 rounded-lg text-white text-sm items-center flex gap-x-2 hover:bg-slate-200 hover:text-slate-800 focus:ring-gray-800\"\n        >\n          Save\n        </button>\n      )}\n    </form>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/CustomAppName/index.jsx",
        "start": 83,
        "end": 104,
        "startLoc": {
          "line": 83,
          "column": 16,
          "position": 735
        },
        "endLoc": {
          "line": 104,
          "column": 1,
          "position": 845
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/SupportEmail/index.jsx",
        "start": 78,
        "end": 99,
        "startLoc": {
          "line": 78,
          "column": 14,
          "position": 685
        },
        "endLoc": {
          "line": 99,
          "column": 1,
          "position": 795
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\"\n            value=\"yes\"\n            checked={autoSubmitSttInput}\n            onChange={handleChange}\n            disabled={saving}\n            className=\"peer sr-only\"\n          />\n          <div className=\"pointer-events-none peer h-6 w-11 rounded-full bg-[#CFCFD0] after:absolute after:left-[2px] after:top-[2px] after:h-5 after:w-5 after:rounded-full after:shadow-xl after:border-none after:bg-white after:box-shadow-md after:transition-all after:content-[''] peer-checked:bg-[#32D583] peer-checked:after:translate-x-full peer-checked:after:border-white peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-transparent\"></div>\n        </label>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/AutoSubmit/index.jsx",
        "start": 44,
        "end": 57,
        "startLoc": {
          "line": 44,
          "column": 12,
          "position": 391
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 462
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/SpellCheck/index.jsx",
        "start": 38,
        "end": 51,
        "startLoc": {
          "line": 38,
          "column": 11,
          "position": 330
        },
        "endLoc": {
          "line": 51,
          "column": 1,
          "position": 401
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\"\n            value=\"yes\"\n            checked={autoPlayAssistantTtsResponse}\n            onChange={handleChange}\n            disabled={saving}\n            className=\"peer sr-only\"\n          />\n          <div className=\"pointer-events-none peer h-6 w-11 rounded-full bg-[#CFCFD0] after:absolute after:left-[2px] after:top-[2px] after:h-5 after:w-5 after:rounded-full after:shadow-xl after:border-none after:bg-white after:box-shadow-md after:transition-all after:content-[''] peer-checked:bg-[#32D583] peer-checked:after:translate-x-full peer-checked:after:border-white peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-transparent\"></div>\n        </label>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/AutoSpeak/index.jsx",
        "start": 47,
        "end": 60,
        "startLoc": {
          "line": 47,
          "column": 11,
          "position": 396
        },
        "endLoc": {
          "line": 60,
          "column": 1,
          "position": 467
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/SpellCheck/index.jsx",
        "start": 38,
        "end": 51,
        "startLoc": {
          "line": 38,
          "column": 11,
          "position": 330
        },
        "endLoc": {
          "line": 51,
          "column": 1,
          "position": 401
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": ">\n      <div className=\"rounded-lg w-full\">\n        <div className=\"flex justify-between items-center\">\n          <Skeleton.default\n            height=\"40px\"\n            width=\"300px\"\n            highlightColor=\"var(--theme-settings-input-active)\"\n            baseColor=\"var(--theme-settings-input-bg)\"\n            count={1}\n          />\n        </div>\n        <Skeleton.default\n          height=\"200px\"\n          width=\"300px\"\n          highlightColor=\"var(--theme-settings-input-active)\"\n          baseColor=\"var(--theme-settings-input-bg)\"\n          count={4}\n          className=\"rounded-lg\"\n          containerClassName=\"flex flex-wrap gap-2 mt-1\"\n        />\n      </div>\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/index.jsx",
        "start": 112,
        "end": 133,
        "startLoc": {
          "line": 112,
          "column": 4,
          "position": 989
        },
        "endLoc": {
          "line": 133,
          "column": 5,
          "position": 1107
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/HubItems/index.jsx",
        "start": 92,
        "end": 113,
        "startLoc": {
          "line": 92,
          "column": 2,
          "position": 873
        },
        "endLoc": {
          "line": 113,
          "column": 7,
          "position": 991
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n    setError(error);\n  };\n\n  return (\n    <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n      <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n        <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n          <div className=\"w-full flex gap-x-2 items-center\">\n            <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n              Create new",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 35,
        "end": 45,
        "startLoc": {
          "line": 35,
          "column": 2,
          "position": 407
        },
        "endLoc": {
          "line": 45,
          "column": 4,
          "position": 483
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 28,
        "end": 37,
        "startLoc": {
          "line": 28,
          "column": 2,
          "position": 272
        },
        "endLoc": {
          "line": 37,
          "column": 4,
          "position": 337
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"px-7 py-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-6 max-h-[60vh] overflow-y-auto pr-2\">\n              <WorkspaceSelection />",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 45,
        "end": 59,
        "startLoc": {
          "line": 45,
          "column": 10,
          "position": 490
        },
        "endLoc": {
          "line": 59,
          "column": 3,
          "position": 596
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 52,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 52,
          "column": 13,
          "position": 462
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\">\n                  &lt;script&gt;\n                </code>{\" \"}\n                tag.\n              </p>\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Create embed",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 92,
        "end": 110,
        "startLoc": {
          "line": 92,
          "column": 64,
          "position": 818
        },
        "endLoc": {
          "line": 110,
          "column": 6,
          "position": 912
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 96,
        "end": 83,
        "startLoc": {
          "line": 96,
          "column": 71,
          "position": 766
        },
        "endLoc": {
          "line": 83,
          "column": 7,
          "position": 642
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": ">\n        <label\n          className={`transition-all duration-300 w-full h-11 p-2.5 rounded-lg flex justify-start items-center gap-2.5 cursor-pointer border ${\n            chatMode === \"query\"\n              ? \"border-theme-sidebar-item-workspace-active bg-theme-bg-secondary\"\n              : \"border-theme-sidebar-border hover:border-theme-sidebar-border hover:bg-theme-bg-secondary\"\n          } `}\n        >\n          <input\n            type=\"radio\"\n            name=\"chat_mode\"\n            value={\"query\"}\n            checked={chatMode === \"query\"}\n            onChange={(e) => setChatMode(e.target.value)}\n            className=\"hidden\"\n          />\n          <div\n            className={`w-4 h-4 rounded-full border-2 border-theme-sidebar-border mr-2 ${\n              chatMode === \"query\"\n                ? \"bg-[var(--theme-sidebar-item-workspace-active)]\"\n                : \"\"\n            }`}\n          ></div>\n          <div className=\"text-theme-text-primary text-sm font-medium font-['Plus Jakarta Sans'] leading-tight\">\n            Query",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 211,
        "end": 235,
        "startLoc": {
          "line": 211,
          "column": 6,
          "position": 1663
        },
        "endLoc": {
          "line": 235,
          "column": 6,
          "position": 1798
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 185,
        "end": 209,
        "startLoc": {
          "line": 185,
          "column": 2,
          "position": 1503
        },
        "endLoc": {
          "line": 209,
          "column": 5,
          "position": 1638
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ");\n    }\n    setError(error);\n  };\n\n  return (\n    <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n      <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n        <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n          <div className=\"w-full flex gap-x-2 items-center\">\n            <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n              Edit",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 40,
        "end": 51,
        "startLoc": {
          "line": 40,
          "column": 2,
          "position": 464
        },
        "endLoc": {
          "line": 51,
          "column": 5,
          "position": 543
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 27,
        "end": 38,
        "startLoc": {
          "line": 27,
          "column": 4,
          "position": 267
        },
        "endLoc": {
          "line": 38,
          "column": 7,
          "position": 346
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "}\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6\">\n          <form onSubmit={handleUpdate}>\n            <div className=\"space-y-4\">\n              <div>\n                <label\n                  htmlFor=\"username",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 51,
        "end": 67,
        "startLoc": {
          "line": 51,
          "column": 9,
          "position": 549
        },
        "endLoc": {
          "line": 67,
          "column": 9,
          "position": 664
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 53,
        "startLoc": {
          "line": 38,
          "column": 3,
          "position": 355
        },
        "endLoc": {
          "line": 53,
          "column": 11,
          "position": 454
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n              {error && <p className=\"text-red-400 text-sm\">Error: {error}</p>}\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Update user",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 149,
        "end": 164,
        "startLoc": {
          "line": 149,
          "column": 3,
          "position": 1198
        },
        "endLoc": {
          "line": 164,
          "column": 5,
          "position": 1294
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx",
        "start": 68,
        "end": 114,
        "startLoc": {
          "line": 68,
          "column": 2,
          "position": 546
        },
        "endLoc": {
          "line": 114,
          "column": 6,
          "position": 860
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n    }\n  };\n\n  return (\n    <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n      <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n        <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n          <div className=\"w-full flex gap-x-2 items-center\">\n            <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n              Edit {variable",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 30,
        "end": 40,
        "startLoc": {
          "line": 30,
          "column": 2,
          "position": 325
        },
        "endLoc": {
          "line": 40,
          "column": 9,
          "position": 398
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx",
        "start": 27,
        "end": 51,
        "startLoc": {
          "line": 27,
          "column": 2,
          "position": 265
        },
        "endLoc": {
          "line": 51,
          "column": 5,
          "position": 546
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "}\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6\">\n          <form onSubmit={handleUpdate}>\n            <div className=\"space-y-4\">\n              <div>\n                <label\n                  htmlFor=\"key",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 40,
        "end": 56,
        "startLoc": {
          "line": 40,
          "column": 4,
          "position": 401
        },
        "endLoc": {
          "line": 56,
          "column": 4,
          "position": 516
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 53,
        "startLoc": {
          "line": 38,
          "column": 3,
          "position": 355
        },
        "endLoc": {
          "line": 53,
          "column": 11,
          "position": 454
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\n                />\n              </div>\n              {error && <p className=\"text-red-400 text-sm\">Error: {error}</p>}\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Update variable",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 108,
        "end": 125,
        "startLoc": {
          "line": 108,
          "column": 2,
          "position": 827
        },
        "endLoc": {
          "line": 125,
          "column": 9,
          "position": 930
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/Directory/NewFolderModal/index.jsx",
        "start": 66,
        "end": 114,
        "startLoc": {
          "line": 66,
          "column": 2,
          "position": 539
        },
        "endLoc": {
          "line": 114,
          "column": 6,
          "position": 860
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ".\n        </a>\n      </p>\n      <div className=\"flex gap-x-4\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"env::AgentSerperApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 141,
        "end": 151,
        "startLoc": {
          "line": 141,
          "column": 4,
          "position": 1030
        },
        "endLoc": {
          "line": 151,
          "column": 23,
          "position": 1098
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 79,
        "end": 89,
        "startLoc": {
          "line": 79,
          "column": 10,
          "position": 661
        },
        "endLoc": {
          "line": 89,
          "column": 23,
          "position": 729
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ".\n        </a>\n      </p>\n      <div className=\"flex gap-x-4\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"env::AgentBingSearchApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 176,
        "end": 186,
        "startLoc": {
          "line": 176,
          "column": 7,
          "position": 1273
        },
        "endLoc": {
          "line": 186,
          "column": 27,
          "position": 1341
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 79,
        "end": 89,
        "startLoc": {
          "line": 79,
          "column": 10,
          "position": 661
        },
        "endLoc": {
          "line": 89,
          "column": 23,
          "position": 729
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ".\n        </a>\n      </p>\n      <div className=\"flex gap-x-4\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"env::AgentSerplyApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 240,
        "end": 250,
        "startLoc": {
          "line": 240,
          "column": 3,
          "position": 1784
        },
        "endLoc": {
          "line": 250,
          "column": 23,
          "position": 1852
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 79,
        "end": 89,
        "startLoc": {
          "line": 79,
          "column": 10,
          "position": 661
        },
        "endLoc": {
          "line": 89,
          "column": 23,
          "position": 729
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ".\n        </a>\n      </p>\n      <div className=\"flex gap-x-4\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"env::AgentTavilyApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 297,
        "end": 307,
        "startLoc": {
          "line": 297,
          "column": 7,
          "position": 2156
        },
        "endLoc": {
          "line": 307,
          "column": 23,
          "position": 2224
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderOptions/index.jsx",
        "start": 79,
        "end": 89,
        "startLoc": {
          "line": 79,
          "column": 10,
          "position": 661
        },
        "endLoc": {
          "line": 89,
          "column": 23,
          "position": 729
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n\n  useEffect(() => {\n    const handleClickOutside = (event) => {\n      if (menuRef.current && !menuRef.current.contains(event.target)) {\n        setOpen(false);\n      }\n    };\n\n    document.addEventListener(\"mousedown\", handleClickOutside);\n    return () => {\n      document.removeEventListener(\"mousedown\", handleClickOutside);\n    };\n  }, []);\n\n  if (!config",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx",
        "start": 213,
        "end": 228,
        "startLoc": {
          "line": 213,
          "column": 2,
          "position": 1713
        },
        "endLoc": {
          "line": 228,
          "column": 7,
          "position": 1833
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/ActionMenu/index.jsx",
        "start": 22,
        "end": 37,
        "startLoc": {
          "line": 22,
          "column": 2,
          "position": 234
        },
        "endLoc": {
          "line": 37,
          "column": 7,
          "position": 354
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n      <div>\n        <label className=\"block text-sm font-medium text-theme-text-primary mb-2\">\n          Result Variable\n        </label>\n        {renderVariableSelect(\n          config.resultVariable,\n          (value) => onConfigChange({ ...config, resultVariable: value }),\n          \"Select or create variable\",\n          true\n        )}\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/nodes/LLMInstructionNode/index.jsx",
        "start": 27,
        "end": 42,
        "startLoc": {
          "line": 27,
          "column": 1,
          "position": 148
        },
        "endLoc": {
          "line": 42,
          "column": 1,
          "position": 236
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/nodes/WebScrapingNode/index.jsx",
        "start": 103,
        "end": 118,
        "startLoc": {
          "line": 103,
          "column": 2,
          "position": 705
        },
        "endLoc": {
          "line": 118,
          "column": 1,
          "position": 793
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n      <div>\n        <label className=\"block text-sm font-medium text-white mb-2\">\n          Store Result In\n        </label>\n        {renderVariableSelect(\n          config.resultVariable,\n          (value) => onConfigChange({ resultVariable: value }),\n          \"Select or create variable\"\n        )}\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/nodes/FileNode/index.jsx",
        "start": 59,
        "end": 73,
        "startLoc": {
          "line": 59,
          "column": 2,
          "position": 424
        },
        "endLoc": {
          "line": 73,
          "column": 1,
          "position": 506
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/nodes/WebsiteNode/index.jsx",
        "start": 55,
        "end": 69,
        "startLoc": {
          "line": 55,
          "column": 2,
          "position": 400
        },
        "endLoc": {
          "line": 69,
          "column": 1,
          "position": 482
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\n          autoComplete=\"off\"\n          spellCheck={false}\n        />\n      </div>\n      <div>\n        <label className=\"block text-sm font-medium text-white mb-2\">\n          Store Result In\n        </label>\n        {renderVariableSelect(\n          config.resultVariable,\n          (value) => onConfigChange({ resultVariable: value }),\n          \"Select or create variable\"\n        )}\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/nodes/CodeNode/index.jsx",
        "start": 39,
        "end": 57,
        "startLoc": {
          "line": 39,
          "column": 2,
          "position": 281
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 382
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/nodes/WebsiteNode/index.jsx",
        "start": 51,
        "end": 69,
        "startLoc": {
          "line": 51,
          "column": 2,
          "position": 381
        },
        "endLoc": {
          "line": 69,
          "column": 1,
          "position": 482
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": ") {\n    return (\n      <>\n        <div\n          data-tooltip-id={`attachment-uid-${uid}-success`}\n          data-tooltip-content={`${file.name} will be attached to this prompt. It will not be embedded into the workspace permanently.`}\n          className={`relative flex items-center gap-x-1 rounded-lg bg-theme-attachment-success-bg border-none w-[180px] group`}\n        >\n          <div className=\"invisible group-hover:visible absolute -top-[5px] -right-[5px] w-fit h-fit z-[10]\">\n            <button\n              onClick={removeFileFromQueue}\n              type=\"button\"\n              className=\"bg-white hover:bg-error hover:text-theme-attachment-text rounded-full p-1 flex items-center justify-center hover:border-transparent border border-theme-attachment-bg\"\n            >\n              <X size={10} className=\"flex-shrink-0\" />\n            </button>\n          </div>\n          {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/Attachments/index.jsx",
        "start": 110,
        "end": 127,
        "startLoc": {
          "line": 110,
          "column": 13,
          "position": 715
        },
        "endLoc": {
          "line": 127,
          "column": 2,
          "position": 826
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/Attachments/index.jsx",
        "start": 69,
        "end": 86,
        "startLoc": {
          "line": 69,
          "column": 9,
          "position": 450
        },
        "endLoc": {
          "line": 86,
          "column": 2,
          "position": 555
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </p>\n          </div>\n        </div>\n        <Tooltip\n          id={`attachment-uid-${uid}-success`}\n          place=\"top\"\n          delayShow={300}\n          className=\"allm-tooltip !allm-text-xs\"\n        />\n      </>\n    );\n  }\n\n  return",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/Attachments/index.jsx",
        "start": 145,
        "end": 159,
        "startLoc": {
          "line": 145,
          "column": 2,
          "position": 967
        },
        "endLoc": {
          "line": 159,
          "column": 7,
          "position": 1031
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/Attachments/index.jsx",
        "start": 96,
        "end": 110,
        "startLoc": {
          "line": 96,
          "column": 2,
          "position": 643
        },
        "endLoc": {
          "line": 110,
          "column": 3,
          "position": 707
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ");\n\n  useEffect(() => {\n    function listenForOutsideClick() {\n      if (!showing || !formRef.current) return false;\n      document.addEventListener(\"click\", closeIfOutside);\n    }\n    listenForOutsideClick();\n  }, [showing, formRef.current]);\n\n  const closeIfOutside = ({ target }) => {\n    if (target.id === \"agent-list-btn\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/AgentMenu/index.jsx",
        "start": 64,
        "end": 75,
        "startLoc": {
          "line": 64,
          "column": 2,
          "position": 465
        },
        "endLoc": {
          "line": 75,
          "column": 17,
          "position": 574
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/TextSizeMenu/index.jsx",
        "start": 50,
        "end": 61,
        "startLoc": {
          "line": 50,
          "column": 3,
          "position": 376
        },
        "endLoc": {
          "line": 61,
          "column": 16,
          "position": 485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "workspace.pfpUrl) {\n    return (\n      <div className=\"relative w-[35px] h-[35px] rounded-full flex-shrink-0 overflow-hidden\">\n        <img\n          src={workspace.pfpUrl}\n          alt=\"Workspace profile picture\"\n          className=\"absolute top-0 left-0 w-full h-full object-cover rounded-full bg-white\"\n        />\n      </div>\n    );\n  }\n\n  return (",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/index.jsx",
        "start": 138,
        "end": 150,
        "startLoc": {
          "line": 138,
          "column": 2,
          "position": 1031
        },
        "endLoc": {
          "line": 150,
          "column": 2,
          "position": 1096
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/PromptReply/index.jsx",
        "start": 82,
        "end": 94,
        "startLoc": {
          "line": 82,
          "column": 2,
          "position": 577
        },
        "endLoc": {
          "line": 94,
          "column": 2,
          "position": 642
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n          <button\n            onClick={onClose}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div\n          className=\"h-full w-full overflow-y-auto\"\n          style={{ maxHeight: \"calc(100vh - 200px)\" }}\n        >\n          <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Citation/index.jsx",
        "start": 162,
        "end": 175,
        "startLoc": {
          "line": 162,
          "column": 2,
          "position": 1395
        },
        "endLoc": {
          "line": 175,
          "column": 4,
          "position": 1480
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 40,
        "end": 69,
        "startLoc": {
          "line": 40,
          "column": 2,
          "position": 366
        },
        "endLoc": {
          "line": 69,
          "column": 5,
          "position": 577
        }
      }
    },
    {
      "format": "javascript",
      "lines": 89,
      "fragment": "}\n              />\n            </ComposedChart>\n          </div>\n        );\n      case \"scatter\":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            {showLegend && (\n              <div className=\"flex justify-end\">\n                <Legend\n                  categories={[value]}\n                  colors={[color || \"blue\", color || \"blue\"]}\n                  className=\"mb-5\"\n                />\n              </div>\n            )}\n            <ScatterChart width={500} height={260} data={data}>\n              <CartesianGrid\n                strokeDasharray=\"3 3\"\n                horizontal\n                vertical={false}\n              />\n              <XAxis\n                dataKey=\"name\"\n                tickLine={false}\n                axisLine={false}\n                interval=\"preserveStartEnd\"\n                tick={{ transform: \"translate(0, 6)\", fill: \"white\" }}\n                style={{\n                  fontSize: \"12px\",\n                  fontFamily: \"Inter; Helvetica\",\n                }}\n                padding={{ left: 10, right: 10 }}\n              />\n              <YAxis\n                tickLine={false}\n                axisLine={false}\n                type=\"number\"\n                tick={{ transform: \"translate(-3, 0)\", fill: \"white\" }}\n                style={{\n                  fontSize: \"12px\",\n                  fontFamily: \"Inter; Helvetica\",\n                }}\n              />\n              <Tooltip legendColor={getTremorColor(color || \"blue\")} />\n              <Scatter dataKey={value} fill={getTremorColor(color || \"blue\")} />\n            </ScatterChart>\n          </div>\n        );\n      case \"pie\":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            <DonutChart\n              data={data}\n              category={value}\n              index=\"name\"\n              colors={[\n                color || \"cyan\",\n                \"violet\",\n                \"rose\",\n                \"amber\",\n                \"emerald\",\n                \"teal\",\n                \"fuchsia\",\n              ]}\n              // No actual legend for pie chart, but this will toggle the central text\n              showLabel={showLegend}\n              valueFormatter={dataFormatter}\n              customTooltip={customTooltip}\n            />\n          </div>\n        );\n      case \"radar\":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            {showLegend && (\n              <div className=\"flex justify-end\">\n                <Legend\n                  categories={[",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 182,
        "end": 270,
        "startLoc": {
          "line": 182,
          "column": 2,
          "position": 1358
        },
        "endLoc": {
          "line": 270,
          "column": 2,
          "position": 1937
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 125,
        "end": 175,
        "startLoc": {
          "line": 125,
          "column": 14,
          "position": 978
        },
        "endLoc": {
          "line": 175,
          "column": 6,
          "position": 1315
        }
      }
    },
    {
      "format": "jsx",
      "lines": 30,
      "fragment": " width={500} height={260} data={data}>\n              <CartesianGrid\n                strokeDasharray=\"3 3\"\n                horizontal\n                vertical={false}\n              />\n              <XAxis\n                dataKey=\"name\"\n                tickLine={false}\n                axisLine={false}\n                interval=\"preserveStartEnd\"\n                tick={{ transform: \"translate(0, 6)\", fill: \"white\" }}\n                style={{\n                  fontSize: \"12px\",\n                  fontFamily: \"Inter; Helvetica\",\n                }}\n                padding={{ left: 10, right: 10 }}\n              />\n              <YAxis\n                tickLine={false}\n                axisLine={false}\n                type=\"number\"\n                tick={{ transform: \"translate(-3, 0)\", fill: \"white\" }}\n                style={{\n                  fontSize: \"12px\",\n                  fontFamily: \"Inter; Helvetica\",\n                }}\n              />\n              <Tooltip legendColor={getTremorColor(color || \"blue\")} />\n              <Scatter",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 202,
        "end": 231,
        "startLoc": {
          "line": 202,
          "column": 13,
          "position": 1486
        },
        "endLoc": {
          "line": 231,
          "column": 8,
          "position": 1687
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 142,
        "end": 171,
        "startLoc": {
          "line": 142,
          "column": 14,
          "position": 1085
        },
        "endLoc": {
          "line": 171,
          "column": 5,
          "position": 1286
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            {showLegend && (\n              <div className=\"flex justify-end\">\n                <Legend\n                  categories={[value]}\n                  colors={[color || \"blue\", color || \"blue\"]}\n                  className=\"mb-5\"\n                />\n              </div>\n            )}\n            <RadarChart",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 261,
        "end": 276,
        "startLoc": {
          "line": 261,
          "column": 8,
          "position": 1872
        },
        "endLoc": {
          "line": 276,
          "column": 11,
          "position": 1977
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 187,
        "end": 202,
        "startLoc": {
          "line": 187,
          "column": 10,
          "position": 1380
        },
        "endLoc": {
          "line": 202,
          "column": 13,
          "position": 1485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            {showLegend && (\n              <div className=\"flex justify-end\">\n                <Legend\n                  categories={[value]}\n                  colors={[color || \"blue\", color || \"blue\"]}\n                  className=\"mb-5\"\n                />\n              </div>\n            )}\n            <RadialBarChart",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 297,
        "end": 312,
        "startLoc": {
          "line": 297,
          "column": 12,
          "position": 2143
        },
        "endLoc": {
          "line": 312,
          "column": 15,
          "position": 2248
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 187,
        "end": 202,
        "startLoc": {
          "line": 187,
          "column": 10,
          "position": 1380
        },
        "endLoc": {
          "line": 202,
          "column": 13,
          "position": 1485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            {showLegend && (\n              <div className=\"flex justify-end\">\n                <Legend\n                  categories={[value]}\n                  colors={[color || \"blue\", color || \"blue\"]}\n                  className=\"mb-5\"\n                />\n              </div>\n            )}\n            <Treemap",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 334,
        "end": 349,
        "startLoc": {
          "line": 334,
          "column": 10,
          "position": 2378
        },
        "endLoc": {
          "line": 349,
          "column": 8,
          "position": 2483
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 187,
        "end": 202,
        "startLoc": {
          "line": 187,
          "column": 10,
          "position": 1380
        },
        "endLoc": {
          "line": 202,
          "column": 13,
          "position": 1485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ":\n        return (\n          <div className=\"bg-theme-bg-primary p-8 rounded-xl text-white light:border light:border-theme-border-primary\">\n            <h3 className=\"text-lg text-theme-text-primary font-medium\">\n              {title}\n            </h3>\n            {showLegend && (\n              <div className=\"flex justify-end\">\n                <Legend\n                  categories={[value]}\n                  colors={[color || \"blue\", color || \"blue\"]}\n                  className=\"mb-5\"\n                />\n              </div>\n            )}\n            <FunnelChart",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 362,
        "end": 377,
        "startLoc": {
          "line": 362,
          "column": 9,
          "position": 2585
        },
        "endLoc": {
          "line": 377,
          "column": 12,
          "position": 2690
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/Chartable/index.jsx",
        "start": 187,
        "end": 202,
        "startLoc": {
          "line": 187,
          "column": 10,
          "position": 1380
        },
        "endLoc": {
          "line": 202,
          "column": 13,
          "position": 1485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ")}\n            </h3>\n          </div>\n        </div>\n        <div className=\"py-7 px-9 space-y-2 flex-col\">\n          <div className=\"w-full text-white text-md flex flex-col gap-y-2\">\n            <p>\n              <span\n                dangerouslySetInnerHTML={{\n                  __html: t(\"connectors.watching.watch_explained_block1\"),\n                }}\n              />\n            </p>\n            <p>{",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/WorkspaceDirectory/index.jsx",
        "start": 352,
        "end": 365,
        "startLoc": {
          "line": 352,
          "column": 36,
          "position": 2778
        },
        "endLoc": {
          "line": 365,
          "column": 2,
          "position": 2854
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/Documents/WorkspaceDirectory/index.jsx",
        "start": 287,
        "end": 301,
        "startLoc": {
          "line": 287,
          "column": 34,
          "position": 2303
        },
        "endLoc": {
          "line": 301,
          "column": 1,
          "position": 2379
        }
      }
    },
    {
      "format": "javascript",
      "lines": 40,
      "fragment": "={true}\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg text-white text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {t(\"agent.mode.wait\")}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div>\n      <div className=\"flex flex-col\">\n        <label htmlFor=\"name\" className=\"block input-label\">\n          {t(\"agent.mode.title\")}\n        </label>\n        <p className=\"text-white text-opacity-60 text-xs font-medium py-1.5\">\n          {t(\"agent.mode.description\")}\n        </p>\n      </div>\n\n      <select\n        name=\"agentModel\"\n        required={true}\n        onChange={() => {\n          setHasChanges(true);\n        }}\n        className=\"border-none bg-theme-settings-input-bg text-white text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n      >\n        {defaultModels.length > 0 && (\n          <optgroup label=\"General models\">\n            {defaultModels.map((model) => {\n              if (!supportedModel(provider, model)) return null;\n              return (\n                <option\n                  key={model}\n                  value={model}\n                  selected={workspace?.agentModel ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx",
        "start": 81,
        "end": 120,
        "startLoc": {
          "line": 81,
          "column": 9,
          "position": 538
        },
        "endLoc": {
          "line": 120,
          "column": 12,
          "position": 814
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx",
        "start": 29,
        "end": 67,
        "startLoc": {
          "line": 29,
          "column": 9,
          "position": 217
        },
        "endLoc": {
          "line": 67,
          "column": 11,
          "position": 477
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div>\n      <div className=\"flex flex-col\">\n        <label htmlFor=\"name\" className=\"block input-label\">\n          {t(\"agent.mode.title\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx",
        "start": 86,
        "end": 97,
        "startLoc": {
          "line": 86,
          "column": 2,
          "position": 581
        },
        "endLoc": {
          "line": 97,
          "column": 19,
          "position": 647
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 38,
        "end": 49,
        "startLoc": {
          "line": 38,
          "column": 3,
          "position": 275
        },
        "endLoc": {
          "line": 49,
          "column": 53,
          "position": 341
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\"\n        required={true}\n        onChange={() => {\n          setHasChanges(true);\n        }}\n        className=\"border-none bg-theme-settings-input-bg text-white text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n      >\n        {defaultModels.length > 0 && (\n          <optgroup label=\"General models\">\n            {defaultModels.map((model) => {\n              if",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx",
        "start": 105,
        "end": 115,
        "startLoc": {
          "line": 105,
          "column": 11,
          "position": 694
        },
        "endLoc": {
          "line": 115,
          "column": 3,
          "position": 769
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/ChatModelSelection/index.jsx",
        "start": 53,
        "end": 63,
        "startLoc": {
          "line": 53,
          "column": 10,
          "position": 376
        },
        "endLoc": {
          "line": 63,
          "column": 7,
          "position": 451
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n              return (\n                <option\n                  key={model}\n                  value={model}\n                  selected={workspace?.agentModel === model}\n                >\n                  {model}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n        {Array.isArray(customModels) && customModels.length > 0 && (\n          <optgroup label=\"Custom models",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx",
        "start": 115,
        "end": 129,
        "startLoc": {
          "line": 115,
          "column": 2,
          "position": 786
        },
        "endLoc": {
          "line": 129,
          "column": 14,
          "position": 879
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 70,
        "end": 84,
        "startLoc": {
          "line": 70,
          "column": 2,
          "position": 488
        },
        "endLoc": {
          "line": 84,
          "column": 18,
          "position": 578
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={workspace?.agentModel === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n        {/* For providers like TogetherAi where we partition model by creator entity. */}\n        {!Array.isArray(customModels) &&\n          Object.keys(customModels).length > 0 && (\n            <>\n              {Object.entries(customModels).map(([organization, models]) => (\n                <optgroup key={organization} label={organization}>\n                  {models.map((model) => {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentModelSelection/index.jsx",
        "start": 132,
        "end": 151,
        "startLoc": {
          "line": 132,
          "column": 1,
          "position": 918
        },
        "endLoc": {
          "line": 151,
          "column": 2,
          "position": 1081
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 85,
        "end": 104,
        "startLoc": {
          "line": 85,
          "column": 2,
          "position": 595
        },
        "endLoc": {
          "line": 104,
          "column": 2,
          "position": 755
        }
      }
    },
    {
      "format": "javascript",
      "lines": 70,
      "fragment": "}\n                  weight=\"bold\"\n                  className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                />\n                <input\n                  type=\"text\"\n                  name=\"llm-search\"\n                  autoComplete=\"off\"\n                  placeholder=\"Search available LLM providers\"\n                  className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                  onChange={(e) => setSearchQuery(e.target.value)}\n                  ref={searchInputRef}\n                  onKeyDown={(e) => {\n                    if (e.key === \"Enter\") e.preventDefault();\n                  }}\n                />\n                <X\n                  size={20}\n                  weight=\"bold\"\n                  className=\"cursor-pointer text-theme-text-primary hover:text-x-button\"\n                  onClick={handleXButton}\n                />\n              </div>\n              <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                {filteredLLMs.map((llm) => {\n                  return (\n                    <AgentLLMItem\n                      llm={llm}\n                      key={llm.name}\n                      availableLLMs={LLMS}\n                      settings={settings}\n                      checked={selectedLLM === llm.value}\n                      onClick={() => updateLLMChoice(llm.value)}\n                    />\n                  );\n                })}\n              </div>\n            </div>\n          </div>\n        ) : (\n          <button\n            className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n            type=\"button\"\n            onClick={() => setSearchMenuOpen(true)}\n          >\n            <div className=\"flex gap-x-4 items-center\">\n              <img\n                src={selectedLLMObject.logo}\n                alt={`${selectedLLMObject.name} logo`}\n                className=\"w-10 h-10 rounded-md\"\n              />\n              <div className=\"flex flex-col text-left\">\n                <div className=\"text-sm font-semibold text-white\">\n                  {selectedLLMObject.name}\n                </div>\n                <div className=\"mt-1 text-xs text-description\">\n                  {selectedLLMObject.description}\n                </div>\n              </div>\n            </div>\n            <CaretUpDown size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        )}\n      </div>\n      {selectedLLM !== \"none\" && (\n        <div className=\"mt-4 flex flex-col gap-y-1\">\n          <AgentModelSelection\n            provider={selectedLLM}\n            workspace={workspace}\n            setHasChanges={setHasChanges}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx",
        "start": 138,
        "end": 207,
        "startLoc": {
          "line": 138,
          "column": 3,
          "position": 1022
        },
        "endLoc": {
          "line": 207,
          "column": 2,
          "position": 1507
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx",
        "start": 105,
        "end": 164,
        "startLoc": {
          "line": 105,
          "column": 2,
          "position": 884
        },
        "endLoc": {
          "line": 164,
          "column": 2,
          "position": 1304
        }
      }
    },
    {
      "format": "jsx",
      "lines": 28,
      "fragment": "\n  );\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [searchMenuOpen, setSearchMenuOpen] = useState(false);\n  const searchInputRef = useRef(null);\n  const { t } = useTranslation();\n  function updateLLMChoice(selection) {\n    setSearchQuery(\"\");\n    setSelectedLLM(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  }\n\n  function handleXButton() {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  }\n\n  useEffect(() => {\n    const filtered = LLMS.filter((llm) =>\n      llm.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredLLMs(filtered);\n  }, [searchQuery",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx",
        "start": 75,
        "end": 102,
        "startLoc": {
          "line": 75,
          "column": 7,
          "position": 443
        },
        "endLoc": {
          "line": 102,
          "column": 12,
          "position": 689
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx",
        "start": 43,
        "end": 70,
        "startLoc": {
          "line": 43,
          "column": 10,
          "position": 345
        },
        "endLoc": {
          "line": 70,
          "column": 5,
          "position": 591
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": "\" value={selectedLLM} />\n        {searchMenuOpen && (\n          <div\n            className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n            onClick={() => setSearchMenuOpen(false)}\n          />\n        )}\n        {searchMenuOpen ? (\n          <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n            <div className=\"w-full flex flex-col gap-y-1\">\n              <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                <MagnifyingGlass\n                  size={20}\n                  weight=\"bold\"\n                  className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                />\n                <input\n                  type=\"text\"\n                  name=\"llm-search\"\n                  autoComplete=\"off\"\n                  placeholder=",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx",
        "start": 126,
        "end": 146,
        "startLoc": {
          "line": 126,
          "column": 14,
          "position": 925
        },
        "endLoc": {
          "line": 146,
          "column": 2,
          "position": 1061
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx",
        "start": 85,
        "end": 106,
        "startLoc": {
          "line": 85,
          "column": 13,
          "position": 742
        },
        "endLoc": {
          "line": 106,
          "column": 19,
          "position": 885
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\"\n                  onChange={(e) => setSearchQuery(e.target.value)}\n                  ref={searchInputRef}\n                  onKeyDown={(e) => {\n                    if (e.key === \"Enter\") e.preventDefault();\n                  }}\n                />\n                <X\n                  size={20}\n                  weight=\"bold\"\n                  className=\"cursor-pointer text-theme-text-primary hover:text-x-button\"\n                  onClick={handleXButton}\n                />\n              </div>\n              <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                {filteredLLMs.map((llm) => {\n                  return (\n                    <AgentLLMItem",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx",
        "start": 147,
        "end": 164,
        "startLoc": {
          "line": 147,
          "column": 180,
          "position": 1070
        },
        "endLoc": {
          "line": 164,
          "column": 13,
          "position": 1197
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx",
        "start": 106,
        "end": 123,
        "startLoc": {
          "line": 106,
          "column": 252,
          "position": 890
        },
        "endLoc": {
          "line": 123,
          "column": 17,
          "position": 1017
        }
      }
    },
    {
      "format": "jsx",
      "lines": 39,
      "fragment": "\n                      llm={llm}\n                      key={llm.name}\n                      availableLLMs={LLMS}\n                      settings={settings}\n                      checked={selectedLLM === llm.value}\n                      onClick={() => updateLLMChoice(llm.value)}\n                    />\n                  );\n                })}\n              </div>\n            </div>\n          </div>\n        ) : (\n          <button\n            className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n            type=\"button\"\n            onClick={() => setSearchMenuOpen(true)}\n          >\n            <div className=\"flex gap-x-4 items-center\">\n              <img\n                src={selectedLLMObject.logo}\n                alt={`${selectedLLMObject.name} logo`}\n                className=\"w-10 h-10 rounded-md\"\n              />\n              <div className=\"flex flex-col text-left\">\n                <div className=\"text-sm font-semibold text-white\">\n                  {selectedLLMObject.name}\n                </div>\n                <div className=\"mt-1 text-xs text-description\">\n                  {selectedLLMObject.description}\n                </div>\n              </div>\n            </div>\n            <CaretUpDown size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        )}\n      </div>\n      {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/AgentLLMSelection/index.jsx",
        "start": 164,
        "end": 202,
        "startLoc": {
          "line": 164,
          "column": 13,
          "position": 1198
        },
        "endLoc": {
          "line": 202,
          "column": 2,
          "position": 1465
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx",
        "start": 123,
        "end": 161,
        "startLoc": {
          "line": 123,
          "column": 17,
          "position": 1018
        },
        "endLoc": {
          "line": 161,
          "column": 2,
          "position": 1285
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": ">\n            <label\n              className={`border-solid transition-all duration-300 w-full h-11 p-2.5 rounded-lg flex justify-start items-center gap-2.5 cursor-pointer border-[1px] ${\n                selectedOption === \"personal\"\n                  ? \"border-theme-sidebar-item-workspace-active bg-theme-bg-secondary\"\n                  : \"border-theme-sidebar-border\"\n              } hover:border-theme-sidebar-border hover:bg-theme-bg-secondary`}\n            >\n              <input\n                type=\"radio\"\n                name=\"use_case\"\n                value={\"personal\"}\n                checked={selectedOption === \"personal\"}\n                onChange={(e) => setSelectedOption(e.target.value)}\n                className=\"hidden\"\n              />\n              <div\n                className={`w-4 h-4 rounded-full border-2 border-theme-sidebar-border mr-2 ${\n                  selectedOption === \"personal\"\n                    ? \"bg-[var(--theme-sidebar-item-workspace-active)]\"\n                    : \"\"\n                }`}\n              ></div>\n              <div className=\"text-theme-text-primary text-sm font-medium font-['Plus Jakarta Sans'] leading-tight\">\n                {t(\"onboarding.survey.useCasePersonal\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/Survey/index.jsx",
        "start": 181,
        "end": 205,
        "startLoc": {
          "line": 181,
          "column": 6,
          "position": 1408
        },
        "endLoc": {
          "line": 205,
          "column": 36,
          "position": 1546
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/Survey/index.jsx",
        "start": 155,
        "end": 179,
        "startLoc": {
          "line": 155,
          "column": 2,
          "position": 1258
        },
        "endLoc": {
          "line": 179,
          "column": 32,
          "position": 1396
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": ")}\n              </div>\n            </label>\n            <label\n              className={`border-solid transition-all duration-300 w-full h-11 p-2.5 rounded-lg flex justify-start items-center gap-2.5 cursor-pointer border-[1px] ${\n                selectedOption === \"other\"\n                  ? \"border-theme-sidebar-item-workspace-active bg-theme-bg-secondary\"\n                  : \"border-theme-sidebar-border\"\n              } hover:border-theme-sidebar-border hover:bg-theme-bg-secondary`}\n            >\n              <input\n                type=\"radio\"\n                name=\"use_case\"\n                value={\"other\"}\n                checked={selectedOption === \"other\"}\n                onChange={(e) => setSelectedOption(e.target.value)}\n                className=\"hidden\"\n              />\n              <div\n                className={`w-4 h-4 rounded-full border-2 border-theme-sidebar-border mr-2 ${\n                  selectedOption === \"other\"\n                    ? \"bg-[var(--theme-sidebar-item-workspace-active)]\"\n                    : \"\"\n                }`}\n              ></div>\n              <div className=\"text-theme-text-primary text-sm font-medium font-['Plus Jakarta Sans'] leading-tight\">\n                {t(\"onboarding.survey.useCaseOther\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/Survey/index.jsx",
        "start": 205,
        "end": 231,
        "startLoc": {
          "line": 205,
          "column": 36,
          "position": 1547
        },
        "endLoc": {
          "line": 231,
          "column": 33,
          "position": 1696
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/Survey/index.jsx",
        "start": 179,
        "end": 179,
        "startLoc": {
          "line": 179,
          "column": 32,
          "position": 1397
        },
        "endLoc": {
          "line": 179,
          "column": 32,
          "position": 1396
        }
      }
    },
    {
      "format": "javascript",
      "lines": 262,
      "fragment": "={settings} />,\n    description: \"The enterprise option of OpenAI hosted on Azure services.\",\n  },\n  {\n    name: \"Anthropic\",\n    value: \"anthropic\",\n    logo: AnthropicLogo,\n    options: (settings) => <AnthropicAiOptions settings={settings} />,\n    description: \"A friendly AI Assistant hosted by Anthropic.\",\n  },\n  {\n    name: \"Gemini\",\n    value: \"gemini\",\n    logo: GeminiLogo,\n    options: (settings) => <GeminiLLMOptions settings={settings} />,\n    description: \"Google's largest and most capable AI model\",\n  },\n  {\n    name: \"NVIDIA NIM\",\n    value: \"nvidia-nim\",\n    logo: NvidiaNimLogo,\n    options: (settings) => <NvidiaNimOptions settings={settings} />,\n    description:\n      \"Run full parameter LLMs directly on your NVIDIA RTX GPU using NVIDIA NIM.\",\n  },\n  {\n    name: \"HuggingFace\",\n    value: \"huggingface\",\n    logo: HuggingFaceLogo,\n    options: (settings) => <HuggingFaceOptions settings={settings} />,\n    description:\n      \"Access 150,000+ open-source LLMs and the world's AI community\",\n  },\n  {\n    name: \"Ollama\",\n    value: \"ollama\",\n    logo: OllamaLogo,\n    options: (settings) => <OllamaLLMOptions settings={settings} />,\n    description: \"Run LLMs locally on your own machine.\",\n  },\n  {\n    name: \"Dell Pro AI Studio\",\n    value: \"dpais\",\n    logo: DellProAiStudioLogo,\n    options: (settings) => <DellProAiStudioOptions settings={settings} />,\n    description:\n      \"Run powerful LLMs quickly on NPU powered by Dell Pro AI Studio.\",\n  },\n  {\n    name: \"LM Studio\",\n    value: \"lmstudio\",\n    logo: LMStudioLogo,\n    options: (settings) => <LMStudioOptions settings={settings} />,\n    description:\n      \"Discover, download, and run thousands of cutting edge LLMs in a few clicks.\",\n  },\n  {\n    name: \"Local AI\",\n    value: \"localai\",\n    logo: LocalAiLogo,\n    options: (settings) => <LocalAiOptions settings={settings} />,\n    description: \"Run LLMs locally on your own machine.\",\n  },\n  {\n    name: \"Novita AI\",\n    value: \"novita\",\n    logo: NovitaLogo,\n    options: (settings) => <NovitaLLMOptions settings={settings} />,\n    description:\n      \"Reliable, Scalable, and Cost-Effective for LLMs from Novita AI\",\n  },\n  {\n    name: \"KoboldCPP\",\n    value: \"koboldcpp\",\n    logo: KoboldCPPLogo,\n    options: (settings) => <KoboldCPPOptions settings={settings} />,\n    description: \"Run local LLMs using koboldcpp.\",\n  },\n  {\n    name: \"Oobabooga Web UI\",\n    value: \"textgenwebui\",\n    logo: TextGenWebUILogo,\n    options: (settings) => <TextGenWebUIOptions settings={settings} />,\n    description: \"Run local LLMs using Oobabooga's Text Generation Web UI.\",\n  },\n  {\n    name: \"Together AI\",\n    value: \"togetherai\",\n    logo: TogetherAILogo,\n    options: (settings) => <TogetherAiOptions settings={settings} />,\n    description: \"Run open source models from Together AI.\",\n  },\n  {\n    name: \"Fireworks AI\",\n    value: \"fireworksai\",\n    logo: FireworksAILogo,\n    options: (settings) => <FireworksAiOptions settings={settings} />,\n    description:\n      \"The fastest and most efficient inference engine to build production-ready, compound AI systems.\",\n  },\n  {\n    name: \"Mistral\",\n    value: \"mistral\",\n    logo: MistralLogo,\n    options: (settings) => <MistralOptions settings={settings} />,\n    description: \"Run open source models from Mistral AI.\",\n  },\n  {\n    name: \"Perplexity AI\",\n    value: \"perplexity\",\n    logo: PerplexityLogo,\n    options: (settings) => <PerplexityOptions settings={settings} />,\n    description:\n      \"Run powerful and internet-connected models hosted by Perplexity AI.\",\n  },\n  {\n    name: \"OpenRouter\",\n    value: \"openrouter\",\n    logo: OpenRouterLogo,\n    options: (settings) => <OpenRouterOptions settings={settings} />,\n    description: \"A unified interface for LLMs.\",\n  },\n  {\n    name: \"Groq\",\n    value: \"groq\",\n    logo: GroqLogo,\n    options: (settings) => <GroqAiOptions settings={settings} />,\n    description:\n      \"The fastest LLM inferencing available for real-time AI applications.\",\n  },\n  {\n    name: \"Cohere\",\n    value: \"cohere\",\n    logo: CohereLogo,\n    options: (settings) => <CohereAiOptions settings={settings} />,\n    description: \"Run Cohere's powerful Command models.\",\n  },\n  {\n    name: \"LiteLLM\",\n    value: \"litellm\",\n    logo: LiteLLMLogo,\n    options: (settings) => <LiteLLMOptions settings={settings} />,\n    description: \"Run LiteLLM's OpenAI compatible proxy for various LLMs.\",\n  },\n  {\n    name: \"DeepSeek\",\n    value: \"deepseek\",\n    logo: DeepSeekLogo,\n    options: (settings) => <DeepSeekOptions settings={settings} />,\n    description: \"Run DeepSeek's powerful LLMs.\",\n  },\n  {\n    name: \"PPIO\",\n    value: \"ppio\",\n    logo: PPIOLogo,\n    options: (settings) => <PPIOLLMOptions settings={settings} />,\n    description:\n      \"Run stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.\",\n  },\n  {\n    name: \"APIpie\",\n    value: \"apipie\",\n    logo: APIPieLogo,\n    options: (settings) => <ApiPieLLMOptions settings={settings} />,\n    description: \"A unified API of AI services from leading providers\",\n  },\n  {\n    name: \"Generic OpenAI\",\n    value: \"generic-openai\",\n    logo: GenericOpenAiLogo,\n    options: (settings) => <GenericOpenAiOptions settings={settings} />,\n    description:\n      \"Connect to any OpenAi-compatible service via a custom configuration\",\n  },\n  {\n    name: \"AWS Bedrock\",\n    value: \"bedrock\",\n    logo: AWSBedrockLogo,\n    options: (settings) => <AWSBedrockLLMOptions settings={settings} />,\n    description: \"Run powerful foundation models privately with AWS Bedrock.\",\n  },\n  {\n    name: \"xAI\",\n    value: \"xai\",\n    logo: XAILogo,\n    options: (settings) => <XAILLMOptions settings={settings} />,\n    description: \"Run xAI's powerful LLMs like Grok-2 and more.\",\n  },\n];\n\nexport default function LLMPreference({\n  setHeader,\n  setForwardBtn,\n  setBackBtn,\n}) {\n  const { t } = useTranslation();\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filteredLLMs, setFilteredLLMs] = useState([]);\n  const [selectedLLM, setSelectedLLM] = useState(null);\n  const [settings, setSettings] = useState(null);\n  const formRef = useRef(null);\n  const hiddenSubmitButtonRef = useRef(null);\n  const isHosted = window.location.hostname.includes(\"useanything.com\");\n  const navigate = useNavigate();\n\n  const TITLE = t(\"onboarding.llm.title\");\n  const DESCRIPTION = t(\"onboarding.llm.description\");\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedLLM(_settings?.LLMProvider || \"openai\");\n    }\n    fetchKeys();\n  }, []);\n\n  function handleForward() {\n    if (hiddenSubmitButtonRef.current) {\n      hiddenSubmitButtonRef.current.click();\n    }\n  }\n\n  function handleBack() {\n    navigate(paths.onboarding.home());\n  }\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = e.target;\n    const data = {};\n    const formData = new FormData(form);\n    data.LLMProvider = selectedLLM;\n    // Default to AnythingLLM embedder and LanceDB\n    data.EmbeddingEngine = \"native\";\n    data.VectorDB = \"lancedb\";\n    for (var [key, value] of formData.entries()) data[key] = value;\n\n    const { error } = await System.updateSystem(data);\n    if (error) {\n      showToast(`Failed to save LLM settings: ${error}`, \"error\");\n      return;\n    }\n    navigate(paths.onboarding.userSetup());\n  };\n\n  useEffect(() => {\n    setHeader({ title: TITLE, description: DESCRIPTION });\n    setForwardBtn({ showing: true, disabled: false, onClick: handleForward });\n    setBackBtn({ showing: true, disabled: false, onClick: handleBack });\n  }, []);\n\n  useEffect(() => {\n    const filtered = LLMS.filter((llm) =>\n      llm.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredLLMs(filtered);\n  }, [searchQuery, selectedLLM]);\n\n  return (\n    <div>\n      <form ref={formRef",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 78,
        "end": 339,
        "startLoc": {
          "line": 78,
          "column": 9,
          "position": 686
        },
        "endLoc": {
          "line": 339,
          "column": 8,
          "position": 2862
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 71,
        "end": 160,
        "startLoc": {
          "line": 71,
          "column": 9,
          "position": 629
        },
        "endLoc": {
          "line": 160,
          "column": 9,
          "position": 1320
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": " = noop,\n      showToast = noop,\n      showNewWsModal = noop,\n    }) => {\n      if (workspaces.length === 0) {\n        showToast(t(\"main-page.noWorkspaceError\"), \"warning\", {\n          clear: true,\n        });\n        showNewWsModal();\n        return false;\n      }\n      setSelectedWorkspace",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Main/Home/Checklist/constants.js",
        "start": 86,
        "end": 97,
        "startLoc": {
          "line": 86,
          "column": 18,
          "position": 473
        },
        "endLoc": {
          "line": 97,
          "column": 21,
          "position": 560
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Main/Home/Checklist/constants.js",
        "start": 62,
        "end": 73,
        "startLoc": {
          "line": 62,
          "column": 9,
          "position": 281
        },
        "endLoc": {
          "line": 73,
          "column": 9,
          "position": 368
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": " = noop,\n    }) => {\n      if (workspaces.length === 0) {\n        showToast(t(\"main-page.noWorkspaceError\"), \"warning\", {\n          clear: true,\n        });\n        showNewWsModal();\n        return false;\n      }\n      navigate(\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Main/Home/Checklist/constants.js",
        "start": 112,
        "end": 122,
        "startLoc": {
          "line": 112,
          "column": 10,
          "position": 670
        },
        "endLoc": {
          "line": 122,
          "column": 1,
          "position": 743
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Main/Home/Checklist/constants.js",
        "start": 64,
        "end": 73,
        "startLoc": {
          "line": 64,
          "column": 15,
          "position": 297
        },
        "endLoc": {
          "line": 73,
          "column": 6,
          "position": 370
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "() {\n  const { t } = useTranslation();\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[86px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n            <div className=\"items-center\">\n              <p className=\"text-lg leading-6 font-bold text-white\">\n                {t(\"customization.chat.title\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/Chat/index.jsx",
        "start": 8,
        "end": 22,
        "startLoc": {
          "line": 8,
          "column": 13,
          "position": 70
        },
        "endLoc": {
          "line": 22,
          "column": 27,
          "position": 192
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/Interface/index.jsx",
        "start": 9,
        "end": 23,
        "startLoc": {
          "line": 9,
          "column": 18,
          "position": 83
        },
        "endLoc": {
          "line": 23,
          "column": 32,
          "position": 205
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "() {\n  const { t } = useTranslation();\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[86px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n            <div className=\"items-center\">\n              <p className=\"text-lg leading-6 font-bold text-white\">\n                {t(\"customization.branding.title\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/Branding/index.jsx",
        "start": 11,
        "end": 25,
        "startLoc": {
          "line": 11,
          "column": 17,
          "position": 97
        },
        "endLoc": {
          "line": 25,
          "column": 31,
          "position": 219
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/Interface/index.jsx",
        "start": 9,
        "end": 23,
        "startLoc": {
          "line": 9,
          "column": 18,
          "position": 83
        },
        "endLoc": {
          "line": 23,
          "column": 32,
          "position": 205
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[86px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n            <div className=\"items-center\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/CommunityHub/Trending/index.jsx",
        "start": 5,
        "end": 16,
        "startLoc": {
          "line": 5,
          "column": 2,
          "position": 43
        },
        "endLoc": {
          "line": 16,
          "column": 52,
          "position": 136
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/Interface/index.jsx",
        "start": 11,
        "end": 22,
        "startLoc": {
          "line": 11,
          "column": 1,
          "position": 104
        },
        "endLoc": {
          "line": 22,
          "column": 39,
          "position": 197
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n\nexport default function ChatRow({ chat, onDelete }) {\n  const {\n    isOpen: isPromptOpen,\n    openModal: openPromptModal,\n    closeModal: closePromptModal,\n  } = useModal();\n  const {\n    isOpen: isResponseOpen,\n    openModal: openResponseModal,\n    closeModal: closeResponseModal,\n  } = useModal();\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx",
        "start": 21,
        "end": 35,
        "startLoc": {
          "line": 21,
          "column": 2,
          "position": 181
        },
        "endLoc": {
          "line": 35,
          "column": 1,
          "position": 275
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/ChatRow/index.jsx",
        "start": 6,
        "end": 19,
        "startLoc": {
          "line": 6,
          "column": 2,
          "position": 67
        },
        "endLoc": {
          "line": 19,
          "column": 3,
          "position": 161
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ",\n  } = useModal();\n\n  const handleDelete = async () => {\n    if (\n      !window.confirm(\n        `Are you sure you want to delete this chat?\\n\\nThis action is irreversible.`\n      )\n    )\n      return false;\n    await System",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx",
        "start": 32,
        "end": 42,
        "startLoc": {
          "line": 32,
          "column": 19,
          "position": 263
        },
        "endLoc": {
          "line": 42,
          "column": 7,
          "position": 322
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/ChatRow/index.jsx",
        "start": 22,
        "end": 32,
        "startLoc": {
          "line": 22,
          "column": 28,
          "position": 185
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 244
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n          </button>\n        </td>\n      </tr>\n      <ModalWrapper isOpen={isPromptOpen}>\n        <TextPreview text={chat.prompt} closeModal={closePromptModal} />\n      </ModalWrapper>\n      <ModalWrapper isOpen={isResponseOpen}>\n        <TextPreview\n          text={parseText(chat.response)}\n          closeModal={closeResponseModal}\n        />\n      </ModalWrapper>\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx",
        "start": 74,
        "end": 87,
        "startLoc": {
          "line": 74,
          "column": 3,
          "position": 571
        },
        "endLoc": {
          "line": 87,
          "column": 5,
          "position": 662
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/ChatRow/index.jsx",
        "start": 77,
        "end": 90,
        "startLoc": {
          "line": 77,
          "column": 2,
          "position": 560
        },
        "endLoc": {
          "line": 90,
          "column": 7,
          "position": 656
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": "\nconst TextPreview = ({ text, closeModal }) => {\n  return (\n    <div className=\"relative w-full md:max-w-2xl max-h-full\">\n      <div className=\"w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border overflow-hidden\">\n        <div className=\"flex items-center justify-between p-6 border-b rounded-t border-theme-modal-border\">\n          <h3 className=\"text-xl font-semibold text-white\">Viewing Text</h3>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"bg-transparent rounded-lg text-sm p-1.5 ml-auto inline-flex items-center bg-sidebar-button hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X className=\"text-white text-lg\" />\n          </button>\n        </div>\n        <div className=\"w-full p-6\">\n          <pre className=\"w-full h-[200px] py-2 px-4 whitespace-pre-line overflow-auto rounded-lg bg-zinc-900 light:bg-theme-bg-secondary border border-gray-500 text-white text-sm\">\n            {text}\n          </pre>\n        </div>\n      </div>\n    </div>\n  );\n};\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx",
        "start": 89,
        "end": 113,
        "startLoc": {
          "line": 89,
          "column": 2,
          "position": 672
        },
        "endLoc": {
          "line": 113,
          "column": 1,
          "position": 848
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/ChatRow/index.jsx",
        "start": 105,
        "end": 129,
        "startLoc": {
          "line": 105,
          "column": 1,
          "position": 728
        },
        "endLoc": {
          "line": 129,
          "column": 1,
          "position": 904
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "();\n  }, []);\n\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/index.jsx",
        "start": 25,
        "end": 36,
        "startLoc": {
          "line": 25,
          "column": 11,
          "position": 263
        },
        "endLoc": {
          "line": 36,
          "column": 54,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx",
        "start": 49,
        "end": 60,
        "startLoc": {
          "line": 49,
          "column": 10,
          "position": 418
        },
        "endLoc": {
          "line": 60,
          "column": 59,
          "position": 483
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": ";\n\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm\"\n        containerClassName=\"flex w-full\"\n      />\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-full p-4 overflow-none",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx",
        "start": 113,
        "end": 130,
        "startLoc": {
          "line": 113,
          "column": 2,
          "position": 1084
        },
        "endLoc": {
          "line": 130,
          "column": 39,
          "position": 1169
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx",
        "start": 50,
        "end": 43,
        "startLoc": {
          "line": 50,
          "column": 2,
          "position": 429
        },
        "endLoc": {
          "line": 43,
          "column": 25,
          "position": 359
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"px-7 py-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-6 max-h-[60vh] overflow-y-auto pr-2\">\n              {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx",
        "start": 56,
        "end": 70,
        "startLoc": {
          "line": 56,
          "column": 4,
          "position": 489
        },
        "endLoc": {
          "line": 70,
          "column": 2,
          "position": 592
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 52,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 52,
          "column": 2,
          "position": 459
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": ");\n  };\n\n  useEffect(() => {\n    function resetStatus() {\n      if (!copied) return false;\n      setTimeout(() => {\n        setCopied(false);\n      }, 3000);\n    }\n    resetStatus();\n  }, [copied]);\n\n  return (\n    <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n      <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n        <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n          <div className=\"w-full flex gap-x-2 items-center\">\n            <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n              Create new API",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx",
        "start": 34,
        "end": 53,
        "startLoc": {
          "line": 34,
          "column": 2,
          "position": 362
        },
        "endLoc": {
          "line": 53,
          "column": 4,
          "position": 512
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx",
        "start": 37,
        "end": 45,
        "startLoc": {
          "line": 37,
          "column": 5,
          "position": 334
        },
        "endLoc": {
          "line": 45,
          "column": 6,
          "position": 485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"px-7 py-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-6 max-h-[60vh] overflow-y-auto pr-2\">\n              {error && <p className=\"text-red-400 text-sm\">Error: {error}</p>}\n              {apiKey && (\n                <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx",
        "start": 53,
        "end": 69,
        "startLoc": {
          "line": 53,
          "column": 4,
          "position": 515
        },
        "endLoc": {
          "line": 69,
          "column": 4,
          "position": 653
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 72,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 72,
          "column": 6,
          "position": 627
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\"\n                  >\n                    Cancel\n                  </button>\n                  <button\n                    type=\"submit\"\n                    className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n                  >\n                    Create API Key\n                  </button>\n                </>\n              ) : (\n                <button\n                  onClick={closeModal}\n                  type=\"button\"\n                  className",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx",
        "start": 113,
        "end": 128,
        "startLoc": {
          "line": 113,
          "column": 91,
          "position": 959
        },
        "endLoc": {
          "line": 128,
          "column": 10,
          "position": 1029
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx",
        "start": 102,
        "end": 117,
        "startLoc": {
          "line": 102,
          "column": 86,
          "position": 910
        },
        "endLoc": {
          "line": 117,
          "column": 9,
          "position": 980
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ");\n    setCopied(true);\n  };\n\n  useEffect(() => {\n    function resetStatus() {\n      if (!copied) return false;\n      setTimeout(() => {\n        setCopied(false);\n      }, 3000);\n    }\n    resetStatus();\n  }, [copied]);\n\n  return (\n    <",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/ApiKeyRow/index.jsx",
        "start": 28,
        "end": 43,
        "startLoc": {
          "line": 28,
          "column": 10,
          "position": 270
        },
        "endLoc": {
          "line": 43,
          "column": 2,
          "position": 368
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx",
        "start": 36,
        "end": 51,
        "startLoc": {
          "line": 36,
          "column": 7,
          "position": 327
        },
        "endLoc": {
          "line": 51,
          "column": 2,
          "position": 425
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ".createdAt}</td>\n        <td className=\"px-6 flex items-center gap-x-6 h-full mt-1\">\n          <button\n            onClick={handleDelete}\n            className=\"text-xs font-medium text-white/80 light:text-black/80 hover:light:text-red-500 hover:text-red-300 rounded-lg px-2 py-1 hover:bg-white hover:light:bg-red-50 hover:bg-opacity-10\"\n          >\n            <Trash className=\"h-5 w-5\" />\n          </button>\n        </td>\n      </tr>\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/WorkspaceRow/index.jsx",
        "start": 46,
        "end": 56,
        "startLoc": {
          "line": 46,
          "column": 10,
          "position": 366
        },
        "endLoc": {
          "line": 56,
          "column": 5,
          "position": 429
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/ChatRow/index.jsx",
        "start": 68,
        "end": 78,
        "startLoc": {
          "line": 68,
          "column": 5,
          "position": 524
        },
        "endLoc": {
          "line": 78,
          "column": 7,
          "position": 587
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": ">\n          <button\n            onClick={handleDelete}\n            className=\"text-xs font-medium text-white/80 light:text-black/80 hover:light:text-red-500 hover:text-red-300 rounded-lg px-2 py-1 hover:bg-white hover:light:bg-red-50 hover:bg-opacity-10\"\n          >\n            <Trash className=\"h-5 w-5\" />\n          </button>\n        </td>\n      </tr>\n    </>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/WorkspaceRow/index.jsx",
        "start": 47,
        "end": 59,
        "startLoc": {
          "line": 47,
          "column": 2,
          "position": 382
        },
        "endLoc": {
          "line": 59,
          "column": 1,
          "position": 439
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/ApiKeyRow/index.jsx",
        "start": 57,
        "end": 69,
        "startLoc": {
          "line": 57,
          "column": 7,
          "position": 507
        },
        "endLoc": {
          "line": 69,
          "column": 1,
          "position": 564
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ") window.location.reload();\n    setError(error);\n  };\n\n  return (\n    <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n      <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n        <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n          <div className=\"w-full flex gap-x-2 items-center\">\n            <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n              Create new workspace",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/NewWorkspaceModal/index.jsx",
        "start": 14,
        "end": 24,
        "startLoc": {
          "line": 14,
          "column": 10,
          "position": 188
        },
        "endLoc": {
          "line": 24,
          "column": 10,
          "position": 276
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 35,
        "end": 45,
        "startLoc": {
          "line": 35,
          "column": 6,
          "position": 397
        },
        "endLoc": {
          "line": 45,
          "column": 6,
          "position": 485
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": " workspace\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-4\">\n              <div>\n                <label\n                  htmlFor=\"name",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/NewWorkspaceModal/index.jsx",
        "start": 24,
        "end": 40,
        "startLoc": {
          "line": 24,
          "column": 4,
          "position": 275
        },
        "endLoc": {
          "line": 40,
          "column": 5,
          "position": 391
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/NewEmbedModal/index.jsx",
        "start": 45,
        "end": 53,
        "startLoc": {
          "line": 45,
          "column": 4,
          "position": 488
        },
        "endLoc": {
          "line": 53,
          "column": 11,
          "position": 454
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ".\n              </p>\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Create workspace",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/NewWorkspaceModal/index.jsx",
        "start": 58,
        "end": 73,
        "startLoc": {
          "line": 58,
          "column": 8,
          "position": 549
        },
        "endLoc": {
          "line": 73,
          "column": 10,
          "position": 625
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 99,
        "end": 83,
        "startLoc": {
          "line": 99,
          "column": 4,
          "position": 784
        },
        "endLoc": {
          "line": 83,
          "column": 7,
          "position": 642
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ", \"success\", { clear: true });\n    }\n  };\n\n  return (\n    <>\n      <tr\n        ref={rowRef}\n        className=\"bg-transparent text-white text-opacity-80 text-xs font-medium border-b border-white/10 h-10\"\n      >\n        <th ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/index.jsx",
        "start": 52,
        "end": 62,
        "startLoc": {
          "line": 52,
          "column": 28,
          "position": 545
        },
        "endLoc": {
          "line": 62,
          "column": 2,
          "position": 599
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/index.jsx",
        "start": 59,
        "end": 70,
        "startLoc": {
          "line": 59,
          "column": 29,
          "position": 542
        },
        "endLoc": {
          "line": 70,
          "column": 11,
          "position": 596
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-4\">\n              <div>\n                <label\n                  htmlFor=\"username\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Username\n                </label>\n                <input\n                  name=\"username\"\n                  type=\"text\"\n                  className=\"border-none bg-theme-settings-input-bg w-full text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                  placeholder=\"User's username\"\n                  minLength",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/NewUserModal/index.jsx",
        "start": 36,
        "end": 62,
        "startLoc": {
          "line": 36,
          "column": 9,
          "position": 407
        },
        "endLoc": {
          "line": 62,
          "column": 10,
          "position": 570
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 77,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 77,
          "column": 13,
          "position": 713
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n                  minLength={2}\n                  required={true}\n                  autoComplete=\"off\"\n                />\n                <p className=\"mt-2 text-xs text-white/60\">\n                  Username must only contain lowercase letters, periods,\n                  numbers, underscores, and hyphens with no spaces\n                </p>\n              </div>\n              <div>\n                <label\n                  htmlFor=\"password\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Password",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/NewUserModal/index.jsx",
        "start": 61,
        "end": 76,
        "startLoc": {
          "line": 61,
          "column": 2,
          "position": 569
        },
        "endLoc": {
          "line": 76,
          "column": 9,
          "position": 669
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 77,
        "end": 92,
        "startLoc": {
          "line": 77,
          "column": 2,
          "position": 720
        },
        "endLoc": {
          "line": 92,
          "column": 4,
          "position": 820
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n                  autoComplete=\"off\"\n                  minLength={8}\n                />\n                <p className=\"mt-2 text-xs text-white/60\">\n                  Password must be at least 8 characters long\n                </p>\n              </div>\n              <div>\n                <label\n                  htmlFor=\"bio\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Bio\n                </label>\n                <textarea\n                  name=\"bio\"\n                  className=\"border-none bg-theme-settings-input-bg w-full text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                  placeholder=\"User's bio\"\n                  autoComplete",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/NewUserModal/index.jsx",
        "start": 83,
        "end": 102,
        "startLoc": {
          "line": 83,
          "column": 2,
          "position": 711
        },
        "endLoc": {
          "line": 102,
          "column": 13,
          "position": 819
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 98,
        "end": 117,
        "startLoc": {
          "line": 98,
          "column": 2,
          "position": 862
        },
        "endLoc": {
          "line": 117,
          "column": 13,
          "position": 970
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\n                  autoComplete=\"off\"\n                  rows={3}\n                />\n              </div>\n              <div>\n                <label\n                  htmlFor=\"role\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Role\n                </label>\n                <select\n                  name=\"role\"\n                  required={true}\n                  defaultValue={\"default\"}\n                  onChange={(e) => setRole(e.target.value)}\n                  className=\"border-none bg-theme-settings-input-bg w-full text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                >\n                  <option value=\"default\">Default</option>\n                  <option value=\"manager\">Manager</option>\n                  {user",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/NewUserModal/index.jsx",
        "start": 101,
        "end": 122,
        "startLoc": {
          "line": 101,
          "column": 2,
          "position": 818
        },
        "endLoc": {
          "line": 122,
          "column": 5,
          "position": 950
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 117,
        "end": 138,
        "startLoc": {
          "line": 117,
          "column": 2,
          "position": 977
        },
        "endLoc": {
          "line": 138,
          "column": 12,
          "position": 1111
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "?.role === \"admin\" && (\n                    <option value=\"admin\">Administrator</option>\n                  )}\n                </select>\n                <RoleHintDisplay role={role} />\n              </div>\n              <MessageLimitInput\n                role={role}\n                enabled={messageLimit.enabled}\n                limit={messageLimit.limit}\n                updateState={setMessageLimit}\n              />\n              {error && <p className=\"text-red-400 text-sm\">Error: {error}</p>}\n              ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/NewUserModal/index.jsx",
        "start": 122,
        "end": 135,
        "startLoc": {
          "line": 122,
          "column": 5,
          "position": 951
        },
        "endLoc": {
          "line": 135,
          "column": 15,
          "position": 1064
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 138,
        "end": 151,
        "startLoc": {
          "line": 138,
          "column": 12,
          "position": 1112
        },
        "endLoc": {
          "line": 151,
          "column": 13,
          "position": 1225
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ".\n              </p>\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Add",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/NewUserModal/index.jsx",
        "start": 137,
        "end": 152,
        "startLoc": {
          "line": 137,
          "column": 7,
          "position": 1108
        },
        "endLoc": {
          "line": 152,
          "column": 4,
          "position": 1182
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 99,
        "end": 114,
        "startLoc": {
          "line": 99,
          "column": 4,
          "position": 784
        },
        "endLoc": {
          "line": 114,
          "column": 7,
          "position": 858
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ");\n    }\n  };\n\n  return (\n    <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n      <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n        <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n          <div className=\"w-full flex gap-x-2 items-center\">\n            <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n              Add New",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx",
        "start": 29,
        "end": 39,
        "startLoc": {
          "line": 29,
          "column": 28,
          "position": 302
        },
        "endLoc": {
          "line": 39,
          "column": 4,
          "position": 376
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 30,
        "end": 36,
        "startLoc": {
          "line": 30,
          "column": 28,
          "position": 323
        },
        "endLoc": {
          "line": 36,
          "column": 5,
          "position": 402
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-4\">\n              <div>\n                <label\n                  htmlFor=\"key\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Key\n                </label>\n                <input\n                  name=\"key\"\n                  type",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx",
        "start": 39,
        "end": 62,
        "startLoc": {
          "line": 39,
          "column": 9,
          "position": 379
        },
        "endLoc": {
          "line": 62,
          "column": 5,
          "position": 522
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 63,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 63,
          "column": 10,
          "position": 545
        }
      }
    },
    {
      "format": "jsx",
      "lines": 23,
      "fragment": "\n                  required={true}\n                  autoComplete=\"off\"\n                  pattern=\"^[a-zA-Z0-9_]+$\"\n                />\n                <p className=\"mt-2 text-xs text-white/60\">\n                  Key must be unique and will be used in prompts as {\"{key}\"}.\n                  Only letters, numbers and underscores are allowed.\n                </p>\n              </div>\n              <div>\n                <label\n                  htmlFor=\"value\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Value\n                </label>\n                <input\n                  name=\"value\"\n                  type=\"text\"\n                  className=\"border-none bg-theme-settings-input-bg w-full text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                  placeholder=\"e.g., Acme Corp\"\n                  required",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx",
        "start": 66,
        "end": 88,
        "startLoc": {
          "line": 66,
          "column": 2,
          "position": 551
        },
        "endLoc": {
          "line": 88,
          "column": 9,
          "position": 697
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 68,
        "end": 90,
        "startLoc": {
          "line": 68,
          "column": 2,
          "position": 582
        },
        "endLoc": {
          "line": 90,
          "column": 13,
          "position": 728
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\n                  required={true}\n                  autoComplete=\"off\"\n                />\n              </div>\n              <div>\n                <label\n                  htmlFor=\"description\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Description\n                </label>\n                <input\n                  name=\"description\"\n                  type=\"text\"\n                  className=\"border-none bg-theme-settings-input-bg w-full text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n                  placeholder=\"Optional description\"\n                  autoComplete",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx",
        "start": 87,
        "end": 104,
        "startLoc": {
          "line": 87,
          "column": 2,
          "position": 696
        },
        "endLoc": {
          "line": 104,
          "column": 13,
          "position": 775
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 90,
        "end": 107,
        "startLoc": {
          "line": 90,
          "column": 2,
          "position": 735
        },
        "endLoc": {
          "line": 107,
          "column": 13,
          "position": 814
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\n                  autoComplete=\"off\"\n                />\n              </div>\n              {error && <p className=\"text-red-400 text-sm\">Error: {error}</p>}\n            </div>\n            <div className=\"flex justify-between items-center mt-6 pt-6 border-t border-theme-modal-border\">\n              <button\n                onClick={closeModal}\n                type=\"button\"\n                className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n              >\n                Cancel\n              </button>\n              <button\n                type=\"submit\"\n                className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n              >\n                Create variable",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/AddVariableModal/index.jsx",
        "start": 103,
        "end": 121,
        "startLoc": {
          "line": 103,
          "column": 2,
          "position": 774
        },
        "endLoc": {
          "line": 121,
          "column": 9,
          "position": 883
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/VariableRow/EditVariableModal/index.jsx",
        "start": 107,
        "end": 83,
        "startLoc": {
          "line": 107,
          "column": 2,
          "position": 821
        },
        "endLoc": {
          "line": 83,
          "column": 7,
          "position": 642
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ");\n  };\n\n  useEffect(() => {\n    function resetStatus() {\n      if (!copied) return false;\n      setTimeout(() => {\n        setCopied(false);\n      }, 3000);\n    }\n    resetStatus();\n  }, [copied]);\n\n  useEffect",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx",
        "start": 46,
        "end": 59,
        "startLoc": {
          "line": 46,
          "column": 2,
          "position": 466
        },
        "endLoc": {
          "line": 59,
          "column": 10,
          "position": 552
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx",
        "start": 37,
        "end": 50,
        "startLoc": {
          "line": 37,
          "column": 5,
          "position": 334
        },
        "endLoc": {
          "line": 50,
          "column": 7,
          "position": 420
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </h3>\n          </div>\n          <button\n            onClick={closeModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div className=\"p-6\">\n          <form onSubmit={handleCreate}>\n            <div className=\"space-y-4\">\n              {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx",
        "start": 74,
        "end": 88,
        "startLoc": {
          "line": 74,
          "column": 7,
          "position": 697
        },
        "endLoc": {
          "line": 88,
          "column": 2,
          "position": 800
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/EmbedRow/EditEmbedModal/index.jsx",
        "start": 38,
        "end": 51,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 356
        },
        "endLoc": {
          "line": 51,
          "column": 2,
          "position": 443
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": "\"\n                    defaultValue={`${window.location.origin}/accept-invite/${invite.code}`}\n                    disabled={true}\n                    className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg outline-none block w-full p-2.5 pr-10\"\n                  />\n                  <button\n                    type=\"button\"\n                    onClick={copyInviteLink}\n                    disabled={copied}\n                    className=\"absolute right-2 top-1/2 -translate-y-1/2 p-1 rounded-md hover:bg-theme-modal-border transition-all duration-300\"\n                  >\n                    {copied ? (\n                      <Check\n                        size={20}\n                        className=\"text-green-400\"\n                        weight=\"bold\"\n                      />\n                    ) : (\n                      <Copy size={20} className=\"text-white\" weight=\"bold\" />\n                    )}\n                  </button>\n                </div>\n              )}\n              <p className=\"text-white text-opacity-60 text-xs md:text-sm\">\n                After",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx",
        "start": 92,
        "end": 116,
        "startLoc": {
          "line": 92,
          "column": 4,
          "position": 852
        },
        "endLoc": {
          "line": 116,
          "column": 6,
          "position": 1011
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx",
        "start": 71,
        "end": 95,
        "startLoc": {
          "line": 71,
          "column": 5,
          "position": 670
        },
        "endLoc": {
          "line": 95,
          "column": 5,
          "position": 821
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": " ? (\n                <>\n                  <button\n                    onClick={closeModal}\n                    type=\"button\"\n                    className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm mr-2\"\n                  >\n                    Cancel\n                  </button>\n                  <button\n                    type=\"submit\"\n                    className=\"transition-all duration-300 bg-white text-black hover:opacity-60 px-4 py-2 rounded-lg text-sm\"\n                  >\n                    Create Invite",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx",
        "start": 156,
        "end": 169,
        "startLoc": {
          "line": 156,
          "column": 7,
          "position": 1387
        },
        "endLoc": {
          "line": 169,
          "column": 7,
          "position": 1449
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx",
        "start": 108,
        "end": 121,
        "startLoc": {
          "line": 108,
          "column": 7,
          "position": 930
        },
        "endLoc": {
          "line": 121,
          "column": 4,
          "position": 992
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n                  </button>\n                </>\n              ) : (\n                <button\n                  onClick={closeModal}\n                  type=\"button\"\n                  className=\"transition-all duration-300 text-white hover:bg-zinc-700 px-4 py-2 rounded-lg text-sm\"\n                >\n                  Close\n                </button>\n              )}\n            </div>\n          </form>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx",
        "start": 169,
        "end": 188,
        "startLoc": {
          "line": 169,
          "column": 7,
          "position": 1450
        },
        "endLoc": {
          "line": 188,
          "column": 1,
          "position": 1534
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/NewApiKeyModal/index.jsx",
        "start": 121,
        "end": 140,
        "startLoc": {
          "line": 121,
          "column": 4,
          "position": 995
        },
        "endLoc": {
          "line": 140,
          "column": 1,
          "position": 1079
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": ");\n    setCopied(true);\n  };\n\n  useEffect(() => {\n    function resetStatus() {\n      if (!copied) return false;\n      setTimeout(() => {\n        setCopied(false);\n      }, 3000);\n    }\n    resetStatus();\n  }, [copied]);\n\n  return (\n    <>\n      <tr\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/InviteRow/index.jsx",
        "start": 27,
        "end": 44,
        "startLoc": {
          "line": 27,
          "column": 5,
          "position": 277
        },
        "endLoc": {
          "line": 44,
          "column": 9,
          "position": 381
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/NewBrowserExtensionApiKeyModal/index.jsx",
        "start": 36,
        "end": 44,
        "startLoc": {
          "line": 36,
          "column": 7,
          "position": 327
        },
        "endLoc": {
          "line": 44,
          "column": 2,
          "position": 374
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  }\n\n  function handleXButton() {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  }\n\n  useEffect(() => {\n    const filtered = SEARCH_PROVIDERS",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/index.jsx",
        "start": 120,
        "end": 135,
        "startLoc": {
          "line": 120,
          "column": 20,
          "position": 865
        },
        "endLoc": {
          "line": 135,
          "column": 17,
          "position": 978
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/index.jsx",
        "start": 51,
        "end": 66,
        "startLoc": {
          "line": 51,
          "column": 15,
          "position": 434
        },
        "endLoc": {
          "line": 66,
          "column": 5,
          "position": 547
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n            </label>\n            <label className=\"border-none relative inline-flex items-center ml-auto cursor-pointer\">\n              <input\n                type=\"checkbox\"\n                className=\"peer sr-only\"\n                checked={enabled}\n                onChange={() => toggleSkill(skill)}\n              />\n              <div className=\"peer-disabled:opacity-50 pointer-events-none peer h-6 w-11 rounded-full bg-[#CFCFD0] after:absolute after:left-[2px] after:top-[2px] after:h-5 after:w-5 after:rounded-full after:shadow-xl after:border-none after:bg-white after:box-shadow-md after:transition-all after:content-[''] peer-checked:bg-[#32D583] peer-checked:after:translate-x-full peer-checked:after:border-white peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-transparent\"></div>\n              <span className=\"ml-3 text-sm font-medium\"></span>\n            </label>\n          ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/SQLConnectorSelection/index.jsx",
        "start": 38,
        "end": 50,
        "startLoc": {
          "line": 38,
          "column": 6,
          "position": 330
        },
        "endLoc": {
          "line": 50,
          "column": 11,
          "position": 421
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx",
        "start": 116,
        "end": 128,
        "startLoc": {
          "line": 116,
          "column": 2,
          "position": 976
        },
        "endLoc": {
          "line": 128,
          "column": 13,
          "position": 1068
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "();\n    return false;\n  }\n\n  // Cannot do nested forms, it will cause all sorts of issues, so we portal this out\n  // to the parent container form so we don't have nested forms.\n  return createPortal(\n    <ModalWrapper isOpen={isOpen}>\n      <div className=\"fixed inset-0 z-50 overflow-auto bg-black bg-opacity-50 flex items-center justify-center\">\n        <div className=\"relative w-full max-w-2xl bg-theme-bg-secondary rounded-lg shadow border-2 border-theme-modal-border\">\n          <div className=\"relative p-6 border-b rounded-t border-theme-modal-border\">\n            <div className=\"w-full flex gap-x-2 items-center\">\n              <h3 className=\"text-xl font-semibold text-white overflow-hidden overflow-ellipsis whitespace-nowrap\">\n                New",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/SQLConnectorSelection/NewConnectionModal.jsx",
        "start": 69,
        "end": 82,
        "startLoc": {
          "line": 69,
          "column": 12,
          "position": 654
        },
        "endLoc": {
          "line": 82,
          "column": 4,
          "position": 747
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/WorkspaceLLMSelection/WorkspaceLLMItem/index.jsx",
        "start": 128,
        "end": 44,
        "startLoc": {
          "line": 128,
          "column": 11,
          "position": 964
        },
        "endLoc": {
          "line": 44,
          "column": 2,
          "position": 362
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n              </h3>\n            </div>\n            <button\n              onClick={handleClose}\n              type=\"button\"\n              className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n            >\n              <X size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          </div>\n          <form\n            ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/SQLConnectorSelection/NewConnectionModal.jsx",
        "start": 82,
        "end": 94,
        "startLoc": {
          "line": 82,
          "column": 11,
          "position": 752
        },
        "endLoc": {
          "line": 94,
          "column": 13,
          "position": 824
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx",
        "start": 44,
        "end": 55,
        "startLoc": {
          "line": 44,
          "column": 9,
          "position": 369
        },
        "endLoc": {
          "line": 55,
          "column": 2,
          "position": 441
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "</p>\n        <a\n          href=\"https://docs.anythingllm.com/mcp-compatibility/overview\"\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n          className=\"text-theme-text-secondary underline hover:text-cta-button\"\n        >\n          Learn more about MCP Servers.\n        </a>\n      </div>\n    );\n  }\n\n  return",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/MCPServers/index.jsx",
        "start": 109,
        "end": 122,
        "startLoc": {
          "line": 109,
          "column": 6,
          "position": 813
        },
        "endLoc": {
          "line": 122,
          "column": 7,
          "position": 878
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/MCPServers/index.jsx",
        "start": 93,
        "end": 106,
        "startLoc": {
          "line": 93,
          "column": 4,
          "position": 707
        },
        "endLoc": {
          "line": 106,
          "column": 3,
          "position": 772
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": ");\n    }\n  }\n\n  useEffect(() => {\n    const handleClickOutside = (event) => {\n      if (menuRef.current && !menuRef.current.contains(event.target)) {\n        setOpen(false);\n      }\n    };\n\n    document.addEventListener(\"mousedown\", handleClickOutside);\n    return () => {\n      document.removeEventListener(\"mousedown\", handleClickOutside);\n    };\n  }, []);\n\n  return",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/MCPServers/ServerPanel.jsx",
        "start": 54,
        "end": 71,
        "startLoc": {
          "line": 54,
          "column": 2,
          "position": 469
        },
        "endLoc": {
          "line": 71,
          "column": 7,
          "position": 593
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx",
        "start": 211,
        "end": 37,
        "startLoc": {
          "line": 211,
          "column": 8,
          "position": 1705
        },
        "endLoc": {
          "line": 37,
          "column": 3,
          "position": 350
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n  return (\n    <div className=\"relative\" ref={menuRef}>\n      <button\n        type=\"button\"\n        onClick={() => setOpen(!open)}\n        className=\"p-1.5 rounded-lg text-white hover:bg-theme-action-menu-item-hover transition-colors duration-300\"\n      >\n        <Gear className=\"h-5 w-5\" weight=\"bold\" />\n      </button>\n      {open && (\n        <div className=\"absolute w-[150px] top-1 left-7 mt-1 border-[1.5px] border-white/40 rounded-lg bg-theme-action-menu-bg flex flex-col shadow-[0_4px_14px_rgba(0,0,0,0.25)] text-white z-99 md:z-10",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/MCPServers/ServerPanel.jsx",
        "start": 70,
        "end": 81,
        "startLoc": {
          "line": 70,
          "column": 1,
          "position": 591
        },
        "endLoc": {
          "line": 81,
          "column": 178,
          "position": 685
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx",
        "start": 228,
        "end": 239,
        "startLoc": {
          "line": 228,
          "column": 2,
          "position": 1842
        },
        "endLoc": {
          "line": 239,
          "column": 179,
          "position": 1936
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ">\n            <input\n              type=\"checkbox\"\n              className=\"peer sr-only\"\n              checked={enabled}\n              onChange={() => toggleSkill(skill)}\n            />\n            <div className=\"peer-disabled:opacity-50 pointer-events-none peer h-6 w-11 rounded-full bg-[#CFCFD0] after:absolute after:left-[2px] after:top-[2px] after:h-5 after:w-5 after:rounded-full after:shadow-xl after:border-none after:bg-white after:box-shadow-md after:transition-all after:content-[''] peer-checked:bg-[#32D583] peer-checked:after:translate-x-full peer-checked:after:border-white peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-transparent\"></div>\n            <span className=\"ml-3 text-sm font-medium\"></span>\n          </label>\n        </div>\n        <img src={image} alt={title} className=\"w-full rounded-md\" />\n        <p className=\"text-theme-text-secondary text-opacity-60 text-xs font-medium py-1.5\">\n          {description}\n          ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/DefaultSkillPanel/index.jsx",
        "start": 34,
        "end": 48,
        "startLoc": {
          "line": 34,
          "column": 11,
          "position": 216
        },
        "endLoc": {
          "line": 48,
          "column": 11,
          "position": 337
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/index.jsx",
        "start": 168,
        "end": 48,
        "startLoc": {
          "line": 168,
          "column": 2,
          "position": 1244
        },
        "endLoc": {
          "line": 48,
          "column": 9,
          "position": 322
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ".active ? \"On\" : \"Off\"}\n            </div>\n            <CaretRight\n              size={14}\n              weight=\"bold\"\n              className=\"text-theme-text-secondary\"\n            />\n          </div>\n        </div>\n      ))}\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/AgentFlows/index.jsx",
        "start": 45,
        "end": 58,
        "startLoc": {
          "line": 45,
          "column": 5,
          "position": 322
        },
        "endLoc": {
          "line": 58,
          "column": 1,
          "position": 388
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/SkillList/index.jsx",
        "start": 48,
        "end": 61,
        "startLoc": {
          "line": 48,
          "column": 7,
          "position": 369
        },
        "endLoc": {
          "line": 61,
          "column": 1,
          "position": 435
        }
      }
    },
    {
      "format": "jsx",
      "lines": 34,
      "fragment": ", \"error\");\n    }\n  }\n\n  useEffect(() => {\n    const handleClickOutside = (event) => {\n      if (menuRef.current && !menuRef.current.contains(event.target)) {\n        setOpen(false);\n      }\n    };\n\n    document.addEventListener(\"mousedown\", handleClickOutside);\n    return () => {\n      document.removeEventListener(\"mousedown\", handleClickOutside);\n    };\n  }, []);\n\n  return (\n    <div className=\"relative\" ref={menuRef}>\n      <button\n        type=\"button\"\n        onClick={() => setOpen(!open)}\n        className=\"p-1.5 rounded-lg text-white hover:bg-theme-action-menu-item-hover transition-colors duration-300\"\n      >\n        <Gear className=\"h-5 w-5\" weight=\"bold\" />\n      </button>\n      {open && (\n        <div className=\"absolute w-[100px] -top-1 left-7 mt-1 border-[1.5px] border-white/40 rounded-lg bg-theme-action-menu-bg flex flex-col shadow-[0_4px_14px_rgba(0,0,0,0.25)] text-white z-99 md:z-10\">\n          <button\n            type=\"button\"\n            onClick={() => navigate(paths.agents.editAgent(flow.uuid))}\n            className=\"border-none flex items-center rounded-lg gap-x-2 hover:bg-theme-action-menu-item-hover py-1.5 px-2 transition-colors duration-200 w-full text-left\"\n          >\n            <span className=\"text-sm\">Edit",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/AgentFlows/FlowPanel.jsx",
        "start": 25,
        "end": 58,
        "startLoc": {
          "line": 25,
          "column": 25,
          "position": 244
        },
        "endLoc": {
          "line": 58,
          "column": 5,
          "position": 518
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx",
        "start": 211,
        "end": 245,
        "startLoc": {
          "line": 211,
          "column": 26,
          "position": 1702
        },
        "endLoc": {
          "line": 245,
          "column": 7,
          "position": 1974
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "}\n            </label>\n            <label className=\"border-none relative inline-flex items-center ml-auto cursor-pointer\">\n              <input\n                type=\"checkbox\"\n                className=\"peer sr-only\"\n                checked={isActive}\n                onChange={handleToggle}\n              />\n              <div className=\"peer-disabled:opacity-50 pointer-events-none peer h-6 w-11 rounded-full bg-[#CFCFD0] after:absolute after:left-[2px] after:top-[2px] after:h-5 after:w-5 after:rounded-full after:shadow-xl after:border-none after:bg-white after:box-shadow-md after:transition-all after:content-[''] peer-checked:bg-[#32D583] peer-checked:after:translate-x-full peer-checked:after:border-white peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-transparent\"></div>\n              <span className=\"ml-3 text-sm font-medium\"></span>\n            </label>\n            <ManageFlowMenu",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/AgentFlows/FlowPanel.jsx",
        "start": 103,
        "end": 115,
        "startLoc": {
          "line": 103,
          "column": 5,
          "position": 928
        },
        "endLoc": {
          "line": 115,
          "column": 15,
          "position": 1014
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/ImportedSkillConfig/index.jsx",
        "start": 116,
        "end": 128,
        "startLoc": {
          "line": 116,
          "column": 2,
          "position": 975
        },
        "endLoc": {
          "line": 128,
          "column": 16,
          "position": 1070
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "(false);\n      }\n    }\n\n    document.addEventListener(\"mousedown\", handleClickOutside);\n    return () => {\n      document.removeEventListener(\"mousedown\", handleClickOutside);\n    };\n  }, []);\n\n  return (\n    <div className=\"absolute top-[calc(40px+16px)] left-4 right-4",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/AgentBuilder/HeaderMenu/index.jsx",
        "start": 24,
        "end": 35,
        "startLoc": {
          "line": 24,
          "column": 16,
          "position": 270
        },
        "endLoc": {
          "line": 35,
          "column": 46,
          "position": 342
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx",
        "start": 83,
        "end": 72,
        "startLoc": {
          "line": 83,
          "column": 12,
          "position": 816
        },
        "endLoc": {
          "line": 72,
          "column": 9,
          "position": 604
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n\n  useEffect(() => {\n    if (!!window)\n      window.addEventListener(PROMPT_INPUT_EVENT, handlePromptUpdate);\n    return () =>\n      window?.removeEventListener(PROMPT_INPUT_EVENT, handlePromptUpdate);\n  }, []);\n\n  useEffect(() => {\n    if (!",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/index.jsx",
        "start": 58,
        "end": 68,
        "startLoc": {
          "line": 58,
          "column": 2,
          "position": 478
        },
        "endLoc": {
          "line": 68,
          "column": 2,
          "position": 556
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SpeechToText/index.jsx",
        "start": 83,
        "end": 93,
        "startLoc": {
          "line": 83,
          "column": 2,
          "position": 553
        },
        "endLoc": {
          "line": 93,
          "column": 11,
          "position": 631
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": ") {\n      if (file.type.startsWith(\"image/\")) {\n        newAccepted.push({\n          uid: v4(),\n          file,\n          contentString: await toBase64(file),\n          status: \"success\",\n          error: null,\n          type: \"attachment\",\n        });\n      } else {\n        // If the user is a default user, we do not want to allow them to upload files.\n        if (!!user && user.role === \"default\") continue;\n        newAccepted.push({\n          uid: v4(),\n          file,\n          contentString: null,\n          status: \"in_progress\",\n          error: null,\n          type: \"upload\",\n        });\n      }\n    }\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/DnDWrapper/index.jsx",
        "start": 141,
        "end": 165,
        "startLoc": {
          "line": 141,
          "column": 14,
          "position": 972
        },
        "endLoc": {
          "line": 165,
          "column": 1,
          "position": 1141
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/DnDWrapper/index.jsx",
        "start": 104,
        "end": 127,
        "startLoc": {
          "line": 104,
          "column": 6,
          "position": 721
        },
        "endLoc": {
          "line": 127,
          "column": 5,
          "position": 890
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "]);\n\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm mt-6\"\n        containerClassName=\"flex w-full\"\n      />\n    );\n  }\n\n  return (\n    <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/Members/index.jsx",
        "start": 32,
        "end": 49,
        "startLoc": {
          "line": 32,
          "column": 10,
          "position": 344
        },
        "endLoc": {
          "line": 49,
          "column": 4,
          "position": 426
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx",
        "start": 50,
        "end": 67,
        "startLoc": {
          "line": 50,
          "column": 2,
          "position": 427
        },
        "endLoc": {
          "line": 67,
          "column": 6,
          "position": 509
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": ");\n\n  const handleUpdate = async (e) => {\n    setSaving(true);\n    e.preventDefault();\n    const data = {};\n    const form = new FormData(formEl.current);\n    for (var [key, value] of form.entries()) data[key] = castToType(key, value);\n    const { workspace: updatedWorkspace, message } = await Workspace.update(\n      workspace.slug,\n      data\n    );\n    if (!!updatedWorkspace) {\n      showToast(\"Workspace updated!\", \"success\", { clear: true });\n    } else {\n      showToast(`Error: ${message}`, \"error\", { clear: true });\n    }\n    setSaving(false);\n    setHasChanges(false);\n  };\n\n  if (!workspace ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/GeneralAppearance/index.jsx",
        "start": 25,
        "end": 46,
        "startLoc": {
          "line": 25,
          "column": 2,
          "position": 267
        },
        "endLoc": {
          "line": 46,
          "column": 2,
          "position": 496
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/VectorDatabase/index.jsx",
        "start": 16,
        "end": 37,
        "startLoc": {
          "line": 16,
          "column": 5,
          "position": 174
        },
        "endLoc": {
          "line": 37,
          "column": 2,
          "position": 403
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ") return null;\n  return (\n    <div className=\"w-full relative\">\n      <form\n        ref={formEl}\n        onSubmit={handleUpdate}\n        className=\"w-1/2 flex flex-col gap-y-6\"\n      >\n        {hasChanges && (\n          <div className=\"absolute top-0 right-0\">\n            <CTAButton type=\"submit\">\n              {saving ? \"Updating...\" : \"Update Workspace\"}\n            </CTAButton>\n          </div>\n        )}\n        <WorkspaceName",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/GeneralAppearance/index.jsx",
        "start": 46,
        "end": 61,
        "startLoc": {
          "line": 46,
          "column": 8,
          "position": 500
        },
        "endLoc": {
          "line": 61,
          "column": 14,
          "position": 606
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/VectorDatabase/index.jsx",
        "start": 37,
        "end": 52,
        "startLoc": {
          "line": 37,
          "column": 10,
          "position": 403
        },
        "endLoc": {
          "line": 52,
          "column": 4,
          "position": 509
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "]);\n\n  const handleUpdate = async (e) => {\n    setSaving(true);\n    e.preventDefault();\n    const data = {};\n    const form = new FormData(formEl.current);\n    for (var [key, value] of form.entries()) data[key] = castToType(key, value);\n    const { workspace: updatedWorkspace, message } = await Workspace.update(\n      workspace.slug,\n      data\n    );\n    if (!!updatedWorkspace) {\n      showToast(\"Workspace updated!\", \"success\", { clear: true });\n    } else {\n      showToast(`Error: ${message}`, \"error\", { clear: true });\n    }\n    setSaving(false);\n    setHasChanges(false);\n  };\n\n  if (!workspace) return null;\n  return (\n    <div id",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/index.jsx",
        "start": 26,
        "end": 49,
        "startLoc": {
          "line": 26,
          "column": 2,
          "position": 273
        },
        "endLoc": {
          "line": 49,
          "column": 3,
          "position": 519
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/GeneralAppearance/index.jsx",
        "start": 25,
        "end": 39,
        "startLoc": {
          "line": 25,
          "column": 5,
          "position": 266
        },
        "endLoc": {
          "line": 39,
          "column": 10,
          "position": 419
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n        className=\"w-1/2 flex flex-col gap-y-6\"\n      >\n        {hasChanges && (\n          <div className=\"absolute top-0 right-0\">\n            <CTAButton type=\"submit\">\n              {saving ? \"Updating...\" : \"Update Workspace\"}\n            </CTAButton>\n          </div>\n        )}\n        <WorkspaceLLMSelection",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceSettings/ChatSettings/index.jsx",
        "start": 53,
        "end": 63,
        "startLoc": {
          "line": 53,
          "column": 2,
          "position": 553
        },
        "endLoc": {
          "line": 63,
          "column": 22,
          "position": 621
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/VectorDatabase/index.jsx",
        "start": 42,
        "end": 52,
        "startLoc": {
          "line": 42,
          "column": 2,
          "position": 441
        },
        "endLoc": {
          "line": 52,
          "column": 4,
          "position": 509
        }
      }
    },
    {
      "format": "javascript",
      "lines": 161,
      "fragment": "={settings} />,\n    description: \"Leverage the OpenAI Whisper-large model using your API key.\",\n  },\n  {\n    name: \"AnythingLLM Built-In\",\n    value: \"local\",\n    logo: AnythingLLMIcon,\n    options: (settings) => <NativeTranscriptionOptions settings={settings} />,\n    description: \"Run a built-in whisper model on this instance privately.\",\n  },\n];\n\nexport default function TranscriptionModelPreference() {\n  const [saving, setSaving] = useState(false);\n  const [hasChanges, setHasChanges] = useState(false);\n  const [settings, setSettings] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filteredProviders, setFilteredProviders] = useState([]);\n  const [selectedProvider, setSelectedProvider] = useState(null);\n  const [searchMenuOpen, setSearchMenuOpen] = useState(false);\n  const searchInputRef = useRef(null);\n  const { t } = useTranslation();\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = e.target;\n    const data = { WhisperProvider: selectedProvider };\n    const formData = new FormData(form);\n\n    for (var [key, value] of formData.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    setSaving(true);\n\n    if (error) {\n      showToast(`Failed to save preferences: ${error}`, \"error\");\n    } else {\n      showToast(\"Transcription preferences saved successfully.\", \"success\");\n    }\n    setSaving(false);\n    setHasChanges(!!error);\n  };\n\n  const updateProviderChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedProvider(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedProvider(_settings?.WhisperProvider || \"local\");\n      setLoading(false);\n    }\n    fetchKeys();\n  }, []);\n\n  useEffect(() => {\n    const filtered = PROVIDERS.filter((provider) =>\n      provider.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredProviders(filtered);\n  }, [searchQuery, selectedProvider]);\n\n  const selectedProviderObject = PROVIDERS.find(\n    (provider) => provider.value === selectedProvider\n  );\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form onSubmit={handleSubmit} className=\"flex w-full\">\n            <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] py-16 md:py-6\">\n              <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n                <div className=\"flex gap-x-4 items-center\">\n                  <p className=\"text-lg leading-6 font-bold text-white\">\n                    {t(\"transcription.title\")}\n                  </p>\n                </div>\n                <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60\">\n                  {t(\"transcription.description\")}\n                </p>\n              </div>\n              <div className=\"w-full justify-end flex\">\n                {hasChanges && (\n                  <CTAButton\n                    onClick={() => handleSubmit()}\n                    className=\"mt-3 mr-0 -mb-14 z-10\"\n                  >\n                    {saving ? \"Saving...\" : \"Save changes\"}\n                  </CTAButton>\n                )}\n              </div>\n              <div className=\"text-base font-bold text-white mt-6 mb-4\">\n                {t(\"transcription.provider\")}\n              </div>\n              <div className=\"relative\">\n                {searchMenuOpen && (\n                  <div\n                    className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n                    onClick={() => setSearchMenuOpen(false)}\n                  />\n                )}\n                {searchMenuOpen ? (\n                  <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n                    <div className=\"w-full flex flex-col gap-y-1\">\n                      <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                        <MagnifyingGlass\n                          size={20}\n                          weight=\"bold\"\n                          className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                        />\n                        <input\n                          type=\"text\"\n                          name=\"provider-search\"\n                          autoComplete=\"off\"\n                          placeholder=\"Search audio transcription providers\"\n                          className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none focus:outline-primary-button active:outline-primary-button outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                          onChange={(e) => setSearchQuery(e.target.value)}\n                          ref={searchInputRef}\n                          onKeyDown={(e) => {\n                            if (e.key === \"Enter\") e.preventDefault();\n                          }}\n                        />\n                        <X\n                          size={20}\n                          weight=\"bold\"\n                          className=\"cursor-pointer text-white hover:text-x-button\"\n                          onClick={handleXButton}\n                        />\n                      </div>\n                      <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                        {filteredProviders.map((provider) => (\n                          <LLMItem\n                            key={provider",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 21,
        "end": 181,
        "startLoc": {
          "line": 21,
          "column": 9,
          "position": 204
        },
        "endLoc": {
          "line": 181,
          "column": 9,
          "position": 1579
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 170,
        "end": 268,
        "startLoc": {
          "line": 170,
          "column": 9,
          "position": 1517
        },
        "endLoc": {
          "line": 268,
          "column": 4,
          "position": 2233
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedProvider",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 66,
        "end": 84,
        "startLoc": {
          "line": 66,
          "column": 20,
          "position": 690
        },
        "endLoc": {
          "line": 84,
          "column": 20,
          "position": 838
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 80,
        "end": 98,
        "startLoc": {
          "line": 80,
          "column": 15,
          "position": 850
        },
        "endLoc": {
          "line": 98,
          "column": 15,
          "position": 998
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": ");\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 99,
        "end": 118,
        "startLoc": {
          "line": 99,
          "column": 3,
          "position": 975
        },
        "endLoc": {
          "line": 118,
          "column": 2,
          "position": 1106
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 182,
        "end": 202,
        "startLoc": {
          "line": 182,
          "column": 12,
          "position": 1616
        },
        "endLoc": {
          "line": 202,
          "column": 13,
          "position": 1747
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": ")}\n              </div>\n              <div className=\"relative\">\n                {searchMenuOpen && (\n                  <div\n                    className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n                    onClick={() => setSearchMenuOpen(false)}\n                  />\n                )}\n                {searchMenuOpen ? (\n                  <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n                    <div className=\"w-full flex flex-col gap-y-1\">\n                      <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                        <MagnifyingGlass\n                          size={20}\n                          weight=\"bold\"\n                          className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                        />\n                        <input\n                          type=\"text\"\n                          name=\"provider-search",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 141,
        "end": 161,
        "startLoc": {
          "line": 141,
          "column": 25,
          "position": 1298
        },
        "endLoc": {
          "line": 161,
          "column": 16,
          "position": 1433
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 228,
        "end": 248,
        "startLoc": {
          "line": 228,
          "column": 24,
          "position": 1952
        },
        "endLoc": {
          "line": 248,
          "column": 11,
          "position": 2087
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\"\n                          onChange={(e) => setSearchQuery(e.target.value)}\n                          ref={searchInputRef}\n                          onKeyDown={(e) => {\n                            if (e.key === \"Enter\") e.preventDefault();\n                          }}\n                        />\n                        <X\n                          size={20}\n                          weight=\"bold\"\n                          className=\"cursor-pointer text-white hover:text-x-button\"\n                          onClick={handleXButton}\n                        />\n                      </div>\n                      <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                        {filteredProviders",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 164,
        "end": 179,
        "startLoc": {
          "line": 164,
          "column": 252,
          "position": 1452
        },
        "endLoc": {
          "line": 179,
          "column": 18,
          "position": 1560
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 251,
        "end": 266,
        "startLoc": {
          "line": 251,
          "column": 180,
          "position": 2106
        },
        "endLoc": {
          "line": 266,
          "column": 13,
          "position": 2214
        }
      }
    },
    {
      "format": "jsx",
      "lines": 28,
      "fragment": "\n                            key={provider.name}\n                            name={provider.name}\n                            value={provider.value}\n                            image={provider.logo}\n                            description={provider.description}\n                            checked={selectedProvider === provider.value}\n                            onClick={() => updateProviderChoice(provider.value)}\n                          />\n                        ))}\n                      </div>\n                    </div>\n                  </div>\n                ) : (\n                  <button\n                    className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n                    type=\"button\"\n                    onClick={() => setSearchMenuOpen(true)}\n                  >\n                    <div className=\"flex gap-x-4 items-center\">\n                      <img\n                        src={selectedProviderObject.logo}\n                        alt={`${selectedProviderObject.name} logo`}\n                        className=\"w-10 h-10 rounded-md\"\n                      />\n                      <div className=\"flex flex-col text-left\">\n                        <div className=\"text-sm font-semibold text-white\">\n                          {selectedProviderObject",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 180,
        "end": 207,
        "startLoc": {
          "line": 180,
          "column": 8,
          "position": 1575
        },
        "endLoc": {
          "line": 207,
          "column": 23,
          "position": 1770
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 267,
        "end": 294,
        "startLoc": {
          "line": 267,
          "column": 13,
          "position": 2229
        },
        "endLoc": {
          "line": 294,
          "column": 18,
          "position": 2424
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": ".description}\n                        </div>\n                      </div>\n                    </div>\n                    <CaretUpDown\n                      size={24}\n                      weight=\"bold\"\n                      className=\"text-white\"\n                    />\n                  </button>\n                )}\n              </div>\n              <div\n                onChange={() => setHasChanges(true)}\n                className=\"mt-4 flex flex-col gap-y-1\"\n              >\n                {selectedProvider",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 210,
        "end": 226,
        "startLoc": {
          "line": 210,
          "column": 23,
          "position": 1794
        },
        "endLoc": {
          "line": 226,
          "column": 17,
          "position": 1879
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 297,
        "end": 313,
        "startLoc": {
          "line": 297,
          "column": 18,
          "position": 2448
        },
        "endLoc": {
          "line": 313,
          "column": 12,
          "position": 2533
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": ");\n      setLoading(false);\n    }\n    fetchIsMultiUserMode();\n  }, []);\n\n  if (loading) {\n    return (\n      <div className=\"h-1/2 transition-all duration-500 relative md:ml-[2px] md:mr-[8px] md:my-[16px] md:rounded-[26px] p-[18px] h-full overflow-y-scroll\">\n        <div className=\"w-full h-full flex justify-center items-center\">\n          <PreLoader />\n        </div>\n      </div>\n    );\n  }\n\n  if",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Security/index.jsx",
        "start": 245,
        "end": 261,
        "startLoc": {
          "line": 245,
          "column": 13,
          "position": 1946
        },
        "endLoc": {
          "line": 261,
          "column": 3,
          "position": 2036
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Security/index.jsx",
        "start": 69,
        "end": 85,
        "startLoc": {
          "line": 69,
          "column": 21,
          "position": 634
        },
        "endLoc": {
          "line": 85,
          "column": 7,
          "position": 724
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": ")}\n          </p>\n        </div>\n        {hasChanges && (\n          <div className=\"flex justify-end\">\n            <CTAButton\n              onClick={() => handleSubmit()}\n              className=\"mt-3 mr-0 -mb-20 z-10\"\n            >\n              {saving ? t(\"common.saving\") : t(\"common.save\")}\n            </CTAButton>\n          </div>\n        )}\n        <div className=\"relative w-full max-h-full\">\n          <div className=\"relative rounded-lg\">\n            <div className=\"flex items-start justify-between px-6 py-4\"></div>\n            <div className=\"space-y-6 flex h-full w-full\">\n              <div className=\"w-full flex flex-col gap-y-4\">\n                <div className=\"\">\n                  <label className=\"mb-2.5 block font-medium text-white\">\n                    {t",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Security/index.jsx",
        "start": 276,
        "end": 296,
        "startLoc": {
          "line": 276,
          "column": 29,
          "position": 2162
        },
        "endLoc": {
          "line": 296,
          "column": 2,
          "position": 2333
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Security/index.jsx",
        "start": 99,
        "end": 119,
        "startLoc": {
          "line": 99,
          "column": 20,
          "position": 838
        },
        "endLoc": {
          "line": 119,
          "column": 21,
          "position": 1009
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\"\n                        minLength={8}\n                        required={true}\n                        autoComplete=\"off\"\n                        defaultValue={usePassword ? \"********\" : \"\"}\n                      />\n                    </div>\n                  </div>\n                )}\n              </div>\n            </div>\n            <div className=\"flex items-center justify-between space-x-14\">\n              <p className=\"text-white text-opacity-80 light:text-theme-text text-xs rounded-lg w-96",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Security/index.jsx",
        "start": 322,
        "end": 334,
        "startLoc": {
          "line": 322,
          "column": 23,
          "position": 2507
        },
        "endLoc": {
          "line": 334,
          "column": 73,
          "position": 2584
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Security/index.jsx",
        "start": 169,
        "end": 181,
        "startLoc": {
          "line": 169,
          "column": 20,
          "position": 1316
        },
        "endLoc": {
          "line": 181,
          "column": 51,
          "position": 1393
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ");\n\n  const LLMSelection =\n    LLM_SELECTION_PRIVACY?.[llmChoice] || FALLBACKS.LLM(llmChoice);\n  const EmbeddingEngine =\n    EMBEDDING_ENGINE_PRIVACY?.[embeddingEngine] ||\n    FALLBACKS.EMBEDDING(embeddingEngine);\n  const VectorDb = VECTOR_DB_PRIVACY?.[vectorDb] || FALLBACKS.VECTOR(vectorDb);\n\n  return (\n    <div className=\"py-8 w-full flex items-start justify-center flex-col gap-y-6 border-b-2 border-theme-sidebar-border",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx",
        "start": 69,
        "end": 79,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 587
        },
        "endLoc": {
          "line": 79,
          "column": 100,
          "position": 679
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/DataHandling/index.jsx",
        "start": 469,
        "end": 479,
        "startLoc": {
          "line": 469,
          "column": 5,
          "position": 2924
        },
        "endLoc": {
          "line": 479,
          "column": 57,
          "position": 3016
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n          </div>\n          <div className=\"flex items-center gap-2.5\">\n            <img\n              src={LLMSelection.logo}\n              alt=\"LLM Logo\"\n              className=\"w-8 h-8 rounded\"\n            />\n            <p className=\"text-theme-text-primary text-sm font-bold\">\n              {LLMSelection.name}\n            </p>\n          </div>\n          <ul className=\"flex flex-col list-disc ml-4\">\n            {LLMSelection.description.map((desc) => (\n              <li className=\"text-theme-text-secondary text-sm",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx",
        "start": 83,
        "end": 97,
        "startLoc": {
          "line": 83,
          "column": 2,
          "position": 723
        },
        "endLoc": {
          "line": 97,
          "column": 34,
          "position": 828
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/DataHandling/index.jsx",
        "start": 483,
        "end": 497,
        "startLoc": {
          "line": 483,
          "column": 10,
          "position": 3057
        },
        "endLoc": {
          "line": 497,
          "column": 32,
          "position": 3162
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ")}\n          </div>\n          <div className=\"flex items-center gap-2.5\">\n            <img\n              src={EmbeddingEngine.logo}\n              alt=\"LLM Logo\"\n              className=\"w-8 h-8 rounded\"\n            />\n            <p className=\"text-theme-text-primary text-sm font-bold\">\n              {EmbeddingEngine.name}\n            </p>\n          </div>\n          <ul className=\"flex flex-col list-disc ml-4\">\n            {EmbeddingEngine.description.map((desc) => (\n              <li className=\"text-theme-text-secondary text-sm",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx",
        "start": 103,
        "end": 117,
        "startLoc": {
          "line": 103,
          "column": 20,
          "position": 880
        },
        "endLoc": {
          "line": 117,
          "column": 34,
          "position": 987
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx",
        "start": 83,
        "end": 517,
        "startLoc": {
          "line": 83,
          "column": 14,
          "position": 721
        },
        "endLoc": {
          "line": 517,
          "column": 32,
          "position": 3318
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ")}\n          </div>\n          <div className=\"flex items-center gap-2.5\">\n            <img\n              src={VectorDb.logo}\n              alt=\"LLM Logo\"\n              className=\"w-8 h-8 rounded\"\n            />\n            <p className=\"text-theme-text-primary text-sm font-bold\">\n              {VectorDb.name}\n            </p>\n          </div>\n          <ul className=\"flex flex-col list-disc ml-4\">\n            {VectorDb.description.map((desc) => (\n              <li className=\"text-theme-text-secondary text-sm",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx",
        "start": 124,
        "end": 138,
        "startLoc": {
          "line": 124,
          "column": 17,
          "position": 1040
        },
        "endLoc": {
          "line": 138,
          "column": 34,
          "position": 1147
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/PrivacyAndData/index.jsx",
        "start": 83,
        "end": 538,
        "startLoc": {
          "line": 83,
          "column": 14,
          "position": 721
        },
        "endLoc": {
          "line": 538,
          "column": 32,
          "position": 3475
        }
      }
    },
    {
      "format": "javascript",
      "lines": 319,
      "fragment": "={settings} />,\n    description: \"The standard option for most non-commercial use.\",\n    requiredConfig: [\"OpenAiKey\"],\n  },\n  {\n    name: \"Azure OpenAI\",\n    value: \"azure\",\n    logo: AzureOpenAiLogo,\n    options: (settings) => <AzureAiOptions settings={settings} />,\n    description: \"The enterprise option of OpenAI hosted on Azure services.\",\n    requiredConfig: [\"AzureOpenAiEndpoint\"],\n  },\n  {\n    name: \"Anthropic\",\n    value: \"anthropic\",\n    logo: AnthropicLogo,\n    options: (settings) => <AnthropicAiOptions settings={settings} />,\n    description: \"A friendly AI Assistant hosted by Anthropic.\",\n    requiredConfig: [\"AnthropicApiKey\"],\n  },\n  {\n    name: \"Gemini\",\n    value: \"gemini\",\n    logo: GeminiLogo,\n    options: (settings) => <GeminiLLMOptions settings={settings} />,\n    description: \"Google's largest and most capable AI model\",\n    requiredConfig: [\"GeminiLLMApiKey\"],\n  },\n  {\n    name: \"NVIDIA NIM\",\n    value: \"nvidia-nim\",\n    logo: NvidiaNimLogo,\n    options: (settings) => <NvidiaNimOptions settings={settings} />,\n    description:\n      \"Run full parameter LLMs directly on your NVIDIA RTX GPU using NVIDIA NIM.\",\n    requiredConfig: [\"NvidiaNimLLMBasePath\"],\n  },\n  {\n    name: \"HuggingFace\",\n    value: \"huggingface\",\n    logo: HuggingFaceLogo,\n    options: (settings) => <HuggingFaceOptions settings={settings} />,\n    description:\n      \"Access 150,000+ open-source LLMs and the world's AI community\",\n    requiredConfig: [\n      \"HuggingFaceLLMEndpoint\",\n      \"HuggingFaceLLMAccessToken\",\n      \"HuggingFaceLLMTokenLimit\",\n    ],\n  },\n  {\n    name: \"Ollama\",\n    value: \"ollama\",\n    logo: OllamaLogo,\n    options: (settings) => <OllamaLLMOptions settings={settings} />,\n    description: \"Run LLMs locally on your own machine.\",\n    requiredConfig: [\"OllamaLLMBasePath\"],\n  },\n  {\n    name: \"Dell Pro AI Studio\",\n    value: \"dpais\",\n    logo: DellProAiStudioLogo,\n    options: (settings) => <DellProAiStudioOptions settings={settings} />,\n    description:\n      \"Run powerful LLMs quickly on NPU powered by Dell Pro AI Studio.\",\n    requiredConfig: [\n      \"DellProAiStudioBasePath\",\n      \"DellProAiStudioModelPref\",\n      \"DellProAiStudioTokenLimit\",\n    ],\n  },\n  {\n    name: \"LM Studio\",\n    value: \"lmstudio\",\n    logo: LMStudioLogo,\n    options: (settings) => <LMStudioOptions settings={settings} />,\n    description:\n      \"Discover, download, and run thousands of cutting edge LLMs in a few clicks.\",\n    requiredConfig: [\"LMStudioBasePath\"],\n  },\n  {\n    name: \"Local AI\",\n    value: \"localai\",\n    logo: LocalAiLogo,\n    options: (settings) => <LocalAiOptions settings={settings} />,\n    description: \"Run LLMs locally on your own machine.\",\n    requiredConfig: [\"LocalAiApiKey\", \"LocalAiBasePath\", \"LocalAiTokenLimit\"],\n  },\n  {\n    name: \"Novita AI\",\n    value: \"novita\",\n    logo: NovitaLogo,\n    options: (settings) => <NovitaLLMOptions settings={settings} />,\n    description:\n      \"Reliable, Scalable, and Cost-Effective for LLMs from Novita AI\",\n    requiredConfig: [\"NovitaLLMApiKey\"],\n  },\n  {\n    name: \"Together AI\",\n    value: \"togetherai\",\n    logo: TogetherAILogo,\n    options: (settings) => <TogetherAiOptions settings={settings} />,\n    description: \"Run open source models from Together AI.\",\n    requiredConfig: [\"TogetherAiApiKey\"],\n  },\n  {\n    name: \"Fireworks AI\",\n    value: \"fireworksai\",\n    logo: FireworksAILogo,\n    options: (settings) => <FireworksAiOptions settings={settings} />,\n    description:\n      \"The fastest and most efficient inference engine to build production-ready, compound AI systems.\",\n    requiredConfig: [\"FireworksAiLLMApiKey\"],\n  },\n  {\n    name: \"Mistral\",\n    value: \"mistral\",\n    logo: MistralLogo,\n    options: (settings) => <MistralOptions settings={settings} />,\n    description: \"Run open source models from Mistral AI.\",\n    requiredConfig: [\"MistralApiKey\"],\n  },\n  {\n    name: \"Perplexity AI\",\n    value: \"perplexity\",\n    logo: PerplexityLogo,\n    options: (settings) => <PerplexityOptions settings={settings} />,\n    description:\n      \"Run powerful and internet-connected models hosted by Perplexity AI.\",\n    requiredConfig: [\"PerplexityApiKey\"],\n  },\n  {\n    name: \"OpenRouter\",\n    value: \"openrouter\",\n    logo: OpenRouterLogo,\n    options: (settings) => <OpenRouterOptions settings={settings} />,\n    description: \"A unified interface for LLMs.\",\n    requiredConfig: [\"OpenRouterApiKey\"],\n  },\n  {\n    name: \"Groq\",\n    value: \"groq\",\n    logo: GroqLogo,\n    options: (settings) => <GroqAiOptions settings={settings} />,\n    description:\n      \"The fastest LLM inferencing available for real-time AI applications.\",\n    requiredConfig: [\"GroqApiKey\"],\n  },\n  {\n    name: \"KoboldCPP\",\n    value: \"koboldcpp\",\n    logo: KoboldCPPLogo,\n    options: (settings) => <KoboldCPPOptions settings={settings} />,\n    description: \"Run local LLMs using koboldcpp.\",\n    requiredConfig: [\n      \"KoboldCPPModelPref\",\n      \"KoboldCPPBasePath\",\n      \"KoboldCPPTokenLimit\",\n    ],\n  },\n  {\n    name: \"Oobabooga Web UI\",\n    value: \"textgenwebui\",\n    logo: TextGenWebUILogo,\n    options: (settings) => <TextGenWebUIOptions settings={settings} />,\n    description: \"Run local LLMs using Oobabooga's Text Generation Web UI.\",\n    requiredConfig: [\"TextGenWebUIBasePath\", \"TextGenWebUITokenLimit\"],\n  },\n  {\n    name: \"Cohere\",\n    value: \"cohere\",\n    logo: CohereLogo,\n    options: (settings) => <CohereAiOptions settings={settings} />,\n    description: \"Run Cohere's powerful Command models.\",\n    requiredConfig: [\"CohereApiKey\"],\n  },\n  {\n    name: \"LiteLLM\",\n    value: \"litellm\",\n    logo: LiteLLMLogo,\n    options: (settings) => <LiteLLMOptions settings={settings} />,\n    description: \"Run LiteLLM's OpenAI compatible proxy for various LLMs.\",\n    requiredConfig: [\"LiteLLMBasePath\"],\n  },\n  {\n    name: \"DeepSeek\",\n    value: \"deepseek\",\n    logo: DeepSeekLogo,\n    options: (settings) => <DeepSeekOptions settings={settings} />,\n    description: \"Run DeepSeek's powerful LLMs.\",\n    requiredConfig: [\"DeepSeekApiKey\"],\n  },\n  {\n    name: \"PPIO\",\n    value: \"ppio\",\n    logo: PPIOLogo,\n    options: (settings) => <PPIOLLMOptions settings={settings} />,\n    description:\n      \"Run stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.\",\n    requiredConfig: [\"PPIOApiKey\"],\n  },\n  {\n    name: \"AWS Bedrock\",\n    value: \"bedrock\",\n    logo: AWSBedrockLogo,\n    options: (settings) => <AWSBedrockLLMOptions settings={settings} />,\n    description: \"Run powerful foundation models privately with AWS Bedrock.\",\n    requiredConfig: [\n      \"AwsBedrockLLMAccessKeyId\",\n      \"AwsBedrockLLMAccessKey\",\n      \"AwsBedrockLLMRegion\",\n      \"AwsBedrockLLMModel\",\n    ],\n  },\n  {\n    name: \"APIpie\",\n    value: \"apipie\",\n    logo: APIPieLogo,\n    options: (settings) => <ApiPieLLMOptions settings={settings} />,\n    description: \"A unified API of AI services from leading providers\",\n    requiredConfig: [\"ApipieLLMApiKey\", \"ApipieLLMModelPref\"],\n  },\n  {\n    name: \"Generic OpenAI\",\n    value: \"generic-openai\",\n    logo: GenericOpenAiLogo,\n    options: (settings) => <GenericOpenAiOptions settings={settings} />,\n    description:\n      \"Connect to any OpenAi-compatible service via a custom configuration\",\n    requiredConfig: [\n      \"GenericOpenAiBasePath\",\n      \"GenericOpenAiModelPref\",\n      \"GenericOpenAiTokenLimit\",\n      \"GenericOpenAiKey\",\n    ],\n  },\n  {\n    name: \"xAI\",\n    value: \"xai\",\n    logo: XAILogo,\n    options: (settings) => <XAILLMOptions settings={settings} />,\n    description: \"Run xAI's powerful LLMs like Grok-2 and more.\",\n    requiredConfig: [\"XAIApiKey\", \"XAIModelPref\"],\n  },\n];\n\nexport default function GeneralLLMPreference() {\n  const [saving, setSaving] = useState(false);\n  const [hasChanges, setHasChanges] = useState(false);\n  const [settings, setSettings] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filteredLLMs, setFilteredLLMs] = useState([]);\n  const [selectedLLM, setSelectedLLM] = useState(null);\n  const [searchMenuOpen, setSearchMenuOpen] = useState(false);\n  const searchInputRef = useRef(null);\n  const { t } = useTranslation();\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = e.target;\n    const data = { LLMProvider: selectedLLM };\n    const formData = new FormData(form);\n\n    for (var [key, value] of formData.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    setSaving(true);\n\n    if (error) {\n      showToast(`Failed to save LLM settings: ${error}`, \"error\");\n    } else {\n      showToast(\"LLM preferences saved successfully.\", \"success\");\n    }\n    setSaving(false);\n    setHasChanges(!!error);\n  };\n\n  const updateLLMChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedLLM(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedLLM(_settings?.LLMProvider);\n      setLoading(false);\n    }\n    fetchKeys();\n  }, []);\n\n  useEffect(() => {\n    const filtered = AVAILABLE_LLM_PROVIDERS.filter((llm) =>\n      llm.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredLLMs(filtered);\n  }, [searchQuery, selectedLLM]);\n\n  const selectedLLMObject = AVAILABLE_LLM_PROVIDERS.find(\n    (llm) => llm.value === selectedLLM\n  );\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 74,
        "end": 392,
        "startLoc": {
          "line": 74,
          "column": 9,
          "position": 667
        },
        "endLoc": {
          "line": 392,
          "column": 2,
          "position": 3240
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 71,
        "end": 160,
        "startLoc": {
          "line": 71,
          "column": 9,
          "position": 629
        },
        "endLoc": {
          "line": 160,
          "column": 9,
          "position": 1320
        }
      }
    },
    {
      "format": "javascript",
      "lines": 223,
      "fragment": "={settings} />,\n    description: \"Run Cohere's powerful Command models.\",\n    requiredConfig: [\"CohereApiKey\"],\n  },\n  {\n    name: \"LiteLLM\",\n    value: \"litellm\",\n    logo: LiteLLMLogo,\n    options: (settings) => <LiteLLMOptions settings={settings} />,\n    description: \"Run LiteLLM's OpenAI compatible proxy for various LLMs.\",\n    requiredConfig: [\"LiteLLMBasePath\"],\n  },\n  {\n    name: \"DeepSeek\",\n    value: \"deepseek\",\n    logo: DeepSeekLogo,\n    options: (settings) => <DeepSeekOptions settings={settings} />,\n    description: \"Run DeepSeek's powerful LLMs.\",\n    requiredConfig: [\"DeepSeekApiKey\"],\n  },\n  {\n    name: \"PPIO\",\n    value: \"ppio\",\n    logo: PPIOLogo,\n    options: (settings) => <PPIOLLMOptions settings={settings} />,\n    description:\n      \"Run stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.\",\n    requiredConfig: [\"PPIOApiKey\"],\n  },\n  {\n    name: \"AWS Bedrock\",\n    value: \"bedrock\",\n    logo: AWSBedrockLogo,\n    options: (settings) => <AWSBedrockLLMOptions settings={settings} />,\n    description: \"Run powerful foundation models privately with AWS Bedrock.\",\n    requiredConfig: [\n      \"AwsBedrockLLMAccessKeyId\",\n      \"AwsBedrockLLMAccessKey\",\n      \"AwsBedrockLLMRegion\",\n      \"AwsBedrockLLMModel\",\n    ],\n  },\n  {\n    name: \"APIpie\",\n    value: \"apipie\",\n    logo: APIPieLogo,\n    options: (settings) => <ApiPieLLMOptions settings={settings} />,\n    description: \"A unified API of AI services from leading providers\",\n    requiredConfig: [\"ApipieLLMApiKey\", \"ApipieLLMModelPref\"],\n  },\n  {\n    name: \"Generic OpenAI\",\n    value: \"generic-openai\",\n    logo: GenericOpenAiLogo,\n    options: (settings) => <GenericOpenAiOptions settings={settings} />,\n    description:\n      \"Connect to any OpenAi-compatible service via a custom configuration\",\n    requiredConfig: [\n      \"GenericOpenAiBasePath\",\n      \"GenericOpenAiModelPref\",\n      \"GenericOpenAiTokenLimit\",\n      \"GenericOpenAiKey\",\n    ],\n  },\n  {\n    name: \"xAI\",\n    value: \"xai\",\n    logo: XAILogo,\n    options: (settings) => <XAILLMOptions settings={settings} />,\n    description: \"Run xAI's powerful LLMs like Grok-2 and more.\",\n    requiredConfig: [\"XAIApiKey\", \"XAIModelPref\"],\n  },\n];\n\nexport default function GeneralLLMPreference() {\n  const [saving, setSaving] = useState(false);\n  const [hasChanges, setHasChanges] = useState(false);\n  const [settings, setSettings] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filteredLLMs, setFilteredLLMs] = useState([]);\n  const [selectedLLM, setSelectedLLM] = useState(null);\n  const [searchMenuOpen, setSearchMenuOpen] = useState(false);\n  const searchInputRef = useRef(null);\n  const { t } = useTranslation();\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = e.target;\n    const data = { LLMProvider: selectedLLM };\n    const formData = new FormData(form);\n\n    for (var [key, value] of formData.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    setSaving(true);\n\n    if (error) {\n      showToast(`Failed to save LLM settings: ${error}`, \"error\");\n    } else {\n      showToast(\"LLM preferences saved successfully.\", \"success\");\n    }\n    setSaving(false);\n    setHasChanges(!!error);\n  };\n\n  const updateLLMChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedLLM(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedLLM(_settings?.LLMProvider);\n      setLoading(false);\n    }\n    fetchKeys();\n  }, []);\n\n  useEffect(() => {\n    const filtered = AVAILABLE_LLM_PROVIDERS.filter((llm) =>\n      llm.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredLLMs(filtered);\n  }, [searchQuery, selectedLLM]);\n\n  const selectedLLMObject = AVAILABLE_LLM_PROVIDERS.find(\n    (llm) => llm.value === selectedLLM\n  );\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form onSubmit={handleSubmit} className=\"flex w-full\">\n            <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n              <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n                <div className=\"flex gap-x-4 items-center\">\n                  <p className=\"text-lg leading-6 font-bold text-white\">\n                    {t(\"llm.title\")}\n                  </p>\n                </div>\n                <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60\">\n                  {t(\"llm.description\")}\n                </p>\n              </div>\n              <div className=\"w-full justify-end flex\">\n                {hasChanges && (\n                  <CTAButton\n                    onClick={() => handleSubmit()}\n                    className=\"mt-3 mr-0 -mb-14 z-10\"\n                  >\n                    {saving ? \"Saving...\" : \"Save changes\"}\n                  </CTAButton>\n                )}\n              </div>\n              <div className=\"text-base font-bold text-white mt-6 mb-4\">\n                {t(\"llm.provider\")}\n              </div>\n              <div className=\"relative\">\n                {searchMenuOpen && (\n                  <div\n                    className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n                    onClick={() => setSearchMenuOpen(false)}\n                  />\n                )}\n                {searchMenuOpen ? (\n                  <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n                    <div className=\"w-full flex flex-col gap-y-1\">\n                      <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                        <MagnifyingGlass\n                          size={20}\n                          weight=\"bold\"\n                          className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                        />\n                        <input\n                          type=\"text\"\n                          name=\"llm-search\"\n                          autoComplete=\"off\"\n                          placeholder=\"Search all LLM providers\"\n                          className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                          onChange={(e) => setSearchQuery(e.target.value)}\n                          ref={searchInputRef}\n                          onKeyDown={(e) => {\n                            if (e.key === \"Enter\") e.preventDefault();\n                          }}\n                        />\n                        <X\n                          size={20}\n                          weight=\"bold\"\n                          className=\"cursor-pointer text-white hover:text-x-button\"\n                          onClick={handleXButton}\n                        />\n                      </div>\n                      <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                        {filteredLLMs.map((llm) => {\n                          return (\n                            <LLMItem\n                              key={llm",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 246,
        "end": 468,
        "startLoc": {
          "line": 246,
          "column": 9,
          "position": 1977
        },
        "endLoc": {
          "line": 468,
          "column": 4,
          "position": 3808
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 125,
        "end": 268,
        "startLoc": {
          "line": 125,
          "column": 9,
          "position": 1208
        },
        "endLoc": {
          "line": 268,
          "column": 4,
          "position": 2233
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": ";\nimport LMStudioLogo from \"@/media/llmprovider/lmstudio.png\";\nimport LocalAiLogo from \"@/media/llmprovider/localai.png\";\nimport TogetherAILogo from \"@/media/llmprovider/togetherai.png\";\nimport FireworksAILogo from \"@/media/llmprovider/fireworksai.jpeg\";\nimport MistralLogo from \"@/media/llmprovider/mistral.jpeg\";\nimport HuggingFaceLogo from \"@/media/llmprovider/huggingface.png\";\nimport PerplexityLogo from \"@/media/llmprovider/perplexity.png\";\nimport OpenRouterLogo from \"@/media/llmprovider/openrouter.jpeg\";\nimport GroqLogo from \"@/media/llmprovider/groq.png\";\nimport KoboldCPPLogo from \"@/media/llmprovider/koboldcpp.png\";\nimport TextGenWebUILogo from \"@/media/llmprovider/text-generation-webui.png\";\nimport CohereLogo",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 14,
        "end": 26,
        "startLoc": {
          "line": 14,
          "column": 33,
          "position": 145
        },
        "endLoc": {
          "line": 26,
          "column": 11,
          "position": 248
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 8,
        "end": 20,
        "startLoc": {
          "line": 8,
          "column": 33,
          "position": 84
        },
        "endLoc": {
          "line": 20,
          "column": 12,
          "position": 187
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ";\nimport PerplexityOptions from \"@/components/LLMSelection/PerplexityOptions\";\nimport OpenRouterOptions from \"@/components/LLMSelection/OpenRouterOptions\";\nimport GroqAiOptions from \"@/components/LLMSelection/GroqAiOptions\";\nimport CohereAiOptions from \"@/components/LLMSelection/CohereAiOptions\";\nimport KoboldCPPOptions from \"@/components/LLMSelection/KoboldCPPOptions\";\nimport TextGenWebUIOptions from \"@/components/LLMSelection/TextGenWebUIOptions\";\nimport LiteLLMOptions from \"@/components/LLMSelection/LiteLLMOptions\";\nimport AWSBedrockLLMOptions from \"@/components/LLMSelection/AwsBedrockLLMOptions\";\nimport DeepSeekOptions from \"@/components/LLMSelection/DeepSeekOptions\";\nimport ApiPieLLMOptions from \"@/components/LLMSelection/ApiPieOptions\";\nimport XAILLMOptions",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 49,
        "end": 60,
        "startLoc": {
          "line": 49,
          "column": 47,
          "position": 452
        },
        "endLoc": {
          "line": 60,
          "column": 14,
          "position": 546
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 42,
        "end": 53,
        "startLoc": {
          "line": 42,
          "column": 47,
          "position": 382
        },
        "endLoc": {
          "line": 53,
          "column": 17,
          "position": 476
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedLLM",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 353,
        "end": 371,
        "startLoc": {
          "line": 353,
          "column": 15,
          "position": 2919
        },
        "endLoc": {
          "line": 371,
          "column": 15,
          "position": 3067
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 80,
        "end": 98,
        "startLoc": {
          "line": 80,
          "column": 15,
          "position": 850
        },
        "endLoc": {
          "line": 98,
          "column": 15,
          "position": 998
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form onSubmit={handleSubmit} className=\"flex w-full\">\n            <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 386,
        "end": 405,
        "startLoc": {
          "line": 386,
          "column": 2,
          "position": 3202
        },
        "endLoc": {
          "line": 405,
          "column": 61,
          "position": 3351
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 183,
        "end": 119,
        "startLoc": {
          "line": 183,
          "column": 1,
          "position": 1619
        },
        "endLoc": {
          "line": 119,
          "column": 61,
          "position": 1127
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ")}\n                </p>\n              </div>\n              <div className=\"w-full justify-end flex\">\n                {hasChanges && (\n                  <CTAButton\n                    onClick={() => handleSubmit()}\n                    className=\"mt-3 mr-0 -mb-14 z-10\"\n                  >\n                    {saving ? \"Saving...\" : \"Save changes\"}\n                  </CTAButton>\n                )}\n              </div>\n              <div className=\"text-base font-bold text-white mt-6 mb-4\">\n                {t(\"llm.provider\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 413,
        "end": 427,
        "startLoc": {
          "line": 413,
          "column": 18,
          "position": 3422
        },
        "endLoc": {
          "line": 427,
          "column": 15,
          "position": 3521
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 214,
        "end": 141,
        "startLoc": {
          "line": 214,
          "column": 21,
          "position": 1846
        },
        "endLoc": {
          "line": 141,
          "column": 25,
          "position": 1297
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": ")}\n              </div>\n              <div className=\"relative\">\n                {searchMenuOpen && (\n                  <div\n                    className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n                    onClick={() => setSearchMenuOpen(false)}\n                  />\n                )}\n                {searchMenuOpen ? (\n                  <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n                    <div className=\"w-full flex flex-col gap-y-1\">\n                      <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                        <MagnifyingGlass\n                          size={20}\n                          weight=\"bold\"\n                          className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                        />\n                        <input\n                          type=\"text\"\n                          name=\"llm-search",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 427,
        "end": 447,
        "startLoc": {
          "line": 427,
          "column": 15,
          "position": 3522
        },
        "endLoc": {
          "line": 447,
          "column": 11,
          "position": 3657
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 228,
        "end": 248,
        "startLoc": {
          "line": 228,
          "column": 24,
          "position": 1952
        },
        "endLoc": {
          "line": 248,
          "column": 11,
          "position": 2087
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\"\n                          className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                          onChange={(e) => setSearchQuery(e.target.value)}\n                          ref={searchInputRef}\n                          onKeyDown={(e) => {\n                            if (e.key === \"Enter\") e.preventDefault();\n                          }}\n                        />\n                        <X\n                          size={20}\n                          weight=\"bold\"\n                          className=\"cursor-pointer text-white hover:text-x-button\"\n                          onClick={handleXButton}\n                        />\n                      </div>\n                      <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                        {filteredLLMs",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 449,
        "end": 465,
        "startLoc": {
          "line": 449,
          "column": 25,
          "position": 3670
        },
        "endLoc": {
          "line": 465,
          "column": 13,
          "position": 3784
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 250,
        "end": 266,
        "startLoc": {
          "line": 250,
          "column": 37,
          "position": 2100
        },
        "endLoc": {
          "line": 266,
          "column": 13,
          "position": 2214
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": ")}\n                      </div>\n                    </div>\n                  </div>\n                ) : (\n                  <button\n                    className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n                    type=\"button\"\n                    onClick={() => setSearchMenuOpen(true)}\n                  >\n                    <div className=\"flex gap-x-4 items-center\">\n                      <img\n                        src={selectedLLMObject?.logo || AnythingLLMIcon}\n                        alt={`${selectedLLMObject?.name} logo`}\n                        className=\"w-10 h-10 rounded-md\"\n                      />\n                      <div className=\"flex flex-col text-left\">\n                        <div className=\"text-sm font-semibold text-white\">\n                          {selectedLLMObject",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 477,
        "end": 495,
        "startLoc": {
          "line": 477,
          "column": 2,
          "position": 3879
        },
        "endLoc": {
          "line": 495,
          "column": 18,
          "position": 4007
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 276,
        "end": 294,
        "startLoc": {
          "line": 276,
          "column": 2,
          "position": 2300
        },
        "endLoc": {
          "line": 294,
          "column": 18,
          "position": 2424
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "}\n                        </div>\n                      </div>\n                    </div>\n                    <CaretUpDown\n                      size={24}\n                      weight=\"bold\"\n                      className=\"text-white\"\n                    />\n                  </button>\n                )}\n              </div>\n              <div\n                onChange={() => setHasChanges(true)}\n                className=\"mt-4 flex flex-col gap-y-1\"\n              >\n                {selectedLLM",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/LLMPreference/index.jsx",
        "start": 499,
        "end": 515,
        "startLoc": {
          "line": 499,
          "column": 28,
          "position": 4044
        },
        "endLoc": {
          "line": 515,
          "column": 12,
          "position": 4127
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 297,
        "end": 313,
        "startLoc": {
          "line": 297,
          "column": 12,
          "position": 2450
        },
        "endLoc": {
          "line": 313,
          "column": 12,
          "position": 2533
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": ");\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form\n            onSubmit",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingTextSplitterPreference/index.jsx",
        "start": 63,
        "end": 83,
        "startLoc": {
          "line": 63,
          "column": 2,
          "position": 547
        },
        "endLoc": {
          "line": 83,
          "column": 9,
          "position": 679
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 182,
        "end": 202,
        "startLoc": {
          "line": 182,
          "column": 12,
          "position": 1616
        },
        "endLoc": {
          "line": 202,
          "column": 3,
          "position": 1748
        }
      }
    },
    {
      "format": "javascript",
      "lines": 272,
      "fragment": "={settings} />,\n    description:\n      \"Use the built-in embedding provider for AnythingLLM. Zero setup!\",\n  },\n  {\n    name: \"OpenAI\",\n    value: \"openai\",\n    logo: OpenAiLogo,\n    options: (settings) => <OpenAiOptions settings={settings} />,\n    description: \"The standard option for most non-commercial use.\",\n  },\n  {\n    name: \"Azure OpenAI\",\n    value: \"azure\",\n    logo: AzureOpenAiLogo,\n    options: (settings) => <AzureAiOptions settings={settings} />,\n    description: \"The enterprise option of OpenAI hosted on Azure services.\",\n  },\n  {\n    name: \"Gemini\",\n    value: \"gemini\",\n    logo: GeminiAiLogo,\n    options: (settings) => <GeminiOptions settings={settings} />,\n    description: \"Run powerful embedding models from Google AI.\",\n  },\n  {\n    name: \"Local AI\",\n    value: \"localai\",\n    logo: LocalAiLogo,\n    options: (settings) => <LocalAiOptions settings={settings} />,\n    description: \"Run embedding models locally on your own machine.\",\n  },\n  {\n    name: \"Ollama\",\n    value: \"ollama\",\n    logo: OllamaLogo,\n    options: (settings) => <OllamaEmbeddingOptions settings={settings} />,\n    description: \"Run embedding models locally on your own machine.\",\n  },\n  {\n    name: \"LM Studio\",\n    value: \"lmstudio\",\n    logo: LMStudioLogo,\n    options: (settings) => <LMStudioEmbeddingOptions settings={settings} />,\n    description:\n      \"Discover, download, and run thousands of cutting edge LLMs in a few clicks.\",\n  },\n  {\n    name: \"Cohere\",\n    value: \"cohere\",\n    logo: CohereLogo,\n    options: (settings) => <CohereEmbeddingOptions settings={settings} />,\n    description: \"Run powerful embedding models from Cohere.\",\n  },\n  {\n    name: \"Voyage AI\",\n    value: \"voyageai\",\n    logo: VoyageAiLogo,\n    options: (settings) => <VoyageAiOptions settings={settings} />,\n    description: \"Run powerful embedding models from Voyage AI.\",\n  },\n  {\n    name: \"LiteLLM\",\n    value: \"litellm\",\n    logo: LiteLLMLogo,\n    options: (settings) => <LiteLLMOptions settings={settings} />,\n    description: \"Run powerful embedding models from LiteLLM.\",\n  },\n  {\n    name: \"Mistral AI\",\n    value: \"mistral\",\n    logo: MistralAiLogo,\n    options: (settings) => <MistralAiOptions settings={settings} />,\n    description: \"Run powerful embedding models from Mistral AI.\",\n  },\n  {\n    name: \"Generic OpenAI\",\n    value: \"generic-openai\",\n    logo: GenericOpenAiLogo,\n    options: (settings) => (\n      <GenericOpenAiEmbeddingOptions settings={settings} />\n    ),\n    description: \"Run embedding models from any OpenAI compatible API service.\",\n  },\n];\n\nexport default function GeneralEmbeddingPreference() {\n  const [saving, setSaving] = useState(false);\n  const [hasChanges, setHasChanges] = useState(false);\n  const [hasEmbeddings, setHasEmbeddings] = useState(false);\n  const [hasCachedEmbeddings, setHasCachedEmbeddings] = useState(false);\n  const [settings, setSettings] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filteredEmbedders, setFilteredEmbedders] = useState([]);\n  const [selectedEmbedder, setSelectedEmbedder] = useState(null);\n  const [searchMenuOpen, setSearchMenuOpen] = useState(false);\n  const searchInputRef = useRef(null);\n  const { isOpen, openModal, closeModal } = useModal();\n  const { t } = useTranslation();\n\n  function embedderModelChanged(formEl) {\n    try {\n      const newModel = new FormData(formEl).get(\"EmbeddingModelPref\") ?? null;\n      if (newModel === null) return false;\n      return settings?.EmbeddingModelPref !== newModel;\n    } catch (error) {\n      console.error(error);\n    }\n    return false;\n  }\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    if (\n      (selectedEmbedder !== settings?.EmbeddingEngine ||\n        embedderModelChanged(e.target)) &&\n      hasChanges &&\n      (hasEmbeddings || hasCachedEmbeddings)\n    ) {\n      openModal();\n    } else {\n      await handleSaveSettings();\n    }\n  };\n\n  const handleSaveSettings = async () => {\n    setSaving(true);\n    const form = document.getElementById(\"embedding-form\");\n    const settingsData = {};\n    const formData = new FormData(form);\n    settingsData.EmbeddingEngine = selectedEmbedder;\n    for (var [key, value] of formData.entries()) settingsData[key] = value;\n\n    const { error } = await System.updateSystem(settingsData);\n    if (error) {\n      showToast(`Failed to save embedding settings: ${error}`, \"error\");\n      setHasChanges(true);\n    } else {\n      showToast(\"Embedding preferences saved successfully.\", \"success\");\n      setHasChanges(false);\n    }\n    setSaving(false);\n    closeModal();\n  };\n\n  const updateChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedEmbedder(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedEmbedder(_settings?.EmbeddingEngine || \"native\");\n      setHasEmbeddings(_settings?.HasExistingEmbeddings || false);\n      setHasCachedEmbeddings(_settings?.HasCachedEmbeddings || false);\n      setLoading(false);\n    }\n    fetchKeys();\n  }, []);\n\n  useEffect(() => {\n    const filtered = EMBEDDERS.filter((embedder) =>\n      embedder.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredEmbedders(filtered);\n  }, [searchQuery, selectedEmbedder]);\n\n  const selectedEmbedderObject = EMBEDDERS.find(\n    (embedder) => embedder.value === selectedEmbedder\n  );\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form\n            id=\"embedding-form\"\n            onSubmit={handleSubmit}\n            className=\"flex w-full\"\n          >\n            <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] py-16 md:py-6\">\n              <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n                <div className=\"flex gap-x-4 items-center\">\n                  <p className=\"text-lg leading-6 font-bold text-white\">\n                    {t(\"embedding.title\")}\n                  </p>\n                </div>\n                <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60\">\n                  {t(\"embedding.desc-start\")}\n                  <br />\n                  {t(\"embedding.desc-end\")}\n                </p>\n              </div>\n              <div className=\"w-full justify-end flex\">\n                {hasChanges && (\n                  <CTAButton\n                    onClick={() => handleSubmit()}\n                    className=\"mt-3 mr-0 -mb-14 z-10\"\n                  >\n                    {saving ? t(\"common.saving\") : t(\"common.save\")}\n                  </CTAButton>\n                )}\n              </div>\n              <div className=\"text-base font-bold text-white mt-6 mb-4\">\n                {t(\"embedding.provider.title\")}\n              </div>\n              <div className=\"relative\">\n                {searchMenuOpen && (\n                  <div\n                    className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n                    onClick={() => setSearchMenuOpen(false)}\n                  />\n                )}\n                {searchMenuOpen ? (\n                  <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n                    <div className=\"w-full flex flex-col gap-y-1\">\n                      <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                        <MagnifyingGlass\n                          size={20}\n                          weight=\"bold\"\n                          className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                        />\n                        <input\n                          type=\"text\"\n                          name=\"embedder-search\"\n                          autoComplete=\"off\"\n                          placeholder=\"Search all embedding providers\"\n                          className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                          onChange={(e) => setSearchQuery(e.target.value)}\n                          ref={searchInputRef}\n                          onKeyDown={(e) => {\n                            if (e.key === \"Enter\") e.preventDefault();\n                          }}\n                        />\n                        <X\n                          size={20}\n                          weight=\"bold\"\n                          className=\"cursor-pointer text-white hover:text-x-button\"\n                          onClick={handleXButton}\n                        />\n                      </div>\n                      <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                        {filteredEmbedders.map((embedder) => (\n                          <EmbedderItem\n                            key={embedder",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 46,
        "end": 317,
        "startLoc": {
          "line": 46,
          "column": 9,
          "position": 417
        },
        "endLoc": {
          "line": 317,
          "column": 9,
          "position": 2695
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 71,
        "end": 268,
        "startLoc": {
          "line": 71,
          "column": 9,
          "position": 629
        },
        "endLoc": {
          "line": 268,
          "column": 4,
          "position": 2233
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\n  {\n    name: \"OpenAI\",\n    value: \"openai\",\n    logo: OpenAiLogo,\n    options: (settings) => <OpenAiOptions settings={settings} />,\n    description: \"The standard option for most non-commercial use.\",\n  },\n  {\n    name: \"Azure OpenAI\",\n    value: \"azure\",\n    logo: AzureOpenAiLogo,\n    options: (settings) => <AzureAiOptions settings={settings} />,\n    description: \"The enterprise option of OpenAI hosted on Azure services.\",\n  },\n  {\n    name: \"Gemini\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 49,
        "end": 65,
        "startLoc": {
          "line": 49,
          "column": 2,
          "position": 436
        },
        "endLoc": {
          "line": 65,
          "column": 9,
          "position": 558
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/OnboardingFlow/Steps/LLMPreference/index.jsx",
        "start": 66,
        "end": 82,
        "startLoc": {
          "line": 66,
          "column": 2,
          "position": 590
        },
        "endLoc": {
          "line": 82,
          "column": 12,
          "position": 712
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    async function fetchKeys() {\n      const _settings = await System.keys();\n      setSettings(_settings);\n      setSelectedEmbedder",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 194,
        "end": 212,
        "startLoc": {
          "line": 194,
          "column": 20,
          "position": 1751
        },
        "endLoc": {
          "line": 212,
          "column": 20,
          "position": 1899
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 80,
        "end": 98,
        "startLoc": {
          "line": 80,
          "column": 15,
          "position": 850
        },
        "endLoc": {
          "line": 98,
          "column": 15,
          "position": 998
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\n  );\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <form\n            id=\"embedding-form",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 228,
        "end": 249,
        "startLoc": {
          "line": 228,
          "column": 17,
          "position": 2062
        },
        "endLoc": {
          "line": 249,
          "column": 15,
          "position": 2199
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 98,
        "end": 202,
        "startLoc": {
          "line": 98,
          "column": 17,
          "position": 973
        },
        "endLoc": {
          "line": 202,
          "column": 14,
          "position": 1751
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ")}\n                </p>\n              </div>\n              <div className=\"w-full justify-end flex\">\n                {hasChanges && (\n                  <CTAButton\n                    onClick={() => handleSubmit()}\n                    className=\"mt-3 mr-0 -mb-14 z-10\"\n                  >\n                    {saving ? t(\"common.saving\") : t(\"common.save\")}\n                  </CTAButton>\n                )}\n              </div>\n              <div className=\"text-base font-bold text-white mt-6 mb-4\">\n                {t(\"embedding.provider.title\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 263,
        "end": 277,
        "startLoc": {
          "line": 263,
          "column": 21,
          "position": 2308
        },
        "endLoc": {
          "line": 277,
          "column": 27,
          "position": 2413
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 214,
        "end": 228,
        "startLoc": {
          "line": 214,
          "column": 21,
          "position": 1846
        },
        "endLoc": {
          "line": 228,
          "column": 24,
          "position": 1951
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": ")}\n              </div>\n              <div className=\"relative\">\n                {searchMenuOpen && (\n                  <div\n                    className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n                    onClick={() => setSearchMenuOpen(false)}\n                  />\n                )}\n                {searchMenuOpen ? (\n                  <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n                    <div className=\"w-full flex flex-col gap-y-1\">\n                      <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                        <MagnifyingGlass\n                          size={20}\n                          weight=\"bold\"\n                          className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                        />\n                        <input\n                          type=\"text\"\n                          name=\"embedder-search",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 277,
        "end": 297,
        "startLoc": {
          "line": 277,
          "column": 27,
          "position": 2414
        },
        "endLoc": {
          "line": 297,
          "column": 16,
          "position": 2549
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 228,
        "end": 248,
        "startLoc": {
          "line": 228,
          "column": 24,
          "position": 1952
        },
        "endLoc": {
          "line": 248,
          "column": 11,
          "position": 2087
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\"\n                          className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                          onChange={(e) => setSearchQuery(e.target.value)}\n                          ref={searchInputRef}\n                          onKeyDown={(e) => {\n                            if (e.key === \"Enter\") e.preventDefault();\n                          }}\n                        />\n                        <X\n                          size={20}\n                          weight=\"bold\"\n                          className=\"cursor-pointer text-white hover:text-x-button\"\n                          onClick={handleXButton}\n                        />\n                      </div>\n                      <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                        {filteredEmbedders",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 299,
        "end": 315,
        "startLoc": {
          "line": 299,
          "column": 31,
          "position": 2562
        },
        "endLoc": {
          "line": 315,
          "column": 18,
          "position": 2676
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 250,
        "end": 266,
        "startLoc": {
          "line": 250,
          "column": 37,
          "position": 2100
        },
        "endLoc": {
          "line": 266,
          "column": 13,
          "position": 2214
        }
      }
    },
    {
      "format": "jsx",
      "lines": 28,
      "fragment": "\n                            key={embedder.name}\n                            name={embedder.name}\n                            value={embedder.value}\n                            image={embedder.logo}\n                            description={embedder.description}\n                            checked={selectedEmbedder === embedder.value}\n                            onClick={() => updateChoice(embedder.value)}\n                          />\n                        ))}\n                      </div>\n                    </div>\n                  </div>\n                ) : (\n                  <button\n                    className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n                    type=\"button\"\n                    onClick={() => setSearchMenuOpen(true)}\n                  >\n                    <div className=\"flex gap-x-4 items-center\">\n                      <img\n                        src={selectedEmbedderObject.logo}\n                        alt={`${selectedEmbedderObject.name} logo`}\n                        className=\"w-10 h-10 rounded-md\"\n                      />\n                      <div className=\"flex flex-col text-left\">\n                        <div className=\"text-sm font-semibold text-white\">\n                          {selectedEmbedderObject",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 316,
        "end": 343,
        "startLoc": {
          "line": 316,
          "column": 13,
          "position": 2691
        },
        "endLoc": {
          "line": 343,
          "column": 23,
          "position": 2886
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 267,
        "end": 294,
        "startLoc": {
          "line": 267,
          "column": 13,
          "position": 2229
        },
        "endLoc": {
          "line": 294,
          "column": 18,
          "position": 2424
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": ".description}\n                        </div>\n                      </div>\n                    </div>\n                    <CaretUpDown\n                      size={24}\n                      weight=\"bold\"\n                      className=\"text-white\"\n                    />\n                  </button>\n                )}\n              </div>\n              <div\n                onChange={() => setHasChanges(true)}\n                className=\"mt-4 flex flex-col gap-y-1\"\n              >\n                {selectedEmbedder",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingPreference/index.jsx",
        "start": 346,
        "end": 362,
        "startLoc": {
          "line": 346,
          "column": 23,
          "position": 2910
        },
        "endLoc": {
          "line": 362,
          "column": 17,
          "position": 2995
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 297,
        "end": 313,
        "startLoc": {
          "line": 297,
          "column": 18,
          "position": 2448
        },
        "endLoc": {
          "line": 313,
          "column": 12,
          "position": 2533
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": "\n  };\n\n  const toggleMenu = () => {\n    setShowMenu(!showMenu);\n  };\n\n  useEffect(() => {\n    function handleClickOutside(event) {\n      if (\n        menuRef.current &&\n        !menuRef.current.contains(event.target) &&\n        !openMenuButton.current.contains(event.target)\n      ) {\n        setShowMenu(false);\n      }\n    }\n\n    document.addEventListener(\"mousedown\", handleClickOutside);\n    return () => {\n      document.removeEventListener(\"mousedown\", handleClickOutside);\n    };\n  }, []);\n\n  useEffect(() => {\n    async function fetchChats() {\n      const { chats: _chats ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/index.jsx",
        "start": 83,
        "end": 109,
        "startLoc": {
          "line": 83,
          "column": 2,
          "position": 823
        },
        "endLoc": {
          "line": 109,
          "column": 2,
          "position": 1013
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx",
        "start": 69,
        "end": 95,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 716
        },
        "endLoc": {
          "line": 95,
          "column": 2,
          "position": 906
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n    setChats((prevChats) => prevChats.filter((chat) => chat.id !== chatId));\n  };\n\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm\"\n        containerClassName=\"flex w-full\"\n      />\n    );\n  }\n\n  return (\n    <",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/Chats/index.jsx",
        "start": 213,
        "end": 232,
        "startLoc": {
          "line": 213,
          "column": 2,
          "position": 1742
        },
        "endLoc": {
          "line": 232,
          "column": 2,
          "position": 1854
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx",
        "start": 111,
        "end": 43,
        "startLoc": {
          "line": 111,
          "column": 2,
          "position": 1051
        },
        "endLoc": {
          "line": 43,
          "column": 2,
          "position": 353
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"items-center flex gap-x-4\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary\">\n                Browser",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 41,
        "end": 53,
        "startLoc": {
          "line": 41,
          "column": 1,
          "position": 450
        },
        "endLoc": {
          "line": 53,
          "column": 8,
          "position": 548
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx",
        "start": 9,
        "end": 21,
        "startLoc": {
          "line": 9,
          "column": 2,
          "position": 86
        },
        "endLoc": {
          "line": 21,
          "column": 8,
          "position": 184
        }
      }
    },
    {
      "format": "javascript",
      "lines": 51,
      "fragment": "}}\n                  />\n                  <X\n                    size={20}\n                    weight=\"bold\"\n                    className=\"cursor-pointer text-white hover:text-x-button\"\n                    onClick={handleXButton}\n                  />\n                </div>\n                <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                  {filteredProviders.map((provider) => (\n                    <LLMItem\n                      key={provider.name}\n                      name={provider.name}\n                      value={provider.value}\n                      image={provider.logo}\n                      description={provider.description}\n                      checked={selectedProvider === provider.value}\n                      onClick={() => updateProviderChoice(provider.value)}\n                    />\n                  ))}\n                </div>\n              </div>\n            </div>\n          ) : (\n            <button\n              className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n              type=\"button\"\n              onClick={() => setSearchMenuOpen(true)}\n            >\n              <div className=\"flex gap-x-4 items-center\">\n                <img\n                  src={selectedProviderObject.logo}\n                  alt={`${selectedProviderObject.name} logo`}\n                  className=\"w-10 h-10 rounded-md\"\n                />\n                <div className=\"flex flex-col text-left\">\n                  <div className=\"text-sm font-semibold text-white\">\n                    {selectedProviderObject.name}\n                  </div>\n                  <div className=\"mt-1 text-xs text-description\">\n                    {selectedProviderObject.description}\n                  </div>\n                </div>\n              </div>\n              <CaretUpDown size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          )}\n        </div>\n        <div\n          onChange={() => setHasChanges(true)}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 165,
        "end": 215,
        "startLoc": {
          "line": 165,
          "column": 21,
          "position": 1508
        },
        "endLoc": {
          "line": 215,
          "column": 2,
          "position": 1868
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 169,
        "end": 223,
        "startLoc": {
          "line": 169,
          "column": 27,
          "position": 1507
        },
        "endLoc": {
          "line": 223,
          "column": 2,
          "position": 1867
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ": selectedProvider };\n    const formData = new FormData(form);\n\n    for (var [key, value] of formData.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    setSaving(true);\n\n    if (error) {\n      showToast(`Failed to save preferences: ${error}`, \"error\");\n    } else {\n      showToast(\"Text-to-speech preferences saved successfully.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 72,
        "end": 82,
        "startLoc": {
          "line": 72,
          "column": 21,
          "position": 666
        },
        "endLoc": {
          "line": 82,
          "column": 49,
          "position": 783
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 48,
        "end": 58,
        "startLoc": {
          "line": 48,
          "column": 16,
          "position": 518
        },
        "endLoc": {
          "line": 58,
          "column": 48,
          "position": 635
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": ", \"success\");\n    }\n    setSaving(false);\n    setHasChanges(!!error);\n  };\n\n  const updateProviderChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedProvider(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    const",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 82,
        "end": 105,
        "startLoc": {
          "line": 82,
          "column": 49,
          "position": 784
        },
        "endLoc": {
          "line": 105,
          "column": 6,
          "position": 952
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 58,
        "end": 95,
        "startLoc": {
          "line": 58,
          "column": 48,
          "position": 636
        },
        "endLoc": {
          "line": 95,
          "column": 6,
          "position": 964
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ";\n\n  useEffect(() => {\n    const filtered = PROVIDERS.filter((provider) =>\n      provider.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredProviders(filtered);\n  }, [searchQuery, selectedProvider]);\n\n  const selectedProviderObject = PROVIDERS.find(\n    (provider) => provider.value === selectedProvider\n  );\n\n  return (\n    <form",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 102,
        "end": 116,
        "startLoc": {
          "line": 102,
          "column": 2,
          "position": 938
        },
        "endLoc": {
          "line": 116,
          "column": 5,
          "position": 1050
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 88,
        "end": 102,
        "startLoc": {
          "line": 88,
          "column": 2,
          "position": 874
        },
        "endLoc": {
          "line": 102,
          "column": 4,
          "position": 986
        }
      }
    },
    {
      "format": "javascript",
      "lines": 115,
      "fragment": "} />,\n    description: \"Uses your browser's built in STT service if supported.\",\n  },\n];\n\nexport default function SpeechToTextProvider({ settings }) {\n  const [saving, setSaving] = useState(false);\n  const [hasChanges, setHasChanges] = useState(false);\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filteredProviders, setFilteredProviders] = useState([]);\n  const [selectedProvider, setSelectedProvider] = useState(\n    settings?.SpeechToTextProvider || \"native\"\n  );\n  const [searchMenuOpen, setSearchMenuOpen] = useState(false);\n  const searchInputRef = useRef(null);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    const form = e.target;\n    const data = { SpeechToTextProvider: selectedProvider };\n    const formData = new FormData(form);\n\n    for (var [key, value] of formData.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    setSaving(true);\n\n    if (error) {\n      showToast(`Failed to save preferences: ${error}`, \"error\");\n    } else {\n      showToast(\"Speech-to-text preferences saved successfully.\", \"success\");\n    }\n    setSaving(false);\n    setHasChanges(!!error);\n  };\n\n  const updateProviderChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedProvider(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    const filtered = PROVIDERS.filter((provider) =>\n      provider.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredProviders(filtered);\n  }, [searchQuery, selectedProvider]);\n\n  const selectedProviderObject = PROVIDERS.find(\n    (provider) => provider.value === selectedProvider\n  );\n\n  return (\n    <form onSubmit={handleSubmit} className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n        <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n          <div className=\"flex gap-x-4 items-center\">\n            <p className=\"text-lg leading-6 font-bold text-white\">\n              Speech-to-text Preference\n            </p>\n          </div>\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60\">\n            Here you can specify what kind of text-to-speech and speech-to-text\n            providers you would want to use in your AnythingLLM experience. By\n            default, we use the browser's built in support for these services,\n            but you may want to use others.\n          </p>\n        </div>\n        <div className=\"w-full justify-end flex\">\n          {hasChanges && (\n            <CTAButton\n              onClick={() => handleSubmit()}\n              className=\"mt-3 mr-0 -mb-14 z-10\"\n            >\n              {saving ? \"Saving...\" : \"Save changes\"}\n            </CTAButton>\n          )}\n        </div>\n        <div className=\"text-base font-bold text-white mt-6 mb-4\">Provider</div>\n        <div className=\"relative\">\n          {searchMenuOpen && (\n            <div\n              className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n              onClick={() => setSearchMenuOpen(false)}\n            />\n          )}\n          {searchMenuOpen ? (\n            <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n              <div className=\"w-full flex flex-col gap-y-1\">\n                <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                  <MagnifyingGlass\n                    size={20}\n                    weight=\"bold\"\n                    className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                  />\n                  <input\n                    type=\"text\"\n                    name=\"stt-provider-search\"\n                    autoComplete=\"off\"\n                    placeholder=\"Search speech to text providers\"\n                    className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                    onChange={(e) => setSearchQuery(e.target.value)}\n                    ref={searchInputRef}\n                    onKeyDown={(e) => {\n                      ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx",
        "start": 15,
        "end": 129,
        "startLoc": {
          "line": 15,
          "column": 9,
          "position": 145
        },
        "endLoc": {
          "line": 129,
          "column": 23,
          "position": 1209
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/VectorDatabase/index.jsx",
        "start": 198,
        "end": 255,
        "startLoc": {
          "line": 198,
          "column": 2,
          "position": 1734
        },
        "endLoc": {
          "line": 255,
          "column": 29,
          "position": 2143
        }
      }
    },
    {
      "format": "javascript",
      "lines": 85,
      "fragment": "}\n              className=\"mt-3 mr-0 -mb-14 z-10\"\n            >\n              {saving ? \"Saving...\" : \"Save changes\"}\n            </CTAButton>\n          )}\n        </div>\n        <div className=\"text-base font-bold text-white mt-6 mb-4\">Provider</div>\n        <div className=\"relative\">\n          {searchMenuOpen && (\n            <div\n              className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n              onClick={() => setSearchMenuOpen(false)}\n            />\n          )}\n          {searchMenuOpen ? (\n            <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n              <div className=\"w-full flex flex-col gap-y-1\">\n                <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                  <MagnifyingGlass\n                    size={20}\n                    weight=\"bold\"\n                    className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                  />\n                  <input\n                    type=\"text\"\n                    name=\"stt-provider-search\"\n                    autoComplete=\"off\"\n                    placeholder=\"Search speech to text providers\"\n                    className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                    onChange={(e) => setSearchQuery(e.target.value)}\n                    ref={searchInputRef}\n                    onKeyDown={(e) => {\n                      if (e.key === \"Enter\") e.preventDefault();\n                    }}\n                  />\n                  <X\n                    size={20}\n                    weight=\"bold\"\n                    className=\"cursor-pointer text-white hover:text-x-button\"\n                    onClick={handleXButton}\n                  />\n                </div>\n                <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                  {filteredProviders.map((provider) => (\n                    <LLMItem\n                      key={provider.name}\n                      name={provider.name}\n                      value={provider.value}\n                      image={provider.logo}\n                      description={provider.description}\n                      checked={selectedProvider === provider.value}\n                      onClick={() => updateProviderChoice(provider.value)}\n                    />\n                  ))}\n                </div>\n              </div>\n            </div>\n          ) : (\n            <button\n              className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n              type=\"button\"\n              onClick={() => setSearchMenuOpen(true)}\n            >\n              <div className=\"flex gap-x-4 items-center\">\n                <img\n                  src={selectedProviderObject.logo}\n                  alt={`${selectedProviderObject.name} logo`}\n                  className=\"w-10 h-10 rounded-md\"\n                />\n                <div className=\"flex flex-col text-left\">\n                  <div className=\"text-sm font-semibold text-white\">\n                    {selectedProviderObject.name}\n                  </div>\n                  <div className=\"mt-1 text-xs text-description\">\n                    {selectedProviderObject.description}\n                  </div>\n                </div>\n              </div>\n              <CaretUpDown size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          )}\n        </div>\n        <div\n          onChange={() => setHasChanges(true)}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx",
        "start": 96,
        "end": 180,
        "startLoc": {
          "line": 96,
          "column": 2,
          "position": 974
        },
        "endLoc": {
          "line": 180,
          "column": 2,
          "position": 1587
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 116,
        "end": 223,
        "startLoc": {
          "line": 116,
          "column": 13,
          "position": 1056
        },
        "endLoc": {
          "line": 223,
          "column": 2,
          "position": 1867
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ": selectedProvider };\n    const formData = new FormData(form);\n\n    for (var [key, value] of formData.entries()) data[key] = value;\n    const { error } = await System.updateSystem(data);\n    setSaving(true);\n\n    if (error) {\n      showToast(`Failed to save preferences: ${error}`, \"error\");\n    } else {\n      showToast(\"Speech-to-text preferences saved successfully.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx",
        "start": 34,
        "end": 44,
        "startLoc": {
          "line": 34,
          "column": 21,
          "position": 363
        },
        "endLoc": {
          "line": 44,
          "column": 49,
          "position": 480
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 48,
        "end": 58,
        "startLoc": {
          "line": 48,
          "column": 16,
          "position": 518
        },
        "endLoc": {
          "line": 58,
          "column": 48,
          "position": 635
        }
      }
    },
    {
      "format": "jsx",
      "lines": 40,
      "fragment": ", \"success\");\n    }\n    setSaving(false);\n    setHasChanges(!!error);\n  };\n\n  const updateProviderChoice = (selection) => {\n    setSearchQuery(\"\");\n    setSelectedProvider(selection);\n    setSearchMenuOpen(false);\n    setHasChanges(true);\n  };\n\n  const handleXButton = () => {\n    if (searchQuery.length > 0) {\n      setSearchQuery(\"\");\n      if (searchInputRef.current) searchInputRef.current.value = \"\";\n    } else {\n      setSearchMenuOpen(!searchMenuOpen);\n    }\n  };\n\n  useEffect(() => {\n    const filtered = PROVIDERS.filter((provider) =>\n      provider.name.toLowerCase().includes(searchQuery.toLowerCase())\n    );\n    setFilteredProviders(filtered);\n  }, [searchQuery, selectedProvider]);\n\n  const selectedProviderObject = PROVIDERS.find(\n    (provider) => provider.value === selectedProvider\n  );\n\n  return (\n    <form onSubmit={handleSubmit} className=\"flex w-full\">\n      <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n        <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white light:border-theme-sidebar-border border-b-2 border-opacity-10\">\n          <div className=\"flex gap-x-4 items-center\">\n            <p className=\"text-lg leading-6 font-bold text-white\">\n              Speech",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx",
        "start": 44,
        "end": 83,
        "startLoc": {
          "line": 44,
          "column": 49,
          "position": 481
        },
        "endLoc": {
          "line": 83,
          "column": 7,
          "position": 807
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/TranscriptionPreference/index.jsx",
        "start": 58,
        "end": 121,
        "startLoc": {
          "line": 58,
          "column": 48,
          "position": 636
        },
        "endLoc": {
          "line": 121,
          "column": 5,
          "position": 1110
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": ">\n              {saving ? \"Saving...\" : \"Save changes\"}\n            </CTAButton>\n          )}\n        </div>\n        <div className=\"text-base font-bold text-white mt-6 mb-4\">Provider</div>\n        <div className=\"relative\">\n          {searchMenuOpen && (\n            <div\n              className=\"fixed top-0 left-0 w-full h-full bg-black bg-opacity-70 backdrop-blur-sm z-10\"\n              onClick={() => setSearchMenuOpen(false)}\n            />\n          )}\n          {searchMenuOpen ? (\n            <div className=\"absolute top-0 left-0 w-full max-w-[640px] max-h-[310px] min-h-[64px] bg-theme-settings-input-bg rounded-lg flex flex-col justify-between cursor-pointer border-2 border-primary-button z-20\">\n              <div className=\"w-full flex flex-col gap-y-1\">\n                <div className=\"flex items-center sticky top-0 z-10 border-b border-[#9CA3AF] mx-4 bg-theme-settings-input-bg\">\n                  <MagnifyingGlass\n                    size={20}\n                    weight=\"bold\"\n                    className=\"absolute left-4 z-30 text-theme-text-primary -ml-4 my-2\"\n                  />\n                  <input\n                    type=\"text\"\n                    name=\"stt-provider-search",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx",
        "start": 98,
        "end": 122,
        "startLoc": {
          "line": 98,
          "column": 13,
          "position": 982
        },
        "endLoc": {
          "line": 122,
          "column": 20,
          "position": 1153
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 133,
        "end": 157,
        "startLoc": {
          "line": 133,
          "column": 2,
          "position": 1263
        },
        "endLoc": {
          "line": 157,
          "column": 20,
          "position": 1434
        }
      }
    },
    {
      "format": "jsx",
      "lines": 69,
      "fragment": "\"\n                    className=\"border-none -ml-4 my-2 bg-transparent z-20 pl-12 h-[38px] w-full px-4 py-1 text-sm outline-none text-theme-text-primary placeholder:text-theme-text-primary placeholder:font-medium\"\n                    onChange={(e) => setSearchQuery(e.target.value)}\n                    ref={searchInputRef}\n                    onKeyDown={(e) => {\n                      if (e.key === \"Enter\") e.preventDefault();\n                    }}\n                  />\n                  <X\n                    size={20}\n                    weight=\"bold\"\n                    className=\"cursor-pointer text-white hover:text-x-button\"\n                    onClick={handleXButton}\n                  />\n                </div>\n                <div className=\"flex-1 pl-4 pr-2 flex flex-col gap-y-1 overflow-y-auto white-scrollbar pb-4 max-h-[245px]\">\n                  {filteredProviders.map((provider) => (\n                    <LLMItem\n                      key={provider.name}\n                      name={provider.name}\n                      value={provider.value}\n                      image={provider.logo}\n                      description={provider.description}\n                      checked={selectedProvider === provider.value}\n                      onClick={() => updateProviderChoice(provider.value)}\n                    />\n                  ))}\n                </div>\n              </div>\n            </div>\n          ) : (\n            <button\n              className=\"w-full max-w-[640px] h-[64px] bg-theme-settings-input-bg rounded-lg flex items-center p-[14px] justify-between cursor-pointer border-2 border-transparent hover:border-primary-button transition-all duration-300\"\n              type=\"button\"\n              onClick={() => setSearchMenuOpen(true)}\n            >\n              <div className=\"flex gap-x-4 items-center\">\n                <img\n                  src={selectedProviderObject.logo}\n                  alt={`${selectedProviderObject.name} logo`}\n                  className=\"w-10 h-10 rounded-md\"\n                />\n                <div className=\"flex flex-col text-left\">\n                  <div className=\"text-sm font-semibold text-white\">\n                    {selectedProviderObject.name}\n                  </div>\n                  <div className=\"mt-1 text-xs text-description\">\n                    {selectedProviderObject.description}\n                  </div>\n                </div>\n              </div>\n              <CaretUpDown size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          )}\n        </div>\n        <div\n          onChange={() => setHasChanges(true)}\n          className=\"mt-4 flex flex-col gap-y-1\"\n        >\n          {selectedProvider &&\n            PROVIDERS.find(\n              (provider) => provider.value === selectedProvider\n            )?.options(settings)}\n        </div>\n      </div>\n    </form>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/stt.jsx",
        "start": 124,
        "end": 192,
        "startLoc": {
          "line": 124,
          "column": 32,
          "position": 1166
        },
        "endLoc": {
          "line": 192,
          "column": 1,
          "position": 1654
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/tts.jsx",
        "start": 159,
        "end": 227,
        "startLoc": {
          "line": 159,
          "column": 32,
          "position": 1447
        },
        "endLoc": {
          "line": 227,
          "column": 1,
          "position": 1935
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": "();\n  }, []);\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      {loading ? (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <div className=\"w-full h-full flex justify-center items-center\">\n            <PreLoader />\n          </div>\n        </div>\n      ) : (\n        <div\n          style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n          className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n        >\n          <SpeechToTextProvider",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/AudioPreference/index.jsx",
        "start": 19,
        "end": 39,
        "startLoc": {
          "line": 19,
          "column": 10,
          "position": 186
        },
        "endLoc": {
          "line": 39,
          "column": 21,
          "position": 326
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/EmbeddingTextSplitterPreference/index.jsx",
        "start": 62,
        "end": 201,
        "startLoc": {
          "line": 62,
          "column": 14,
          "position": 537
        },
        "endLoc": {
          "line": 201,
          "column": 5,
          "position": 1746
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": ";\n\n  const removeApiKey = (id) => {\n    setApiKeys((prevKeys) => prevKeys.filter((apiKey) => apiKey.id !== id));\n  };\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"items-center flex gap-x-4\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary\">\n                {t(\"api.title\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/index.jsx",
        "start": 34,
        "end": 51,
        "startLoc": {
          "line": 34,
          "column": 2,
          "position": 373
        },
        "endLoc": {
          "line": 51,
          "column": 12,
          "position": 526
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 36,
        "end": 40,
        "startLoc": {
          "line": 36,
          "column": 2,
          "position": 398
        },
        "endLoc": {
          "line": 40,
          "column": 16,
          "position": 348
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n            </CTAButton>\n          </div>\n          <div className=\"overflow-x-auto mt-6\">\n            {loading ? (\n              <Skeleton.default\n                height=\"80vh\"\n                width=\"100%\"\n                highlightColor=\"var(--theme-bg-primary)\"\n                baseColor=\"var(--theme-bg-secondary)\"\n                count={1}\n                className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm\"\n                containerClassName=\"flex w-full\"\n              />\n            ) : (",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/GeneralSettings/ApiKeys/index.jsx",
        "start": 72,
        "end": 86,
        "startLoc": {
          "line": 72,
          "column": 2,
          "position": 675
        },
        "endLoc": {
          "line": 86,
          "column": 2,
          "position": 758
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 67,
        "end": 81,
        "startLoc": {
          "line": 67,
          "column": 4,
          "position": 667
        },
        "endLoc": {
          "line": 81,
          "column": 6,
          "position": 750
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ";\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"items-center flex gap-x-4\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary\">\n                Instance",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/index.jsx",
        "start": 15,
        "end": 28,
        "startLoc": {
          "line": 15,
          "column": 2,
          "position": 160
        },
        "endLoc": {
          "line": 28,
          "column": 9,
          "position": 260
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 40,
        "end": 21,
        "startLoc": {
          "line": 40,
          "column": 2,
          "position": 448
        },
        "endLoc": {
          "line": 21,
          "column": 8,
          "position": 184
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": ");\n      setLoading(false);\n    }\n    fetchData();\n  }, []);\n\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm mt-6\"\n        containerClassName=\"flex w-full\"\n      />\n    );\n  }\n\n  return (\n    <table className=\"w-full text-xs text-left rounded-lg mt-6 min-w-[640px] border-spacing-0",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/index.jsx",
        "start": 66,
        "end": 87,
        "startLoc": {
          "line": 66,
          "column": 12,
          "position": 605
        },
        "endLoc": {
          "line": 87,
          "column": 72,
          "position": 716
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx",
        "start": 46,
        "end": 67,
        "startLoc": {
          "line": 46,
          "column": 8,
          "position": 403
        },
        "endLoc": {
          "line": 67,
          "column": 55,
          "position": 514
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n          </th>\n          <th scope=\"col\" className=\"px-6 py-3\">\n            Created On\n          </th>\n          <th scope=\"col\" className=\"px-6 py-3 rounded-tr-lg\">\n            {\" \"}\n          </th>\n        </tr>\n      </thead>\n      <tbody>\n        {workspaces",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Workspaces/index.jsx",
        "start": 97,
        "end": 108,
        "startLoc": {
          "line": 97,
          "column": 6,
          "position": 805
        },
        "endLoc": {
          "line": 108,
          "column": 11,
          "position": 882
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/Features/LiveSync/manage/index.jsx",
        "start": 77,
        "end": 88,
        "startLoc": {
          "line": 77,
          "column": 8,
          "position": 613
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 690
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "() {\n  const { isOpen, openModal, closeModal } = useModal();\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"items-center flex gap-x-4\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary\">\n                Users",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/index.jsx",
        "start": 15,
        "end": 29,
        "startLoc": {
          "line": 15,
          "column": 11,
          "position": 144
        },
        "endLoc": {
          "line": 29,
          "column": 6,
          "position": 269
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Workspaces/index.jsx",
        "start": 14,
        "end": 21,
        "startLoc": {
          "line": 14,
          "column": 16,
          "position": 135
        },
        "endLoc": {
          "line": 21,
          "column": 8,
          "position": 184
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ");\n      setLoading(false);\n    }\n    fetchUsers();\n  }, []);\n\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm mt-8",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Users/index.jsx",
        "start": 66,
        "end": 80,
        "startLoc": {
          "line": 66,
          "column": 7,
          "position": 592
        },
        "endLoc": {
          "line": 80,
          "column": 59,
          "position": 672
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/index.jsx",
        "start": 22,
        "end": 60,
        "startLoc": {
          "line": 22,
          "column": 8,
          "position": 248
        },
        "endLoc": {
          "line": 60,
          "column": 59,
          "position": 483
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\n  };\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"items-center flex gap-x-4\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary\">\n                System",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/SystemPromptVariables/index.jsx",
        "start": 34,
        "end": 48,
        "startLoc": {
          "line": 34,
          "column": 2,
          "position": 349
        },
        "endLoc": {
          "line": 48,
          "column": 7,
          "position": 452
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 39,
        "end": 21,
        "startLoc": {
          "line": 39,
          "column": 2,
          "position": 445
        },
        "endLoc": {
          "line": 21,
          "column": 8,
          "position": 184
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ";\n\n  const handlePrevious = () => {\n    setOffset(Math.max(offset - 1, 0));\n  };\n\n  const handleNext = () => {\n    setOffset(offset + 1);\n  };\n\n  return",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Logging/index.jsx",
        "start": 46,
        "end": 56,
        "startLoc": {
          "line": 46,
          "column": 2,
          "position": 460
        },
        "endLoc": {
          "line": 56,
          "column": 7,
          "position": 532
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedChats/index.jsx",
        "start": 101,
        "end": 111,
        "startLoc": {
          "line": 101,
          "column": 2,
          "position": 966
        },
        "endLoc": {
          "line": 111,
          "column": 6,
          "position": 1038
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": ");\n  };\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"flex gap-x-4 items-center",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Logging/index.jsx",
        "start": 53,
        "end": 65,
        "startLoc": {
          "line": 53,
          "column": 2,
          "position": 523
        },
        "endLoc": {
          "line": 65,
          "column": 26,
          "position": 612
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 39,
        "end": 19,
        "startLoc": {
          "line": 39,
          "column": 2,
          "position": 443
        },
        "endLoc": {
          "line": 19,
          "column": 26,
          "position": 168
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\n  if (loading) {\n    return (\n      <Skeleton.default\n        height=\"80vh\"\n        width=\"100%\"\n        highlightColor=\"var(--theme-bg-primary)\"\n        baseColor=\"var(--theme-bg-secondary)\"\n        count={1}\n        className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm\"\n        containerClassName=\"flex w-full\"\n      />\n    );\n  }\n\n  return (\n    <>\n      <table className=\"w-full text-xs text-left rounded-lg min-w-[640px] border-spacing-0\">\n        <thead className=\"text-theme-text-secondary text-xs leading-[18px] font-bold uppercase border-white/10 border-b\">\n          <tr>\n            <th scope=\"col\" className=\"px-6 py-3 rounded-tl-lg\">\n              {t(\"event.table.type\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Logging/index.jsx",
        "start": 106,
        "end": 127,
        "startLoc": {
          "line": 106,
          "column": 2,
          "position": 851
        },
        "endLoc": {
          "line": 127,
          "column": 19,
          "position": 979
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/EmbedConfigs/index.jsx",
        "start": 27,
        "end": 237,
        "startLoc": {
          "line": 27,
          "column": 1,
          "position": 276
        },
        "endLoc": {
          "line": 237,
          "column": 20,
          "position": 1905
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ");\n\n  return (\n    <div className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex\">\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] bg-theme-bg-secondary w-full h-full overflow-y-scroll p-4 md:p-0\"\n      >\n        <div className=\"flex flex-col w-full px-1 md:pl-6 md:pr-[50px] md:py-6 py-16\">\n          <div className=\"w-full flex flex-col gap-y-1 pb-6 border-white/10 border-b-2\">\n            <div className=\"items-center flex gap-x-4\">\n              <p className=\"text-lg leading-6 font-bold text-theme-text-primary\">\n                Invitations",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/index.jsx",
        "start": 27,
        "end": 40,
        "startLoc": {
          "line": 27,
          "column": 2,
          "position": 273
        },
        "endLoc": {
          "line": 40,
          "column": 12,
          "position": 374
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Workspaces/index.jsx",
        "start": 15,
        "end": 21,
        "startLoc": {
          "line": 15,
          "column": 2,
          "position": 159
        },
        "endLoc": {
          "line": 21,
          "column": 8,
          "position": 184
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n            </CTAButton>\n          </div>\n          <div className=\"overflow-x-auto mt-6\">\n            {loading ? (\n              <Skeleton.default\n                height=\"80vh\"\n                width=\"100%\"\n                highlightColor=\"var(--theme-bg-primary)\"\n                baseColor=\"var(--theme-bg-secondary)\"\n                count={1}\n                className=\"w-full p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm\"\n                containerClassName=\"flex w-full\"\n              />\n            ) : (\n              <table className=\"w-full text-xs text-left rounded-lg min-w-[640px] border-spacing-0\">\n                <thead className=\"text-theme-text-secondary text-xs leading-[18px] font-bold uppercase border-white/10 border-b\">\n                  <tr>\n                    <th scope=\"col\" className=\"px-6 py-3 rounded-tl-lg\">\n                      Status",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Invitations/index.jsx",
        "start": 54,
        "end": 73,
        "startLoc": {
          "line": 54,
          "column": 5,
          "position": 510
        },
        "endLoc": {
          "line": 73,
          "column": 7,
          "position": 640
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/BrowserExtensionApiKey/index.jsx",
        "start": 67,
        "end": 91,
        "startLoc": {
          "line": 67,
          "column": 4,
          "position": 667
        },
        "endLoc": {
          "line": 91,
          "column": 2,
          "position": 805
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\"\n      className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex md:mt-0 mt-6\"\n    >\n      <Sidebar />\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] w-full h-full flex\"\n      >\n        {children}\n      </div>\n    </div>\n  );\n}\n\nfunction FeatureList",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/index.jsx",
        "start": 92,
        "end": 106,
        "startLoc": {
          "line": 92,
          "column": 37,
          "position": 727
        },
        "endLoc": {
          "line": 106,
          "column": 12,
          "position": 797
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/index.jsx",
        "start": 104,
        "end": 118,
        "startLoc": {
          "line": 104,
          "column": 36,
          "position": 749
        },
        "endLoc": {
          "line": 118,
          "column": 11,
          "position": 819
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": " ? \"On\" : \"Off\"}\n            </div>\n            <CaretRight\n              size={14}\n              weight=\"bold\"\n              className=\"text-theme-text-secondary\"\n            />\n          </div>\n        </div>\n      ))}\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/index.jsx",
        "start": 139,
        "end": 152,
        "startLoc": {
          "line": 139,
          "column": 2,
          "position": 1059
        },
        "endLoc": {
          "line": 152,
          "column": 1,
          "position": 1123
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/Imported/SkillList/index.jsx",
        "start": 48,
        "end": 61,
        "startLoc": {
          "line": 48,
          "column": 7,
          "position": 371
        },
        "endLoc": {
          "line": 61,
          "column": 1,
          "position": 435
        }
      }
    },
    {
      "format": "javascript",
      "lines": 89,
      "fragment": "}\n                    />\n                  );\n                }}\n              </MCPServerHeader>\n            </div>\n          </div>\n        </div>\n\n        {/* Selected agent skill setting panel */}\n        <div className=\"flex-[2] flex flex-col gap-y-[18px] mt-10\">\n          <div className=\"bg-theme-bg-secondary text-white rounded-xl flex-1 p-4 overflow-y-scroll no-scroll\">\n            {SelectedSkillComponent ? (\n              <>\n                {selectedMcpServer ? (\n                  <ServerPanel\n                    server={selectedMcpServer}\n                    toggleServer={toggleMCP}\n                    onDelete={handleMCPServerDelete}\n                  />\n                ) : selectedFlow ? (\n                  <FlowPanel\n                    flow={selectedFlow}\n                    toggleFlow={toggleFlow}\n                    enabled={activeFlowIds.includes(selectedFlow.uuid)}\n                    onDelete={handleFlowDelete}\n                  />\n                ) : selectedSkill.imported ? (\n                  <ImportedSkillConfig\n                    key={selectedSkill.hubId}\n                    selectedSkill={selectedSkill}\n                    setImportedSkills={setImportedSkills}\n                  />\n                ) : (\n                  <>\n                    {defaultSkills?.[selectedSkill] ? (\n                      // The selected skill is a default skill - show the default skill panel\n                      <SelectedSkillComponent\n                        skill={defaultSkills[selectedSkill]?.skill}\n                        settings={settings}\n                        toggleSkill={toggleDefaultSkill}\n                        enabled={\n                          !disabledAgentSkills.includes(\n                            defaultSkills[selectedSkill]?.skill\n                          )\n                        }\n                        setHasChanges={setHasChanges}\n                        {...defaultSkills[selectedSkill]}\n                      />\n                    ) : (\n                      // The selected skill is a configurable skill - show the configurable skill panel\n                      <SelectedSkillComponent\n                        skill={configurableSkills[selectedSkill]?.skill}\n                        settings={settings}\n                        toggleSkill={toggleAgentSkill}\n                        enabled={agentSkills.includes(\n                          configurableSkills[selectedSkill]?.skill\n                        )}\n                        setHasChanges={setHasChanges}\n                        {...configurableSkills[selectedSkill]}\n                      />\n                    )}\n                  </>\n                )}\n              </>\n            ) : (\n              <div className=\"flex flex-col items-center justify-center h-full text-theme-text-secondary\">\n                <Robot size={40} />\n                <p className=\"font-medium\">\n                  Select an Agent Skill, Agent Flow, or MCP Server\n                </p>\n              </div>\n            )}\n          </div>\n        </div>\n      </form>\n    </SkillLayout>\n  );\n}\n\nfunction SkillLayout({ children, hasChanges, handleSubmit, handleCancel }) {\n  return (\n    <div\n      id=\"workspace-agent-settings-container\"\n      className=\"w-screen h-screen overflow-hidden bg-theme-bg-container flex md:mt-0 mt-6\"\n    >\n      <Sidebar />\n      <div\n        style={{",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/index.jsx",
        "start": 535,
        "end": 623,
        "startLoc": {
          "line": 535,
          "column": 15,
          "position": 4222
        },
        "endLoc": {
          "line": 623,
          "column": 2,
          "position": 4780
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/index.jsx",
        "start": 349,
        "end": 429,
        "startLoc": {
          "line": 349,
          "column": 3,
          "position": 2981
        },
        "endLoc": {
          "line": 429,
          "column": 11,
          "position": 3498
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\n    e.preventDefault();\n    const data = {\n      workspace: {},\n      system: {},\n      env: {},\n    };\n\n    const form = new FormData(formEl.current);\n    for (var [key, value] of form.entries()) {\n      if (key.startsWith(\"system::\")) {\n        const [_, label] = key.split(\"system::\");\n        data.system[label] = String(value);\n        continue;\n      }\n\n      if (key.startsWith(\"env::\")) {\n        const [_, label] = key.split(\"env::\");\n        data.env[label] = String(value);\n        continue;\n      }\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/index.jsx",
        "start": 127,
        "end": 148,
        "startLoc": {
          "line": 127,
          "column": 2,
          "position": 1279
        },
        "endLoc": {
          "line": 148,
          "column": 7,
          "position": 1482
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/AgentConfig/index.jsx",
        "start": 32,
        "end": 54,
        "startLoc": {
          "line": 32,
          "column": 2,
          "position": 362
        },
        "endLoc": {
          "line": 54,
          "column": 1,
          "position": 565
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ");\n  };\n\n  if (loading) {\n    return (\n      <div\n        style={{ height: isMobile ? \"100%\" : \"calc(100% - 32px)\" }}\n        className=\"relative md:ml-[2px] md:mr-[16px] md:my-[16px] md:rounded-[16px] w-full h-full flex justify-center items-center\"\n      >\n        <FullScreenLoader />\n      </div>\n    );\n  }\n\n  if",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/index.jsx",
        "start": 229,
        "end": 243,
        "startLoc": {
          "line": 229,
          "column": 5,
          "position": 2232
        },
        "endLoc": {
          "line": 243,
          "column": 3,
          "position": 2304
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/ExperimentalFeatures/index.jsx",
        "start": 31,
        "end": 45,
        "startLoc": {
          "line": 31,
          "column": 2,
          "position": 328
        },
        "endLoc": {
          "line": 45,
          "column": 7,
          "position": 400
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": " && (\n            <div className=\"fixed top-0 left-0 w-full h-full bg-sidebar z-30\">\n              <div className=\"flex flex-col h-full\">\n                <div className=\"flex items-center p-4\">\n                  <button\n                    type=\"button\"\n                    onClick={() => {\n                      setShowSkillModal(false);\n                      setSelectedSkill(\"\");\n                    }}\n                    className=\"text-white/60 hover:text-white transition-colors duration-200\"\n                  >\n                    <div className=\"flex items-center text-sky-400\">\n                      <CaretLeft size={24} />\n                      <div>Back</div>\n                    </div>\n                  </button>\n                </div>\n                <div className=\"flex-1 overflow-y-auto p-4\">\n                  <div className=\" bg-theme-bg-secondary text-white rounded-xl p-4 overflow-y-scroll no-scroll",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/Admin/Agents/index.jsx",
        "start": 336,
        "end": 355,
        "startLoc": {
          "line": 336,
          "column": 15,
          "position": 2881
        },
        "endLoc": {
          "line": 355,
          "column": 77,
          "position": 3027
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/ChatEmbedWidgets/index.jsx",
        "start": 33,
        "end": 52,
        "startLoc": {
          "line": 33,
          "column": 14,
          "position": 275
        },
        "endLoc": {
          "line": 52,
          "column": 76,
          "position": 421
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\n        count={1}\n        className=\"max-w-full md:max-w-[80%] p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm mt-6\"\n        containerClassName=\"flex justify-start\"\n      />\n      <Skeleton.default\n        height=\"100px\"\n        width={isMobile ? \"88%\" : \"25%\"}\n        baseColor={baseColor}\n        highlightColor={highlightColor}\n        count={1}\n        className=\"max-w-full md:max-w-[80%] p-4 rounded-b-2xl rounded-tr-2xl rounded-tl-sm mt-6\"\n        containerClassName=\"flex justify-end\"\n      />\n      <Skeleton.default\n        height=\"160px",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/WorkspaceChat/LoadingChat/index.jsx",
        "start": 35,
        "end": 50,
        "startLoc": {
          "line": 35,
          "column": 2,
          "position": 230
        },
        "endLoc": {
          "line": 50,
          "column": 6,
          "position": 313
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/LoadingChat/index.jsx",
        "start": 17,
        "end": 32,
        "startLoc": {
          "line": 17,
          "column": 2,
          "position": 120
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 203
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\n  return (\n    <div\n      onClick={() => onClick(value)}\n      className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n        checked ? \"bg-theme-bg-secondary\" : \"\"\n      }`}\n    >\n      <input\n        type=\"checkbox\"\n        value={value}\n        className=\"peer hidden\"\n        checked={checked}\n        readOnly={true}\n        formNoValidate={true}\n      />\n      <div className=\"flex gap-x-4 items-center\">\n        <img\n          ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx",
        "start": 8,
        "end": 26,
        "startLoc": {
          "line": 8,
          "column": 2,
          "position": 38
        },
        "endLoc": {
          "line": 26,
          "column": 11,
          "position": 138
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Agents/WebSearchSelection/SearchProviderItem/index.jsx",
        "start": 2,
        "end": 19,
        "startLoc": {
          "line": 2,
          "column": 2,
          "position": 45
        },
        "endLoc": {
          "line": 19,
          "column": 2,
          "position": 137
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\"\n            defaultValue={settings?.QdrantEndpoint}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"QdrantApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/VectorDBSelection/QDrantDBOptions/index.jsx",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 22,
          "position": 104
        },
        "endLoc": {
          "line": 27,
          "column": 13,
          "position": 186
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/WeaviateDBOptions/index.jsx",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 22,
          "position": 102
        },
        "endLoc": {
          "line": 27,
          "column": 15,
          "position": 184
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ")}\n            </h3>\n          </div>\n          <button\n            onClick={hideModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div\n          className=\"h-full w-full overflow-y-auto\"\n          style={{ maxHeight: \"calc(100vh - 200px)\" }}\n        >\n          <form onSubmit={handleUpdate} ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/UserMenu/AccountModal/index.jsx",
        "start": 77,
        "end": 92,
        "startLoc": {
          "line": 77,
          "column": 32,
          "position": 820
        },
        "endLoc": {
          "line": 92,
          "column": 2,
          "position": 924
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/AddPresetModal.jsx",
        "start": 34,
        "end": 69,
        "startLoc": {
          "line": 34,
          "column": 29,
          "position": 365
        },
        "endLoc": {
          "line": 69,
          "column": 2,
          "position": 584
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n                </p>\n              </div>\n              <div>\n                <label\n                  htmlFor=\"bio\"\n                  className=\"block mb-2 text-sm font-medium text-white\"\n                >\n                  Bio\n                </label>\n                <textarea\n                  name=\"bio\"\n                  className=\"border-none bg-theme-settings-input-bg placeholder:text-theme-settings-input-placeholder border-gray-500 text-white text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5 min-h-[100px] resize-y",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/UserMenu/AccountModal/index.jsx",
        "start": 169,
        "end": 181,
        "startLoc": {
          "line": 169,
          "column": 2,
          "position": 1405
        },
        "endLoc": {
          "line": 181,
          "column": 249,
          "position": 1460
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/Admin/Users/UserRow/EditUserModal/index.jsx",
        "start": 103,
        "end": 115,
        "startLoc": {
          "line": 103,
          "column": 5,
          "position": 904
        },
        "endLoc": {
          "line": 115,
          "column": 217,
          "position": 959
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\"\n          data-tooltip-content={t(\"customization.chat.auto_speak.description\")}\n          className=\"cursor-pointer h-fit\"\n        >\n          <Info size={16} weight=\"bold\" className=\"text-white\" />\n        </div>\n      </div>\n      <div className=\"flex items-center gap-x-4\">\n        <label className=\"relative inline-flex cursor-pointer items-center\">\n          <input\n            id=\"autoSpeak",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/UserMenu/AccountModal/index.jsx",
        "start": 363,
        "end": 373,
        "startLoc": {
          "line": 363,
          "column": 16,
          "position": 2699
        },
        "endLoc": {
          "line": 373,
          "column": 10,
          "position": 2781
        }
      },
      "secondFile": {
        "name": "frontend/src/components/UserMenu/AccountModal/index.jsx",
        "start": 305,
        "end": 315,
        "startLoc": {
          "line": 305,
          "column": 17,
          "position": 2300
        },
        "endLoc": {
          "line": 315,
          "column": 11,
          "position": 2382
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "() {\n  const { t } = useTranslation();\n\n  return (\n    <div className=\"flex flex-col md:flex-row md:items-center gap-x-2 text-white mb-4 bg-blue-800/30 w-fit rounded-lg px-4 py-2\">\n      <div className=\"gap-x-2 flex items-center\">\n        <Gauge size={25} />\n        <p className=\"text-sm\">\n          {t(\"transcription.warn-start\")}\n          <br />\n          {t(\"transcription.warn-recommend\")}\n          <br />\n          <br />\n          <i>{t(\"transcription.warn-end\")} (1.56",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/TranscriptionSelection/NativeTranscriptionOptions/index.jsx",
        "start": 70,
        "end": 83,
        "startLoc": {
          "line": 70,
          "column": 13,
          "position": 530
        },
        "endLoc": {
          "line": 83,
          "column": 5,
          "position": 648
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TranscriptionSelection/NativeTranscriptionOptions/index.jsx",
        "start": 50,
        "end": 63,
        "startLoc": {
          "line": 50,
          "column": 13,
          "position": 380
        },
        "endLoc": {
          "line": 63,
          "column": 4,
          "position": 498
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": " }) {\n  const playerRef = useRef(null);\n  const [speaking, setSpeaking] = useState(false);\n  const [loading, setLoading] = useState(false);\n  const [audioSrc, setAudioSrc] = useState(null);\n\n  async function speakMessage(e) {\n    e.preventDefault();\n    if (speaking) {\n      playerRef?.current?.pause();\n      return;\n    }\n\n    try {\n      if (!audioSrc) {\n        setLoading(true);\n        const client = new PiperTTSClient({ voiceId });\n        const blobUrl = await client.getAudioBlobForText(\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/TextToSpeech/PiperTTSOptions/index.jsx",
        "start": 134,
        "end": 152,
        "startLoc": {
          "line": 134,
          "column": 8,
          "position": 1233
        },
        "endLoc": {
          "line": 152,
          "column": 1,
          "position": 1410
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/piperTTS.jsx",
        "start": 5,
        "end": 22,
        "startLoc": {
          "line": 5,
          "column": 8,
          "position": 69
        },
        "endLoc": {
          "line": 22,
          "column": 8,
          "position": 246
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": ";\n      } else {\n        playerRef.current.play();\n      }\n    } catch (e) {\n      console.error(e);\n      setLoading(false);\n      setSpeaking(false);\n    }\n  }\n\n  useEffect(() => {\n    function setupPlayer() {\n      if (!playerRef?.current) return;\n      playerRef.current.addEventListener(\"play\", () => {\n        setSpeaking(true);\n      });\n\n      playerRef.current.addEventListener(\"pause\", () => {\n        playerRef.current.currentTime = 0;\n        setSpeaking(false);\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/TextToSpeech/PiperTTSOptions/index.jsx",
        "start": 157,
        "end": 178,
        "startLoc": {
          "line": 157,
          "column": 5,
          "position": 1451
        },
        "endLoc": {
          "line": 178,
          "column": 9,
          "position": 1613
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/ChatHistory/HistoricalMessage/Actions/TTSButton/piperTTS.jsx",
        "start": 24,
        "end": 45,
        "startLoc": {
          "line": 24,
          "column": 2,
          "position": 262
        },
        "endLoc": {
          "line": 45,
          "column": 7,
          "position": 424
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ";\n\n  return (\n    <div className=\"flex gap-x-4\">\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          API Key\n        </label>\n        <input\n          type=\"password\"\n          name=\"TTSElevenLabsKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 8,
        "end": 18,
        "startLoc": {
          "line": 8,
          "column": 2,
          "position": 87
        },
        "endLoc": {
          "line": 18,
          "column": 17,
          "position": 151
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/OpenAiOptions/index.jsx",
        "start": 8,
        "end": 18,
        "startLoc": {
          "line": 8,
          "column": 13,
          "position": 91
        },
        "endLoc": {
          "line": 18,
          "column": 13,
          "position": 155
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": ");\n  const [customAppName, setCustomAppName] = useState(null);\n\n  const {\n    isOpen: isRecoveryCodeModalOpen,\n    openModal: openRecoveryCodeModal,\n    closeModal: closeRecoveryCodeModal,\n  } = useModal();\n\n  const handleLogin = async (e) => {\n    setError(null);\n    setLoading(true);\n    e.preventDefault();\n    const data = {};\n    const form = new FormData(e.target);\n    for (var [key, value] of form.entries()) data[key] = value;\n    const { valid, user",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/Password/MultiUserAuth.jsx",
        "start": 177,
        "end": 193,
        "startLoc": {
          "line": 177,
          "column": 6,
          "position": 1403
        },
        "endLoc": {
          "line": 193,
          "column": 5,
          "position": 1569
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/Password/SingleUserAuth.jsx",
        "start": 16,
        "end": 32,
        "startLoc": {
          "line": 16,
          "column": 5,
          "position": 211
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 377
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n        window.localStorage.setItem(AUTH_TOKEN, token);\n        window.location = paths.home();\n      }\n    } else {\n      setError(message);\n      setLoading(false);\n    }\n    setLoading(false);\n  };\n\n  const handleDownloadComplete = () => setDownloadComplete",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/Password/MultiUserAuth.jsx",
        "start": 203,
        "end": 214,
        "startLoc": {
          "line": 203,
          "column": 2,
          "position": 1678
        },
        "endLoc": {
          "line": 214,
          "column": 20,
          "position": 1758
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/Password/SingleUserAuth.jsx",
        "start": 39,
        "end": 50,
        "startLoc": {
          "line": 39,
          "column": 2,
          "position": 450
        },
        "endLoc": {
          "line": 50,
          "column": 2,
          "position": 530
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ", token]);\n\n  useEffect(() => {\n    const fetchCustomAppName = async () => {\n      const { appName } = await System.fetchCustomAppName();\n      setCustomAppName(appName || \"\");\n      setLoading(false);\n    };\n    fetchCustomAppName();\n  }, []);\n\n  if",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/Password/MultiUserAuth.jsx",
        "start": 259,
        "end": 270,
        "startLoc": {
          "line": 259,
          "column": 5,
          "position": 2196
        },
        "endLoc": {
          "line": 270,
          "column": 3,
          "position": 2289
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/Password/SingleUserAuth.jsx",
        "start": 59,
        "end": 70,
        "startLoc": {
          "line": 59,
          "column": 17,
          "position": 604
        },
        "endLoc": {
          "line": 70,
          "column": 7,
          "position": 697
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\">\n          <div className=\"flex items-start justify-between pt-11 pb-9 rounded-t\">\n            <div className=\"flex items-center flex-col gap-y-4\">\n              <div className=\"flex gap-x-1\">\n                <h3 className=\"text-md md:text-2xl font-bold text-white text-center white-space-nowrap hidden md:block\">\n                  {t(\"login.multi-user.welcome\")}\n                </h3>\n                <p className=\"text-4xl md:text-2xl font-bold bg-gradient-to-r from-[#75D6FF] via-[#FFFFFF] light:via-[#75D6FF] to-[#FFFFFF] light:to-[#75D6FF] bg-clip-text text-transparent\">\n                  {customAppName || \"AnythingLLM\"}\n                </p>\n              </div>\n              <p className=\"text-sm text-theme-text-secondary text-center\">\n                {t(\"login.sign-in.start\")} {customAppName || \"AnythingLLM\"}{\" \"}\n                {t(\"login.sign-in.end\")}\n              </p>\n            </div>\n          </div>\n          <div className=\"w-full px-4 md:px-12\">\n            <div className=\"w-full flex flex-col gap-y-4\">\n              <div className=\"w-screen md:w-full md:px-0 px-6\">\n                <input\n                  name=\"username",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/Password/MultiUserAuth.jsx",
        "start": 284,
        "end": 305,
        "startLoc": {
          "line": 284,
          "column": 154,
          "position": 2378
        },
        "endLoc": {
          "line": 305,
          "column": 9,
          "position": 2561
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/Password/SingleUserAuth.jsx",
        "start": 73,
        "end": 94,
        "startLoc": {
          "line": 73,
          "column": 157,
          "position": 724
        },
        "endLoc": {
          "line": 94,
          "column": 9,
          "position": 907
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n                  className=\"border-none bg-theme-settings-input-bg text-theme-text-primary placeholder:text-theme-settings-input-placeholder focus:outline-primary-button active:outline-primary-button outline-none text-sm rounded-md p-2.5 w-full h-[48px] md:w-[300px] md:h-[34px]\"\n                  required={true}\n                  autoComplete=\"off\"\n                />\n              </div>\n              {error && <p className=\"text-red-400 text-sm\">Error: {error}</p>}\n            </div>\n          </div>\n          <div className=\"flex items-center md:p-12 px-10 mt-12 md:mt-0 space-x-2 border-gray-600 w-full flex-col gap-y-8\">\n            <button\n              disabled={loading}\n              type=\"submit\"\n              className=\"md:text-primary-button md:bg-transparent text-dark-text text-sm font-bold focus:ring-4 focus:outline-none rounded-md border-[1.5px] border-primary-button md:h-[34px] h-[48px] md:hover:text-white md:hover:bg-primary-button bg-primary-button focus:z-10 w-full\"\n            >\n              {loading\n                ? t(\"login.multi-user.validating\")\n                : t(\"login.multi-user.login\")}\n            </button>\n            ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/Password/MultiUserAuth.jsx",
        "start": 317,
        "end": 336,
        "startLoc": {
          "line": 317,
          "column": 2,
          "position": 2639
        },
        "endLoc": {
          "line": 336,
          "column": 13,
          "position": 2762
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/Password/SingleUserAuth.jsx",
        "start": 96,
        "end": 115,
        "startLoc": {
          "line": 96,
          "column": 2,
          "position": 921
        },
        "endLoc": {
          "line": 115,
          "column": 11,
          "position": 1044
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\n            </button>\n          </div>\n        </div>\n      </form>\n\n      <ModalWrapper isOpen={isRecoveryCodeModalOpen} noPortal={true}>\n        <RecoveryCodeModal\n          recoveryCodes={recoveryCodes}\n          onDownloadComplete={handleDownloadComplete}\n          onClose={closeRecoveryCodeModal}\n        />\n      </ModalWrapper>\n    </>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/Password/MultiUserAuth.jsx",
        "start": 342,
        "end": 358,
        "startLoc": {
          "line": 342,
          "column": 2,
          "position": 2808
        },
        "endLoc": {
          "line": 358,
          "column": 1,
          "position": 2886
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Modals/Password/SingleUserAuth.jsx",
        "start": 113,
        "end": 129,
        "startLoc": {
          "line": 113,
          "column": 2,
          "position": 1038
        },
        "endLoc": {
          "line": 129,
          "column": 1,
          "position": 1116
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n              </h3>\n            </div>\n            <button\n              onClick={hideModal}\n              type=\"button\"\n              className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n            >\n              <X size={24} weight=\"bold\" className=\"text-white\" />\n            </button>\n          </div>\n          <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/ManageWorkspace/index.jsx",
        "start": 47,
        "end": 58,
        "startLoc": {
          "line": 47,
          "column": 19,
          "position": 511
        },
        "endLoc": {
          "line": 58,
          "column": 4,
          "position": 582
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/SetupProvider/index.jsx",
        "start": 44,
        "end": 55,
        "startLoc": {
          "line": 44,
          "column": 9,
          "position": 369
        },
        "endLoc": {
          "line": 55,
          "column": 5,
          "position": 440
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.XAIModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 94,
        "end": 108,
        "startLoc": {
          "line": 94,
          "column": 17,
          "position": 764
        },
        "endLoc": {
          "line": 108,
          "column": 7,
          "position": 851
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 84,
        "end": 98,
        "startLoc": {
          "line": 84,
          "column": 18,
          "position": 579
        },
        "endLoc": {
          "line": 98,
          "column": 9,
          "position": 663
        }
      }
    },
    {
      "format": "javascript",
      "lines": 81,
      "fragment": "? \"*\".repeat(20) : \"\"}\n          required={true}\n          autoComplete=\"off\"\n          spellCheck={false}\n          onChange={(e) => setInputValue(e.target.value)}\n          onBlur={() => setApiKey(inputValue)}\n        />\n      </div>\n      {!settings?.credentialsOnly && (\n        <TogetherAiModelSelection settings={settings} apiKey={apiKey} />\n      )}\n    </div>\n  );\n}\n\nfunction TogetherAiModelSelection({ settings, apiKey }) {\n  const [groupedModels, setGroupedModels] = useState({});\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      setLoading(true);\n      try {\n        const key = apiKey === \"*\".repeat(20) ? null : apiKey;\n        const { models } = await System.customModels(\"togetherai\", key);\n        if (models?.length > 0) {\n          const modelsByOrganization = models.reduce((acc, model) => {\n            if (model.type !== \"chat\") return acc; // Only show chat models in dropdown\n            const org = model.organization || \"Unknown\";\n            acc[org] = acc[org] || [];\n            acc[org].push({\n              id: model.id,\n              name: model.name || model.id,\n              organization: org,\n              maxLength: model.maxLength,\n            });\n            return acc;\n          }, {});\n          setGroupedModels(modelsByOrganization);\n        }\n      } catch (error) {\n        console.error(\"Error fetching Together AI models:\", error);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"TogetherAiModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"TogetherAiModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/TogetherAiOptions/index.jsx",
        "start": 19,
        "end": 99,
        "startLoc": {
          "line": 19,
          "column": 18,
          "position": 173
        },
        "endLoc": {
          "line": 99,
          "column": 13,
          "position": 890
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 19,
        "end": 98,
        "startLoc": {
          "line": 19,
          "column": 11,
          "position": 171
        },
        "endLoc": {
          "line": 98,
          "column": 6,
          "position": 793
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"TogetherAiModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/TogetherAiOptions/index.jsx",
        "start": 74,
        "end": 92,
        "startLoc": {
          "line": 74,
          "column": 20,
          "position": 726
        },
        "endLoc": {
          "line": 92,
          "column": 20,
          "position": 839
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.TogetherAiModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/TogetherAiOptions/index.jsx",
        "start": 92,
        "end": 115,
        "startLoc": {
          "line": 92,
          "column": 20,
          "position": 840
        },
        "endLoc": {
          "line": 115,
          "column": 1,
          "position": 994
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 87,
        "end": 110,
        "startLoc": {
          "line": 87,
          "column": 24,
          "position": 715
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"PerplexityModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/PerplexityOptions/index.jsx",
        "start": 50,
        "end": 68,
        "startLoc": {
          "line": 50,
          "column": 20,
          "position": 411
        },
        "endLoc": {
          "line": 68,
          "column": 20,
          "position": 524
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.PerplexityModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/PerplexityOptions/index.jsx",
        "start": 73,
        "end": 88,
        "startLoc": {
          "line": 73,
          "column": 28,
          "position": 563
        },
        "endLoc": {
          "line": 88,
          "column": 5,
          "position": 655
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 84,
        "end": 109,
        "startLoc": {
          "line": 84,
          "column": 18,
          "position": 579
        },
        "endLoc": {
          "line": 109,
          "column": 7,
          "position": 856
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx",
        "start": 62,
        "end": 73,
        "startLoc": {
          "line": 62,
          "column": 143,
          "position": 538
        },
        "endLoc": {
          "line": 73,
          "column": 14,
          "position": 605
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 71,
        "end": 82,
        "startLoc": {
          "line": 71,
          "column": 104,
          "position": 613
        },
        "endLoc": {
          "line": 82,
          "column": 19,
          "position": 680
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.PPIOModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx",
        "start": 80,
        "end": 101,
        "startLoc": {
          "line": 80,
          "column": 121,
          "position": 652
        },
        "endLoc": {
          "line": 101,
          "column": 1,
          "position": 794
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 89,
        "end": 110,
        "startLoc": {
          "line": 89,
          "column": 104,
          "position": 727
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "();\n  }, []);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"OpenRouterModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 92,
        "end": 102,
        "startLoc": {
          "line": 92,
          "column": 17,
          "position": 771
        },
        "endLoc": {
          "line": 102,
          "column": 20,
          "position": 855
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx",
        "start": 49,
        "end": 69,
        "startLoc": {
          "line": 49,
          "column": 12,
          "position": 435
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"OpenRouterModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 102,
        "end": 120,
        "startLoc": {
          "line": 102,
          "column": 20,
          "position": 856
        },
        "endLoc": {
          "line": 120,
          "column": 20,
          "position": 969
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.OpenRouterModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 120,
        "end": 143,
        "startLoc": {
          "line": 120,
          "column": 20,
          "position": 970
        },
        "endLoc": {
          "line": 143,
          "column": 1,
          "position": 1124
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 87,
        "end": 110,
        "startLoc": {
          "line": 87,
          "column": 24,
          "position": 715
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\">\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          API Key\n        </label>\n        <input\n          type=\"password\"\n          name=\"OpenAiKey\"\n          className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n          placeholder=\"OpenAI API Key\"\n          defaultValue={settings?.OpenAiKey ? \"*\".repeat(20) : \"\"}\n          required={true}\n          autoComplete=\"off\"\n          spellCheck={false}\n          onChange={(e) => setInputValue(e.target.value)}\n          onBlur={() => setOpenAIKey(inputValue)}\n        />\n      </div>\n      {",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx",
        "start": 9,
        "end": 27,
        "startLoc": {
          "line": 9,
          "column": 23,
          "position": 99
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 242
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TranscriptionSelection/OpenAiOptions/index.jsx",
        "start": 8,
        "end": 26,
        "startLoc": {
          "line": 8,
          "column": 31,
          "position": 87
        },
        "endLoc": {
          "line": 26,
          "column": 2,
          "position": 230
        }
      }
    },
    {
      "format": "jsx",
      "lines": 26,
      "fragment": ",\n        typeof apiKey === \"boolean\" ? null : apiKey\n      );\n\n      if (models?.length > 0) {\n        const modelsByOrganization = models.reduce((acc, model) => {\n          acc[model.organization] = acc[model.organization] || [];\n          acc[model.organization].push(model);\n          return acc;\n        }, {});\n        setGroupedModels(modelsByOrganization);\n      }\n\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"OpenAiModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx",
        "start": 42,
        "end": 67,
        "startLoc": {
          "line": 42,
          "column": 9,
          "position": 389
        },
        "endLoc": {
          "line": 67,
          "column": 16,
          "position": 596
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 44,
        "end": 69,
        "startLoc": {
          "line": 44,
          "column": 17,
          "position": 393
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"OpenAiModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx",
        "start": 67,
        "end": 85,
        "startLoc": {
          "line": 67,
          "column": 16,
          "position": 597
        },
        "endLoc": {
          "line": 85,
          "column": 16,
          "position": 710
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.OpenAiModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx",
        "start": 85,
        "end": 108,
        "startLoc": {
          "line": 85,
          "column": 16,
          "position": 711
        },
        "endLoc": {
          "line": 108,
          "column": 1,
          "position": 865
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 87,
        "end": 110,
        "startLoc": {
          "line": 87,
          "column": 24,
          "position": 715
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.OllamaLLMModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n      <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 297,
        "end": 312,
        "startLoc": {
          "line": 297,
          "column": 19,
          "position": 2334
        },
        "endLoc": {
          "line": 312,
          "column": 65,
          "position": 2432
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 84,
        "end": 109,
        "startLoc": {
          "line": 84,
          "column": 18,
          "position": 579
        },
        "endLoc": {
          "line": 109,
          "column": 73,
          "position": 863
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"NvidiaNimLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NvidiaNimOptions/remote.jsx",
        "start": 96,
        "end": 114,
        "startLoc": {
          "line": 96,
          "column": 22,
          "position": 663
        },
        "endLoc": {
          "line": 114,
          "column": 22,
          "position": 776
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": "? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        {!settings?.credentialsOnly && (\n          <NovitaModelSelection settings={settings} />\n        )}\n      </div>\n      <AdvancedControls settings={settings} />\n    </div>\n  );\n}\n\nfunction AdvancedControls({ settings }) {\n  const [showAdvancedControls, setShowAdvancedControls] = useState(false);\n\n  return (\n    <div className=\"flex flex-col gap-y-4\">\n      <div className=\"flex justify-start\">\n        <button\n          type=\"button\"\n          onClick={() => setShowAdvancedControls(!showAdvancedControls)}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-theme-text-primary text-sm font-semibold block mb-3\">\n            Stream Timeout (ms)\n          </label>\n          <input\n            type=\"number\"\n            name=\"NovitaLLMTimeout\"\n            className=\"border-none bg-theme-settings-input-bg text-theme-text-primary placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"Timeout value between token responses to auto-timeout the stream\"\n            defaultValue={settings?.NovitaLLMTimeout ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 18,
        "end": 62,
        "startLoc": {
          "line": 18,
          "column": 17,
          "position": 155
        },
        "endLoc": {
          "line": 62,
          "column": 18,
          "position": 507
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 18,
        "end": 60,
        "startLoc": {
          "line": 18,
          "column": 18,
          "position": 155
        },
        "endLoc": {
          "line": 60,
          "column": 19,
          "position": 491
        }
      }
    },
    {
      "format": "javascript",
      "lines": 74,
      "fragment": "?? 500}\n            autoComplete=\"off\"\n            onScroll={(e) => e.target.blur()}\n            min={500}\n            step={1}\n          />\n          <p className=\"text-xs leading-[18px] font-base text-theme-text-primary text-opacity-60 mt-2\">\n            Timeout value between token responses to auto-timeout the stream.\n          </p>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction NovitaModelSelection({ settings }) {\n  const [groupedModels, setGroupedModels] = useState({});\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      setLoading(true);\n      const { models } = await System.customModels(\"novita\");\n      if (models?.length > 0) {\n        const modelsByOrganization = models.reduce((acc, model) => {\n          acc[model.organization] = acc[model.organization] || [];\n          acc[model.organization].push(model);\n          return acc;\n        }, {});\n        setGroupedModels(modelsByOrganization);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, []);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-theme-text-primary text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"NovitaLLMModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg text-theme-text-primary border-theme-border text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-theme-text-primary text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"NovitaLLMModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg text-theme-text-primary border-theme-border text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.NovitaLLMModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 62,
        "end": 135,
        "startLoc": {
          "line": 62,
          "column": 18,
          "position": 508
        },
        "endLoc": {
          "line": 135,
          "column": 20,
          "position": 1125
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 60,
        "end": 132,
        "startLoc": {
          "line": 60,
          "column": 19,
          "position": 492
        },
        "endLoc": {
          "line": 132,
          "column": 21,
          "position": 1073
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": " settings={settings} />\n        )}\n      </div>\n      <AdvancedControls settings={settings} />\n    </div>\n  );\n}\n\nfunction AdvancedControls({ settings }) {\n  const [showAdvancedControls, setShowAdvancedControls] = useState(false);\n\n  return (\n    <div className=\"flex flex-col gap-y-4\">\n      <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 25,
        "end": 38,
        "startLoc": {
          "line": 25,
          "column": 21,
          "position": 209
        },
        "endLoc": {
          "line": 38,
          "column": 4,
          "position": 301
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 25,
        "end": 38,
        "startLoc": {
          "line": 25,
          "column": 25,
          "position": 209
        },
        "endLoc": {
          "line": 38,
          "column": 7,
          "position": 301
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\n          onClick={() => setShowAdvancedControls(!showAdvancedControls)}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 40,
        "end": 52,
        "startLoc": {
          "line": 40,
          "column": 2,
          "position": 319
        },
        "endLoc": {
          "line": 52,
          "column": 7,
          "position": 425
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 62,
        "end": 78,
        "startLoc": {
          "line": 62,
          "column": 7,
          "position": 490
        },
        "endLoc": {
          "line": 78,
          "column": 1,
          "position": 608
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ");\n      if (models?.length > 0) {\n        const modelsByOrganization = models.reduce((acc, model) => {\n          acc[model.organization] = acc[model.organization] || [];\n          acc[model.organization].push(model);\n          return acc;\n        }, {});\n        setGroupedModels(modelsByOrganization);\n      }\n      setLoading(false);\n    }\n    findCustomModels",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 84,
        "end": 95,
        "startLoc": {
          "line": 84,
          "column": 9,
          "position": 708
        },
        "endLoc": {
          "line": 95,
          "column": 17,
          "position": 822
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx",
        "start": 38,
        "end": 49,
        "startLoc": {
          "line": 38,
          "column": 7,
          "position": 320
        },
        "endLoc": {
          "line": 49,
          "column": 12,
          "position": 434
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n      setLoading(false);\n    }\n    findCustomModels();\n  }, []);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-theme-text-primary text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"NovitaLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 92,
        "end": 105,
        "startLoc": {
          "line": 92,
          "column": 2,
          "position": 810
        },
        "endLoc": {
          "line": 105,
          "column": 19,
          "position": 907
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OpenRouterOptions/index.jsx",
        "start": 89,
        "end": 68,
        "startLoc": {
          "line": 89,
          "column": 1,
          "position": 758
        },
        "endLoc": {
          "line": 68,
          "column": 13,
          "position": 569
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-theme-text-primary text-sm font-semibold block mb-3",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 107,
        "end": 119,
        "startLoc": {
          "line": 107,
          "column": 121,
          "position": 920
        },
        "endLoc": {
          "line": 119,
          "column": 57,
          "position": 998
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 71,
        "end": 83,
        "startLoc": {
          "line": 71,
          "column": 104,
          "position": 613
        },
        "endLoc": {
          "line": 83,
          "column": 44,
          "position": 691
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ">\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-theme-text-primary text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"NovitaLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 112,
        "end": 123,
        "startLoc": {
          "line": 112,
          "column": 7,
          "position": 960
        },
        "endLoc": {
          "line": 123,
          "column": 19,
          "position": 1021
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 78,
        "end": 89,
        "startLoc": {
          "line": 78,
          "column": 2,
          "position": 664
        },
        "endLoc": {
          "line": 89,
          "column": 13,
          "position": 725
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg text-theme-text-primary border-theme-border text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.NovitaLLMModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/NovitaLLMOptions/index.jsx",
        "start": 123,
        "end": 146,
        "startLoc": {
          "line": 123,
          "column": 19,
          "position": 1022
        },
        "endLoc": {
          "line": 146,
          "column": 1,
          "position": 1176
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx",
        "start": 78,
        "end": 110,
        "startLoc": {
          "line": 78,
          "column": 14,
          "position": 640
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"MistralModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/MistralOptions/index.jsx",
        "start": 70,
        "end": 83,
        "startLoc": {
          "line": 70,
          "column": 2,
          "position": 600
        },
        "endLoc": {
          "line": 83,
          "column": 17,
          "position": 670
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 74,
        "end": 87,
        "startLoc": {
          "line": 74,
          "column": 3,
          "position": 644
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.MistralModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/MistralOptions/index.jsx",
        "start": 88,
        "end": 106,
        "startLoc": {
          "line": 88,
          "column": 25,
          "position": 709
        },
        "endLoc": {
          "line": 106,
          "column": 1,
          "position": 811
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/LLMSelector/ChatModelSelection/index.jsx",
        "start": 84,
        "end": 91,
        "startLoc": {
          "line": 84,
          "column": 18,
          "position": 579
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 665
        }
      }
    },
    {
      "format": "javascript",
      "lines": 93,
      "fragment": "}\n          />\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-center gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                Local AI Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"LocalAiBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:8080/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LocalAIModelSelection({ settings, basePath = null, apiKey = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath || !basePath.includes(\"/v1\")) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"localai\",\n        typeof apiKey === \"boolean\" ? null : apiKey,\n        basePath\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath, apiKey]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"LocalAiModelPref\"\n          disabled={true",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 86,
        "end": 178,
        "startLoc": {
          "line": 86,
          "column": 2,
          "position": 723
        },
        "endLoc": {
          "line": 178,
          "column": 5,
          "position": 1421
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 53,
        "end": 121,
        "startLoc": {
          "line": 53,
          "column": 5,
          "position": 422
        },
        "endLoc": {
          "line": 121,
          "column": 3,
          "position": 919
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": "\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-center gap-4",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 87,
        "end": 107,
        "startLoc": {
          "line": 87,
          "column": 3,
          "position": 726
        },
        "endLoc": {
          "line": 107,
          "column": 31,
          "position": 888
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 58,
        "end": 53,
        "startLoc": {
          "line": 58,
          "column": 2,
          "position": 465
        },
        "endLoc": {
          "line": 53,
          "column": 19,
          "position": 444
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.LocalAiModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 197,
        "end": 220,
        "startLoc": {
          "line": 197,
          "column": 17,
          "position": 1540
        },
        "endLoc": {
          "line": 220,
          "column": 1,
          "position": 1679
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 292,
        "end": 91,
        "startLoc": {
          "line": 292,
          "column": 19,
          "position": 2296
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 665
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "({ settings, basePath = null, apiKey = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 76,
        "end": 88,
        "startLoc": {
          "line": 76,
          "column": 22,
          "position": 618
        },
        "endLoc": {
          "line": 88,
          "column": 6,
          "position": 741
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 147,
        "end": 245,
        "startLoc": {
          "line": 147,
          "column": 22,
          "position": 1129
        },
        "endLoc": {
          "line": 245,
          "column": 4,
          "position": 1947
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ",\n        typeof apiKey === \"boolean\" ? null : apiKey,\n        basePath\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath, apiKey]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 89,
        "end": 102,
        "startLoc": {
          "line": 89,
          "column": 10,
          "position": 760
        },
        "endLoc": {
          "line": 102,
          "column": 44,
          "position": 871
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 160,
        "end": 173,
        "startLoc": {
          "line": 160,
          "column": 10,
          "position": 1281
        },
        "endLoc": {
          "line": 173,
          "column": 44,
          "position": 1392
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {basePath?.includes(\"/v1\")\n              ? \"-- loading available models --\"\n              : \"-- waiting for URL --\"}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 106,
        "end": 122,
        "startLoc": {
          "line": 106,
          "column": 17,
          "position": 895
        },
        "endLoc": {
          "line": 122,
          "column": 44,
          "position": 995
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 177,
        "end": 193,
        "startLoc": {
          "line": 177,
          "column": 17,
          "position": 1416
        },
        "endLoc": {
          "line": 193,
          "column": 44,
          "position": 1516
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"LiteLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 113,
        "end": 126,
        "startLoc": {
          "line": 113,
          "column": 24,
          "position": 947
        },
        "endLoc": {
          "line": 126,
          "column": 17,
          "position": 1018
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/MistralOptions/index.jsx",
        "start": 70,
        "end": 87,
        "startLoc": {
          "line": 70,
          "column": 28,
          "position": 599
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.LiteLLMModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 126,
        "end": 149,
        "startLoc": {
          "line": 126,
          "column": 17,
          "position": 1019
        },
        "endLoc": {
          "line": 149,
          "column": 1,
          "position": 1158
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 292,
        "end": 91,
        "startLoc": {
          "line": 292,
          "column": 19,
          "position": 2296
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 665
        }
      }
    },
    {
      "format": "javascript",
      "lines": 142,
      "fragment": "}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum number of tokens for context and response.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                LM Studio Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"LMStudioBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:1234/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n            <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n              Enter the URL where LM Studio is running.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LMStudioModelSelection({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\n          \"lmstudio\",\n          null,\n          basePath\n        );\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          LM Studio Model\n        </label>\n        <select\n          name=\"LMStudioModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {!!basePath\n              ? \"--loading available models--\"\n              : \"Enter LM Studio URL first\"}\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Select the LM Studio model you want to use. Models will load after\n          entering a valid LM Studio URL.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        LM Studio Model\n      </label>\n      <select\n        name=\"LMStudioModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.LMStudioModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 64,
        "end": 205,
        "startLoc": {
          "line": 64,
          "column": 22,
          "position": 518
        },
        "endLoc": {
          "line": 205,
          "column": 19,
          "position": 1579
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 51,
        "end": 208,
        "startLoc": {
          "line": 51,
          "column": 2,
          "position": 399
        },
        "endLoc": {
          "line": 208,
          "column": 18,
          "position": 1625
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": " as your LLM requires you to set an embedding service to\n              use.\n            </p>\n          </div>\n          <a\n            href={paths.settings.embedder.modelPreference()}\n            className=\"text-sm md:text-base my-2 underline\"\n          >\n            Manage embedding &rarr;\n          </a>\n        </div>\n      )}\n      <div className=\"w-full flex items-start gap-[36px] mt-1.5",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 38,
        "end": 50,
        "startLoc": {
          "line": 38,
          "column": 9,
          "position": 321
        },
        "endLoc": {
          "line": 50,
          "column": 42,
          "position": 412
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 32,
        "end": 44,
        "startLoc": {
          "line": 32,
          "column": 8,
          "position": 302
        },
        "endLoc": {
          "line": 44,
          "column": 43,
          "position": 393
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": "\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"4096\"\n            defaultChecked=\"4096\"\n            min={1}\n            value={maxTokens}\n            onChange={handleMaxTokensChange}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum number of tokens for context and response.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 58,
        "end": 82,
        "startLoc": {
          "line": 58,
          "column": 19,
          "position": 482
        },
        "endLoc": {
          "line": 82,
          "column": 7,
          "position": 658
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 45,
        "end": 69,
        "startLoc": {
          "line": 45,
          "column": 20,
          "position": 347
        },
        "endLoc": {
          "line": 69,
          "column": 9,
          "position": 539
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 82,
        "end": 92,
        "startLoc": {
          "line": 82,
          "column": 6,
          "position": 663
        },
        "endLoc": {
          "line": 92,
          "column": 30,
          "position": 749
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 69,
        "end": 79,
        "startLoc": {
          "line": 69,
          "column": 9,
          "position": 542
        },
        "endLoc": {
          "line": 79,
          "column": 14,
          "position": 628
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": " Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"LMStudioBasePath",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 96,
        "end": 115,
        "startLoc": {
          "line": 96,
          "column": 7,
          "position": 790
        },
        "endLoc": {
          "line": 115,
          "column": 17,
          "position": 901
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 111,
        "end": 130,
        "startLoc": {
          "line": 111,
          "column": 3,
          "position": 929
        },
        "endLoc": {
          "line": 130,
          "column": 16,
          "position": 1040
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": " = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\n          \"lmstudio\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 135,
        "end": 149,
        "startLoc": {
          "line": 135,
          "column": 9,
          "position": 1031
        },
        "endLoc": {
          "line": 149,
          "column": 11,
          "position": 1163
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 147,
        "end": 247,
        "startLoc": {
          "line": 147,
          "column": 7,
          "position": 1143
        },
        "endLoc": {
          "line": 247,
          "column": 9,
          "position": 1970
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ",\n          basePath\n        );\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 150,
        "end": 161,
        "startLoc": {
          "line": 150,
          "column": 5,
          "position": 1168
        },
        "endLoc": {
          "line": 161,
          "column": 2,
          "position": 1245
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 248,
        "end": 259,
        "startLoc": {
          "line": 248,
          "column": 10,
          "position": 1975
        },
        "endLoc": {
          "line": 259,
          "column": 2,
          "position": 2052
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.LMStudioModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n      <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n        Choose the LM",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 194,
        "end": 215,
        "startLoc": {
          "line": 194,
          "column": 18,
          "position": 1494
        },
        "endLoc": {
          "line": 215,
          "column": 3,
          "position": 1639
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 292,
        "end": 313,
        "startLoc": {
          "line": 292,
          "column": 19,
          "position": 2296
        },
        "endLoc": {
          "line": 313,
          "column": 7,
          "position": 2441
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "={() => onClick(value)}\n      className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n        checked ? \"bg-theme-bg-secondary\" : \"\"\n      }`}\n    >\n      <input\n        type=\"checkbox\"\n        value={value}\n        className=\"peer hidden\"\n        checked={checked}\n        readOnly={true}\n        formNoValidate={true}\n      />\n      <div className=\"flex gap-x-4 items-center\">\n        <img\n          src={image}\n          alt={`${name} logo`}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LLMItem/index.jsx",
        "start": 11,
        "end": 27,
        "startLoc": {
          "line": 11,
          "column": 8,
          "position": 49
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 153
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx",
        "start": 11,
        "end": 27,
        "startLoc": {
          "line": 11,
          "column": 8,
          "position": 49
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 153
        }
      }
    },
    {
      "format": "jsx",
      "lines": 38,
      "fragment": "({\n  name,\n  value,\n  image,\n  description,\n  checked,\n  onClick,\n}) {\n  return (\n    <div\n      onClick={() => onClick(value)}\n      className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n        checked ? \"bg-theme-bg-secondary\" : \"\"\n      }`}\n    >\n      <input\n        type=\"checkbox\"\n        value={value}\n        className=\"peer hidden\"\n        checked={checked}\n        readOnly={true}\n        formNoValidate={true}\n      />\n      <div className=\"flex gap-x-4 items-center\">\n        <img\n          src={image}\n          alt={`${name} logo`}\n          className=\"w-10 h-10 rounded-md\"\n        />\n        <div className=\"flex flex-col\">\n          <div className=\"text-sm font-semibold text-white\">{name}</div>\n          <div className=\"mt-1 text-xs text-description\">{description}</div>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/LLMItem/index.jsx",
        "start": 1,
        "end": 38,
        "startLoc": {
          "line": 1,
          "column": 8,
          "position": 7
        },
        "endLoc": {
          "line": 38,
          "column": 1,
          "position": 228
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx",
        "start": 1,
        "end": 28,
        "startLoc": {
          "line": 1,
          "column": 13,
          "position": 7
        },
        "endLoc": {
          "line": 28,
          "column": 1,
          "position": 227
        }
      }
    },
    {
      "format": "javascript",
      "lines": 157,
      "fragment": "}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum number of tokens for context and response.\n          </p>\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-2\">\n            Max response tokens\n          </label>\n          <input\n            type=\"number\"\n            name=\"KoboldCPPMaxTokens\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"2048\"\n            min={1}\n            value={maxTokens}\n            onChange={handleMaxTokensChange}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum number of tokens for the response.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                KoboldCPP Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"border-none bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"KoboldCPPBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://127.0.0.1:5000/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n            <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n              Enter the URL where KoboldCPP is running.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction KoboldCPPModelSelection({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath || !basePath.includes(\"/v1\")) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\n          \"koboldcpp\",\n          null,\n          basePath\n        );\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          KoboldCPP Model\n        </label>\n        <select\n          name=\"KoboldCPPModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {basePath?.includes(\"/v1\")\n              ? \"--loading available models--\"\n              : \"Enter KoboldCPP URL first\"}\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Select the KoboldCPP model you want to use. Models will load after\n          entering a valid KoboldCPP URL.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        KoboldCPP Model\n      </label>\n      <select\n        name=\"KoboldCPPModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.map((model) => (\n          <option\n            key={model.id}\n            value={model.id}\n            selected={settings.KoboldCPPModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 57,
        "end": 213,
        "startLoc": {
          "line": 57,
          "column": 5,
          "position": 436
        },
        "endLoc": {
          "line": 213,
          "column": 20,
          "position": 1594
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 51,
        "end": 208,
        "startLoc": {
          "line": 51,
          "column": 6,
          "position": 432
        },
        "endLoc": {
          "line": 208,
          "column": 18,
          "position": 1625
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "=\"4096\"\n            min={1}\n            value={tokenLimit}\n            onChange={handleTokenLimitChange}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum number of tokens for context and response.\n          </p>\n        </div>\n        ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 52,
        "end": 64,
        "startLoc": {
          "line": 52,
          "column": 12,
          "position": 392
        },
        "endLoc": {
          "line": 64,
          "column": 9,
          "position": 485
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 48,
        "end": 60,
        "startLoc": {
          "line": 48,
          "column": 15,
          "position": 362
        },
        "endLoc": {
          "line": 60,
          "column": 7,
          "position": 471
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": " response.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                KoboldCPP",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 81,
        "end": 107,
        "startLoc": {
          "line": 81,
          "column": 4,
          "position": 619
        },
        "endLoc": {
          "line": 107,
          "column": 10,
          "position": 830
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 57,
        "end": 96,
        "startLoc": {
          "line": 57,
          "column": 4,
          "position": 457
        },
        "endLoc": {
          "line": 96,
          "column": 3,
          "position": 787
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath || !basePath.includes(\"/v1\")) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 146,
        "end": 158,
        "startLoc": {
          "line": 146,
          "column": 24,
          "position": 1063
        },
        "endLoc": {
          "line": 158,
          "column": 4,
          "position": 1189
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 135,
        "end": 159,
        "startLoc": {
          "line": 135,
          "column": 23,
          "position": 1024
        },
        "endLoc": {
          "line": 159,
          "column": 6,
          "position": 1262
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ",\n          null,\n          basePath\n        );\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length ===",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 160,
        "end": 174,
        "startLoc": {
          "line": 160,
          "column": 12,
          "position": 1213
        },
        "endLoc": {
          "line": 174,
          "column": 4,
          "position": 1311
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 149,
        "end": 163,
        "startLoc": {
          "line": 149,
          "column": 11,
          "position": 1164
        },
        "endLoc": {
          "line": 163,
          "column": 3,
          "position": 1262
        }
      }
    },
    {
      "format": "javascript",
      "lines": 82,
      "fragment": "? \"*\".repeat(20) : \"\"}\n          required={true}\n          autoComplete=\"off\"\n          spellCheck={false}\n          onChange={(e) => setInputValue(e.target.value)}\n          onBlur={() => setApiKey(inputValue)}\n        />\n      </div>\n\n      {!settings?.credentialsOnly && (\n        <GroqAIModelSelection settings={settings} apiKey={apiKey} />\n      )}\n    </div>\n  );\n}\n\nfunction GroqAIModelSelection({ apiKey, settings }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!apiKey) {\n        setCustomModels([]);\n        setLoading(true);\n        return;\n      }\n\n      try {\n        setLoading(true);\n        const { models } = await System.customModels(\"groq\", apiKey);\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      } finally {\n        setLoading(false);\n      }\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"GroqModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            --loading available models--\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Enter a valid API key to view all available models for your account.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"GroqModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Available models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.GroqModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx",
        "start": 19,
        "end": 100,
        "startLoc": {
          "line": 19,
          "column": 12,
          "position": 171
        },
        "endLoc": {
          "line": 100,
          "column": 15,
          "position": 812
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 19,
        "end": 100,
        "startLoc": {
          "line": 19,
          "column": 11,
          "position": 171
        },
        "endLoc": {
          "line": 100,
          "column": 14,
          "position": 812
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "({ apiKey, settings }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!apiKey) {\n        setCustomModels([]);\n        setLoading(true);\n        return;\n      }\n\n      try {\n        setLoading(true);\n        const { models } = await System.customModels(\"groq\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx",
        "start": 35,
        "end": 49,
        "startLoc": {
          "line": 35,
          "column": 21,
          "position": 293
        },
        "endLoc": {
          "line": 49,
          "column": 7,
          "position": 427
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 35,
        "end": 49,
        "startLoc": {
          "line": 35,
          "column": 18,
          "position": 293
        },
        "endLoc": {
          "line": 49,
          "column": 6,
          "position": 427
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": ", apiKey);\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      } finally {\n        setLoading(false);\n      }\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"GroqModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx",
        "start": 49,
        "end": 68,
        "startLoc": {
          "line": 49,
          "column": 7,
          "position": 428
        },
        "endLoc": {
          "line": 68,
          "column": 14,
          "position": 569
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 49,
        "end": 69,
        "startLoc": {
          "line": 49,
          "column": 6,
          "position": 428
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": ">\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"GroqModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx",
        "start": 78,
        "end": 89,
        "startLoc": {
          "line": 78,
          "column": 2,
          "position": 664
        },
        "endLoc": {
          "line": 89,
          "column": 14,
          "position": 725
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 76,
        "end": 87,
        "startLoc": {
          "line": 76,
          "column": 7,
          "position": 653
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Available models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.GroqModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n      <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n        Select",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GroqAiOptions/index.jsx",
        "start": 91,
        "end": 110,
        "startLoc": {
          "line": 91,
          "column": 104,
          "position": 738
        },
        "endLoc": {
          "line": 110,
          "column": 7,
          "position": 868
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/XAiLLMOptions/index.jsx",
        "start": 91,
        "end": 313,
        "startLoc": {
          "line": 91,
          "column": 121,
          "position": 738
        },
        "endLoc": {
          "line": 313,
          "column": 7,
          "position": 2437
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"GeminiLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GeminiLLMOptions/index.jsx",
        "start": 81,
        "end": 94,
        "startLoc": {
          "line": 81,
          "column": 2,
          "position": 553
        },
        "endLoc": {
          "line": 94,
          "column": 19,
          "position": 636
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 56,
        "end": 69,
        "startLoc": {
          "line": 56,
          "column": 1,
          "position": 517
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"GeminiLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/GeminiLLMOptions/index.jsx",
        "start": 94,
        "end": 112,
        "startLoc": {
          "line": 94,
          "column": 19,
          "position": 637
        },
        "endLoc": {
          "line": 112,
          "column": 19,
          "position": 750
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": ");\n\n      if (models?.length > 0) {\n        const modelsByOrganization = models.reduce((acc, model) => {\n          acc[model.organization] = acc[model.organization] || [];\n          acc[model.organization].push(model);\n          return acc;\n        }, {});\n\n        setGroupedModels(modelsByOrganization);\n      }\n\n      setLoading(false);\n    }\n    findCustomModels();\n  }, []);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"FireworksAiLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/FireworksAiOptions/index.jsx",
        "start": 35,
        "end": 59,
        "startLoc": {
          "line": 35,
          "column": 14,
          "position": 305
        },
        "endLoc": {
          "line": 59,
          "column": 24,
          "position": 507
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 46,
        "end": 69,
        "startLoc": {
          "line": 46,
          "column": 7,
          "position": 413
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"FireworksAiLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/FireworksAiOptions/index.jsx",
        "start": 59,
        "end": 77,
        "startLoc": {
          "line": 59,
          "column": 24,
          "position": 508
        },
        "endLoc": {
          "line": 77,
          "column": 24,
          "position": 621
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.FireworksAiLLMModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/FireworksAiOptions/index.jsx",
        "start": 77,
        "end": 100,
        "startLoc": {
          "line": 77,
          "column": 24,
          "position": 622
        },
        "endLoc": {
          "line": 100,
          "column": 1,
          "position": 776
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 87,
        "end": 110,
        "startLoc": {
          "line": 87,
          "column": 24,
          "position": 715
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ");\n\n  return (\n    <div className=\"flex gap-[36px] mt-1.5\">\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          API Key\n        </label>\n        <input\n          type=\"password\"\n          name=\"DeepSeekApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx",
        "start": 8,
        "end": 18,
        "startLoc": {
          "line": 8,
          "column": 3,
          "position": 86
        },
        "endLoc": {
          "line": 18,
          "column": 15,
          "position": 151
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OpenAiOptions/index.jsx",
        "start": 6,
        "end": 16,
        "startLoc": {
          "line": 6,
          "column": 10,
          "position": 82
        },
        "endLoc": {
          "line": 16,
          "column": 10,
          "position": 147
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"DeepSeekModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx",
        "start": 53,
        "end": 66,
        "startLoc": {
          "line": 53,
          "column": 2,
          "position": 460
        },
        "endLoc": {
          "line": 66,
          "column": 18,
          "position": 543
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 56,
        "end": 69,
        "startLoc": {
          "line": 56,
          "column": 1,
          "position": 517
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"DeepSeekModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx",
        "start": 66,
        "end": 84,
        "startLoc": {
          "line": 66,
          "column": 18,
          "position": 544
        },
        "endLoc": {
          "line": 84,
          "column": 18,
          "position": 657
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {models.map((model) => (\n          <option\n            key={model.id}\n            value={model.id}\n            selected={settings?.DeepSeekModelPref === model.id}\n          >\n            {model.name}\n          </option>\n        ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx",
        "start": 84,
        "end": 101,
        "startLoc": {
          "line": 84,
          "column": 18,
          "position": 658
        },
        "endLoc": {
          "line": 101,
          "column": 1,
          "position": 755
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/NvidiaNimOptions/remote.jsx",
        "start": 114,
        "end": 131,
        "startLoc": {
          "line": 114,
          "column": 22,
          "position": 777
        },
        "endLoc": {
          "line": 131,
          "column": 1,
          "position": 874
        }
      }
    },
    {
      "format": "javascript",
      "lines": 126,
      "fragment": "}\n                required={true}\n                autoComplete=\"off\"\n              />\n            </div>\n          </>\n        )}\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-center gap-4\">\n          <div className=\"flex flex-col w-fit\">\n            <div className=\"flex justify-between items-center mb-2 gap-x-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                Dell Pro AI Studio Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"DellProAiStudioBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:8553/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction DellProAiStudioModelSelection({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"dpais\",\n        null,\n        basePath,\n        2_000\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"DellProAiStudioModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"DellProAiStudioModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.DellProAiStudioModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 45,
        "end": 170,
        "startLoc": {
          "line": 45,
          "column": 26,
          "position": 329
        },
        "endLoc": {
          "line": 170,
          "column": 26,
          "position": 1217
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 52,
        "end": 208,
        "startLoc": {
          "line": 52,
          "column": 2,
          "position": 416
        },
        "endLoc": {
          "line": 208,
          "column": 18,
          "position": 1625
        }
      }
    },
    {
      "format": "jsx",
      "lines": 21,
      "fragment": "\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-center gap-4\">\n          <div className=\"flex flex-col w-fit",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 51,
        "end": 71,
        "startLoc": {
          "line": 51,
          "column": 2,
          "position": 358
        },
        "endLoc": {
          "line": 71,
          "column": 20,
          "position": 526
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 59,
        "end": 108,
        "startLoc": {
          "line": 59,
          "column": 2,
          "position": 470
        },
        "endLoc": {
          "line": 108,
          "column": 19,
          "position": 899
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": " Studio Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"DellProAiStudioBasePath",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 74,
        "end": 93,
        "startLoc": {
          "line": 74,
          "column": 3,
          "position": 558
        },
        "endLoc": {
          "line": 93,
          "column": 24,
          "position": 671
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 96,
        "end": 130,
        "startLoc": {
          "line": 96,
          "column": 3,
          "position": 788
        },
        "endLoc": {
          "line": 130,
          "column": 16,
          "position": 1040
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"dpais\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 110,
        "end": 123,
        "startLoc": {
          "line": 110,
          "column": 30,
          "position": 760
        },
        "endLoc": {
          "line": 123,
          "column": 8,
          "position": 894
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 135,
        "end": 47,
        "startLoc": {
          "line": 135,
          "column": 23,
          "position": 1024
        },
        "endLoc": {
          "line": 47,
          "column": 10,
          "position": 422
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"DellProAiStudioModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 128,
        "end": 141,
        "startLoc": {
          "line": 128,
          "column": 2,
          "position": 924
        },
        "endLoc": {
          "line": 141,
          "column": 25,
          "position": 1017
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 157,
        "end": 177,
        "startLoc": {
          "line": 157,
          "column": 2,
          "position": 1222
        },
        "endLoc": {
          "line": 177,
          "column": 17,
          "position": 1415
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 141,
        "end": 155,
        "startLoc": {
          "line": 141,
          "column": 25,
          "position": 1018
        },
        "endLoc": {
          "line": 155,
          "column": 44,
          "position": 1108
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 83,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 83,
          "column": 44,
          "position": 691
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"DellProAiStudioModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 146,
        "end": 159,
        "startLoc": {
          "line": 146,
          "column": 3,
          "position": 1061
        },
        "endLoc": {
          "line": 159,
          "column": 25,
          "position": 1131
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 184,
        "end": 197,
        "startLoc": {
          "line": 184,
          "column": 2,
          "position": 1469
        },
        "endLoc": {
          "line": 197,
          "column": 17,
          "position": 1539
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.DellProAiStudioModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/DPAISOptions/index.jsx",
        "start": 159,
        "end": 182,
        "startLoc": {
          "line": 159,
          "column": 25,
          "position": 1132
        },
        "endLoc": {
          "line": 182,
          "column": 1,
          "position": 1271
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 292,
        "end": 91,
        "startLoc": {
          "line": 292,
          "column": 19,
          "position": 2296
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 665
        }
      }
    },
    {
      "format": "javascript",
      "lines": 75,
      "fragment": "? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        {!settings?.credentialsOnly && (\n          <APIPieModelSelection settings={settings} />\n        )}\n      </div>\n    </div>\n  );\n}\n\nfunction APIPieModelSelection({ settings }) {\n  const [groupedModels, setGroupedModels] = useState({});\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      setLoading(true);\n      const { models } = await System.customModels(\"apipie\");\n      if (models?.length > 0) {\n        const modelsByOrganization = models.reduce((acc, model) => {\n          acc[model.organization] = acc[model.organization] || [];\n          acc[model.organization].push(model);\n          return acc;\n        }, {});\n\n        setGroupedModels(modelsByOrganization);\n      }\n\n      setLoading(false);\n    }\n    findCustomModels();\n  }, []);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"ApipieLLMModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"ApipieLLMModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.ApipieLLMModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/ApiPieOptions/index.jsx",
        "start": 17,
        "end": 91,
        "startLoc": {
          "line": 17,
          "column": 17,
          "position": 139
        },
        "endLoc": {
          "line": 91,
          "column": 20,
          "position": 739
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/FireworksAiOptions/index.jsx",
        "start": 16,
        "end": 89,
        "startLoc": {
          "line": 16,
          "column": 22,
          "position": 130
        },
        "endLoc": {
          "line": 89,
          "column": 25,
          "position": 725
        }
      }
    },
    {
      "format": "jsx",
      "lines": 24,
      "fragment": ");\n      if (models?.length > 0) {\n        const modelsByOrganization = models.reduce((acc, model) => {\n          acc[model.organization] = acc[model.organization] || [];\n          acc[model.organization].push(model);\n          return acc;\n        }, {});\n\n        setGroupedModels(modelsByOrganization);\n      }\n\n      setLoading(false);\n    }\n    findCustomModels();\n  }, []);\n\n  if (loading || Object.keys(groupedModels).length === 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"ApipieLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/ApiPieOptions/index.jsx",
        "start": 38,
        "end": 61,
        "startLoc": {
          "line": 38,
          "column": 9,
          "position": 320
        },
        "endLoc": {
          "line": 61,
          "column": 19,
          "position": 521
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/PPIOLLMOptions/index.jsx",
        "start": 38,
        "end": 69,
        "startLoc": {
          "line": 38,
          "column": 7,
          "position": 320
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"ApipieLLMModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/ApiPieOptions/index.jsx",
        "start": 63,
        "end": 79,
        "startLoc": {
          "line": 63,
          "column": 210,
          "position": 534
        },
        "endLoc": {
          "line": 79,
          "column": 19,
          "position": 635
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 71,
        "end": 87,
        "startLoc": {
          "line": 71,
          "column": 104,
          "position": 613
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\"\n      >\n        {Object.keys(groupedModels)\n          .sort()\n          .map((organization) => (\n            <optgroup key={organization} label={organization}>\n              {groupedModels[organization].map((model) => (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.ApipieLLMModelPref === model.id}\n                >\n                  {model.name}\n                </option>\n              ))}\n            </optgroup>\n          ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/ApiPieOptions/index.jsx",
        "start": 81,
        "end": 102,
        "startLoc": {
          "line": 81,
          "column": 210,
          "position": 648
        },
        "endLoc": {
          "line": 102,
          "column": 1,
          "position": 790
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 89,
        "end": 110,
        "startLoc": {
          "line": 89,
          "column": 104,
          "position": 727
        },
        "endLoc": {
          "line": 110,
          "column": 1,
          "position": 869
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": ");\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [apiKey]);\n\n  if (loading) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Chat Model Selection\n        </label>\n        <select\n          name=\"AnthropicModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/AnthropicAiOptions/index.jsx",
        "start": 92,
        "end": 105,
        "startLoc": {
          "line": 92,
          "column": 7,
          "position": 651
        },
        "endLoc": {
          "line": 105,
          "column": 19,
          "position": 736
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/DeepSeekOptions/index.jsx",
        "start": 53,
        "end": 69,
        "startLoc": {
          "line": 53,
          "column": 2,
          "position": 458
        },
        "endLoc": {
          "line": 69,
          "column": 24,
          "position": 600
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            -- loading available models --\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-3\">\n        Chat Model Selection\n      </label>\n      <select\n        name=\"AnthropicModelPref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/AnthropicAiOptions/index.jsx",
        "start": 105,
        "end": 123,
        "startLoc": {
          "line": 105,
          "column": 19,
          "position": 737
        },
        "endLoc": {
          "line": 123,
          "column": 19,
          "position": 850
        }
      },
      "secondFile": {
        "name": "frontend/src/components/TextToSpeech/ElevenLabsOptions/index.jsx",
        "start": 69,
        "end": 87,
        "startLoc": {
          "line": 69,
          "column": 24,
          "position": 601
        },
        "endLoc": {
          "line": 87,
          "column": 24,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {models.map((model) => (\n          <option\n            key={model.id}\n            value={model.id}\n            selected={settings?.AnthropicModelPref === model.id}\n          >\n            {model.name}\n          </option>\n        ))}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/LLMSelection/AnthropicAiOptions/index.jsx",
        "start": 123,
        "end": 140,
        "startLoc": {
          "line": 123,
          "column": 19,
          "position": 851
        },
        "endLoc": {
          "line": 140,
          "column": 1,
          "position": 948
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/NvidiaNimOptions/remote.jsx",
        "start": 114,
        "end": 131,
        "startLoc": {
          "line": 114,
          "column": 22,
          "position": 777
        },
        "endLoc": {
          "line": 131,
          "column": 1,
          "position": 874
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "({ settings }) {\n  return (\n    <div className=\"w-full flex flex-col gap-y-4\">\n      <div className=\"w-full flex items-center gap-[36px] mt-1.5\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"OpenAiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OpenAiOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 14,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 10,
          "position": 89
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/ZillizCloudOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 19,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 15,
          "position": 89
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\"\n            defaultValue={settings?.OpenAiKey ? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Model Preference\n          </label>\n          <select\n            name=\"EmbeddingModelPref\"\n            required={true}\n            className",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OpenAiOptions/index.jsx",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 15,
          "position": 102
        },
        "endLoc": {
          "line": 27,
          "column": 10,
          "position": 198
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 18,
          "position": 102
        },
        "endLoc": {
          "line": 27,
          "column": 13,
          "position": 198
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": ">\n                    {model}\n                  </option>\n                );\n              })}\n            </optgroup>\n          </select>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OpenAiOptions/index.jsx",
        "start": 40,
        "end": 52,
        "startLoc": {
          "line": 40,
          "column": 19,
          "position": 278
        },
        "endLoc": {
          "line": 52,
          "column": 1,
          "position": 329
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx",
        "start": 45,
        "end": 57,
        "startLoc": {
          "line": 45,
          "column": 2,
          "position": 307
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 358
        }
      }
    },
    {
      "format": "javascript",
      "lines": 138,
      "fragment": "}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum length of text chunks for embedding.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                Ollama Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"EmbeddingBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://127.0.0.1:11434\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n            <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n              Enter the URL where Ollama is running.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction OllamaEmbeddingModelSelection({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\"ollama\", null, basePath);\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Ollama Embedding Model\n        </label>\n        <select\n          name=\"EmbeddingModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {!!basePath\n              ? \"--loading available models--\"\n              : \"Enter Ollama URL first\"}\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Select the Ollama model for embeddings. Models will load after\n          entering a valid Ollama URL.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        Ollama Embedding Model\n      </label>\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.EmbeddingModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 48,
        "end": 185,
        "startLoc": {
          "line": 48,
          "column": 27,
          "position": 355
        },
        "endLoc": {
          "line": 185,
          "column": 20,
          "position": 1396
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 51,
        "end": 208,
        "startLoc": {
          "line": 51,
          "column": 2,
          "position": 399
        },
        "endLoc": {
          "line": 208,
          "column": 18,
          "position": 1625
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": ".\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                Ollama",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 54,
        "end": 80,
        "startLoc": {
          "line": 54,
          "column": 10,
          "position": 413
        },
        "endLoc": {
          "line": 80,
          "column": 7,
          "position": 622
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 57,
        "end": 96,
        "startLoc": {
          "line": 57,
          "column": 9,
          "position": 459
        },
        "endLoc": {
          "line": 96,
          "column": 3,
          "position": 787
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": " Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"EmbeddingBasePath",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 80,
        "end": 99,
        "startLoc": {
          "line": 80,
          "column": 7,
          "position": 623
        },
        "endLoc": {
          "line": 99,
          "column": 18,
          "position": 734
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 111,
        "end": 130,
        "startLoc": {
          "line": 111,
          "column": 3,
          "position": 929
        },
        "endLoc": {
          "line": 130,
          "column": 16,
          "position": 1040
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\"ollama\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 119,
        "end": 132,
        "startLoc": {
          "line": 119,
          "column": 30,
          "position": 855
        },
        "endLoc": {
          "line": 132,
          "column": 9,
          "position": 992
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 135,
        "end": 247,
        "startLoc": {
          "line": 135,
          "column": 23,
          "position": 1024
        },
        "endLoc": {
          "line": 247,
          "column": 1,
          "position": 1968
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ");\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Ollama Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 132,
        "end": 147,
        "startLoc": {
          "line": 132,
          "column": 9,
          "position": 999
        },
        "endLoc": {
          "line": 147,
          "column": 10,
          "position": 1124
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 250,
        "end": 265,
        "startLoc": {
          "line": 250,
          "column": 9,
          "position": 1981
        },
        "endLoc": {
          "line": 265,
          "column": 6,
          "position": 2109
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {!!basePath\n              ? \"--loading available models--\"\n              : \"Enter Ollama URL first\"}\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Select the Ollama model for",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 150,
        "end": 161,
        "startLoc": {
          "line": 150,
          "column": 19,
          "position": 1141
        },
        "endLoc": {
          "line": 161,
          "column": 4,
          "position": 1221
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 268,
        "end": 279,
        "startLoc": {
          "line": 268,
          "column": 19,
          "position": 2124
        },
        "endLoc": {
          "line": 279,
          "column": 4,
          "position": 2204
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ". Models will load after\n          entering a valid Ollama URL.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        Ollama Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 161,
        "end": 171,
        "startLoc": {
          "line": 161,
          "column": 11,
          "position": 1224
        },
        "endLoc": {
          "line": 171,
          "column": 10,
          "position": 1294
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 279,
        "end": 289,
        "startLoc": {
          "line": 279,
          "column": 4,
          "position": 2211
        },
        "endLoc": {
          "line": 289,
          "column": 6,
          "position": 2281
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.EmbeddingModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n      <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n        Choose the Ollama model you want to use for generating",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 174,
        "end": 195,
        "startLoc": {
          "line": 174,
          "column": 19,
          "position": 1311
        },
        "endLoc": {
          "line": 195,
          "column": 11,
          "position": 1470
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/OllamaLLMOptions/index.jsx",
        "start": 292,
        "end": 313,
        "startLoc": {
          "line": 292,
          "column": 19,
          "position": 2296
        },
        "endLoc": {
          "line": 313,
          "column": 5,
          "position": 2455
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "({ settings }) {\n  return (\n    <div className=\"w-full flex flex-col gap-y-4\">\n      <div className=\"w-full flex items-center gap-[36px] mt-1.5\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"MistralApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/MistralAiOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 17,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 14,
          "position": 89
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/ZillizCloudOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 19,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 15,
          "position": 89
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n            defaultValue={settings?.MistralApiKey ? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Model Preference\n          </label>\n          <select\n            name=\"EmbeddingModelPref\"\n            required={true}\n            defaultValue={settings?.EmbeddingModelPref}\n            className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n          >\n            <optgroup label=\"Available embedding models\">\n              {[\"mistral-embed\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/MistralAiOptions/index.jsx",
        "start": 13,
        "end": 31,
        "startLoc": {
          "line": 13,
          "column": 19,
          "position": 102
        },
        "endLoc": {
          "line": 31,
          "column": 16,
          "position": 229
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx",
        "start": 13,
        "end": 32,
        "startLoc": {
          "line": 13,
          "column": 18,
          "position": 102
        },
        "endLoc": {
          "line": 32,
          "column": 1,
          "position": 229
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "].map((model) => {\n                return (\n                  <option key={model} value={model}>\n                    {model}\n                  </option>\n                );\n              })}\n            </optgroup>\n          </select>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/MistralAiOptions/index.jsx",
        "start": 31,
        "end": 45,
        "startLoc": {
          "line": 31,
          "column": 16,
          "position": 230
        },
        "endLoc": {
          "line": 45,
          "column": 1,
          "position": 313
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx",
        "start": 43,
        "end": 57,
        "startLoc": {
          "line": 43,
          "column": 15,
          "position": 275
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 358
        }
      }
    },
    {
      "format": "javascript",
      "lines": 143,
      "fragment": "}\n            autoComplete=\"off\"\n          />\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <div className=\"flex flex-col gap-y-1 mb-2\">\n            <label className=\"text-white text-sm font-semibold flex items-center gap-x-2\">\n              Local AI API Key{\" \"}\n              <p className=\"!text-xs !italic !font-thin\">optional</p>\n            </label>\n          </div>\n          <input\n            type=\"password\"\n            name=\"LocalAiApiKey\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"sk-mysecretkey\"\n            defaultValue={settings?.LocalAiApiKey ? \"*\".repeat(20) : \"\"}\n            autoComplete=\"off\"\n            spellCheck={false}\n            onChange={(e) => setApiKeyValue(e.target.value)}\n            onBlur={() => setApiKey(apiKeyValue)}\n          />\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-center gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                LocalAI Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"EmbeddingBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:8080/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LocalAIModelSelection({ settings, apiKey = null, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath || !basePath.includes(\"/v1\")) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"localai\",\n        typeof apiKey === \"boolean\" ? null : apiKey,\n        basePath\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath, apiKey]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Embedding Model Name\n        </label>\n        <select\n          name=\"EmbeddingModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {basePath?.includes(\"/v1\")\n              ? \"-- loading available models --\"\n              : \"-- waiting for URL --\"}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        Embedding Model Name\n      </label>\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 44,
        "end": 186,
        "startLoc": {
          "line": 44,
          "column": 6,
          "position": 359
        },
        "endLoc": {
          "line": 186,
          "column": 2,
          "position": 1435
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 64,
        "end": 208,
        "startLoc": {
          "line": 64,
          "column": 5,
          "position": 537
        },
        "endLoc": {
          "line": 208,
          "column": 2,
          "position": 1624
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "({ settings }) {\n  const {\n    autoDetecting: loading,\n    basePath,\n    basePathValue,\n    showAdvancedControls,\n    setShowAdvancedControls,\n    handleAutoDetectClick,\n  } = useProviderEndpointAutoDiscovery({\n    provider: \"localai\",\n    initialBasePath: settings?.EmbeddingBasePath",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 8,
        "end": 18,
        "startLoc": {
          "line": 8,
          "column": 15,
          "position": 83
        },
        "endLoc": {
          "line": 18,
          "column": 18,
          "position": 148
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 8,
        "end": 19,
        "startLoc": {
          "line": 8,
          "column": 17,
          "position": 80
        },
        "endLoc": {
          "line": 19,
          "column": 16,
          "position": 167
        }
      }
    },
    {
      "format": "jsx",
      "lines": 43,
      "fragment": "\n        <div className=\"flex flex-col w-60\">\n          <div className=\"flex flex-col gap-y-1 mb-2\">\n            <label className=\"text-white text-sm font-semibold flex items-center gap-x-2\">\n              Local AI API Key{\" \"}\n              <p className=\"!text-xs !italic !font-thin\">optional</p>\n            </label>\n          </div>\n          <input\n            type=\"password\"\n            name=\"LocalAiApiKey\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"sk-mysecretkey\"\n            defaultValue={settings?.LocalAiApiKey ? \"*\".repeat(20) : \"\"}\n            autoComplete=\"off\"\n            spellCheck={false}\n            onChange={(e) => setApiKeyValue(e.target.value)}\n            onBlur={() => setApiKey(apiKeyValue)}\n          />\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-center gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                LocalAI",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 47,
        "end": 89,
        "startLoc": {
          "line": 47,
          "column": 2,
          "position": 373
        },
        "endLoc": {
          "line": 89,
          "column": 8,
          "position": 739
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 69,
        "end": 111,
        "startLoc": {
          "line": 69,
          "column": 2,
          "position": 560
        },
        "endLoc": {
          "line": 111,
          "column": 6,
          "position": 926
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": " Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"EmbeddingBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:8080/v1",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 89,
        "end": 110,
        "startLoc": {
          "line": 89,
          "column": 8,
          "position": 740
        },
        "endLoc": {
          "line": 110,
          "column": 25,
          "position": 863
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 111,
        "end": 101,
        "startLoc": {
          "line": 111,
          "column": 3,
          "position": 929
        },
        "endLoc": {
          "line": 101,
          "column": 23,
          "position": 746
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:8080/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LocalAIModelSelection({ settings, apiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 108,
        "end": 125,
        "startLoc": {
          "line": 108,
          "column": 18,
          "position": 852
        },
        "endLoc": {
          "line": 125,
          "column": 7,
          "position": 946
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 130,
        "end": 147,
        "startLoc": {
          "line": 130,
          "column": 16,
          "position": 1041
        },
        "endLoc": {
          "line": 147,
          "column": 9,
          "position": 1135
        }
      }
    },
    {
      "format": "jsx",
      "lines": 28,
      "fragment": ", basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath || !basePath.includes(\"/v1\")) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"localai\",\n        typeof apiKey === \"boolean\" ? null : apiKey,\n        basePath\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath, apiKey]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 125,
        "end": 152,
        "startLoc": {
          "line": 125,
          "column": 5,
          "position": 951
        },
        "endLoc": {
          "line": 152,
          "column": 10,
          "position": 1208
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 135,
        "end": 265,
        "startLoc": {
          "line": 135,
          "column": 9,
          "position": 1028
        },
        "endLoc": {
          "line": 265,
          "column": 7,
          "position": 2107
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {basePath?.includes(\"/v1\")\n              ? \"-- loading available models --\"\n              : \"-- waiting for URL --\"}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 155,
        "end": 172,
        "startLoc": {
          "line": 155,
          "column": 19,
          "position": 1227
        },
        "endLoc": {
          "line": 172,
          "column": 10,
          "position": 1332
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 177,
        "end": 194,
        "startLoc": {
          "line": 177,
          "column": 17,
          "position": 1416
        },
        "endLoc": {
          "line": 194,
          "column": 5,
          "position": 1521
        }
      }
    },
    {
      "format": "jsx",
      "lines": 27,
      "fragment": "\n      </label>\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings?.EmbeddingModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 172,
        "end": 198,
        "startLoc": {
          "line": 172,
          "column": 5,
          "position": 1337
        },
        "endLoc": {
          "line": 198,
          "column": 1,
          "position": 1491
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 171,
        "end": 91,
        "startLoc": {
          "line": 171,
          "column": 6,
          "position": 1297
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 665
        }
      }
    },
    {
      "format": "javascript",
      "lines": 25,
      "fragment": "={settings?.LiteLLMBasePath}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n            onChange={(e) => setBasePathValue(e.target.value)}\n            onBlur={() => setBasePath(basePathValue)}\n          />\n        </div>\n        <LiteLLMModelSelection\n          settings={settings}\n          basePath={basePath}\n          apiKey={apiKey}\n        />\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Max embedding chunk length\n          </label>\n          <input\n            type=\"number\"\n            name=\"EmbeddingModelMaxChunkLength\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"8192\"\n            min={1}\n            onScroll={(e) => e.target.blur()}\n            defaultValue={settings?.EmbeddingModelMaxChunkLength",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 24,
        "end": 48,
        "startLoc": {
          "line": 24,
          "column": 13,
          "position": 242
        },
        "endLoc": {
          "line": 48,
          "column": 29,
          "position": 425
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 22,
        "end": 46,
        "startLoc": {
          "line": 22,
          "column": 13,
          "position": 216
        },
        "endLoc": {
          "line": 46,
          "column": 18,
          "position": 397
        }
      }
    },
    {
      "format": "javascript",
      "lines": 94,
      "fragment": "}\n            autoComplete=\"off\"\n          />\n        </div>\n      </div>\n      <div className=\"w-full flex items-center gap-[36px]\">\n        <div className=\"flex flex-col w-60\">\n          <div className=\"flex flex-col gap-y-1 mb-4\">\n            <label className=\"text-white text-sm font-semibold flex items-center gap-x-2\">\n              API Key <p className=\"!text-xs !italic !font-thin\">optional</p>\n            </label>\n          </div>\n          <input\n            type=\"password\"\n            name=\"LiteLLMAPIKey\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"sk-mysecretkey\"\n            defaultValue={settings?.LiteLLMAPIKey ? \"*\".repeat(20) : \"\"}\n            autoComplete=\"off\"\n            spellCheck={false}\n            onChange={(e) => setApiKeyValue(e.target.value)}\n            onBlur={() => setApiKey(apiKeyValue)}\n          />\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LiteLLMModelSelection({ settings, basePath = null, apiKey = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"litellm\",\n        typeof apiKey === \"boolean\" ? null : apiKey,\n        basePath\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath, apiKey]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Embedding Model Selection\n        </label>\n        <select\n          name=\"EmbeddingModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {basePath?.includes(\"/v1\")\n              ? \"-- loading available models --\"\n              : \"-- waiting for URL --\"}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <div className=\"flex items-center\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Embedding Model Selection\n        </label>\n        <EmbeddingModelTooltip />\n      </div>\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.EmbeddingModelPref ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 49,
        "end": 142,
        "startLoc": {
          "line": 49,
          "column": 6,
          "position": 432
        },
        "endLoc": {
          "line": 142,
          "column": 20,
          "position": 1154
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 47,
        "end": 137,
        "startLoc": {
          "line": 47,
          "column": 5,
          "position": 404
        },
        "endLoc": {
          "line": 137,
          "column": 18,
          "position": 1104
        }
      }
    },
    {
      "format": "jsx",
      "lines": 26,
      "fragment": "\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Base URL\n          </label>\n          <input\n            type=\"url\"\n            name=\"LiteLLMBasePath\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"http://127.0.0.1:4000\"\n            defaultValue={settings?.LiteLLMBasePath}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n            onChange={(e) => setBasePathValue(e.target.value)}\n            onBlur={() => setBasePath(basePathValue)}\n          />\n        </div>\n        <LiteLLMModelSelection\n          settings={settings}\n          basePath={basePath}\n          apiKey={apiKey}\n        />\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Max",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 14,
        "end": 39,
        "startLoc": {
          "line": 14,
          "column": 43,
          "position": 178
        },
        "endLoc": {
          "line": 39,
          "column": 4,
          "position": 355
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 12,
        "end": 37,
        "startLoc": {
          "line": 12,
          "column": 36,
          "position": 152
        },
        "endLoc": {
          "line": 37,
          "column": 6,
          "position": 329
        }
      }
    },
    {
      "format": "jsx",
      "lines": 61,
      "fragment": "\"\n            min={1}\n            onScroll={(e) => e.target.blur()}\n            defaultValue={settings?.EmbeddingModelMaxChunkLength}\n            required={false}\n            autoComplete=\"off\"\n          />\n        </div>\n      </div>\n      <div className=\"w-full flex items-center gap-[36px]\">\n        <div className=\"flex flex-col w-60\">\n          <div className=\"flex flex-col gap-y-1 mb-4\">\n            <label className=\"text-white text-sm font-semibold flex items-center gap-x-2\">\n              API Key <p className=\"!text-xs !italic !font-thin\">optional</p>\n            </label>\n          </div>\n          <input\n            type=\"password\"\n            name=\"LiteLLMAPIKey\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"sk-mysecretkey\"\n            defaultValue={settings?.LiteLLMAPIKey ? \"*\".repeat(20) : \"\"}\n            autoComplete=\"off\"\n            spellCheck={false}\n            onChange={(e) => setApiKeyValue(e.target.value)}\n            onBlur={() => setApiKey(apiKeyValue)}\n          />\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LiteLLMModelSelection({ settings, basePath = null, apiKey = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      const { models } = await System.customModels(\n        \"litellm\",\n        typeof apiKey === \"boolean\" ? null : apiKey,\n        basePath\n      );\n      setCustomModels(models || []);\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath, apiKey]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-3\">\n          Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 45,
        "end": 105,
        "startLoc": {
          "line": 45,
          "column": 5,
          "position": 394
        },
        "endLoc": {
          "line": 105,
          "column": 10,
          "position": 904
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LiteLLMOptions/index.jsx",
        "start": 43,
        "end": 47,
        "startLoc": {
          "line": 43,
          "column": 5,
          "position": 366
        },
        "endLoc": {
          "line": 47,
          "column": 5,
          "position": 392
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": "\n        </label>\n        <select\n          name=\"EmbeddingModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {basePath?.includes(\"/v1\")\n              ? \"-- loading available models --\"\n              : \"-- waiting for URL --\"}\n          </option>\n        </select>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <div",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 105,
        "end": 124,
        "startLoc": {
          "line": 105,
          "column": 10,
          "position": 909
        },
        "endLoc": {
          "line": 124,
          "column": 4,
          "position": 1018
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/LocalAiOptions/index.jsx",
        "start": 152,
        "end": 193,
        "startLoc": {
          "line": 152,
          "column": 5,
          "position": 1213
        },
        "endLoc": {
          "line": 193,
          "column": 6,
          "position": 1511
        }
      }
    },
    {
      "format": "jsx",
      "lines": 26,
      "fragment": ">\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.EmbeddingModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 129,
        "end": 154,
        "startLoc": {
          "line": 129,
          "column": 4,
          "position": 1059
        },
        "endLoc": {
          "line": 154,
          "column": 1,
          "position": 1208
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 172,
        "end": 91,
        "startLoc": {
          "line": 172,
          "column": 6,
          "position": 1301
        },
        "endLoc": {
          "line": 91,
          "column": 1,
          "position": 665
        }
      }
    },
    {
      "format": "javascript",
      "lines": 154,
      "fragment": "={settings} basePath={basePath.value} />\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-2\">\n            Max Embedding Chunk Length\n          </label>\n          <input\n            type=\"number\"\n            name=\"EmbeddingModelMaxChunkLength\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"8192\"\n            min={1}\n            value={maxChunkLength}\n            onChange={handleMaxChunkLengthChange}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum length of text chunks for embedding.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                LM Studio Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"EmbeddingBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:1234/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n            <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n              Enter the URL where LM Studio is running.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LMStudioModelSelection({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\n          \"lmstudio\",\n          null,\n          basePath\n        );\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          LM Studio Embedding Model\n        </label>\n        <select\n          name=\"EmbeddingModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {!!basePath\n              ? \"--loading available models--\"\n              : \"Enter LM Studio URL first\"}\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Select the LM Studio model for embeddings. Models will load after\n          entering a valid LM Studio URL.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        LM Studio Embedding Model\n      </label>\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.EmbeddingModelPref === model.id}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 33,
        "end": 186,
        "startLoc": {
          "line": 33,
          "column": 9,
          "position": 260
        },
        "endLoc": {
          "line": 186,
          "column": 2,
          "position": 1419
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 34,
        "end": 185,
        "startLoc": {
          "line": 34,
          "column": 9,
          "position": 260
        },
        "endLoc": {
          "line": 185,
          "column": 2,
          "position": 1401
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "({ settings }) {\n  const {\n    autoDetecting: loading,\n    basePath,\n    basePathValue,\n    showAdvancedControls,\n    setShowAdvancedControls,\n    handleAutoDetectClick,\n  } = useProviderEndpointAutoDiscovery({\n    provider: \"lmstudio\",\n    initialBasePath: settings?.EmbeddingBasePath",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 8,
        "end": 18,
        "startLoc": {
          "line": 8,
          "column": 25,
          "position": 83
        },
        "endLoc": {
          "line": 18,
          "column": 18,
          "position": 148
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/KoboldCPPOptions/index.jsx",
        "start": 8,
        "end": 19,
        "startLoc": {
          "line": 8,
          "column": 17,
          "position": 80
        },
        "endLoc": {
          "line": 19,
          "column": 17,
          "position": 164
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": ",\n  });\n\n  const [maxChunkLength, setMaxChunkLength] = useState(\n    settings?.EmbeddingModelMaxChunkLength || 8192\n  );\n\n  const handleMaxChunkLengthChange = (e) => {\n    setMaxChunkLength(Number(e.target.value));\n  };\n\n  return (\n    <div className=\"w-full flex flex-col gap-y-7\">\n      <div className=\"w-full flex items-start gap-[36px] mt-1.5\">\n        <LMStudioModelSelection",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 19,
        "end": 33,
        "startLoc": {
          "line": 19,
          "column": 21,
          "position": 156
        },
        "endLoc": {
          "line": 33,
          "column": 23,
          "position": 257
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 19,
        "end": 33,
        "startLoc": {
          "line": 19,
          "column": 19,
          "position": 156
        },
        "endLoc": {
          "line": 33,
          "column": 30,
          "position": 257
        }
      }
    },
    {
      "format": "jsx",
      "lines": 66,
      "fragment": "/>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-2\">\n            Max Embedding Chunk Length\n          </label>\n          <input\n            type=\"number\"\n            name=\"EmbeddingModelMaxChunkLength\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"8192\"\n            min={1}\n            value={maxChunkLength}\n            onChange={handleMaxChunkLengthChange}\n            onScroll={(e) => e.target.blur()}\n            required={true}\n            autoComplete=\"off\"\n          />\n          <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n            Maximum length of text chunks for embedding.\n          </p>\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} Manual Endpoint Input\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4\">\n          <div className=\"flex flex-col w-60\">\n            <div className=\"flex justify-between items-center mb-2\">\n              <label className=\"text-white text-sm font-semibold\">\n                LM Studio Base URL\n              </label>\n              {loading ? (\n                <PreLoader size=\"6\" />\n              ) : (\n                <>\n                  {!basePathValue.value && (\n                    <button\n                      onClick={handleAutoDetectClick}\n                      className=\"bg-primary-button text-xs font-medium px-2 py-1 rounded-lg hover:bg-secondary hover:text-white shadow-[0_4px_14px_rgba(0,0,0,0.25)]\"\n                    >\n                      Auto-Detect\n                    </button>\n                  )}\n                </>\n              )}\n            </div>\n            <input\n              type=\"url\"\n              name=\"EmbeddingBasePath\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:1234/v1",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 33,
        "end": 98,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 273
        },
        "endLoc": {
          "line": 98,
          "column": 25,
          "position": 748
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 36,
        "end": 101,
        "startLoc": {
          "line": 36,
          "column": 9,
          "position": 273
        },
        "endLoc": {
          "line": 101,
          "column": 23,
          "position": 746
        }
      }
    },
    {
      "format": "jsx",
      "lines": 53,
      "fragment": "\"\n              className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n              placeholder=\"http://localhost:1234/v1\"\n              value={basePathValue.value}\n              required={true}\n              autoComplete=\"off\"\n              spellCheck={false}\n              onChange={basePath.onChange}\n              onBlur={basePath.onBlur}\n            />\n            <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n              Enter the URL where LM Studio is running.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nfunction LMStudioModelSelection({ settings, basePath = null }) {\n  const [customModels, setCustomModels] = useState([]);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function findCustomModels() {\n      if (!basePath) {\n        setCustomModels([]);\n        setLoading(false);\n        return;\n      }\n      setLoading(true);\n      try {\n        const { models } = await System.customModels(\n          \"lmstudio\",\n          null,\n          basePath\n        );\n        setCustomModels(models || []);\n      } catch (error) {\n        console.error(\"Failed to fetch custom models:\", error);\n        setCustomModels([]);\n      }\n      setLoading(false);\n    }\n    findCustomModels();\n  }, [basePath]);\n\n  if (loading || customModels.length == 0) {\n    return (\n      <div className=\"flex flex-col w-60\">\n        <label className=\"text-white text-sm font-semibold block mb-2\">\n          LM Studio Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 96,
        "end": 148,
        "startLoc": {
          "line": 96,
          "column": 18,
          "position": 737
        },
        "endLoc": {
          "line": 148,
          "column": 10,
          "position": 1136
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 115,
        "end": 167,
        "startLoc": {
          "line": 115,
          "column": 17,
          "position": 902
        },
        "endLoc": {
          "line": 167,
          "column": 6,
          "position": 1301
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": " Embedding Model\n        </label>\n        <select\n          name=\"EmbeddingModelPref\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {!!basePath\n              ? \"--loading available models--\"\n              : \"Enter LM Studio URL first\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 148,
        "end": 158,
        "startLoc": {
          "line": 148,
          "column": 7,
          "position": 1135
        },
        "endLoc": {
          "line": 158,
          "column": 28,
          "position": 1200
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 147,
        "end": 157,
        "startLoc": {
          "line": 147,
          "column": 7,
          "position": 1123
        },
        "endLoc": {
          "line": 157,
          "column": 25,
          "position": 1188
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\"\n          disabled={true}\n          className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n        >\n          <option disabled={true} selected={true}>\n            {!!basePath\n              ? \"--loading available models--\"\n              : \"Enter LM Studio URL first\"}\n          </option>\n        </select>\n        <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n          Select the LM Studio model for",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 151,
        "end": 162,
        "startLoc": {
          "line": 151,
          "column": 19,
          "position": 1153
        },
        "endLoc": {
          "line": 162,
          "column": 4,
          "position": 1235
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 170,
        "end": 181,
        "startLoc": {
          "line": 170,
          "column": 18,
          "position": 1316
        },
        "endLoc": {
          "line": 181,
          "column": 4,
          "position": 1398
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": ". Models will load after\n          entering a valid LM Studio URL.\n        </p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex flex-col w-60\">\n      <label className=\"text-white text-sm font-semibold block mb-2\">\n        LM Studio Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 162,
        "end": 172,
        "startLoc": {
          "line": 162,
          "column": 11,
          "position": 1238
        },
        "endLoc": {
          "line": 172,
          "column": 10,
          "position": 1312
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
        "start": 181,
        "end": 191,
        "startLoc": {
          "line": 181,
          "column": 4,
          "position": 1405
        },
        "endLoc": {
          "line": 191,
          "column": 6,
          "position": 1479
        }
      }
    },
    {
      "format": "jsx",
      "lines": 25,
      "fragment": " Embedding Model\n      </label>\n      <select\n        name=\"EmbeddingModelPref\"\n        required={true}\n        className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n      >\n        {customModels.length > 0 && (\n          <optgroup label=\"Your loaded models\">\n            {customModels.map((model) => {\n              return (\n                <option\n                  key={model.id}\n                  value={model.id}\n                  selected={settings.EmbeddingModelPref === model.id}\n                >\n                  {model.id}\n                </option>\n              );\n            })}\n          </optgroup>\n        )}\n      </select>\n      <p className=\"text-xs leading-[18px] font-base text-white text-opacity-60 mt-2\">\n        Choose the LM Studio model you want to use for generating",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/LMStudioOptions/index.jsx",
        "start": 172,
        "end": 196,
        "startLoc": {
          "line": 172,
          "column": 7,
          "position": 1311
        },
        "endLoc": {
          "line": 196,
          "column": 11,
          "position": 1490
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OllamaOptions/index.jsx",
        "start": 171,
        "end": 215,
        "startLoc": {
          "line": 171,
          "column": 7,
          "position": 1293
        },
        "endLoc": {
          "line": 215,
          "column": 5,
          "position": 1655
        }
      }
    },
    {
      "format": "jsx",
      "lines": 28,
      "fragment": "\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Max embedding chunk length\n          </label>\n          <input\n            type=\"number\"\n            name=\"EmbeddingModelMaxChunkLength\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"8192\"\n            min={1}\n            onScroll={(e) => e.target.blur()}\n            defaultValue={settings?.EmbeddingModelMaxChunkLength}\n            required={false}\n            autoComplete=\"off\"\n          />\n        </div>\n      </div>\n      <div className=\"w-full flex items-center gap-[36px]\">\n        <div className=\"flex flex-col w-60\">\n          <div className=\"flex flex-col gap-y-1 mb-4\">\n            <label className=\"text-white text-sm font-semibold flex items-center gap-x-2\">\n              API Key <p className=\"!text-xs !italic !font-thin\">optional</p>\n            </label>\n          </div>\n          <input\n            type=\"password\"\n            name=\"GenericOpenAiEmbeddingApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/GenericOpenAiOptions/index.jsx",
        "start": 38,
        "end": 65,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 282
        },
        "endLoc": {
          "line": 65,
          "column": 29,
          "position": 489
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/LiteLLMOptions/index.jsx",
        "start": 36,
        "end": 61,
        "startLoc": {
          "line": 36,
          "column": 3,
          "position": 331
        },
        "endLoc": {
          "line": 61,
          "column": 14,
          "position": 510
        }
      }
    },
    {
      "format": "jsx",
      "lines": 22,
      "fragment": "\n          />\n        </div>\n      </div>\n      <div className=\"flex justify-start mt-4\">\n        <button\n          onClick={(e) => {\n            e.preventDefault();\n            setShowAdvancedControls(!showAdvancedControls);\n          }}\n          className=\"border-none text-theme-text-primary hover:text-theme-text-secondary flex items-center text-sm\"\n        >\n          {showAdvancedControls ? \"Hide\" : \"Show\"} advanced settings\n          {showAdvancedControls ? (\n            <CaretUp size={14} className=\"ml-1\" />\n          ) : (\n            <CaretDown size={14} className=\"ml-1\" />\n          )}\n        </button>\n      </div>\n      <div hidden={!showAdvancedControls}>\n        <div className=\"w-full flex items-start gap-4",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/GenericOpenAiOptions/index.jsx",
        "start": 72,
        "end": 93,
        "startLoc": {
          "line": 72,
          "column": 2,
          "position": 537
        },
        "endLoc": {
          "line": 93,
          "column": 30,
          "position": 701
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LocalAiOptions/index.jsx",
        "start": 86,
        "end": 53,
        "startLoc": {
          "line": 86,
          "column": 2,
          "position": 724
        },
        "endLoc": {
          "line": 53,
          "column": 19,
          "position": 444
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "({ settings }) {\n  return (\n    <div className=\"w-full flex flex-col gap-y-4\">\n      <div className=\"w-full flex items-center gap-[36px] mt-1.5\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"GeminiEmbeddingApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/GeminiOptions/index.jsx",
        "start": 16,
        "end": 26,
        "startLoc": {
          "line": 16,
          "column": 14,
          "position": 82
        },
        "endLoc": {
          "line": 26,
          "column": 22,
          "position": 164
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/ZillizCloudOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 19,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 15,
          "position": 89
        }
      }
    },
    {
      "format": "jsx",
      "lines": 18,
      "fragment": "\"\n            defaultValue={settings?.GeminiEmbeddingApiKey ? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Model Preference\n          </label>\n          <select\n            name=\"EmbeddingModelPref\"\n            required={true}\n            className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n          >\n            <optgroup label=\"Available embedding models\">\n              {DEFAULT_MODELS",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/GeminiOptions/index.jsx",
        "start": 28,
        "end": 45,
        "startLoc": {
          "line": 28,
          "column": 15,
          "position": 177
        },
        "endLoc": {
          "line": 45,
          "column": 15,
          "position": 294
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx",
        "start": 13,
        "end": 30,
        "startLoc": {
          "line": 13,
          "column": 18,
          "position": 102
        },
        "endLoc": {
          "line": 30,
          "column": 2,
          "position": 219
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": "={() => onClick(value)}\n      className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n        checked ? \"bg-theme-bg-secondary\" : \"\"\n      }`}\n    >\n      <input\n        type=\"checkbox\"\n        value={value}\n        className=\"peer hidden\"\n        checked={checked}\n        readOnly={true}\n        formNoValidate={true}\n      />\n      <div className=\"flex gap-x-4 items-center\">\n        <img\n          src={image}\n          alt={`${name} logo`}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/EmbedderItem/index.jsx",
        "start": 11,
        "end": 27,
        "startLoc": {
          "line": 11,
          "column": 8,
          "position": 49
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 153
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx",
        "start": 11,
        "end": 27,
        "startLoc": {
          "line": 11,
          "column": 8,
          "position": 49
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 153
        }
      }
    },
    {
      "format": "jsx",
      "lines": 38,
      "fragment": "({\n  name,\n  value,\n  image,\n  description,\n  checked,\n  onClick,\n}) {\n  return (\n    <div\n      onClick={() => onClick(value)}\n      className={`w-full p-2 rounded-md hover:cursor-pointer hover:bg-theme-bg-secondary ${\n        checked ? \"bg-theme-bg-secondary\" : \"\"\n      }`}\n    >\n      <input\n        type=\"checkbox\"\n        value={value}\n        className=\"peer hidden\"\n        checked={checked}\n        readOnly={true}\n        formNoValidate={true}\n      />\n      <div className=\"flex gap-x-4 items-center\">\n        <img\n          src={image}\n          alt={`${name} logo`}\n          className=\"w-10 h-10 rounded-md\"\n        />\n        <div className=\"flex flex-col\">\n          <div className=\"text-sm font-semibold text-white\">{name}</div>\n          <div className=\"mt-1 text-xs text-description\">{description}</div>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/EmbedderItem/index.jsx",
        "start": 1,
        "end": 38,
        "startLoc": {
          "line": 1,
          "column": 13,
          "position": 7
        },
        "endLoc": {
          "line": 38,
          "column": 1,
          "position": 228
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/VectorDBItem/index.jsx",
        "start": 1,
        "end": 28,
        "startLoc": {
          "line": 1,
          "column": 13,
          "position": 7
        },
        "endLoc": {
          "line": 28,
          "column": 1,
          "position": 227
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "({ settings }) {\n  return (\n    <div className=\"w-full flex flex-col gap-y-4\">\n      <div className=\"w-full flex items-center gap-[36px] mt-1.5\">\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"CohereApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/CohereOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 23,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 13,
          "position": 89
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/ZillizCloudOptions/index.jsx",
        "start": 1,
        "end": 11,
        "startLoc": {
          "line": 1,
          "column": 19,
          "position": 7
        },
        "endLoc": {
          "line": 11,
          "column": 15,
          "position": 89
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": "API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"CohereApiKey\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"Cohere API Key\"\n            defaultValue={settings?.CohereApiKey ? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Model",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/CohereOptions/index.jsx",
        "start": 7,
        "end": 22,
        "startLoc": {
          "line": 7,
          "column": 13,
          "position": 67
        },
        "endLoc": {
          "line": 22,
          "column": 6,
          "position": 173
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/CohereAiOptions/index.jsx",
        "start": 7,
        "end": 22,
        "startLoc": {
          "line": 7,
          "column": 2,
          "position": 69
        },
        "endLoc": {
          "line": 22,
          "column": 5,
          "position": 175
        }
      }
    },
    {
      "format": "jsx",
      "lines": 19,
      "fragment": "\"\n            defaultValue={settings?.CohereApiKey ? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Model Preference\n          </label>\n          <select\n            name=\"EmbeddingModelPref\"\n            required={true}\n            className=\"border-none bg-theme-settings-input-bg border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n          >\n            <optgroup label=\"Available embedding models\">\n              {[\n                \"embed-english-v3.0\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/CohereOptions/index.jsx",
        "start": 13,
        "end": 31,
        "startLoc": {
          "line": 13,
          "column": 15,
          "position": 102
        },
        "endLoc": {
          "line": 31,
          "column": 21,
          "position": 222
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/VoyageAiOptions/index.jsx",
        "start": 13,
        "end": 31,
        "startLoc": {
          "line": 13,
          "column": 18,
          "position": 102
        },
        "endLoc": {
          "line": 31,
          "column": 25,
          "position": 222
        }
      }
    },
    {
      "format": "jsx",
      "lines": 20,
      "fragment": ",\n              ].map((model) => {\n                return (\n                  <option\n                    key={model}\n                    value={model}\n                    selected={settings?.EmbeddingModelPref === model}\n                  >\n                    {model}\n                  </option>\n                );\n              })}\n            </optgroup>\n          </select>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/CohereOptions/index.jsx",
        "start": 37,
        "end": 56,
        "startLoc": {
          "line": 37,
          "column": 26,
          "position": 247
        },
        "endLoc": {
          "line": 56,
          "column": 1,
          "position": 345
        }
      },
      "secondFile": {
        "name": "frontend/src/components/EmbeddingSelection/OpenAiOptions/index.jsx",
        "start": 33,
        "end": 57,
        "startLoc": {
          "line": 33,
          "column": 25,
          "position": 231
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 358
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\n          </label>\n          <input\n            type=\"url\"\n            name=\"AzureOpenAiEndpoint\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"https://my-azure.openai.azure.com\"\n            defaultValue={settings?.AzureOpenAiEndpoint}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/AzureAiOptions/index.jsx",
        "start": 7,
        "end": 23,
        "startLoc": {
          "line": 7,
          "column": 9,
          "position": 72
        },
        "endLoc": {
          "line": 23,
          "column": 4,
          "position": 164
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/AzureAiOptions/index.jsx",
        "start": 11,
        "end": 27,
        "startLoc": {
          "line": 11,
          "column": 2,
          "position": 104
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 196
        }
      }
    },
    {
      "format": "jsx",
      "lines": 15,
      "fragment": "\"\n            defaultValue={settings?.AzureOpenAiEndpoint}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            API Key\n          </label>\n          <input\n            type=\"password\"\n            name=\"AzureOpenAiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/AzureAiOptions/index.jsx",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 34,
          "position": 104
        },
        "endLoc": {
          "line": 27,
          "column": 15,
          "position": 186
        }
      },
      "secondFile": {
        "name": "frontend/src/components/VectorDBSelection/WeaviateDBOptions/index.jsx",
        "start": 13,
        "end": 27,
        "startLoc": {
          "line": 13,
          "column": 22,
          "position": 102
        },
        "endLoc": {
          "line": 27,
          "column": 15,
          "position": 184
        }
      }
    },
    {
      "format": "jsx",
      "lines": 17,
      "fragment": "\n          </label>\n          <input\n            type=\"password\"\n            name=\"AzureOpenAiKey\"\n            className=\"border-none bg-theme-settings-input-bg text-white placeholder:text-theme-settings-input-placeholder text-sm rounded-lg focus:outline-primary-button active:outline-primary-button outline-none block w-full p-2.5\"\n            placeholder=\"Azure OpenAI API Key\"\n            defaultValue={settings?.AzureOpenAiKey ? \"*\".repeat(20) : \"\"}\n            required={true}\n            autoComplete=\"off\"\n            spellCheck={false}\n          />\n        </div>\n\n        <div className=\"flex flex-col w-60\">\n          <label className=\"text-white text-sm font-semibold block mb-3\">\n            Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/EmbeddingSelection/AzureAiOptions/index.jsx",
        "start": 23,
        "end": 39,
        "startLoc": {
          "line": 23,
          "column": 4,
          "position": 167
        },
        "endLoc": {
          "line": 39,
          "column": 10,
          "position": 271
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/AzureAiOptions/index.jsx",
        "start": 27,
        "end": 43,
        "startLoc": {
          "line": 27,
          "column": 2,
          "position": 202
        },
        "endLoc": {
          "line": 43,
          "column": 2,
          "position": 306
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ");\n        tmpWorker.removeEventListener(\"message\", handleMessage);\n        timeout && clearTimeout(timeout);\n        tmpWorker.terminate();\n      };\n\n      timeout = setTimeout(() => {\n        reject(\"TTS Worker timed out.\");\n      }, 30_000);\n      tmpWorker.addEventListener(\"message\", handleMessage);\n    });\n  }\n\n  /**\n   * Runs prediction via webworker so we can get an audio blob back.\n   * @returns {Promise<{blobURL: string|null, error: string|null}>} objectURL blob: type.\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/utils/piperTTS/index.js",
        "start": 68,
        "end": 84,
        "startLoc": {
          "line": 68,
          "column": 8,
          "position": 632
        },
        "endLoc": {
          "line": 84,
          "column": 6,
          "position": 723
        }
      },
      "secondFile": {
        "name": "frontend/src/utils/piperTTS/index.js",
        "start": 43,
        "end": 56,
        "startLoc": {
          "line": 43,
          "column": 7,
          "position": 386
        },
        "endLoc": {
          "line": 56,
          "column": 7,
          "position": 477
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": "\n          uuid: v4(),\n          content: data.content,\n          role: \"assistant\",\n          sources: [],\n          closed: true,\n          error: null,\n          animate: false,\n          pending: false,\n        },\n      ];\n    });\n  }\n\n  if (data",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/utils/chat/agent.js",
        "start": 59,
        "end": 73,
        "startLoc": {
          "line": 59,
          "column": 2,
          "position": 539
        },
        "endLoc": {
          "line": 73,
          "column": 5,
          "position": 622
        }
      },
      "secondFile": {
        "name": "frontend/src/utils/chat/agent.js",
        "start": 33,
        "end": 47,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 326
        },
        "endLoc": {
          "line": 47,
          "column": 2,
          "position": 409
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ") {\n    return setChatHistory((prev) => {\n      return [\n        ...prev.filter((msg) => !!msg.content),\n        {\n          uuid: v4(),\n          content: data.content,\n          role: \"assistant\",\n          sources: [],\n          closed: true,\n          error: data",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/utils/chat/agent.js",
        "start": 73,
        "end": 83,
        "startLoc": {
          "line": 73,
          "column": 13,
          "position": 629
        },
        "endLoc": {
          "line": 83,
          "column": 5,
          "position": 718
        }
      },
      "secondFile": {
        "name": "frontend/src/utils/chat/agent.js",
        "start": 29,
        "end": 39,
        "startLoc": {
          "line": 29,
          "column": 2,
          "position": 282
        },
        "endLoc": {
          "line": 39,
          "column": 5,
          "position": 371
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "() {\n  const { loading, requiresAuth, mode } = usePasswordModal();\n\n  if (loading) return <FullScreenLoader />;\n  if (requiresAuth !== false) {\n    return <>{requiresAuth !== null && <PasswordModal mode={mode} />}</>;\n  }\n\n  return <ShowWorkspaceChat />;\n}\n\nfunction ShowWorkspaceChat() {\n  const { slug",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceChat/index.jsx",
        "start": 10,
        "end": 22,
        "startLoc": {
          "line": 10,
          "column": 14,
          "position": 117
        },
        "endLoc": {
          "line": 22,
          "column": 5,
          "position": 232
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/index.jsx",
        "start": 36,
        "end": 48,
        "startLoc": {
          "line": 36,
          "column": 18,
          "position": 293
        },
        "endLoc": {
          "line": 48,
          "column": 2,
          "position": 408
        }
      }
    },
    {
      "format": "jsx",
      "lines": 13,
      "fragment": "();\n  const [workspace, setWorkspace] = useState(null);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    async function getWorkspace() {\n      if (!slug) return;\n      const _workspace = await Workspace.bySlug(slug);\n      if (!_workspace) {\n        setLoading(false);\n        return;\n      }\n      ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/pages/WorkspaceChat/index.jsx",
        "start": 22,
        "end": 34,
        "startLoc": {
          "line": 22,
          "column": 10,
          "position": 239
        },
        "endLoc": {
          "line": 34,
          "column": 7,
          "position": 353
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/WorkspaceSettings/index.jsx",
        "start": 50,
        "end": 63,
        "startLoc": {
          "line": 50,
          "column": 8,
          "position": 450
        },
        "endLoc": {
          "line": 63,
          "column": 1,
          "position": 564
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n        return true;\n      })\n      .catch((e) => {\n        console.error(e);\n        return false;\n      });\n  },\n};\n\nexport default AgentPlugins",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/experimental/agentPlugins.js",
        "start": 47,
        "end": 57,
        "startLoc": {
          "line": 47,
          "column": 2,
          "position": 441
        },
        "endLoc": {
          "line": 57,
          "column": 13,
          "position": 496
        }
      },
      "secondFile": {
        "name": "frontend/src/models/experimental/liveSync.js",
        "start": 49,
        "end": 59,
        "startLoc": {
          "line": 49,
          "column": 2,
          "position": 477
        },
        "endLoc": {
          "line": 59,
          "column": 17,
          "position": 532
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"转录模型首选项\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/zh/common.js",
        "start": 524,
        "end": 538,
        "startLoc": {
          "line": 524,
          "column": 10,
          "position": 3157
        },
        "endLoc": {
          "line": 538,
          "column": 10,
          "position": 3242
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 44,
      "fragment": ",\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"编辑帐户\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/zh/common.js",
        "start": 847,
        "end": 890,
        "startLoc": {
          "line": 847,
          "column": 15,
          "position": 5084
        },
        "endLoc": {
          "line": 890,
          "column": 7,
          "position": 5376
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 679,
        "end": 722,
        "startLoc": {
          "line": 679,
          "column": 5,
          "position": 4048
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  \"keyboard-shortcuts\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/zh/common.js",
        "start": 901,
        "end": 911,
        "startLoc": {
          "line": 901,
          "column": 7,
          "position": 5448
        },
        "endLoc": {
          "line": 911,
          "column": 21,
          "position": 5511
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 742,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 742,
          "column": 14,
          "position": 4474
        }
      }
    },
    {
      "format": "javascript",
      "lines": 20,
      "fragment": ",\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/zh/common.js",
        "start": 909,
        "end": 928,
        "startLoc": {
          "line": 909,
          "column": 5,
          "position": 5504
        },
        "endLoc": {
          "line": 928,
          "column": 1,
          "position": 5610
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 910,
        "end": 929,
        "startLoc": {
          "line": 910,
          "column": 2,
          "position": 5505
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Query mode refusal response\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 225,
        "end": 238,
        "startLoc": {
          "line": 225,
          "column": 227,
          "position": 1365
        },
        "endLoc": {
          "line": 238,
          "column": 30,
          "position": 1447
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Chuyển đổi giọng nói Model Preference\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 366,
        "end": 380,
        "startLoc": {
          "line": 366,
          "column": 15,
          "position": 2131
        },
        "endLoc": {
          "line": 380,
          "column": 40,
          "position": 2216
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ": null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 541,
        "end": 551,
        "startLoc": {
          "line": 541,
          "column": 13,
          "position": 3140
        },
        "endLoc": {
          "line": 551,
          "column": 8,
          "position": 3206
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 517,
        "end": 527,
        "startLoc": {
          "line": 517,
          "column": 20,
          "position": 2976
        },
        "endLoc": {
          "line": 527,
          "column": 7,
          "position": 3042
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 648,
        "end": 663,
        "startLoc": {
          "line": 648,
          "column": 5,
          "position": 3860
        },
        "endLoc": {
          "line": 663,
          "column": 5,
          "position": 3953
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 651,
        "end": 666,
        "startLoc": {
          "line": 651,
          "column": 9,
          "position": 3863
        },
        "endLoc": {
          "line": 666,
          "column": 14,
          "position": 3956
        }
      }
    },
    {
      "format": "javascript",
      "lines": 67,
      "fragment": ",\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 675,
        "end": 741,
        "startLoc": {
          "line": 675,
          "column": 5,
          "position": 4038
        },
        "endLoc": {
          "line": 741,
          "column": 5,
          "position": 4486
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 678,
        "end": 744,
        "startLoc": {
          "line": 678,
          "column": 14,
          "position": 4041
        },
        "endLoc": {
          "line": 744,
          "column": 9,
          "position": 4489
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 904,
        "end": 926,
        "startLoc": {
          "line": 904,
          "column": 5,
          "position": 5487
        },
        "endLoc": {
          "line": 926,
          "column": 1,
          "position": 5608
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 907,
        "end": 929,
        "startLoc": {
          "line": 907,
          "column": 14,
          "position": 5490
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"Çalışma Alanları Adı\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/tr/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 23,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Sorgu Modu Ret Yanıtı\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/tr/common.js",
        "start": 226,
        "end": 239,
        "startLoc": {
          "line": 226,
          "column": 190,
          "position": 1366
        },
        "endLoc": {
          "line": 239,
          "column": 24,
          "position": 1448
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Transkripsiyon Model Tercihi\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/tr/common.js",
        "start": 367,
        "end": 381,
        "startLoc": {
          "line": 367,
          "column": 18,
          "position": 2132
        },
        "endLoc": {
          "line": 381,
          "column": 31,
          "position": 2217
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/tr/common.js",
        "start": 501,
        "end": 927,
        "startLoc": {
          "line": 501,
          "column": 25,
          "position": 2866
        },
        "endLoc": {
          "line": 927,
          "column": 1,
          "position": 5609
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Ответ об отказе в режиме запроса\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ru/common.js",
        "start": 235,
        "end": 248,
        "startLoc": {
          "line": 235,
          "column": 244,
          "position": 1375
        },
        "endLoc": {
          "line": 248,
          "column": 35,
          "position": 1457
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Предпочтение модели транскрипции\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ru/common.js",
        "start": 376,
        "end": 390,
        "startLoc": {
          "line": 376,
          "column": 16,
          "position": 2141
        },
        "endLoc": {
          "line": 390,
          "column": 35,
          "position": 2226
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: \"Добро пожаловать в ваше новое рабочее пространство.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ru/common.js",
        "start": 693,
        "end": 708,
        "startLoc": {
          "line": 693,
          "column": 16,
          "position": 3905
        },
        "endLoc": {
          "line": 708,
          "column": 54,
          "position": 3998
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 651,
        "end": 666,
        "startLoc": {
          "line": 651,
          "column": 9,
          "position": 3863
        },
        "endLoc": {
          "line": 666,
          "column": 14,
          "position": 3956
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": ",\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"Редактировать учётную запись\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ru/common.js",
        "start": 720,
        "end": 764,
        "startLoc": {
          "line": 720,
          "column": 42,
          "position": 4083
        },
        "endLoc": {
          "line": 764,
          "column": 31,
          "position": 4382
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 678,
        "end": 722,
        "startLoc": {
          "line": 678,
          "column": 14,
          "position": 4041
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 198,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ru/common.js",
        "start": 775,
        "end": 972,
        "startLoc": {
          "line": 775,
          "column": 22,
          "position": 4454
        },
        "endLoc": {
          "line": 972,
          "column": 1,
          "position": 5654
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 929,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Preferência de Transcrição\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/pt_BR/common.js",
        "start": 546,
        "end": 560,
        "startLoc": {
          "line": 546,
          "column": 18,
          "position": 3179
        },
        "endLoc": {
          "line": 560,
          "column": 29,
          "position": 3264
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      ignores: \"Arquivos Ignorados\",\n      git_ignore:\n        \"Liste no formato .gitignore para ignorar arquivos específicos. Pressione enter após cada entrada.\",\n      task_explained:\n        \"Após conclusão, todos os arquivos estarão disponíveis para vínculo.\",\n      branch: \"Branch\",\n      branch_loading: \"-- carregando branches --\",\n      branch_explained: \"Branch para coletar arquivos.\",\n      token_information:\n        \"Sem preencher o <b>Token de Acesso</b>, este conector só poderá coletar arquivos <b>do nível superior</b> devido a limitações da API pública.\",\n      token_personal: \"Obtenha um Token de Acesso Pessoal gratuito aqui.\",\n    },\n    youtube",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/pt_BR/common.js",
        "start": 737,
        "end": 750,
        "startLoc": {
          "line": 737,
          "column": 32,
          "position": 4269
        },
        "endLoc": {
          "line": 750,
          "column": 8,
          "position": 4335
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/pt_BR/common.js",
        "start": 708,
        "end": 721,
        "startLoc": {
          "line": 708,
          "column": 21,
          "position": 4100
        },
        "endLoc": {
          "line": 721,
          "column": 7,
          "position": 4166
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"Editar conta\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/pt_BR/common.js",
        "start": 918,
        "end": 931,
        "startLoc": {
          "line": 918,
          "column": 9,
          "position": 5335
        },
        "endLoc": {
          "line": 931,
          "column": 15,
          "position": 5417
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 709,
        "end": 722,
        "startLoc": {
          "line": 709,
          "column": 5,
          "position": 4258
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  \"keyboard-shortcuts\": {\n    title: \"Atalhos de Teclado\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/pt_BR/common.js",
        "start": 942,
        "end": 953,
        "startLoc": {
          "line": 942,
          "column": 19,
          "position": 5489
        },
        "endLoc": {
          "line": 953,
          "column": 21,
          "position": 5561
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 912,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 912,
          "column": 5,
          "position": 5520
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"Werkruimten Naam\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/nl/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 19,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Afwijzingsreactie in Querymodus\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/nl/common.js",
        "start": 226,
        "end": 239,
        "startLoc": {
          "line": 226,
          "column": 246,
          "position": 1366
        },
        "endLoc": {
          "line": 239,
          "column": 34,
          "position": 1448
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n    provider: \"LLM Provider\",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Transcriptiemodel Voorkeur\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/nl/common.js",
        "start": 366,
        "end": 381,
        "startLoc": {
          "line": 366,
          "column": 194,
          "position": 2125
        },
        "endLoc": {
          "line": 381,
          "column": 29,
          "position": 2217
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 365,
        "end": 370,
        "startLoc": {
          "line": 365,
          "column": 188,
          "position": 2124
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/nl/common.js",
        "start": 501,
        "end": 927,
        "startLoc": {
          "line": 501,
          "column": 35,
          "position": 2866
        },
        "endLoc": {
          "line": 927,
          "column": 1,
          "position": 5609
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Transkripcijas modeļa preferences\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/lv/common.js",
        "start": 558,
        "end": 572,
        "startLoc": {
          "line": 558,
          "column": 28,
          "position": 3191
        },
        "endLoc": {
          "line": 572,
          "column": 36,
          "position": 3276
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": ",\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"Rediģēt kontu\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/lv/common.js",
        "start": 906,
        "end": 950,
        "startLoc": {
          "line": 906,
          "column": 43,
          "position": 5137
        },
        "endLoc": {
          "line": 950,
          "column": 16,
          "position": 5436
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 678,
        "end": 722,
        "startLoc": {
          "line": 678,
          "column": 14,
          "position": 4041
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 28,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/lv/common.js",
        "start": 961,
        "end": 988,
        "startLoc": {
          "line": 961,
          "column": 16,
          "position": 5508
        },
        "endLoc": {
          "line": 988,
          "column": 1,
          "position": 5670
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 929,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"워크스페이스 이름\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ko/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 12,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"쿼리 모드 거부 응답 메시지\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ko/common.js",
        "start": 222,
        "end": 235,
        "startLoc": {
          "line": 222,
          "column": 108,
          "position": 1362
        },
        "endLoc": {
          "line": 235,
          "column": 18,
          "position": 1444
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"텍스트 변환 모델 기본 설정\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ko/common.js",
        "start": 361,
        "end": 375,
        "startLoc": {
          "line": 361,
          "column": 10,
          "position": 2126
        },
        "endLoc": {
          "line": 375,
          "column": 18,
          "position": 2211
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ko/common.js",
        "start": 491,
        "end": 917,
        "startLoc": {
          "line": 491,
          "column": 15,
          "position": 2856
        },
        "endLoc": {
          "line": 917,
          "column": 1,
          "position": 5599
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"クエリモード拒否応答\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 233,
        "end": 246,
        "startLoc": {
          "line": 233,
          "column": 61,
          "position": 1373
        },
        "endLoc": {
          "line": 246,
          "column": 13,
          "position": 1455
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"文字起こしモデルの設定\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 373,
        "end": 387,
        "startLoc": {
          "line": 373,
          "column": 12,
          "position": 2138
        },
        "endLoc": {
          "line": 387,
          "column": 14,
          "position": 2223
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n      ignores: \"無視するファイル\",\n      git_ignore:\n        \".gitignore形式で収集時に無視したいファイルをリストしてください。エンターキーで各エントリを保存します。\",\n      task_explained:\n        \"完了後、すべてのファイルがドキュメントピッカーからワークスペースに埋め込めるようになります。\",\n      branch: \"収集したいブランチ\",\n      branch_loading: \"-- 利用可能なブランチを読み込み中 --\",\n      branch_explained: \"収集したいブランチを指定します。\",\n      token_information:\n        \"<b>GitLabアクセストークン</b>を入力しない場合、GitLabの公開APIのレート制限により<b>トップレベル</b>のファイルのみ収集可能です。\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 553,
        "end": 563,
        "startLoc": {
          "line": 553,
          "column": 20,
          "position": 3155
        },
        "endLoc": {
          "line": 563,
          "column": 81,
          "position": 3206
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 523,
        "end": 533,
        "startLoc": {
          "line": 523,
          "column": 17,
          "position": 2985
        },
        "endLoc": {
          "line": 533,
          "column": 81,
          "position": 3036
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: \"新しいワークスペースへようこそ。\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 684,
        "end": 699,
        "startLoc": {
          "line": 684,
          "column": 9,
          "position": 3896
        },
        "endLoc": {
          "line": 699,
          "column": 19,
          "position": 3989
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 651,
        "end": 666,
        "startLoc": {
          "line": 651,
          "column": 9,
          "position": 3863
        },
        "endLoc": {
          "line": 666,
          "column": 14,
          "position": 3956
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": ",\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"アカウントを編集\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 711,
        "end": 755,
        "startLoc": {
          "line": 711,
          "column": 24,
          "position": 4074
        },
        "endLoc": {
          "line": 755,
          "column": 11,
          "position": 4373
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 678,
        "end": 722,
        "startLoc": {
          "line": 678,
          "column": 14,
          "position": 4041
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 102,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError:\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 766,
        "end": 867,
        "startLoc": {
          "line": 766,
          "column": 7,
          "position": 4445
        },
        "endLoc": {
          "line": 867,
          "column": 1,
          "position": 5059
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 829,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 829,
          "column": 2,
          "position": 5022
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ja/common.js",
        "start": 944,
        "end": 966,
        "startLoc": {
          "line": 944,
          "column": 13,
          "position": 5527
        },
        "endLoc": {
          "line": 966,
          "column": 1,
          "position": 5648
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 907,
        "end": 929,
        "startLoc": {
          "line": 907,
          "column": 14,
          "position": 5490
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"Nome delle aree di lavoro\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/it/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 28,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Risposta al rifiuto nella modalità di query\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/it/common.js",
        "start": 227,
        "end": 240,
        "startLoc": {
          "line": 227,
          "column": 245,
          "position": 1367
        },
        "endLoc": {
          "line": 240,
          "column": 46,
          "position": 1449
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Preferenza del modello di trascrizione\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/it/common.js",
        "start": 370,
        "end": 384,
        "startLoc": {
          "line": 370,
          "column": 15,
          "position": 2135
        },
        "endLoc": {
          "line": 384,
          "column": 41,
          "position": 2220
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/it/common.js",
        "start": 504,
        "end": 930,
        "startLoc": {
          "line": 504,
          "column": 31,
          "position": 2869
        },
        "endLoc": {
          "line": 930,
          "column": 1,
          "position": 5612
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"שם סביבת העבודה\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/he/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 18,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"תגובת סירוב במצב שאילתה\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/he/common.js",
        "start": 222,
        "end": 235,
        "startLoc": {
          "line": 222,
          "column": 167,
          "position": 1362
        },
        "endLoc": {
          "line": 235,
          "column": 26,
          "position": 1444
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"העדפת דגם תמלול\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/he/common.js",
        "start": 361,
        "end": 375,
        "startLoc": {
          "line": 361,
          "column": 10,
          "position": 2126
        },
        "endLoc": {
          "line": 375,
          "column": 18,
          "position": 2211
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/he/common.js",
        "start": 491,
        "end": 917,
        "startLoc": {
          "line": 491,
          "column": 26,
          "position": 2856
        },
        "endLoc": {
          "line": 917,
          "column": 1,
          "position": 5599
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"Nom des espaces de travail\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fr/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 29,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Réponse de refus en mode requête\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fr/common.js",
        "start": 229,
        "end": 242,
        "startLoc": {
          "line": 229,
          "column": 248,
          "position": 1369
        },
        "endLoc": {
          "line": 242,
          "column": 35,
          "position": 1451
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Préférence du modèle de transcription\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fr/common.js",
        "start": 372,
        "end": 386,
        "startLoc": {
          "line": 372,
          "column": 18,
          "position": 2137
        },
        "endLoc": {
          "line": 386,
          "column": 40,
          "position": 2222
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fr/common.js",
        "start": 506,
        "end": 932,
        "startLoc": {
          "line": 506,
          "column": 29,
          "position": 2871
        },
        "endLoc": {
          "line": 932,
          "column": 1,
          "position": 5614
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"نام فضای کار\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fa/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 15,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"پاسخ رد در حالت پرس‌وجو\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fa/common.js",
        "start": 224,
        "end": 237,
        "startLoc": {
          "line": 224,
          "column": 201,
          "position": 1364
        },
        "endLoc": {
          "line": 237,
          "column": 26,
          "position": 1446
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"ترجیحات مدل رونویسی\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fa/common.js",
        "start": 365,
        "end": 379,
        "startLoc": {
          "line": 365,
          "column": 24,
          "position": 2130
        },
        "endLoc": {
          "line": 379,
          "column": 22,
          "position": 2215
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/fa/common.js",
        "start": 498,
        "end": 924,
        "startLoc": {
          "line": 498,
          "column": 33,
          "position": 2863
        },
        "endLoc": {
          "line": 924,
          "column": 1,
          "position": 5606
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"Nombre de espacios de trabajo\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/es/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 32,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Respuesta de rechazo en modo consulta\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/es/common.js",
        "start": 228,
        "end": 241,
        "startLoc": {
          "line": 228,
          "column": 251,
          "position": 1368
        },
        "endLoc": {
          "line": 241,
          "column": 40,
          "position": 1450
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Preferencia de modelo de transcripción\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/es/common.js",
        "start": 371,
        "end": 385,
        "startLoc": {
          "line": 371,
          "column": 19,
          "position": 2136
        },
        "endLoc": {
          "line": 385,
          "column": 41,
          "position": 2221
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 331,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError:\n      \"Por favor, crea un espacio de trabajo antes de iniciar un chat.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/es/common.js",
        "start": 505,
        "end": 835,
        "startLoc": {
          "line": 505,
          "column": 32,
          "position": 2870
        },
        "endLoc": {
          "line": 835,
          "column": 66,
          "position": 5029
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 867,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 867,
          "column": 31,
          "position": 5061
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/es/common.js",
        "start": 914,
        "end": 936,
        "startLoc": {
          "line": 914,
          "column": 21,
          "position": 5497
        },
        "endLoc": {
          "line": 936,
          "column": 1,
          "position": 5618
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 907,
        "end": 929,
        "startLoc": {
          "line": 907,
          "column": 14,
          "position": 5490
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 52,
      "fragment": "// Anything with \"null\" requires a translation. Contribute to translation via a PR!\nconst TRANSLATIONS = {\n  onboarding: {\n    survey: {\n      email: null,\n      useCase: null,\n      useCaseWork: null,\n      useCasePersonal: null,\n      useCaseOther: null,\n      comment: null,\n      commentPlaceholder: null,\n      skip: null,\n      thankYou: null,\n      title: null,\n      description: null,\n    },\n    home: {\n      title: null,\n      getStarted: null,\n    },\n    llm: {\n      title: null,\n      description: null,\n    },\n    userSetup: {\n      title: null,\n      description: null,\n      howManyUsers: null,\n      justMe: null,\n      myTeam: null,\n      instancePassword: null,\n      setPassword: null,\n      passwordReq: null,\n      passwordWarn: null,\n      adminUsername: null,\n      adminUsernameReq: null,\n      adminPassword: null,\n      adminPasswordReq: null,\n      teamHint: null,\n    },\n    data: {\n      title: null,\n      description: null,\n      settingsHint: null,\n    },\n    workspace: {\n      title: null,\n      description: null,\n    },\n  },\n  common: {\n    \"workspaces-name\": \"Name der Arbeitsbereiche\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 27,
          "position": 328
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 1,
        "end": 52,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 328
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Abfragemodus-Ablehnungsantwort\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 226,
        "end": 239,
        "startLoc": {
          "line": 226,
          "column": 277,
          "position": 1366
        },
        "endLoc": {
          "line": 239,
          "column": 33,
          "position": 1448
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Transkriptionsmodell-Präferenz\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 368,
        "end": 382,
        "startLoc": {
          "line": 368,
          "column": 15,
          "position": 2133
        },
        "endLoc": {
          "line": 382,
          "column": 33,
          "position": 2218
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: \"Willkommen zu deinem Arbeitsbereich.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 690,
        "end": 705,
        "startLoc": {
          "line": 690,
          "column": 38,
          "position": 3902
        },
        "endLoc": {
          "line": 705,
          "column": 39,
          "position": 3995
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 651,
        "end": 666,
        "startLoc": {
          "line": 651,
          "column": 9,
          "position": 3863
        },
        "endLoc": {
          "line": 666,
          "column": 14,
          "position": 3956
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": ",\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"Account bearbeiten\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 717,
        "end": 761,
        "startLoc": {
          "line": 717,
          "column": 45,
          "position": 4080
        },
        "endLoc": {
          "line": 761,
          "column": 21,
          "position": 4379
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 678,
        "end": 722,
        "startLoc": {
          "line": 678,
          "column": 14,
          "position": 4041
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 102,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError:\n      \"Bitte erstellen Sie einen Arbeitsbereich, bevor Sie einen Chat beginnen.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 772,
        "end": 873,
        "startLoc": {
          "line": 772,
          "column": 21,
          "position": 4451
        },
        "endLoc": {
          "line": 873,
          "column": 75,
          "position": 5067
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 867,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 867,
          "column": 31,
          "position": 5061
        }
      }
    },
    {
      "format": "javascript",
      "lines": 23,
      "fragment": ",\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/de/common.js",
        "start": 954,
        "end": 976,
        "startLoc": {
          "line": 954,
          "column": 32,
          "position": 5537
        },
        "endLoc": {
          "line": 976,
          "column": 1,
          "position": 5658
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 907,
        "end": 929,
        "startLoc": {
          "line": 907,
          "column": 14,
          "position": 5490
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"Afvisningssvar for forespørgsels-tilstand\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/da/common.js",
        "start": 234,
        "end": 247,
        "startLoc": {
          "line": 234,
          "column": 226,
          "position": 1374
        },
        "endLoc": {
          "line": 247,
          "column": 44,
          "position": 1456
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"Foretrukken transskriptionsmodel\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/da/common.js",
        "start": 375,
        "end": 389,
        "startLoc": {
          "line": 375,
          "column": 14,
          "position": 2140
        },
        "endLoc": {
          "line": 389,
          "column": 35,
          "position": 2225
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: \"Velkommen til dit nye arbejdsområde.\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/da/common.js",
        "start": 692,
        "end": 707,
        "startLoc": {
          "line": 692,
          "column": 25,
          "position": 3904
        },
        "endLoc": {
          "line": 707,
          "column": 39,
          "position": 3997
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 651,
        "end": 666,
        "startLoc": {
          "line": 651,
          "column": 9,
          "position": 3863
        },
        "endLoc": {
          "line": 666,
          "column": 14,
          "position": 3956
        }
      }
    },
    {
      "format": "javascript",
      "lines": 45,
      "fragment": ",\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: \"Rediger konto\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/da/common.js",
        "start": 719,
        "end": 763,
        "startLoc": {
          "line": 719,
          "column": 39,
          "position": 4082
        },
        "endLoc": {
          "line": 763,
          "column": 16,
          "position": 4381
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 678,
        "end": 722,
        "startLoc": {
          "line": 678,
          "column": 14,
          "position": 4041
        },
        "endLoc": {
          "line": 722,
          "column": 5,
          "position": 4340
        }
      }
    },
    {
      "format": "javascript",
      "lines": 198,
      "fragment": ",\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/da/common.js",
        "start": 774,
        "end": 971,
        "startLoc": {
          "line": 774,
          "column": 20,
          "position": 4453
        },
        "endLoc": {
          "line": 971,
          "column": 1,
          "position": 5653
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 732,
        "end": 929,
        "startLoc": {
          "line": 732,
          "column": 5,
          "position": 4411
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ",\n      history: {\n        title: null,\n        clearAll: null,\n        noHistory: null,\n        restore: null,\n        delete: null,\n        deleteConfirm: null,\n        clearAllConfirm: null,\n        expand: null,\n      },\n    },\n    refusal: {\n      title: \"الرد على رفض وضعية الاستعلام\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ar/common.js",
        "start": 233,
        "end": 246,
        "startLoc": {
          "line": 233,
          "column": 190,
          "position": 1373
        },
        "endLoc": {
          "line": 246,
          "column": 31,
          "position": 1455
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 223,
        "end": 236,
        "startLoc": {
          "line": 223,
          "column": 68,
          "position": 1363
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 1445
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n    providers: {\n      azure_openai: {\n        azure_service_endpoint: null,\n        api_key: null,\n        chat_deployment_name: null,\n        chat_model_token_limit: null,\n        model_type: null,\n        default: null,\n        reasoning: null,\n      },\n    },\n  },\n  transcription: {\n    title: \"تفضيل نموذج النسخ\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ar/common.js",
        "start": 373,
        "end": 387,
        "startLoc": {
          "line": 373,
          "column": 27,
          "position": 2138
        },
        "endLoc": {
          "line": 387,
          "column": 20,
          "position": 2223
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/zh_TW/common.js",
        "start": 356,
        "end": 370,
        "startLoc": {
          "line": 356,
          "column": 10,
          "position": 2121
        },
        "endLoc": {
          "line": 370,
          "column": 13,
          "position": 2206
        }
      }
    },
    {
      "format": "javascript",
      "lines": 427,
      "fragment": ",\n  },\n  connectors: {\n    \"search-placeholder\": null,\n    \"no-connectors\": null,\n    github: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    gitlab: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      token: null,\n      optional: null,\n      token_explained: null,\n      token_description: null,\n      token_explained_start: null,\n      token_explained_link1: null,\n      token_explained_middle: null,\n      token_explained_link2: null,\n      token_explained_end: null,\n      fetch_issues: null,\n      ignores: null,\n      git_ignore: null,\n      task_explained: null,\n      branch: null,\n      branch_loading: null,\n      branch_explained: null,\n      token_information: null,\n      token_personal: null,\n    },\n    youtube: {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained_start: null,\n      URL_explained_link: null,\n      URL_explained_end: null,\n      task_explained: null,\n      language: null,\n      language_explained: null,\n      loading_languages: null,\n    },\n    \"website-depth\": {\n      name: null,\n      description: null,\n      URL: null,\n      URL_explained: null,\n      depth: null,\n      depth_explained: null,\n      max_pages: null,\n      max_pages_explained: null,\n      task_explained: null,\n    },\n    confluence: {\n      name: null,\n      description: null,\n      deployment_type: null,\n      deployment_type_explained: null,\n      base_url: null,\n      base_url_explained: null,\n      space_key: null,\n      space_key_explained: null,\n      username: null,\n      username_explained: null,\n      auth_type: null,\n      auth_type_explained: null,\n      auth_type_username: null,\n      auth_type_personal: null,\n      token: null,\n      token_explained_start: null,\n      token_explained_link: null,\n      token_desc: null,\n      pat_token: null,\n      pat_token_explained: null,\n      task_explained: null,\n    },\n    manage: {\n      documents: null,\n      \"data-connectors\": null,\n      \"desktop-only\": null,\n      dismiss: null,\n      editing: null,\n    },\n    directory: {\n      \"my-documents\": null,\n      \"new-folder\": null,\n      \"search-document\": null,\n      \"no-documents\": null,\n      \"move-workspace\": null,\n      name: null,\n      \"delete-confirmation\": null,\n      \"removing-message\": null,\n      \"move-success\": null,\n      date: null,\n      type: null,\n      no_docs: null,\n      select_all: null,\n      deselect_all: null,\n      remove_selected: null,\n      costs: null,\n      save_embed: null,\n    },\n    upload: {\n      \"processor-offline\": null,\n      \"processor-offline-desc\": null,\n      \"click-upload\": null,\n      \"file-types\": null,\n      \"or-submit-link\": null,\n      \"placeholder-link\": null,\n      fetching: null,\n      \"fetch-website\": null,\n      \"privacy-notice\": null,\n    },\n    pinning: {\n      what_pinning: null,\n      pin_explained_block1: null,\n      pin_explained_block2: null,\n      pin_explained_block3: null,\n      accept: null,\n    },\n    watching: {\n      what_watching: null,\n      watch_explained_block1: null,\n      watch_explained_block2: null,\n      watch_explained_block3_start: null,\n      watch_explained_block3_link: null,\n      watch_explained_block3_end: null,\n      accept: null,\n    },\n    obsidian: {\n      name: null,\n      description: null,\n      vault_location: null,\n      vault_description: null,\n      selected_files: null,\n      importing: null,\n      import_vault: null,\n      processing_time: null,\n      vault_warning: null,\n    },\n  },\n  chat_window: {\n    welcome: null,\n    get_started: null,\n    get_started_default: null,\n    upload: null,\n    or: null,\n    send_chat: null,\n    send_message: null,\n    attach_file: null,\n    slash: null,\n    agents: null,\n    text_size: null,\n    microphone: null,\n    send: null,\n    attachments_processing: null,\n    tts_speak_message: null,\n    copy: null,\n    regenerate: null,\n    regenerate_response: null,\n    good_response: null,\n    more_actions: null,\n    hide_citations: null,\n    show_citations: null,\n    pause_tts_speech_message: null,\n    fork: null,\n    delete: null,\n    save_submit: null,\n    cancel: null,\n    edit_prompt: null,\n    edit_response: null,\n    at_agent: null,\n    default_agent_description: null,\n    custom_agents_coming_soon: null,\n    slash_reset: null,\n    preset_reset_description: null,\n    add_new_preset: null,\n    command: null,\n    your_command: null,\n    placeholder_prompt: null,\n    description: null,\n    placeholder_description: null,\n    save: null,\n    small: null,\n    normal: null,\n    large: null,\n    workspace_llm_manager: {\n      search: null,\n      loading_workspace_settings: null,\n      available_models: null,\n      available_models_description: null,\n      save: null,\n      saving: null,\n      missing_credentials: null,\n      missing_credentials_description: null,\n    },\n  },\n  profile_settings: {\n    edit_account: null,\n    profile_picture: null,\n    remove_profile_picture: null,\n    username: null,\n    username_description: null,\n    new_password: null,\n    passwort_description: null,\n    cancel: null,\n    update_account: null,\n    theme: null,\n    language: null,\n    failed_upload: null,\n    upload_success: null,\n    failed_remove: null,\n    profile_updated: null,\n    failed_update_user: null,\n    account: null,\n    support: null,\n    signout: null,\n  },\n  customization: {\n    interface: {\n      title: null,\n      description: null,\n    },\n    branding: {\n      title: null,\n      description: null,\n    },\n    chat: {\n      title: null,\n      description: null,\n      auto_submit: {\n        title: null,\n        description: null,\n      },\n      auto_speak: {\n        title: null,\n        description: null,\n      },\n      spellcheck: {\n        title: null,\n        description: null,\n      },\n    },\n    items: {\n      theme: {\n        title: null,\n        description: null,\n      },\n      \"show-scrollbar\": {\n        title: null,\n        description: null,\n      },\n      \"support-email\": {\n        title: null,\n        description: null,\n      },\n      \"app-name\": {\n        title: null,\n        description: null,\n      },\n      \"chat-message-alignment\": {\n        title: null,\n        description: null,\n      },\n      \"display-language\": {\n        title: null,\n        description: null,\n      },\n      logo: {\n        title: null,\n        description: null,\n        add: null,\n        recommended: null,\n        remove: null,\n        replace: null,\n      },\n      \"welcome-messages\": {\n        title: null,\n        description: null,\n        new: null,\n        system: null,\n        user: null,\n        message: null,\n        assistant: null,\n        \"double-click\": null,\n        save: null,\n      },\n      \"browser-appearance\": {\n        title: null,\n        description: null,\n        tab: {\n          title: null,\n          description: null,\n        },\n        favicon: {\n          title: null,\n          description: null,\n        },\n      },\n      \"sidebar-footer\": {\n        title: null,\n        description: null,\n        icon: null,\n        link: null,\n      },\n    },\n  },\n  \"main-page\": {\n    noWorkspaceError: null,\n    checklist: {\n      title: null,\n      tasksLeft: null,\n      completed: null,\n      dismiss: null,\n      tasks: {\n        create_workspace: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        send_chat: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        embed_document: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        setup_system_prompt: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        define_slash_command: {\n          title: null,\n          description: null,\n          action: null,\n        },\n        visit_community: {\n          title: null,\n          description: null,\n          action: null,\n        },\n      },\n    },\n    quickLinks: {\n      title: null,\n      sendChat: null,\n      embedDocument: null,\n      createWorkspace: null,\n    },\n    exploreMore: {\n      title: null,\n      features: {\n        customAgents: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        slashCommands: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n        systemPrompts: {\n          title: null,\n          description: null,\n          primaryAction: null,\n          secondaryAction: null,\n        },\n      },\n    },\n    announcements: {\n      title: null,\n    },\n    resources: {\n      title: null,\n      links: {\n        docs: null,\n        star: null,\n      },\n      keyboardShortcuts: null,\n    },\n  },\n  \"keyboard-shortcuts\": {\n    title: null,\n    shortcuts: {\n      settings: null,\n      workspaceSettings: null,\n      home: null,\n      workspaces: null,\n      apiKeys: null,\n      llmPreferences: null,\n      chatSettings: null,\n      help: null,\n      showLLMSelector: null,\n    },\n  },\n};\n\nexport default TRANSLATIONS;\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/ar/common.js",
        "start": 506,
        "end": 932,
        "startLoc": {
          "line": 506,
          "column": 34,
          "position": 2871
        },
        "endLoc": {
          "line": 932,
          "column": 1,
          "position": 5614
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/vn/common.js",
        "start": 500,
        "end": 929,
        "startLoc": {
          "line": 500,
          "column": 30,
          "position": 2865
        },
        "endLoc": {
          "line": 929,
          "column": 1,
          "position": 5611
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": "\" />\n                        <p className=\"text-sidebar text-sm font-semibold\">\n                          {t(\"new-workspace.title\")}\n                        </p>\n                      </button>\n                    )}\n                  </div>\n                  <ActiveWorkspaces />\n                </div>\n              </div>\n              <div className=\"z-99 absolute bottom-0 left-0 right-0 pt-2 pb-6 rounded-br-[26px] bg-theme-bg-sidebar bg-opacity-80 backdrop-filter backdrop-blur-md",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Sidebar/index.jsx",
        "start": 186,
        "end": 196,
        "startLoc": {
          "line": 186,
          "column": 8,
          "position": 1419
        },
        "endLoc": {
          "line": 196,
          "column": 133,
          "position": 1484
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Sidebar/index.jsx",
        "start": 68,
        "end": 78,
        "startLoc": {
          "line": 68,
          "column": 5,
          "position": 586
        },
        "endLoc": {
          "line": 78,
          "column": 131,
          "position": 651
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\">\n                <Footer />\n              </div>\n            </div>\n          </div>\n        </div>\n        {showingNewWsModal && <NewWorkspaceModal hideModal={hideNewWsModal} />}\n      </div>\n    </>\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Sidebar/index.jsx",
        "start": 196,
        "end": 207,
        "startLoc": {
          "line": 196,
          "column": 133,
          "position": 1485
        },
        "endLoc": {
          "line": 207,
          "column": 1,
          "position": 1547
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Sidebar/index.jsx",
        "start": 78,
        "end": 89,
        "startLoc": {
          "line": 78,
          "column": 131,
          "position": 652
        },
        "endLoc": {
          "line": 89,
          "column": 1,
          "position": 714
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n    function handleBg() {\n      if (showSidebar) {\n        setTimeout(() => {\n          setShowBgOverlay(true);\n        }, 300);\n      } else {\n        setShowBgOverlay(false);\n      }\n    }\n    handleBg();\n  }, [showSidebar]);\n\n  if",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/SettingsSidebar/index.jsx",
        "start": 34,
        "end": 47,
        "startLoc": {
          "line": 34,
          "column": 2,
          "position": 308
        },
        "endLoc": {
          "line": 47,
          "column": 3,
          "position": 390
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Sidebar/index.jsx",
        "start": 105,
        "end": 118,
        "startLoc": {
          "line": 105,
          "column": 25,
          "position": 875
        },
        "endLoc": {
          "line": 118,
          "column": 7,
          "position": 957
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ");\n  const { t } = useTranslation();\n\n  useEffect(() => {\n    const fetchSupportEmail = async () => {\n      const supportEmail = await System.fetchSupportEmail();\n      setSupportEmail(\n        supportEmail?.email\n          ? `mailto:${supportEmail.email}`\n          : paths.mailToMintplex()\n      );\n    };\n    fetchSupportEmail();\n  }, []);\n\n  return",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/SettingsSidebar/index.jsx",
        "start": 186,
        "end": 201,
        "startLoc": {
          "line": 186,
          "column": 2,
          "position": 1309
        },
        "endLoc": {
          "line": 201,
          "column": 7,
          "position": 1426
        }
      },
      "secondFile": {
        "name": "frontend/src/pages/GeneralSettings/Settings/components/SupportEmail/index.jsx",
        "start": 13,
        "end": 57,
        "startLoc": {
          "line": 13,
          "column": 3,
          "position": 163
        },
        "endLoc": {
          "line": 57,
          "column": 3,
          "position": 536
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": " }) {\n  const { isAuthd, shouldRedirectToOnboarding, multiUserMode } =\n    useIsAuthenticated();\n  if (isAuthd === null) return <FullScreenLoader />;\n\n  if (shouldRedirectToOnboarding) {\n    return <Navigate to={paths.onboarding.home()} />;\n  }\n\n  const user = userFromStorage();\n  return isAuthd && (user?.role !==",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/PrivateRoute/index.jsx",
        "start": 116,
        "end": 126,
        "startLoc": {
          "line": 116,
          "column": 10,
          "position": 861
        },
        "endLoc": {
          "line": 126,
          "column": 4,
          "position": 969
        }
      },
      "secondFile": {
        "name": "frontend/src/components/PrivateRoute/index.jsx",
        "start": 87,
        "end": 97,
        "startLoc": {
          "line": 87,
          "column": 6,
          "position": 637
        },
        "endLoc": {
          "line": 97,
          "column": 4,
          "position": 745
        }
      }
    },
    {
      "format": "jsx",
      "lines": 11,
      "fragment": " ? (\n    <KeyboardShortcutWrapper>\n      <UserMenu>\n        <Component />\n      </UserMenu>\n    </KeyboardShortcutWrapper>\n  ) : (\n    <Navigate to={paths.login(true)} />\n  );\n}\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/PrivateRoute/index.jsx",
        "start": 145,
        "end": 155,
        "startLoc": {
          "line": 145,
          "column": 8,
          "position": 1127
        },
        "endLoc": {
          "line": 155,
          "column": 1,
          "position": 1187
        }
      },
      "secondFile": {
        "name": "frontend/src/components/PrivateRoute/index.jsx",
        "start": 126,
        "end": 136,
        "startLoc": {
          "line": 126,
          "column": 2,
          "position": 978
        },
        "endLoc": {
          "line": 136,
          "column": 1,
          "position": 1037
        }
      }
    },
    {
      "format": "jsx",
      "lines": 16,
      "fragment": ")}\n            </h3>\n          </div>\n          <button\n            onClick={hideModal}\n            type=\"button\"\n            className=\"absolute top-4 right-4 transition-all duration-300 bg-transparent rounded-lg text-sm p-1 inline-flex items-center hover:bg-theme-modal-border hover:border-theme-modal-border hover:border-opacity-50 border-transparent border\"\n          >\n            <X size={24} weight=\"bold\" className=\"text-white\" />\n          </button>\n        </div>\n        <div\n          className=\"h-full w-full overflow-y-auto\"\n          style={{ maxHeight: \"calc(100vh - 200px)\" }}\n        >\n          <form ref",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Modals/NewWorkspace.jsx",
        "start": 32,
        "end": 47,
        "startLoc": {
          "line": 32,
          "column": 22,
          "position": 383
        },
        "endLoc": {
          "line": 47,
          "column": 4,
          "position": 482
        }
      },
      "secondFile": {
        "name": "frontend/src/components/WorkspaceChat/ChatContainer/PromptInput/SlashCommands/SlashPresets/AddPresetModal.jsx",
        "start": 34,
        "end": 69,
        "startLoc": {
          "line": 34,
          "column": 29,
          "position": 365
        },
        "endLoc": {
          "line": 69,
          "column": 9,
          "position": 579
        }
      }
    },
    {
      "format": "jsx",
      "lines": 14,
      "fragment": "\n                weight=\"fill\"\n                className=\"h-5 w-5\"\n                color=\"var(--theme-sidebar-footer-icon-fill)\"\n              />\n            </Link>\n          </div>\n          <div className=\"flex w-fit\">\n            <Link\n              to={paths.discord()}\n              target=\"_blank\"\n              rel=\"noreferrer\"\n              className=\"transition-all duration-300 p-2 rounded-full bg-theme-sidebar-footer-icon hover:bg-theme-sidebar-footer-icon-hover\"\n              aria-label=\"Join our Discord server",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/Footer/index.jsx",
        "start": 79,
        "end": 92,
        "startLoc": {
          "line": 79,
          "column": 9,
          "position": 557
        },
        "endLoc": {
          "line": 92,
          "column": 24,
          "position": 634
        }
      },
      "secondFile": {
        "name": "frontend/src/components/Footer/index.jsx",
        "start": 62,
        "end": 75,
        "startLoc": {
          "line": 62,
          "column": 11,
          "position": 460
        },
        "endLoc": {
          "line": 75,
          "column": 5,
          "position": 537
        }
      }
    },
    {
      "format": "jsx",
      "lines": 12,
      "fragment": "\n      <label className=\"transition-all duration-300 inline-flex flex-col h-full w-60 cursor-pointer items-start justify-between rounded-2xl bg-preference-gradient border-2 border-transparent shadow-md px-5 py-4 text-white hover:bg-selected-preference-gradient hover:border-white/60 peer-checked:border-white peer-checked:border-opacity-90 peer-checked:bg-selected-preference-gradient\">\n        <div className=\"flex items-center\">\n          <img src={image} alt={name} className=\"h-10 w-10 rounded\" />\n          <div className=\"ml-4 text-sm font-semibold\">{name}</div>\n        </div>\n        <div className=\"mt-2 text-xs font-base text-white tracking-wide\">\n          {description}\n        </div>\n        <a\n          href={link}\n          target",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/components/DataConnectorOption/index.jsx",
        "start": 6,
        "end": 17,
        "startLoc": {
          "line": 6,
          "column": 2,
          "position": 80
        },
        "endLoc": {
          "line": 17,
          "column": 7,
          "position": 180
        }
      },
      "secondFile": {
        "name": "frontend/src/components/LLMSelection/LLMProviderOption/index.jsx",
        "start": 19,
        "end": 30,
        "startLoc": {
          "line": 19,
          "column": 3,
          "position": 112
        },
        "endLoc": {
          "line": 30,
          "column": 10,
          "position": 216
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ": {\n    translationKey: \"help\",\n    action: () => {\n      window.dispatchEvent(\n        new CustomEvent(KEYBOARD_SHORTCUTS_HELP_EVENT, {\n          detail: { show: true },\n        })\n      );\n    },\n  },\n  \"⌘ + Shift + L\"",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/utils/keyboardShortcuts.js",
        "start": 55,
        "end": 65,
        "startLoc": {
          "line": 55,
          "column": 3,
          "position": 466
        },
        "endLoc": {
          "line": 65,
          "column": 16,
          "position": 535
        }
      },
      "secondFile": {
        "name": "frontend/src/utils/keyboardShortcuts.js",
        "start": 45,
        "end": 55,
        "startLoc": {
          "line": 45,
          "column": 16,
          "position": 396
        },
        "endLoc": {
          "line": 55,
          "column": 3,
          "position": 465
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n        headers: baseHeaders(),\n      }\n    )\n      .then((res) => res.json())\n      .catch((e) => {\n        return { workspace: null, message: e.message };\n      });\n\n    return { workspace, message };\n  },\n  chatHistory",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 45,
        "end": 56,
        "startLoc": {
          "line": 45,
          "column": 67,
          "position": 484
        },
        "endLoc": {
          "line": 56,
          "column": 12,
          "position": 574
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspaceThread.js",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 2,
          "position": 125
        },
        "endLoc": {
          "line": 24,
          "column": 7,
          "position": 246
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ")\n      .then((res) => {\n        if (res.ok) return true;\n        throw new Error(\"Failed to delete chats.\");\n      })\n      .catch((e) => {\n        console.log(e);\n        return false;\n      });\n  },\n  deleteEditedChats",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 85,
        "end": 95,
        "startLoc": {
          "line": 85,
          "column": 2,
          "position": 900
        },
        "endLoc": {
          "line": 95,
          "column": 18,
          "position": 980
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspaceThread.js",
        "start": 179,
        "end": 189,
        "startLoc": {
          "line": 179,
          "column": 5,
          "position": 1550
        },
        "endLoc": {
          "line": 189,
          "column": 20,
          "position": 1630
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": ") {\n    const ctrl = new AbortController();\n\n    // Listen for the ABORT_STREAM_EVENT key to be emitted by the client\n    // to early abort the streaming response. On abort we send a special `stopGeneration`\n    // event to be handled which resets the UI for us to be able to send another message.\n    // The backend response abort handling is done in each LLM's handleStreamResponse.\n    window.addEventListener(ABORT_STREAM_EVENT, () => {\n      ctrl.abort();\n      handleChat({ id: v4(), type: \"stopGeneration\" });\n    });\n\n    await fetchEventSource(`",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 136,
        "end": 148,
        "startLoc": {
          "line": 136,
          "column": 2,
          "position": 1307
        },
        "endLoc": {
          "line": 148,
          "column": 2,
          "position": 1394
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspaceThread.js",
        "start": 95,
        "end": 108,
        "startLoc": {
          "line": 95,
          "column": 3,
          "position": 902
        },
        "endLoc": {
          "line": 108,
          "column": 1,
          "position": 989
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "\n          );\n        }\n        return true;\n      })\n      .catch((e) => {\n        console.error(e);\n        return false;\n      });\n  },\n  ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 308,
        "end": 318,
        "startLoc": {
          "line": 308,
          "column": 41,
          "position": 2943
        },
        "endLoc": {
          "line": 318,
          "column": 3,
          "position": 2997
        }
      },
      "secondFile": {
        "name": "frontend/src/models/experimental/liveSync.js",
        "start": 47,
        "end": 57,
        "startLoc": {
          "line": 47,
          "column": 43,
          "position": 470
        },
        "endLoc": {
          "line": 57,
          "column": 2,
          "position": 524
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ")\n      .then((res) => {\n        if (res.ok) return true;\n        throw new Error(\"Failed to update chat.\");\n      })\n      .catch((e) => {\n        console.log(e);\n        return false;\n      });\n  },\n  ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 385,
        "end": 395,
        "startLoc": {
          "line": 385,
          "column": 2,
          "position": 3761
        },
        "endLoc": {
          "line": 395,
          "column": 3,
          "position": 3840
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspaceThread.js",
        "start": 202,
        "end": 212,
        "startLoc": {
          "line": 202,
          "column": 5,
          "position": 1733
        },
        "endLoc": {
          "line": 212,
          "column": 2,
          "position": 1812
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": " }),\n    })\n      .then((res) => {\n        if (res.ok) return true;\n        throw new Error(\"Failed to delete chats.\");\n      })\n      .catch((e) => {\n        console.log(e);\n        return false;\n      });\n  },\n  deleteChat",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 399,
        "end": 410,
        "startLoc": {
          "line": 399,
          "column": 11,
          "position": 3908
        },
        "endLoc": {
          "line": 410,
          "column": 11,
          "position": 3995
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 84,
        "end": 189,
        "startLoc": {
          "line": 84,
          "column": 8,
          "position": 893
        },
        "endLoc": {
          "line": 189,
          "column": 20,
          "position": 1630
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ");\n        }\n        return data;\n      })\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 112,
        "end": 122,
        "startLoc": {
          "line": 112,
          "column": 28,
          "position": 1285
        },
        "endLoc": {
          "line": 122,
          "column": 1,
          "position": 1352
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 94,
        "end": 299,
        "startLoc": {
          "line": 94,
          "column": 28,
          "position": 1084
        },
        "endLoc": {
          "line": 299,
          "column": 3,
          "position": 2826
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify(data),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n  setupMultiUser",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 150,
        "end": 161,
        "startLoc": {
          "line": 150,
          "column": 25,
          "position": 1675
        },
        "endLoc": {
          "line": 161,
          "column": 15,
          "position": 1780
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 138,
        "end": 299,
        "startLoc": {
          "line": 138,
          "column": 20,
          "position": 1545
        },
        "endLoc": {
          "line": 299,
          "column": 18,
          "position": 2827
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify(data),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n  isMultiUserMode",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 162,
        "end": 173,
        "startLoc": {
          "line": 162,
          "column": 27,
          "position": 1805
        },
        "endLoc": {
          "line": 173,
          "column": 16,
          "position": 1910
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 138,
        "end": 299,
        "startLoc": {
          "line": 138,
          "column": 20,
          "position": 1545
        },
        "endLoc": {
          "line": 299,
          "column": 18,
          "position": 2827
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n      body: JSON.stringify({ name }),\n    })\n      .then((res) => res.ok)\n      .catch((e) => {\n        console.error(e);\n        return false;\n      });\n  },\n  uploadPfp",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 210,
        "end": 221,
        "startLoc": {
          "line": 210,
          "column": 23,
          "position": 2292
        },
        "endLoc": {
          "line": 221,
          "column": 10,
          "position": 2384
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 186,
        "end": 197,
        "startLoc": {
          "line": 186,
          "column": 25,
          "position": 2053
        },
        "endLoc": {
          "line": 197,
          "column": 16,
          "position": 2145
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ", {\n      method: \"POST\",\n      body: formData,\n      headers: baseHeaders(),\n    })\n      .then((res) => {\n        if (!res.ok) throw new Error(\"Error uploading pfp.\");\n        return { success: true, error: null };\n      })\n      .catch((e) => {\n        console.log(e);\n        return { success: false, error: e.message };\n      });\n  },\n  uploadLogo",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 222,
        "end": 236,
        "startLoc": {
          "line": 222,
          "column": 20,
          "position": 2409
        },
        "endLoc": {
          "line": 236,
          "column": 11,
          "position": 2547
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 334,
        "end": 380,
        "startLoc": {
          "line": 334,
          "column": 13,
          "position": 3208
        },
        "endLoc": {
          "line": 380,
          "column": 20,
          "position": 3681
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n      {\n        method: \"GET\",\n        cache: \"no-cache\",\n        headers: baseHeaders(),\n      }\n    )\n      .then((res) => res.json())\n      .catch((e) => {\n        console.log(e);\n        return { email",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 293,
        "end": 303,
        "startLoc": {
          "line": 293,
          "column": 23,
          "position": 3260
        },
        "endLoc": {
          "line": 303,
          "column": 6,
          "position": 3337
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 261,
        "end": 271,
        "startLoc": {
          "line": 261,
          "column": 21,
          "position": 2876
        },
        "endLoc": {
          "line": 271,
          "column": 11,
          "position": 2953
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n      {\n        method: \"GET\",\n        cache: \"no-cache\",\n        headers: baseHeaders(),\n      }\n    )\n      .then((res) => res.json())\n      .catch((e) => {\n        console.log(e);\n        return { customAppName",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 324,
        "end": 334,
        "startLoc": {
          "line": 324,
          "column": 25,
          "position": 3625
        },
        "endLoc": {
          "line": 334,
          "column": 14,
          "position": 3702
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 261,
        "end": 271,
        "startLoc": {
          "line": 261,
          "column": 21,
          "position": 2876
        },
        "endLoc": {
          "line": 271,
          "column": 11,
          "position": 2953
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": "}`, {\n      method: \"GET\",\n      cache: \"no-cache\",\n      headers: baseHeaders(),\n    })\n      .then((res) => {\n        if (res.ok && res.status !== 204) return res.blob();\n        throw new Error(\"Failed to fetch pfp.\");\n      })\n      .then((blob) => (blob ? URL.createObjectURL(blob) : null))\n      .catch((e) => {\n        // console.log(e);\n        return null;\n      });\n  },\n  ",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 374,
        "end": 389,
        "startLoc": {
          "line": 374,
          "column": 3,
          "position": 4134
        },
        "endLoc": {
          "line": 389,
          "column": 3,
          "position": 4280
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 319,
        "end": 366,
        "startLoc": {
          "line": 319,
          "column": 7,
          "position": 3032
        },
        "endLoc": {
          "line": 366,
          "column": 1,
          "position": 3520
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ", {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => {\n        if (res.ok) return { success: true, error: null };\n        throw new Error(\"Failed to remove pfp.\");\n      })\n      .catch((e) => {\n        console.log(e);\n        return { success: false, error: e.message };\n      });\n  },\n\n  isDefaultLogo",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 390,
        "end": 404,
        "startLoc": {
          "line": 390,
          "column": 20,
          "position": 4306
        },
        "endLoc": {
          "line": 404,
          "column": 14,
          "position": 4437
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 367,
        "end": 349,
        "startLoc": {
          "line": 367,
          "column": 13,
          "position": 3551
        },
        "endLoc": {
          "line": 349,
          "column": 9,
          "position": 3347
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify({ offset }),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return [];\n      });\n  },\n  clearEventLogs",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 555,
        "end": 566,
        "startLoc": {
          "line": 555,
          "column": 20,
          "position": 5916
        },
        "endLoc": {
          "line": 566,
          "column": 15,
          "position": 6011
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 543,
        "end": 554,
        "startLoc": {
          "line": 543,
          "column": 25,
          "position": 5792
        },
        "endLoc": {
          "line": 554,
          "column": 10,
          "position": 5887
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ", {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n  exportChats",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 578,
        "end": 588,
        "startLoc": {
          "line": 578,
          "column": 2,
          "position": 6157
        },
        "endLoc": {
          "line": 588,
          "column": 12,
          "position": 6250
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 567,
        "end": 299,
        "startLoc": {
          "line": 567,
          "column": 20,
          "position": 6035
        },
        "endLoc": {
          "line": 299,
          "column": 18,
          "position": 2827
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify(data),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n  dataConnectors",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 606,
        "end": 617,
        "startLoc": {
          "line": 606,
          "column": 14,
          "position": 6470
        },
        "endLoc": {
          "line": 617,
          "column": 15,
          "position": 6575
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 138,
        "end": 299,
        "startLoc": {
          "line": 138,
          "column": 20,
          "position": 1545
        },
        "endLoc": {
          "line": 299,
          "column": 18,
          "position": 2827
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "\n          );\n        return data;\n      })\n      .then((res) => ({ preset: res.preset, error: null }))\n      .catch((e) => {\n        console.error(e);\n        return { preset: null, error: e.message };\n      });\n  },\n\n  deleteSlashCommandPreset",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/system.js",
        "start": 666,
        "end": 677,
        "startLoc": {
          "line": 666,
          "column": 41,
          "position": 7070
        },
        "endLoc": {
          "line": 677,
          "column": 25,
          "position": 7168
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 645,
        "end": 656,
        "startLoc": {
          "line": 645,
          "column": 39,
          "position": 6848
        },
        "endLoc": {
          "line": 656,
          "column": 25,
          "position": 6946
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify({ name }),\n    })\n      .then((res) => res.json())\n      .catch((e) => ({\n        success: false,\n        error: e.message,\n      }));\n  },\n}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/mcpServers.js",
        "start": 63,
        "end": 74,
        "startLoc": {
          "line": 63,
          "column": 21,
          "position": 424
        },
        "endLoc": {
          "line": 74,
          "column": 2,
          "position": 520
        }
      },
      "secondFile": {
        "name": "frontend/src/models/mcpServers.js",
        "start": 45,
        "end": 57,
        "startLoc": {
          "line": 45,
          "column": 21,
          "position": 298
        },
        "endLoc": {
          "line": 57,
          "column": 1,
          "position": 394
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify(data),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n  deleteEmbed",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/embed.js",
        "start": 30,
        "end": 41,
        "startLoc": {
          "line": 30,
          "column": 2,
          "position": 322
        },
        "endLoc": {
          "line": 41,
          "column": 12,
          "position": 427
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 138,
        "end": 299,
        "startLoc": {
          "line": 138,
          "column": 20,
          "position": 1545
        },
        "endLoc": {
          "line": 299,
          "column": 18,
          "position": 2827
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify({ offset }),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return [];\n      });\n  },\n  deleteChat",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/embed.js",
        "start": 56,
        "end": 67,
        "startLoc": {
          "line": 56,
          "column": 14,
          "position": 617
        },
        "endLoc": {
          "line": 67,
          "column": 11,
          "position": 712
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 543,
        "end": 554,
        "startLoc": {
          "line": 543,
          "column": 25,
          "position": 5792
        },
        "endLoc": {
          "line": 554,
          "column": 10,
          "position": 5887
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "${chatId}`, {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n};\n\nexport default Embed",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/embed.js",
        "start": 68,
        "end": 80,
        "startLoc": {
          "line": 68,
          "column": 14,
          "position": 737
        },
        "endLoc": {
          "line": 80,
          "column": 6,
          "position": 841
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 578,
        "end": 27,
        "startLoc": {
          "line": 578,
          "column": 25,
          "position": 6153
        },
        "endLoc": {
          "line": 27,
          "column": 7,
          "position": 276
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify(data),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n};\n\nexport default Document",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/document.js",
        "start": 25,
        "end": 38,
        "startLoc": {
          "line": 25,
          "column": 22,
          "position": 283
        },
        "endLoc": {
          "line": 38,
          "column": 9,
          "position": 395
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 138,
        "end": 27,
        "startLoc": {
          "line": 138,
          "column": 20,
          "position": 1545
        },
        "endLoc": {
          "line": 27,
          "column": 7,
          "position": 276
        }
      }
    },
    {
      "format": "javascript",
      "lines": 22,
      "fragment": ", {\n        method: \"POST\",\n        headers: baseHeaders(),\n        cache: \"force-cache\",\n        body: JSON.stringify({ repo, accessToken }),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return res.data;\n        })\n        .then((data) => {\n          return { branches: data?.branches || [], error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          showToast(e.message, \"error\");\n          return { branches: [], error: e.message };\n        });\n    },\n    collect: async function ({\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 47,
        "end": 68,
        "startLoc": {
          "line": 47,
          "column": 22,
          "position": 566
        },
        "endLoc": {
          "line": 68,
          "column": 1,
          "position": 796
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 8,
        "end": 28,
        "startLoc": {
          "line": 8,
          "column": 22,
          "position": 83
        },
        "endLoc": {
          "line": 28,
          "column": 2,
          "position": 313
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": "}),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return { data: res.data, error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          return { data: null, error: e.message };\n        });\n    },\n  },\n  youtube",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 85,
        "end": 98,
        "startLoc": {
          "line": 85,
          "column": 9,
          "position": 907
        },
        "endLoc": {
          "line": 98,
          "column": 8,
          "position": 1047
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 12,
        "end": 45,
        "startLoc": {
          "line": 12,
          "column": 2,
          "position": 125
        },
        "endLoc": {
          "line": 45,
          "column": 7,
          "position": 528
        }
      }
    },
    {
      "format": "javascript",
      "lines": 14,
      "fragment": " }),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return { data: res.data, error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          return { data: null, error: e.message };\n        });\n    },\n  },\n  websiteDepth",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 103,
        "end": 116,
        "startLoc": {
          "line": 103,
          "column": 4,
          "position": 1113
        },
        "endLoc": {
          "line": 116,
          "column": 13,
          "position": 1254
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 12,
        "end": 45,
        "startLoc": {
          "line": 12,
          "column": 12,
          "position": 124
        },
        "endLoc": {
          "line": 45,
          "column": 7,
          "position": 528
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": " }),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return { data: res.data, error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          return { data: null, error: e.message };\n        });\n    },\n  },\n\n",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 121,
        "end": 135,
        "startLoc": {
          "line": 121,
          "column": 9,
          "position": 1332
        },
        "endLoc": {
          "line": 135,
          "column": 1,
          "position": 1472
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 12,
        "end": 45,
        "startLoc": {
          "line": 12,
          "column": 12,
          "position": 124
        },
        "endLoc": {
          "line": 45,
          "column": 3,
          "position": 527
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ",\n        }),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return { data: res.data, error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          return { data: null, error: e.message };\n        });\n    },\n  },\n\n  drupalwiki",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 153,
        "end": 168,
        "startLoc": {
          "line": 153,
          "column": 20,
          "position": 1584
        },
        "endLoc": {
          "line": 168,
          "column": 11,
          "position": 1728
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 84,
        "end": 135,
        "startLoc": {
          "line": 84,
          "column": 11,
          "position": 904
        },
        "endLoc": {
          "line": 135,
          "column": 11,
          "position": 1474
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n        }),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return { data: res.data, error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          return { data: null, error: e.message };\n        });\n    },\n  },\n  obsidian",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 176,
        "end": 190,
        "startLoc": {
          "line": 176,
          "column": 12,
          "position": 1809
        },
        "endLoc": {
          "line": 190,
          "column": 9,
          "position": 1952
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 84,
        "end": 45,
        "startLoc": {
          "line": 84,
          "column": 11,
          "position": 904
        },
        "endLoc": {
          "line": 45,
          "column": 7,
          "position": 528
        }
      }
    },
    {
      "format": "javascript",
      "lines": 15,
      "fragment": ",\n        }),\n      })\n        .then((res) => res.json())\n        .then((res) => {\n          if (!res.success) throw new Error(res.reason);\n          return { data: res.data, error: null };\n        })\n        .catch((e) => {\n          console.error(e);\n          return { data: null, error: e.message };\n        });\n    },\n  },\n}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 196,
        "end": 210,
        "startLoc": {
          "line": 196,
          "column": 6,
          "position": 2019
        },
        "endLoc": {
          "line": 210,
          "column": 2,
          "position": 2161
        }
      },
      "secondFile": {
        "name": "frontend/src/models/dataConnector.js",
        "start": 84,
        "end": 45,
        "startLoc": {
          "line": 84,
          "column": 11,
          "position": 904
        },
        "endLoc": {
          "line": 45,
          "column": 3,
          "position": 527
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ", {\n      method: \"GET\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return {\n          success: false,\n          error: e.message,\n          createdByMe",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/communityHub.js",
        "start": 141,
        "end": 151,
        "startLoc": {
          "line": 141,
          "column": 22,
          "position": 1035
        },
        "endLoc": {
          "line": 151,
          "column": 12,
          "position": 1119
        }
      },
      "secondFile": {
        "name": "frontend/src/models/mcpServers.js",
        "start": 10,
        "end": 131,
        "startLoc": {
          "line": 10,
          "column": 27,
          "position": 63
        },
        "endLoc": {
          "line": 131,
          "column": 7,
          "position": 987
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": ",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n\n  revoke",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/browserExtensionApiKey.js",
        "start": 19,
        "end": 29,
        "startLoc": {
          "line": 19,
          "column": 7,
          "position": 194
        },
        "endLoc": {
          "line": 29,
          "column": 7,
          "position": 279
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 412,
        "end": 122,
        "startLoc": {
          "line": 412,
          "column": 6,
          "position": 4033
        },
        "endLoc": {
          "line": 122,
          "column": 29,
          "position": 1354
        }
      }
    },
    {
      "format": "javascript",
      "lines": 13,
      "fragment": "}`, {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n};\n\nexport default BrowserExtensionApiKey",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/browserExtensionApiKey.js",
        "start": 30,
        "end": 42,
        "startLoc": {
          "line": 30,
          "column": 3,
          "position": 306
        },
        "endLoc": {
          "line": 42,
          "column": 23,
          "position": 408
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 578,
        "end": 27,
        "startLoc": {
          "line": 578,
          "column": 7,
          "position": 6155
        },
        "endLoc": {
          "line": 27,
          "column": 7,
          "position": 276
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ");\n        return res;\n      })\n      .then((res) => res.json())\n      .catch((e) => ({\n        success: false,\n        error: e.message,\n        flow: null,\n      }));\n  },\n\n  /**\n   * Execute a specific flow\n   * @param {string} uuid - The UUID of the flow to run\n   * @param {object} variables - Optional variables to pass to the flow\n   * @returns {Promise<{success: boolean, error: string | null, results: object | null}>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/agentFlows.js",
        "start": 61,
        "end": 77,
        "startLoc": {
          "line": 61,
          "column": 21,
          "position": 456
        },
        "endLoc": {
          "line": 77,
          "column": 6,
          "position": 534
        }
      },
      "secondFile": {
        "name": "frontend/src/models/agentFlows.js",
        "start": 22,
        "end": 36,
        "startLoc": {
          "line": 22,
          "column": 22,
          "position": 170
        },
        "endLoc": {
          "line": 36,
          "column": 6,
          "position": 248
        }
      }
    },
    {
      "format": "javascript",
      "lines": 16,
      "fragment": ");\n        return res;\n      })\n      .then((res) => res.json())\n      .catch((e) => ({\n        success: false,\n        error: e.message,\n      }));\n  },\n\n  /**\n   * Toggle a flow's active status\n   * @param {string} uuid - The UUID of the flow to toggle\n   * @param {boolean} active - The new active status\n   * @returns {Promise<{success: boolean, error: string | null}>}\n   */",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/agentFlows.js",
        "start": 110,
        "end": 125,
        "startLoc": {
          "line": 110,
          "column": 24,
          "position": 689
        },
        "endLoc": {
          "line": 125,
          "column": 6,
          "position": 760
        }
      },
      "secondFile": {
        "name": "frontend/src/models/agentFlows.js",
        "start": 22,
        "end": 61,
        "startLoc": {
          "line": 22,
          "column": 22,
          "position": 170
        },
        "endLoc": {
          "line": 61,
          "column": 6,
          "position": 396
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "}`, {\n      method: \"POST\",\n      headers: baseHeaders(),\n      body: JSON.stringify(data),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n  deleteUser",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 31,
        "end": 42,
        "startLoc": {
          "line": 31,
          "column": 7,
          "position": 323
        },
        "endLoc": {
          "line": 42,
          "column": 11,
          "position": 430
        }
      },
      "secondFile": {
        "name": "frontend/src/models/embed.js",
        "start": 30,
        "end": 299,
        "startLoc": {
          "line": 30,
          "column": 8,
          "position": 320
        },
        "endLoc": {
          "line": 299,
          "column": 18,
          "position": 2827
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "}`, {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n\n  // Invitations",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 43,
        "end": 54,
        "startLoc": {
          "line": 43,
          "column": 7,
          "position": 457
        },
        "endLoc": {
          "line": 54,
          "column": 15,
          "position": 553
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 578,
        "end": 122,
        "startLoc": {
          "line": 578,
          "column": 7,
          "position": 6155
        },
        "endLoc": {
          "line": 122,
          "column": 29,
          "position": 1354
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "}`, {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n\n  // Workspaces Mgmt",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 83,
        "end": 94,
        "startLoc": {
          "line": 83,
          "column": 9,
          "position": 863
        },
        "endLoc": {
          "line": 94,
          "column": 19,
          "position": 959
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 578,
        "end": 122,
        "startLoc": {
          "line": 578,
          "column": 7,
          "position": 6155
        },
        "endLoc": {
          "line": 122,
          "column": 29,
          "position": 1354
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": ", {\n      method: \"GET\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .then((res) => res?.users || [])\n      .catch((e) => {\n        console.error(e);\n        return [];\n      });\n  },\n  newWorkspace",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 108,
        "end": 119,
        "startLoc": {
          "line": 108,
          "column": 8,
          "position": 1115
        },
        "endLoc": {
          "line": 119,
          "column": 13,
          "position": 1215
        }
      },
      "secondFile": {
        "name": "frontend/src/models/workspace.js",
        "start": 57,
        "end": 18,
        "startLoc": {
          "line": 57,
          "column": 8,
          "position": 607
        },
        "endLoc": {
          "line": 18,
          "column": 8,
          "position": 163
        }
      }
    },
    {
      "format": "javascript",
      "lines": 12,
      "fragment": "}`, {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.json())\n      .catch((e) => {\n        console.error(e);\n        return { success: false, error: e.message };\n      });\n  },\n\n  // System Preferences",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 147,
        "end": 158,
        "startLoc": {
          "line": 147,
          "column": 12,
          "position": 1527
        },
        "endLoc": {
          "line": 158,
          "column": 22,
          "position": 1623
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 578,
        "end": 122,
        "startLoc": {
          "line": 578,
          "column": 7,
          "position": 6155
        },
        "endLoc": {
          "line": 122,
          "column": 29,
          "position": 1354
        }
      }
    },
    {
      "format": "javascript",
      "lines": 17,
      "fragment": ", {\n      method: \"POST\",\n      headers: baseHeaders(),\n    })\n      .then((res) => {\n        if (!res.ok) {\n          throw new Error(res.statusText || \"Error generating api key.\");\n        }\n        return res.json();\n      })\n      .catch((e) => {\n        console.error(e);\n        return { apiKey: null, error: e.message };\n      });\n  },\n  deleteApiKey: async function (apiKeyId = \"\") {\n    return fetch(`${API_BASE}/admin/delete-api-key/",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 223,
        "end": 239,
        "startLoc": {
          "line": 223,
          "column": 25,
          "position": 2178
        },
        "endLoc": {
          "line": 239,
          "column": 23,
          "position": 2338
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 482,
        "end": 498,
        "startLoc": {
          "line": 482,
          "column": 26,
          "position": 5244
        },
        "endLoc": {
          "line": 498,
          "column": 17,
          "position": 5404
        }
      }
    },
    {
      "format": "javascript",
      "lines": 11,
      "fragment": "${apiKeyId}`, {\n      method: \"DELETE\",\n      headers: baseHeaders(),\n    })\n      .then((res) => res.ok)\n      .catch((e) => {\n        console.error(e);\n        return false;\n      });\n  },\n}",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/models/admin.js",
        "start": 239,
        "end": 249,
        "startLoc": {
          "line": 239,
          "column": 23,
          "position": 2339
        },
        "endLoc": {
          "line": 249,
          "column": 2,
          "position": 2418
        }
      },
      "secondFile": {
        "name": "frontend/src/models/system.js",
        "start": 498,
        "end": 197,
        "startLoc": {
          "line": 498,
          "column": 17,
          "position": 5405
        },
        "endLoc": {
          "line": 197,
          "column": 3,
          "position": 2144
        }
      }
    },
    {
      "format": "javascript",
      "lines": 74,
      "fragment": ";\nconst languageNames = new Intl.DisplayNames(Object.keys(resources), {\n  type: \"language\",\n});\n\nfunction langDisplayName(lang) {\n  return languageNames.of(lang);\n}\n\nfunction compareStructures(lang, a, b, subdir = null) {\n  //if a and b aren't the same type, they can't be equal\n  if (typeof a !== typeof b && a !== null && b !== null) {\n    console.log(\"Invalid type comparison\", [\n      {\n        lang,\n        a: typeof a,\n        b: typeof b,\n        values: {\n          a,\n          b,\n        },\n        ...(!!subdir ? { subdir } : {}),\n      },\n    ]);\n    return false;\n  }\n\n  // Need the truthy guard because\n  // typeof null === 'object'\n  if (a && typeof a === \"object\") {\n    var keysA = Object.keys(a).sort(),\n      keysB = Object.keys(b).sort();\n\n    //if a and b are objects with different no of keys, unequal\n    if (keysA.length !== keysB.length) {\n      console.log(\"Keys are missing!\", {\n        [lang]: keysA,\n        en: keysB,\n        ...(!!subdir ? { subdir } : {}),\n        diff: {\n          added: keysB.filter((key) => !keysA.includes(key)),\n          removed: keysA.filter((key) => !keysB.includes(key)),\n        },\n      });\n      return false;\n    }\n\n    //if keys aren't all the same, unequal\n    if (\n      !keysA.every(function (k, i) {\n        return k === keysB[i];\n      })\n    ) {\n      console.log(\"Keys are not equal!\", {\n        [lang]: keysA,\n        en: keysB,\n        ...(!!subdir ? { subdir } : {}),\n      });\n      return false;\n    }\n\n    //recurse on the values for each key\n    return keysA.every(function (key) {\n      //if we made it here, they have identical keys\n      return compareStructures(lang, a[key], b[key], key);\n    });\n\n    //for primitives just ignore since we don't check values.\n  } else {\n    return true;\n  }\n}\n\nfunction",
      "tokens": 0,
      "firstFile": {
        "name": "frontend/src/locales/normalizeEn.mjs",
        "start": 5,
        "end": 78,
        "startLoc": {
          "line": 5,
          "column": 5,
          "position": 26
        },
        "endLoc": {
          "line": 78,
          "column": 9,
          "position": 623
        }
      },
      "secondFile": {
        "name": "frontend/src/locales/verifyTranslations.mjs",
        "start": 1,
        "end": 74,
        "startLoc": {
          "line": 1,
          "column": 17,
          "position": 11
        },
        "endLoc": {
          "line": 74,
          "column": 6,
          "position": 608
        }
      }
    }
  ],
  "filename": "/home/runner/work/anything-llm/anything-llm/node_modules/@jscpd/html-reporter/dist/templates/main.pug"
}